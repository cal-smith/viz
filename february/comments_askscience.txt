I'm surprised that no one has posted about this already, but aside from detailed hardware information available (http://en.wikipedia.org/wiki/Apollo_Guidance_Computer), NASA has gone as far as releasing the actual source code used on the Apollo 11 mission (http://googlecode.blogspot.com/2009/07/apollo-11-missions-40th-anniversary-one.html).

Sadly though, for any conspiracy minded person who denies the reality of the moon landings, no amount of information will convince them to give up their deeply held beliefs. So you can pass this information along, but it will most likely be denied as fake.  To add to that, you can actually run the software through a complete mission with the [Virtual AGC](http://www.ibiblio.org/apollo/) software, which simulates the guidance computer hardware and various bits and pieces connected to it. 

The page you mentioned links to it, but I thought it deserved a specific mention. The source code is definitely worth a read as well, the comments are easy enough to read even if the code itself is not. I know plenty of people who have been talked out of conspiracies with evidence.  Some people are just easily convinced and no one has ever shown them the other side of the argument. I remember having discussions about how the lighting was staged with studio equipment and so told the guy "did it ever occur to you maybe they brought the studio equipment to the moon?" [deleted] I would've thought that they used quaternions but all I see is ugly euler angle code...

Is this just because the math operations would get too heavy with quaternions? Because the technique to use quaternions to simulate 3D rotations was developed and published in 1985.

https://www.cs.cmu.edu/~kiranb/animation/p245-shoemake.pdf The 1985 is the use in animated computer graphics, interpolating rotations and that sort of stuff. As you might imagine movies and TV commercials would not be pushing mathematical state of the art... The relationship between quaternions and rotation was established back in 1800s, by multiple people independently (Gauss, Rodrigues, and Hamilton, at least).

Quaternions use 4 variables when Euler angles use 3; also, I imagine the direction data would come in form of azimuth/elevation (pointing a scope at a star or something of that kind). A few years ago I used their software as the basis for a small calculator that worked out the strength of a cylinder when made out of different metals and holding different pressures of gas. Took a bit of modernisation, and it was complicated, but it actually worked. &gt;Problem is, I can't find a lot of specific de-bunking arguments discussing the computational power of the machines involved. 

I think you're both misunderstanding what computers are actually used for. Computers aren't magical devices that just make things like landing on the moon easy. Space travel isn't a matter of ordering a computer "take me to the moon." The calculations required to compute a trajectory are really computationally very simple, and it's always been (and always will be) a matter of having intelligent humans know when and why to apply something.

[This image of NASA engineers popped up recently.](http://i.imgur.com/B3X48s9.jpg) The equations behind them are all from orbital mechanics, the basics of which were well understood for a long time. And relevant to your question, they are all trivial to calculate even with the computational power available in 1969 - you really don't need much more than a pocket calculator.

&gt;Have you been to Florida to see those pieces of junk?

I have, and they are goddam beautiful pieces of art. The fabrication of the rocket engines is simply astonishing.


Computers haven't exactly been the game-changing technology in large scale engineering projects that the unfamiliar might think they are. Large projects (like say the JSF) are more expensive than they ever were in the past, despite all of our computational resources. Look at other engineering tech of the era - the SR71 was designed in the early 60s using cigarettes and slide rules and is still the fastest air-breathing manned craft ever made.

edit: good lord people, 2 golds? I feel like I didn't even really answer the question!

Edit 2: [a good read on actual details of how the trajectories were calculated, for those with a little background in orbital mechanics.](http://www.embedded.com/electronics-blogs/programmer-s-toolbox/4008319/2/Calculating-trajectories-for-Apollo-program) choice quote:

&gt; Despite their low performance, on paper, we got a lot of work out of those old machines. For those used to waiting 15 seconds for a Windows spreadsheet to even load, it's difficult to imagine how much work a 1-MHz computer can do when it's running full tilt in machine language, not encumbered by bloated software, interpreted languages, and a GUI interface. I'm old enough to remember, and look back on those days wistfully.


And you kerbal fanatics need to realize it's not as realistic as you think ;) I want to add a note about the PC's of that time that most people miss.  Back in the early days of computer technology everything was custom hardware.  Most of the pieces were designed to calculate a specific task whereas modern technology relies on generic processors that use software.  So even though that old hardware may not be as powerful as today's equipment it was extremely efficient and quick at calculating what it was designed to do.  If he doesn't understand point him towards a ICU 101 course where they can show him how fast electrical signaling can crunch numbers in a simple circuit.  

I want to add one more thing that your boss may not understand. The circumference of the word was [calculated in 240BC](http://www.windows2universe.org/citizen_science/myw/w2u_eratosthenes_calc_earth_size.html).  This is a perfect example of how powerful human ingenuity really is.  We can do a lot without the need for computers even thousands of years ago. Adding onto that, he could open up Philosophi Naturalis Principia Mathematica and show his boss a diagram drawn in 1687 by Issac Newton of what an Earth orbiting object (a satellite) would look like.  All of the calculations used to get us to and from the Moon are based on that book. [deleted] Lets not forget that the AGC is one of the most publicly documented systems out there.  (today anyway)

http://en.wikipedia.org/wiki/Apollo_Guidance_Computer

The lady that designed the operating system changed the way software was made today.  Wikipedia can put it much better than I can. I met Frank O'Brien a few years ago. He wrote the book "The Apollo Guidance Computer: Architecture and Operation". When he told me that it had what amounts to a hypervisor on it I was floored. Could you please explain what a hypervisor is? It sounds really cool. Adding to what everyone said, the hypervisor in relation to the AGC was used to spin up several instances of the AGC software, which was a way to get redundancy.  If one AGC instance became unresponsive or crashed there where others waiting to take it's place, all within a single computer. So it was to make up for a lack of error correction technology?

Also, I had no clue that they would have had something like that. To me it is amazing that they worked out how to keep each instance separate yet have the thing working as quickly as they needed to on such weak hardware. &gt;A hypervisor or virtual machine monitor (VMM) is a piece of computer software, firmware or hardware that creates and runs virtual machines. A computer on which a hypervisor is running one or more virtual machines is defined as a host machine. Each virtual machine is called a guest machine.   
    
    
http://en.wikipedia.org/wiki/Hypervisor Change of plans: let the Wookie win.

Seriously though, this isn't a winnable argument. The bosses belief are not and never will be based in fact. He is expressing a personal bias (that probably doesn't even have anything to do with the moon landing), and because that bias isn't rationally based, any attempt to change it, no matter how logical, will be met with progressively more strident opposition.

Seriously; let the Wookie win. How about the fact that Kepler figured out the planet's orbits are slightly elliptical.... 400 years ago.... using some observations taken by Brahe. The eccentricity of the orbits is so small, it's astonishing he figured it out so long ago. I went and looked up the Philosophi Naturalis Principia Mathematica viewer from the Cambridge Digital Libary, dated 1687. 

I don't know latin, but I think this is where he starts talking about the moon:
http://cudl.lib.cam.ac.uk/view/PR-ADV-B-00039-00001/852

4 page diagram of a comet orbiting the sun:
http://cudl.lib.cam.ac.uk/view/PR-ADV-B-00039-00001/981

I need to go find an english copy to read, now cause I feel like I should know the stuff this guy figured out 328 years ago. To piggy back even more, the computers they did have were pretty amazing, even if they aren't what we would really thing of as computers today, I'm thinking specifically of ww2 mechanical fire control computers. Almost 25 years earlier, it was astounding what they could do.

http://youtu.be/s1i-dnAH9Y4 Here's a great site for these mechanical computers (warning: you can spend many hours here!)

http://www.glennsmuseum.com/bombsights/bombsights.html

Spacecraft navigation and control is in some ways a much simpler problem.  With no air resistance to complicate matters, it's just classic Newtonian physics.  There was also a small army of engineers back on earth checking and double checking every command and telemetry point. [deleted] I get absolutely awed sometimes. All of that, then add the fact that they did these things and more /underwater/ as well. Submerging and firing torpedoes with a basically a few gears and a grease pen. And basically blind.

I'm not underestimating the space program, but if a quarter century earlier we were doing amazing things... is it so hard to believe a concerted effort could launch a rocket?

I find moon landing deniers sad. It doesn't make me angry, just sad. We have done amazing things in human history and some people can't feel that pride, instead jumping right into, "nuh uh, it was a conspiracy". Watching Buzz Aldrin feed a denier some knuckles was both fulfilling and incredibly sad. Another interesting factoid, it was only about 20 years from the first all welded ship (before they were riveted) to the first nuclear powered submarine. &gt; I find moon landing deniers sad. It doesn't make me angry, just sad. We have done amazing things in human history and some people can't feel that pride, instead jumping right into, "nuh uh, it was a conspiracy".

The sheer arrogance is what irks me the most.  I've had the displeasure of talking to several moon landing deniers and to a person the argument has boiled down to "the science, technology and human ingenuity behind the moon landings doesn't fit my intuitive understanding of the way things work, therefore they must not have happened." It's infuriating. Imo, those are the most magnificent mechanical devices ever created.  Only the Analytical Engine would come close. I think it was Henry Cavendish that used equipment consisting of two spherical masses to calculate the mass of the Earth by the effect of gravity exerted by the two masses on each other. This was in the 1790s. 

Two chunks of lead and some 1790s measurement equipment to get within 1% of the currently accepted value of the mass of the Earth isn't too bad. How about how they solved for circumference of the earth. A few sticks, shadows and the distance between the sticks. 

Edit: [276BC](http://en.wikipedia.org/wiki/Eratosthenes) I wish I could impress the awe I feel when I read about this stuff on other people. It'd make the world a better place if everyone could appreciate how their phone worked.   Stumbled on this: http://history.nasa.gov/afj/compessay.htm  

Every detail you never knew you wanted to know about the Apollo guidance computers right down to the opcodes and the voltages of the power rails.  72 KB of ROM, 4 KB of RAM, all ferrite-core. [Photo of AGC ferrite core memory](https://upload.wikimedia.org/wikipedia/commons/f/f1/Apollo_1024_bit_core_memory_module.jpg).  Crazy impressive. [deleted] [deleted] What does icu stand for?

Edit: I'm interested to know and I was unable to find it through a few Google searches. &gt; icu 

Given this context, the acronym most likely stands for **Instrument Control Units**. Check [this article](http://www3.imperial.ac.uk/spat/research/areas/space_magnetometer_laboratory/spaceinstrumentationresearch/spaceinstrumentdesign/instrumentcontrolunits) for more info. [deleted] &gt; I want to add a note about the PC's of that time that most people miss. Back in the early days of computer technology everything was custom hardware.

Not to mention the programs for Apollo were stored hand wired as *individual physical bits* of memory.

http://authors.library.caltech.edu/5456/1/hrst.mit.edu/hrs/apollo/public/visual3.htm
 Excellent point, thank you! I'm not sure what you mean by PC's of the 1960s or "custom hardware". There were no desktop Turing complete computers in the early 1960s. The mainframes of the early 1960s were, however, general purpose machines. In 1963 the University of Texas at Austin owned a CDC 1604, a general purpose machine of Von Neumann architecture. By 1964 more than 50 1604s had been built. It ran an operating system with a full set of numerical functions (like sine, cosine, exponential and many, many others), and at least a FORTRAN compiler, for the first widely used high level scientific language. By 1964 the University owned at least an IBM 7044, another general purpose machine. I coded for both of them. NASA's funding dwarfed that of the University. They had numbers of IBM 7094s, a general purpose machine comparable to the CDC 1604. The 7094 was the second transistorized generation of the basic 709 design, Which originally produced with vacuum tubes. The Apollo Guidance Computer was not Von Neumann architecture machine. Most of the software was stored in read-only memory. See the three Wikipedia articles on the CDC 1604, IBM 7090 and Apollo Guidance Computer for data to show your boss. Good luck with not pissing him off. Basically all of physics and math before the computing revolution was basically done by human ingenuity. I think it's worth mentioning that mathematics is often ahead engineering and often science often by hundreds of years. 

http://www.bbc.co.uk/podcasts/series/maths I think this is a great starting point to show your boss how brilliant we are.  It is not that math is actually ahead of science and engineering.  Mathematicians don't discover dark matter or disprove the aether.  

What does happen often is that things that scientists (usually physicists) find uses for inventions made by mathematicians that had no practical use at the time they were discovered.

Conversely, physicists often invent mathematics to solve their own problems that mathematicians find useful or interesting.   When someone says "Your phone is more powerful than the computers NASA used to get to the moon" the right response is "Yeah, but your phone has you telling it what to do, and those computers had NASA." 

Edit:  Thanks for the gold.  It brightened a kinda crappy day :D

Edit 2:  More specifically, those computers had a contract with a team lead by [Margaret Hamilton.](https://medium.com/@verne/margaret-hamilton-the-engineer-who-took-the-apollo-to-the-moon-7d550c73d3fa)  Here's a good one: the Adreno 420 GPU in the Google Nexus 6 and other mobile devices has about the same computing power as the top supercomputer in 1995, the Fujitsu Numerical Wind Tunnel. The company I work for recently built a GPU server with several Nvidia Titans for $20,000. It's about as fast as the Earth Simulator, the fastest supercomputer in the world from 2002 to 2004. The Earth Simulator cost about $750 million in 2015 dollars. [deleted] Absolutely right. Orbital mechanics is not that computationally intensive, compared to many other fields. Remember what Jim Lovell told his young son when he asked who was driving the spacecraft on the way to the moon: "I think that Isaac Newton is in the driver's seat right now". Newton would have been immediately able to grasp the computations used for the Apollo missions.

Another good example to use is the atomic bomb. Figuring out how to get the subcritical masses together quickly and cleanly enough to set off a real atomic explosion took a fair amount of number-crunching, but it was done with 1945 technology. The folks at Los Alamos would have fainted with joy if they could have had 1969 computers, but they got it done with what they had.

As for the hardware that your boss has seen in Florida, the Saturn V is actually a terrific rocket. Not a single launch failure, despite being by far the largest and most powerful thing of its kind ever built. (Contrast that with the Soviet N-1, their own shot at a manned moon launcher, which failed every single time, catastrophically on at least one occasion). The Saturn was a beast indeed.

Now, the LEM is pretty alarming. You can see one in the Air and Space Museum in DC, and it looks like it's made of aluminum foil and duct tape. It nearly was. The LEM was never designed to operate in any sort of atmosphere - we're not used to seeing anything like that. It was designed to be the lightest possible thing that would get two people down to the surface of the moon and back in one piece, and it would flex and crinkle as it pressurized (see Andrew Chaikin's book "A Man on the Moon" for some of the alarmed reaction of the early test missions!) Here's a good shot of the LEM with and without its skin: http://space.stackexchange.com/questions/5899/why-does-the-ascent-stage-of-apollo-11s-lunar-module-look-like-its-made-of-pap
 And also relating to the hardware for Apollo: Maybe it's because I was a young boy or 9 or 10 when all this was going on but I've always thought that all the Apollo equipment was rather elegantly designed. Just to dismiss it as "junk" shows, to me at least, a complete lack of understanding of engineering, ergonomics and functionality.   &gt; As for the hardware that your boss has seen in Florida, the Saturn V is actually a terrific rocket. Not a single launch failure, despite being by far the largest and most powerful thing of its kind ever built. (Contrast that with the Soviet N-1, their own shot at a manned moon launcher, which failed every single time, catastrophically on at least one occasion). The Saturn was a beast indeed.

Yeah, I think it's simply ridiculous to describe the Saturn V as "a piece of junk." The F1 engines were nothing short of an engineering marvel. I've had the pleasure of working with a number of current-generation rocket designers, 30 year old guys, and their goal is to hopefully create something half as impressive as the F1s. We had to make the F1s so large and powerful because we knew what would happen otherwise. We'd get something like the N-1, but with more engines and points of failure because we didn't have an engine with the kind of impulse and thrust to weight ratio that the Soviets had in the NK-33. &gt; The LEM was never designed to operate in any sort of atmosphere

This is amazing. I had never thought of that reason for it being so light skinned. Thanks for pointing that out. Yep, it's a true spaceship. You see that with robotic missions like Cassini, Rosetta, the Mars orbiters and so on, but for manned craft we're used to something more. . .robust. I was about to make a post telling OP to ask his boss whether boss thinks the bombing of Nagasaki was faked. He should have that discussion with some survivors. Interestingly enough, where the computing technology required to go to the moon was actually fairly rudimentary, the film technology required to fake the landing actually did not exist. Well that's an interesting take I've not heard before. Can you elaborate? How *would* you have faked it? What would have been required to do so? At minimum you'd need to be able to simulate low gravity in a convincing way. Including how other objects would behave like dust, rocks and, at one point, a golf ball. That alone would be well beyond the capabilities of late 60s Hollywood. There's also an interesting piece from the [engineering team at Nvidia about what they had to do to render one of the photos taken on the moon](http://blogs.nvidia.com/blog/2014/09/18/debunked/).  A fake photo showing astronauts on the moon would basically have been impossible to pull off. No, it would have been impossible to render in real time, and probably not at all.  That doesn't mean it was impossible to fake a photo, just that it would have been done using other methods. Also, remember that we would have had to have faked *six* moon landings, not just the Apollo 11 mission! Any one of which the Soviets would have *loved* to expose. Someone else in the thread also pointed out that any schlub with a ham radio in their garage could confirm where the astronauts were.  
OP's boss needs to visit an old WWII battleship or drive a vintage car. They don't have GPS or DVD players or amazing technology; it's copper wires and buttons and knobs. And then he needs to ask himself just what the hell else would he have expected to see. But don't you see? The Soviets were in on it as well! All part of the New World Order!

Really, the Soviets are the best way to counter such claims.  [Here's](https://www.youtube.com/watch?v=_loUDS4c3Cs) an interesting, if kinda long, video on this very subject. One thing that hasn't been mentioned yet, if I recall correctly, there wasn't a way to play a continuous video for the length of the live broadcast, completely uncut.  Have you seen the best special effects in the movies of 1969? They weren't even convincing then, let alone now. The top flight effects of star wars a few years later still used clumsy mattes to mask scenes and they took no effort to simulate the various gravitational effects of various locations.  2001: A Space Odyssey is incredibly convincing most of the time. There are maybe one or two poorly masked shots in the entire movie, the rest is *extremely* well executed.

Granted, 2001 is the exception, both for the time and practical VFX in general. There are mid- to big budget movies from the 80s that look worse. Kubrick was simply extremely competent, obsessed with detail and had the right people around him. Exactly. And he had Arthur C. Clarke along to help him nerd out on all the space details. A much later film that does a great job with free fall is (naturally enough) Apollo 13.

But simulating free fall is surely a lot easier, perversely, than simulating 1/6g for a convincing moonwalk. You can fly a "vomit comet" plane around enough times to get zero-g footage, if you have the time and money, but how do you do a realistic spacesuited figure bouncing around like he weighs 40 pounds? Actually, you can use a vomit comet to simulate whatever reduced gravity you want, by flying a less extreme trajectory. Now how to use that 30-60 second interval to film the hours of uninterrupted footage that was broadcasted from the moon landings is where you run into a problem. You are exactly right. I was rewatching it not too long ago on Bluray, and it really does hold up remarkably well, with, as you mentioned, the exception of just a few shots. Ironically, this is why some people insist that it was Kubrick himself who faked the moon landings.  If Kubrik had faked the moon Landings, we would have to chew through three days of footage of Astronauts doing basically nothing before getting to the actual landing, and Armstrong would have been the only one to come back in the form of a giant space embryo. and then he left secret messages in other movies right?  This is the best argument to combat someone who believes the landing was a hoax. I found a youtube video some time ago... or maybe it was a reddit post... from a current film maker. He describes in detail the effort it would have taken to stage the event. I've made my dad read or watch the video (I'll try to find it) and it convinced him. Now if I can only convince him of anthroprogenic climate change, I can establish a real intellectual relationship with the man.

Here it is https://www.youtube.com/watch?v=_loUDS4c3Cs Here is a video of a film guy supporting your claim. He drops some things I had to lookup, I checked them all out. Excellent facts.

https://www.youtube.com/watch?v=sGXTF6bs1IU

If one's pivotal argument is NASA did not have the technology to get to the moon, then you have to also submit that NASA did not have the technology to fake it. You can't have it both ways. 

Or one can go ask Buzz Aldrin and Buzz with punch that person in the face.  Thank you for that info. I also have friend who throw these "facts" at everyone. He also talks about the van Allan belt which supposedly is so radioactive that everyone in the lunar orbiter apparently would have basically incinerated. (his words) I would greatly enjoy setting him straight. :-)  umm..if the space program was faked, how does he know about the Van Allen belt and radiation levels expected? FYI, don't request a bunch of radiation data from NASA or you'll get the government calling your house. They were mostly asking to make sure I'd pay for the memory to hold all the data it would take (at the time a terabyte was a lot, so I most certainly was not willing to pay that amount) from the Lunar Orbiter 1 mission that studied radiation (I should have asked for Explorer I data too, but didn't really think of it at the time). I think I requested some of the Apollo mission data, but I do remember that it was well over a terabyte of data and that I would've gotten it all in raw format. They were probably also making sure I wasn't going *to misuse the data.* (Edited by adding the italicized portion to complete the thought).

Either way, I think they were also wondering what I was going to do with the data. It was to settle an argument with a person that also didn't believe we landed on the moon. I wanted precise data. They led me to the compiled data that I did use at the time, and realized soon after, that it wouldn't matter how detailed the data was. You have to tie people that don't believe we landed on the moon down (well, their ideas) before even trying to discuss anything with them, because they will move the goal posts as much as arguing with someone about religion. It's insane.

In the end, I was happy about the experience, because the scientist who I spoke to had worked with Van Allen on a few missions (sorry, I can't remember who it was). It was a decent conversation in which few words were actually understood on my end. I told my whole family at the time. That was one of the highlights of my life.

Edit: "too" to "to" What kind of info (if any) did you manage to extract from the data? That they really didn't get that much direct radiation overall (edit: due to shielding). I'd have to talk to someone from NASA to get to the compiled data again, but I assure you, it's all on the internet. The raw data isn't, but you can request that from NASA. Just remember that they are taking it as it is directly from the spools (edit: it's probably on hard drives actually, but iirc, the data is still as it was.. so probably like a really big tar file, except the data you see is the data that was being gathered... oh, you'd need a way to distinguish what data was for what instrument too, so request that too. Or at least what instruments they had.), so you are going to have to write a script to sift through all the tape data. Plus you will need the flight plans and timing, because that data alone is not going to give you the entire picture. It's a lot of stuff to work through just to try to prove a point which is why I felt like I was the one doing all the work while some dude sat there and just mouthed off about how it's not possible that we went to the moon without ever doing any legwork.

EDIT: Don't let that stop you if you really want to go through the data though. You will probably have to coordinate something with them, since they will have to buy storage that they will have to transfer the data to. Even with the huge amount of space at a time when a terabyte seemed like a hell of a lot, they were willing to send it. So, now they should still be able to send the data for even less cost. I'm not sure if procedures have changed though due to all the funding cuts. I am a guy who likes to play with data and has some time on his hands. Do you have any links?

Was the data you played with already unpacked in some way? I know old tapes interleaved the data channels...

Would be really interesting to try to write some sort of unholy mess of a program that took ancient datasets like that and repacked it somehow as IRIG Chapter 10 files. I never got the raw data, but they were willing to send it. Hold up, let me find the location I requested them from. NASA has changed the site quite a bit since then (I think it was in the late 90s to early 00s). I did the initial request for data entirely online though, so didn't talk to anyone until they called me. I'm almost positive I'm on a list somewhere.

Holy crap, you can actually [request lunar samples](http://curator.jsc.nasa.gov/lunar/index.cfm)... that's interesting. 

Here is a lot of data that you can search by craft: http://nssdc.gsfc.nasa.gov/nmc/spacecraftSearch.do

OK, I'm having a hard time finding the page where I requested data from the craft itself. I spent a long time finding it the first time I found it. I'm going to post this and keep looking.

EDIT: I'm thinking somewhere in data.nasa.gov.. Hmmph, maybe not... there are so many places to look. Give me a little.

EDIT2: oh, maybe it wasn't Apollo. I wanted to say Mercury at first. Was it those missions? I'm not sure. Maybe I should figure out the exact flight I was requesting and look for that, since that's how I think I did it the first time around. Ok, still working on it.
 That's [wikiable](http://en.wikipedia.org/wiki/Van_Allen_radiation_belt#Implications_for_space_travel) The best thing would be to take the doubting boss to the Air and Space Museum where the computational power used for space flight is stored in glass display cases. In fact both American and Russian "computational powers" are displayed side by side. [This is what is there.](https://airandspace.si.edu/exhibitions/space-race/online/sec300/sec321.htm) Oh no, yours is the best answer.

"Computers? Where we're going, we don't need computers.

"The moon, by the way. We're going to the moon."

The fact that we put ourselves through 100,000+ miles of hard damn vacuum to step on another world to prove that we had this figured out 300 years ago and just needed the tools is a far more incredible testament to our capabilities than "we did it cuz 'pooters." &gt; fastest air-breathing craft ever made

Just a note (and you're not entirely wrong - and I do *love* the entire SR-71 program) that this isn't correct; the X-43A would like a word.  However, the SR-71 is the fastest *manned* air-breathing aircraft ever made (at least as far as what's not classified - there might be something faster that we don't know about yet). &gt; something faster 

Would you count the [A-12](http://en.wikipedia.org/wiki/Lockheed_A-12) as [different](http://roadrunnersinternationale.com/a-12s.html) enough from the SR-71 ? It's hard to say; it clearly was a different (if *closely* related) airplane in a lot of ways (being a single-seater for instance).  But I still think that the Oxcart aircraft and the SR-71 are for the most part all part of the same program.

If the SR-71 program had involved more airframes I might consider them more separate, but I tend to think of it all as one long evolution of some more of Kelly Johnson's crazy genius. I think one part of people's misconception is about having a hard time believing that you can calculate orbital maneuvers on paper, even though something happening at that scale in space is simpler than anything that is currently happening to everyone on earth. There is constant friction here, with the ground, with the air. It's a lot more complicated than what's happening in empty space, we're just used to it. "and is still the fastest air-breathing craft ever made."


I always assume if we are told about military technology, its because something better exists. 
 President Johnson publicly announced the existence of the SR71 in 1964, before any were actually delivered to the air force. Keeping details secret is one thing, but keeping the existence of a massive project secret is pretty difficult. Same with B-2 and F-117. The B-2 was shown to the world before the first aircraft was delivered. The F-117 was actually delivered and operational units stood up before it's existance was admitted, but it hadn't actually flown in anger at that stage, only operational conversion and training flights. OTOH, President Carter canceled the B-1 and kept the B-2 project secret, despite Reagan pillorying him for it on the campaign trail. Reagan only got to know of the B-2 much later ~~after being elected~~; he still resuscitated the B-1

The SR-71 itself was a variant of the faster single seater developed for the CIA - the A-12 - which had been secretly flying for [a couple of years](http://roadrunnersinternationale.com/a-12s.html) by the time the SR-71 had been announced.

Keeping a project secret is overhyped. Not necessarily. While The Art Of War does indeed recommend obfuscating ones true capabilities, understating them is just one of the two general ways to achieve that. The alternative, which is to overstate them, can be used to elicit caution and low morale in a foe that would otherwise have an advantage and should press the attack.

In the game-theoretical context of a nuclearized world the former is far more dangerous than the latter, because a successfully feigned weakness can only increase the expected payoff of a first strike in the enemys estimation. One last thing to think about is that the Russians has the technology to track everything and they never once said that the moon landings were a hoax, even if it meant they could then attempt top become the first to land.

Long story short (about all the moon landing hoax stuff out there)... if things were faked, the Russians would've been the first to say it to keep them in the space race. &gt;  they are all trivial to calculate even with the computational power available in 1969 - you really don't need much more than a pocket calculator.

They are all trivial to calculate with a slide rule and a bit of time!

 &gt; using cigarettes and slide rules

There's more truth to this than most people would think. I know, I love the old pictures of engineers of the era. A bunch of dapper men in ties smoking cigarettes and drinking coffee. &gt;  you really don't need much more than a pocket calculator.

I don't think those existed in 1969, but they did have desktop calculators, actual computers, and their trusty sliderules. That's what I meant, they did have desktop calculator and slide rules. In the modern age, you can do all of the orbital calculations they needed using little more than a pocket calculator. And a couple ~~dozen hours logged in Kerbal Space Program~~ semesters of advanced mathematics. &gt; a pocket calculator.

Ha, they used Curta calculators on at least some of it, the MECHANICAL ones, that company did great business until the advent of the electronic calculator &gt;&gt;  you really don't need much more than a pocket calculator.

&gt;I don't think those existed in 1969, but they did have desktop calculators, actual computers, and their trusty sliderules.

It's commonly remarked that the computers in the old days were only as powerful as today's pocket calculators. Even if that's true, that's all the power you need for this job. Oh, trust me, *I'm* not misunderstanding anything about computers. I'm an engineer with a college degree, I understand the physics involved and I understand how computers work. My boss can't even use Excel correctly... 
I guess I was really asking for a quantifiable estimate of the  computing power available in 1969, to compare it to the computing power necessary to run some calculus-level physics equations. &gt; Oh, trust me, I'm not misunderstanding anything about computers. I'm an engineer with a college degree, I understand the physics involved and I understand how computers work.

You might be misunderstanding just how reliant (i.e., not) 60s engineers were on computers ;) Hand drawn engineering schematics are something of a lost art and completely foreign to many engineers.

&gt;I guess I was really asking for a quantifiable estimate of the computing power available in 1969, to compare it to the computing power necessary to run some calculus-level physics equations.

To give you a more concrete idea, all the orbital equations shown on the blackboard in that NASA picture I tackled in fractions of a second with a Ti89 in my undergrad orbital mechanics course. (Granted those are first order approximations for ideal bodies, but the perturbations for second order effects aren't so terribly expensive either.) So... you're an engineer and you work for someone who thinks the moon landing was faked. What in the world kind of gig is that? Just explain to him that it was actually easier to blast people to the moon with brute force than it would have been to fake the moon landing with camera technology at the time. 

https://www.youtube.com/watch?v=_loUDS4c3Cs

Film technology was super far behind, it would have been literally impossible to fake.  I recommend your boss watch this six part documentary on the major subsystems of the Apollo missions. Here is [the episode](http://www.dailymotion.com/video/xxxiij_moon-machines-2008-part-3-the-navigation-computer_tech) that describes the creation of the Apollo Guidance Computer. That's some fascinating stuff. Thanks for posting. Well for one thing a large rocket was certainly launched, and NASA published the trajectories so people could independently track the craft, which the Russians did. And just from that alone we can know that something went to the moon and therefore clearly the calculations had been done. 

The part that makes the moon landing obviously true in my mind is just the fact that the big expensive bit is the rocket itself, if you can launch that much mass and reach the moon the only thing stopping you from sending people is the size of their balls.  I certainly think that "So they faked the moon landings, but the Russians never noticed or pointed it out to the rest of the world?" should be a compelling "argument"

There's also a video on youtube somewhere where a bloke explains that they didn't actually have the film technology to fake the moon footage, given the framerates of the footage and such. The fact that the Russians accepted the landing as fact is the most compelling argument. They had the biggest motive and the greatest means to disprove a landing. you forget that the Russians must have actually been in on it, since the Cold War was merely a convenient way to fuel the military industrial complex of both nations.

(That's me playing the role of Conspiracy theorist, engaged in my third favorite logical fallacy) I used that argument on an associate. They responded with something along the lines of, "It would have been beneficial to the Russians to let the US fake a moon landing, as neither country was anywhere near accomplishing it. The Russians were just wasting their money. If the US 'landed on the moon' first, they could stop spending their money." Problem with that is that the Soviets continued to spend money on their own moon-landing program until 1974, and that same program's existence was classified by the Soviets until 1990. It wouldn't serve as a face-saving propaganda measure to publicly corroborate a "faked" American moon-landing  in order to justify canceling of one's own classified program 5 years later, and only declassify that program during the dismantling of  Soviet state 16 years after that. 
Funfact: the Soviet program produced the Proton rocket that Russia still uses to this day, and the Soviet equivalent to the Saturn V was called the N1. But the Russians wanted to win just as much as the US did. This was a battle to determine the number 1 superpower in the world. You can bet anything that the Russians would want that title. Their claim makes no sense. The Russians didn't even see it the way Americans do. They consider the dozen other 1st ' s they accomplished while America was still exploding at the launchpad victory anyways. America won after many losses by reframing the whole competition. Upping the stakes basically. That's interesting. I'd never heard that take on it before. Do you have any more info on how the Soviets considered themselves the victors of the space race? I'm just now realizing I've only ever heard that the US won -- from US sources. First orbiting satellite, first human in space, first human to orbit earth.

That's off the top of my head. I don't know if they "won" any others. first animal returned from space alive, first animal in orbit, etc. They also currently have their own space station AND own a bigger portion of the ISS than any other individual country, including the USA I'm reading Chris Hadfield's book An astronauts guide to life on earth, and he describes launching with the Russians. He visited the Yuri Gagarins office and statue before liftoff, and even stopped to pee on the transport van's tire like Yuri did, as is tradition. Yuri was a national hero to the USSR, and his face is all over Soviet propaganda. They are quite proud of his accomplishments, years before the moon race. The Soviet government, at least, focused on their many firsts in space and didn't focus on the moon.

https://s-media-cache-ak0.pinimg.com/236x/ac/6f/62/ac6f625116a3b7385723897142b968db.jpg How is that even an argument? The US were the ones in the position to dump truckloads of cash onto NASA until they reached the moon while the Soviets had financial problems.



&gt;"The Russians were just wasting their money. If the US 'landed on the moon' first, they could stop spending their money"

That sentence doesn't really make sense to me. Am I missing something?
 It's good that it doesn't make sense to you. The only thing that you're missing is that the sentence was from someone who doesn't believe we landed on the moon. Of course it makes no sense. They didnt really care. They recognized that it didnt really matter who went to the moon first. They knew they couldnt just give up but they wanted to stop spending money on stuff they didnt really need. 


It'd be like if you were racing someone and so you got to the mailbox first, but then you both continued on so you got to the driveway first, and by this time youre getting tired, so now you get to the blue house first and youre exhausted and just want to stop, so when he gets to the end of the street you say "oh yeah good job bro you won". I like the argument of "If NASA was willing to fake such a significant achievement, I'm sure by now they would have faked a second one".  Not to mention theres a very good amount of third party evidence of the moon landing.  They also left a mirror you can shoot a laser at and have it bounce back at you http://en.wikipedia.org/wiki/Lunar_Laser_Ranging_experiment

Doesn't matter what the computational power was.  The fact is that we did it, and that's provable by the presence of the mirror.

 The Russians were actually watching the moon, they were trying to land a robotic lander which failed... anyways, they knew the Americans were trying a manned landing so they gave them their promise they would not interfere and stepped back and watched. America landed. The Soviets realized they lost and gave up on the moon race recognizing they did not have the funds or technical know how to compete. 

Had America lied, the Soviets would have had a field day proving them wrong. They would have landed on the moon and showed emptiness where American lunar landing debris should have been. Subsequent pictures of the landing sites by orbiters have shown the debris still there left behind by the moon walkers.

Furthermore, its not like we landed once... we went many times, it would be inconceivable to fake that many launches and landings considering the scale of things involved. 

Just the size of Saturn rocket gives you an idea of how many people were involved... The Soviet Lunokhod robots actually did work, eventually, after some failures. And they were definitely trying to do a manned mission, until the N-1 kept blowing up, which certainly took them out of the running.  Not too long before the famous Apollo missions, NASA were still doing calculations by hand.  They calculated the trajectory of John Glenn's flight by hand.  They only started using computers to do calculation in 1962, and continued to employ teams to double-check the computer's calculations.  It is my belief that they double-checked most or all of the computer's calculations by hand.

One such person in charge of this was Katherine Johnson, a mathematician and physicist.

https://en.wikipedia.org/wiki/Katherine_Johnson

She calculated the trajectory for the Apollo 11 mission.

&gt; In 1962, when NASA used computers for the first time to calculate John Glenn's orbit around Earth, officials called on her to verify the computer's numbers. Ms. Johnson later worked directly with real computers. Her ability and reputation for accuracy helped to establish confidence in the new technology. She calculated the trajectory for the 1969 Apollo 11 flight to the Moon. Later in her career, she worked on the Space Shuttle program, the Earth Resources Satellite, and on plans for a mission to Mars.

Note: This section of the wikipedia page is in need of some citations, if anyone can help. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] You can make the [translunar injection burn](https://en.wikipedia.org/wiki/Trans-lunar_injection#Modeling) using a pocket watch, a gyroscope, and a few numbers: the starting mass of your ship including fuel, the burn rate of your rocket, and the thrust of your rocket.  The burn time can be worked out by hand using some fairly simple calculus.  No computer necessary.  What's hard to believe? Well for the final landing, they didn't.

"When Armstrong again looked outside, he saw that the computer's landing target was in a boulder-strewn area just north and east of a 300-meter (980 ft) diameter crater (later determined to be West crater, named for its location in the western part of the originally planned landing ellipse). Armstrong took semi-automatic control[25] and, with Aldrin calling out altitude and velocity data, landed at 20:17:40 UTC on July 20 with about 25 seconds of fuel left.[5]"

Geeks rarely give enough credit to the amazing skills of the people operating the tech marvels.

See other comments for the trajectory calculations etc. Exactly. There *was* a computer powerful enough to quickly make the specific adjustments needed to land on the moon. It was made of meat and it called itself Neil.  Ask your boss to read "Surely You're Joking, Mr. Feynman". There are a couple of chapters there about "computers" for the Manhattan project. The US created the atom bombs, multiple nuclear plants and an entire nuclear industry, relying upon subtle physics calculations made with [punch cards](http://www.atomicheritage.org/history/computing-and-manhattan-project), log tables and human computers.

Now point out that the moon shot was a couple of decades later. They had mainframes and [embedded computers](http://www.computerweekly.com/feature/Apollo-11-The-computers-that-put-man-on-the-moon) running machine code. They had a pretty big target that they could see to aim at. The equations governing space travel had been known for a few decades and were much easier. (eg mostly newtonian laws &amp; tsiolkovsky's equations, they [didn't even really need einstein](http://boards.straightdope.com/sdmb/showthread.php?t=446756&amp;highlight=relativity+moon+landing)) They had a parking orbit around the earth to make their trajectory burns simpler. 

And with all of this, they still didn't have precision for the moon landing; Neil Armstrong [observed]( http://en.wikipedia.org/wiki/Neil_Armstrong#Voyage_to_the_Moon) that they were passing over the craters ~[3 seconds early](https://www.hq.nasa.gov/alsj/a11/a11.landing.html) (which would have led them to land more than a mile long from their planned site), he wound up taking manual control and landing 4 miles away.

For a bonus: Note that Kelly Johnson designed the SR-71 (of Mach 3+ fame) with a small skunk works team using [sliderules and paper](http://fyidesigndept.com/industrial-design/sr-71). Of course, *with* modern computation, controls and GPS, a private company can get a [rocket booster to hit ](http://www.vox.com/2015/2/8/7993353/spacex-launch-live-stream)  a 300 foot floating target on the first attempt

 Rocket trajectory is far from cutting-edge math.  Its really not.  The math needed to land a plane on the ground on Earth is far more complicated than landing on the moon.  This is what happens when you don't have to deal with an atmosphere and the friction/wind resistance that goes along with it.   This.

Rocket science is easy. It's rocket engineering that's hard.
Rocket goes up, orbital mechanics. Schoolboy stuff.

Timing ignition and engineering your engine so as not to explode on the pad. More difficult. You mean we are just gonna strap ourselves to a bomb and see where it goes? Works in KSP.

Anyone have any info about what the Soviets thought? Were we still a cold war enemy, or did they share  their amazement at moon landings?  I wasn't born at the time of the moon landings, but afterwards they were simply not giving special attention to them - it was one of multiple milestones in space exploration, and given as much amazement as all the other milestones.

On historical notes and anniversaries for space exploration as such, the main focus was given on the early years when Soviets had a clear lead. The symbolic role that "Man on moon" fulfills in USA was mirrored by all the same things on "Man in space".  

All american successes were acknowledged, but always shown in context with all the other missions all over the solar system, e.g. Venus missions or space stations. There clearly was no concept of "a space race won by USA" - literature about space exploration showed that a race was happening, and it had mixed results; Apollo won on the moon "race category", but it was just one category between Sputnik and Salyut+Mir. If you put up a picture with all the successful missions, then it looked like 50/50 or 60/40 depending on how they did the illustration. Point out that they didn't have enough computing power to do payroll for a multinational corporation either, but multinationals still existed and people still got paid. :) Were I in your shoes, I would be more interested in understanding polarization than the science of the moon landing. 

People who believe in conspiracy theories have a [different type of brain structure](http://www.scientificamerican.com/article/why-people-believe-conspiracy-theoies/). Not only can you not change their minds, presenting them with facts will often just [reinforce what they already believe](http://youarenotsosmart.com/2011/06/10/the-backfire-effect/). 

Your boss will be more certain than ever, after your explanation, that we never landed on the moon. But, more important to your career, he will also be certain that you are not very smart. After all,  you cannot see what is obvious to him. 

*People never forget how you make them feel.* Much more important than any facts when it comes to bosses. I agree. Let it go. Does it really matter to you if your boss doesn't believe in the moon landings? Heck, if you insinuate that you agree with him, he might like you a lot more! I would not be able to respect a moon landing denier. That would be impossible to not come up too often in front of other people. It would be like working for someone who openly denied dinosaurs were real or something. I understand where you're coming from. I work with people who believe that the Earth is 4,000 years old and evolution is a lie, and once in a while I get a great urge to debate them. However I don't.

The reason is, at the end of the day there's a whole other person other than that idea, and the vast majority of them are very nice, capable people. Does not believing in the age of the Earth affect how good your accountant is at saving you money? Agreed also. He's not going to change his mind from the application of logic. OP, just let it ride. How about arguing for an even more ludicrous conspiracy theory. Like: Of course we went to the moon, just like the ancient Egyptians did, using technology lent to us by our Lizard overlords. I wouldn't say that's true for everyone. I've changed my mind about quite a few things.

Edit: without specifics my buddy gave us basically this three hour presentation about why at least the first moon landing was faked. I was convinced for a week or two.  Tell him a "computer" doesn't mean what he thinks it means. We had gears that could have done it without 5ghz super computers. A computer doesn't just mean it's just made of silicon computer chips. We also don't use vacuum tubes anymore like we did for the moon.

[As explained in this 1953 US Navy film.](https://www.youtube.com/watch?v=s1i-dnAH9Y4&amp;feature=player_detailpage#t=105)

 Simple, Ask him to explain how a man made reflector was placed on the moon if we didn't go.

Anyone at any time (as long as hare facing the moon) with a powerful enough laser can bounce it off the reflector we left up there.  How can it be proven that it's not naturally occurring, because it reflects back to the point of origin just like a bike reflector which requires some precision engineering to make it accurate over 100k miles. The reflector is designed to send a beam back along the same path no matter the angle coming in. I absolutely believe it was delivered during the landing but the reflector only needed to be dropped on the surface.  They don't really need to precisely aim it towards earth.  You still have to make sure the thing lands heads up on somewhat flat land. Also dropping something on the moon is a lot different from dropping it on earth thanks to the mostly non-existent atmosphere. Things will accelerate from the point of dropping them to the point of impact at what, 5.32 (Something like this anyways) feet per second per second.

You can't use a parachute without an atmosphere, and lithobraking wasn't really thought of back then to my knowledge. Braking it with rockets is also a bit of a no, since the amount of weight you add is non-trivial, and the thing would also need some kind of righting system that would probably require some more fairly heavy things.

All in all, it was probably easier the way we did it. What does your boss think computers do?  They are useful to do a ton of calculations simultaneously, which isn't necessary to land on the moon.

I think your boss is either overrating what computers can do (A person still needs to give it the formulas it uses to run calculations) or he's overrating how complicated the math was get to the moon.  The math was relatively easy.  It's the engineering that's the hard part.... And computers can't do engineering. The simplest argument against any possible hoax: We were in a space race with the USSR. The USSR could receive Apollo 11's transmissions from the moon, same as NASA. If they detected any hint of shenanigans (broadcasting from satellites, et. al, which is easily discernible from transmissions from the moon), they would have been the first to expose it.  Yes! It amazes me that this isn't a more widely used argument. Their technology was a very close second at the time. So even if you believe a hundred thousand Americans conspired to lie about the moon landings, you can't possibly believe the Soviets would go along with it! It also must be said that Armstrong was a hell of a pilot and took manual control of the moon lander to avoid a boulder on the landing site. In this case the shortcoming was in detailed knowledge of the landing site not in computing power. Either way, that's why a manual override and a skilled pilot were in all the various  spacecrafts. Well, I'd take a different approach.  To answer, "How can I explain..." I would say you don't.

Having cut my teeth on an IBM 1130 (took up a room, had 8 KILObytes of core memory), I know what it could do.  Play chess, run oddball interpretive languages (APL anyone?) and all manner of other cool things.  Solving the equations that were needed faster than a slide rule was well within its grasp.  And the machines that NASA had were many times faster than that.

I also had the pleasure of working with and getting to know someone who was on the servo control team that ultimately steered the Saturn V.  Don't think he was making it up.

But, your boss is swimming in the same pool as the anti-vaxers and people still spotting Elvis.  Facts aren't going to sway him.   &gt; Problem is, I can't find a lot of specific de-bunking arguments discussing the computational power of the machines involved. How can I, in polite enough terms that I won't lose my job, and citing specifics, explain to him he's wrong?

People these days think of computers and wonder "How did we cope in the past?"

A good university student can, with pen and paper, work through the maths needed to get close enough to the moon to enable a human pilot to do the landing. No guarantee it will get down in one piece, but NASA would have spent a lot of time practicing, and they had huge budget to buy whatever they needed to help (and they lost missions and shuttles, too). We lost a probe on Mars because one team did their measurements in metric and the other did it in Imperial. For real. Posts pointing to the simplicity of orbital mechanics need a footnote: calculating an orbit for a moon landing does not require an enormous amount of computational power, but it does require a computer. The three body problem has no general analytical solution--so we had to run simulations to develop a specific orbit suitable for manned missions. The guy who did it received a medal from NASA for his work.

http://en.wikipedia.org/wiki/Richard_Arenstorf

The computers required for this were on the ground, not in the command module or the lander, and they didn't have to be very powerful. But we did need computers, not just slide rules.

 He can learn how to operate the Apollo guidance computer with [this online simulator](http://svtsim.com/moonjs/agc.html).  The project this is based on has ["A Kinder, Gentler Introduction"](http://www.ibiblio.org/apollo/ForDummies.html) to the AGC as well as [source code and binaries](http://www.ibiblio.org/apollo/download.html). Actually, as someone who works in the movie business, I think the better argument is that, in 1969, there's no way we had the technology to convincingly fake the moon landing! Even movies such as *2001: A Space Odyssey* that were considered amazing technical achievements in their day have noticeable flaws that betray their staged nature if you look closely (and know what you're looking for). Given that every attempt to prove that the moon landing footage is fake has been thoroughly debunked, I'd say it's highly unlikely that they'd have been able to produce falsified footage that stood up to extremely close scrutiny for 45 years.

Even if they were able to do so, the sheer amount of manpower and expense it would have required in 1969 would have been staggering. You would have to have a great number of experts in cinematography, lighting, set construction, and special effects, not to mention a well-trained and highly experienced film crew. The United States government didn't keep those sorts of experts in their employ. Where would these people come from? There was only one place to get such people in 1969, and that was Hollywood. The same Hollywood that was still mistrustful of the government following the activities of the HUAC and blacklists of the 40s and 50s. So how do you go about finding a crew for such an endeavor, while still keeping it a total secret? All it would take is one disgruntled person to spread the word and the cover would have been completely blown (and believe me, in Hollywood word travels *fast*). Finding that many people would certainly have been doable, but it would have been essentially impossible to keep it a secret for nearly half a century.

Today, with modern cameras, more sophisticated filming techniques, and digital visual effects, faking the moon landing would probably be achievable, and you might even be able to keep the production small enough that secrecy could be maintained. But in 1969? No way. Don't bother trying, he is hopeless.  You can never convince a conspiracy theorist is they are wrong. Any facts that you got support their narrative are falsified, anyone who doesn't agree with their agenda is a shill.  I like approaching the problem from the opposite angle: 

Instead of focusing on the computing power, focus on the filmmaking:
https://www.youtube.com/watch?v=_loUDS4c3Cs

Our filmmaking techniques weren't nearly advanced enough at the time to produce the film that we know today as the moon landing. The technical details of the [Apollo Guidance Computer](http://en.wikipedia.org/wiki/Apollo_Guidance_Computer) are freely avaiable on the web.  [Not only do computer emulators exist](http://www.ibiblio.org/apollo/), but a number of electrical engineers (with too much free time) [have made replicas for fun](http://www.galaxiki.org/web/main/_blog/all/build-your-own-nasa-apollo-landing-computer-no-kidding.shtml).  There are no secrets about these machines, at this point it's demonstrably true that they could do what NASA said they could do.
 Most conspiracy theorists are not people who are convinced by evidence. Unless you get a thrill out of arguing endlessly, you're probably better off just nodding and saying "that's an interesting opinion" when the topic comes up. Yes, this question should really be grouped as psychology. Even if you sat him down and worked step-by-step through the equations and then proceeded to build your own Apollo mission and take him there, he still probably wouldn't believe you. Presenting a conspiracy theorist (or religious extremist, homeopath, hardcore racist, or anyone else who really wants to believe) with evidence will usually only cause them to double down or accuse you of falsifying the data or any of a hundred other reasons their mind can come up with for why they are right. It's a rarity when arguing with them accomplishes anything and even the ones that eventually see the light of day come to that realization on their own. 
 I'm a classic computer hobbyist. I've screwed around with both simulations of the Apollo AGC, and Apollo AGS, as well as an IBM 7094, which was the ground computer at the time (NASA had an IBM System/360 Model 91 or two, but I believe they weren't used for the Apollo missions).

The machines are very much able to do the required orbital calculations. If you have the interest, you can try out [this simulator project of both the AGC and AGS](http://www.ibiblio.org/apollo/) running the original software that took the spacecraft too the moon. The [SIMH](https://github.com/simh) project has a simulation of the IBM 7090 and 7094, which can run [a copy of the IBSYS batch operating system](http://simh.trailing-edge.com/kits/ibsys_kit.zip) which includes an example of FORTRAN code for a fluid heat flow simulation (if I recall correctly) in the kit.


If that isn't satisfying enough, [here is documentation of the guidance equations used in the command module AGC during from Apollo 15 to 17](http://www.ibiblio.org/apollo/Documents/HSI-208454.pdf). 1960's computers could do calculations just as complex as modern computers, they just took a lot longer.

Also, a lot of the math that went into making the saturn V and sending people to the moon was done by scientists and not computers. Consider that the Manhattan project was done entirely without computers. The task of modelling the behaviour of subatomic particles inside a nuclear bomb is at least as difficult as calculating the trajectories of space craft manoeuvring around the moon.

Does your boss believe in nukes? Why are you arguing with your boss about something pointless that neither of you know much about? Do you feel compelled to tell him that Kilimanjaro has snow, or we migrated from Africa? Will that help? Don't do do it. You're not going to convince him.

The lunar computers were developed for only those one things. They're not exactly computers as we know them but more algorithm expediters. There's something similar with the analog computers that destroyers used for calculating trajectories to hit other ships over the horizon. It might help to touch on that as explanation but as the number of people with close understanding of 45 year old lunar computers is just about zero now you might have difficulty nevertheless. Does he have any background in programming? All of the code for the Apollo Guidance Computer is available online and you can use the technical sheets to determine how many instructions per second they could compute.  
http://www.ibiblio.org/apollo/links.html

Here's a documentary about the computers.

http://www.dailymotion.com/video/xxxiij_moon-machines-2008-part-3-the-navigation-computer_tech When I was in the Army I worked on the [PATRIOT missile system](http://en.wikipedia.org/wiki/MIM-104_Patriot#The_AN.2FMPQ-53_and_AN.2FMPQ-65_Radar_Set). If we could knock down SCUDs/cruise missiles/ARMs/fighter jets/etc at MACH 5 speeds out to  ~~CLASSIFIED~~ distances using 512K max RAM and a 24-bit computer clocked at 6 MHz, I'm pretty sure the geniuses NASA could easily land a rocket on a big ass rock. lol  
  
As long as the math/science (and the basics had been there for a very long time) is there you don't need crazy tools to use it.  There's a scene in Apollo 13 (great movie!) where several of the scientists verify some of the computer calculations using an abacus. It takes just a few seconds. This gives a pretty good idea of how simple the math is --- the computers take a similar amount of time to compute them as the humans. If given proper measurements, enough time, paper, and skilled people to check his work, Sir Isaac Newton could have made the calculations to land on the moon. The math is time consuming without computers, but not impossible. Computer calculations simulate the more arduous process of doing the math by hand. Inferior computers do not produce inferior results, but simply take more time (given that they are programmed correctly in the first place, of course.)

TL;DR Computers don't enable us to do the calculations, they just do them vastly more quickly. Where was your boss educated as a child that these basic accomplishments are not taught as facts?

It is not like the Apollo Guidance Computer needed to run Kerbal Space Program inside the ship.

The AGC had to be able to compute engine burns based on inputs of measured inertial data (accelerometers &amp; gyroscopes), telescope pointing data "which way is Florida? Which way is the North Star?", and sensors "radar feet to the moon surface" And the computer could then know when to switch on and off the main engines and the attitude control jets. It's like a page of math, which doesn't need to run at very high speed. 10 seconds to compute trajectory is no problem at all. In fact it was kinda slow and the computer did act like "overload-too much to do" during one landing stage,  it in fact it kept up on the math and just kind of got unresponsive to new user input, much like a modern pc.


There are entire books that document the computers on the Apollo spacecraft.
[Journey to the Moon](http://www.amazon.com/Journey-Moon-Library-Flight-Eldon/dp/156347185X) is an excellent book that documents the dvpevelop,net of the Apollo guidance computer in excruciating detail. There are images of original documents including diagrams and chunks of code. The computers that flew to and landed in the moon were "block 2" or second generation of AGC that were developed by MIT starting in the early 1960s. The book covers the basic silicon units (simple gates made from smaller diode resistor logic I think). These were assembled into larger things like registers, ALU, etc. it used core memory for ram, and rope core for rom. The hardware specs are well documented on Wikipedia. It was a 15 bit word length machine. It had 2048 words of core ram, and 36k words of rom (role core).
The engineers on it used or invented many concept which we use today: multitasking, call address stack, virtual machine with interpreted byte code. They needed to do math in higher precision and needed to do multiplication and division which the hardware could not do natively, so they had subroutines for large multiply etc., and even more complex functions such as trigonometry. 

There are simulators online you can run them yourself.

 This might help:  
*Line-Of-Sight Guidance Techniques For Manned Orbital Rendezvous*  
http://dspace.mit.edu/handle/1721.1/12652  
- This is Edwin "Buzz" Aldrin's MIT Master's Thesis as a PDF.  
  
Three years later he was able to validate his thesis as pilot of Gemini XII  
http://en.wikipedia.org/wiki/Gemini_12  
  
Three years after that he was the pilot of the LEM of Apollo XI, doing the necessary calculations and providing data to Armstrong, who was at the controls. 
  
There is your "computer." Your boss doesn't want to believe we landed there. He wants to feel special in that he knows something secret and mysterious. There's a certain romanticism around being cynical to reality and thinking that you know more about the world than everyone around you. I for one am capable of re-enacting the Apollo missions in KSP without any guidance computers. If you understand the physics, are good at judging the timings for orbital encounters and the like it's not too hard. I think it would be very easy for a collection of the top minds in astrophysics to have done all the calcs on the ground and simply used computers to execute the commands. That would simply require memory (And a lot of clipboards and to-do lists for the astronauts)
 To be fair, KSP is significantly more forgiving, does not simulate multi-body physics, and allows infinite trial and error. N-Body physics arent really a necessary thing for flights to and from the moon over the short duration of the Apollo flights. I did those calculations by hand for my senior year orbital mechanics final with 2 body physics and my numbers were pretty damned close to NASA's. 

The math really isnt all that difficult. Everything else is what makes it tough.


With that being said /u/wfro42 should give it a shot with RSS installed and get back to us on "easy" :P Worth noting that back then they would have pre-calculated EVERYTHING. Trajectories, burn times, stage release times etc, etc...

The computers on board weren't there to calculate and control in real time. It's really just there as an elaborate timing and triggering device. The computers on board were definitely controlling the orbit in "real time" (the trip is long, you don't need a 100Hz control loop; but you do need a control loop).  This is not really true.  Launch sequences were precomputed, but the exact spot they landed in, the exact remaining fuel/orientation, variations in time of lunar ascent, would invalidate precomputed burns.

The AGC could totally compute the trajectories and burn times, and it had full integration with the inertial measurement systems, optical star trackers, and had I/o port control over the main engine and attitude jets.

However, it was kind of optional and the ground control teams had there own much larger computers which could also compute pretty much all the same stuff, as long as the telemetry was sent down from the ship. So they could decide which computer to use for different functions.
 Show him a calculator and the him NASA had 150 people staffed at all times in the control room of the mission. All equations that were made had to be confirmed by 75 people and if anyone didn't agree, they disregarded and started again. 

They had a lot riding on it after all. &gt;How can I, in polite enough terms that I won't lose my job, ... explain to him he's wrong?

You can't. Don't try. It's a losing proposition. If this keeps going on, one of you will get angry and defensive, and you'll end up hurting a professional relationship over an argument about something that does NOT matter. Next time it comes up, just smile, say, "Oh, I hadn't heard about that before," and ask him about his kids or the football game or *anything* that is not moon landings. Trust me, it's not worth your time to argue with coworkers over such harmless quirks. I can think of several things off the top of my head:

1) Both the USSR and the US had already sent probes to the surface of the moon. Those were autonomous probes with computers that performed orbital mechanics calculations (which, as others have pointed out, isn't that difficult).

2) We have pictures from the dark side of the moon from those missions. There's no way that those could be faked. Either a probe or people went to the dark side of the moon or every single scientist who has studied the moon since then are part of the same giant conspiracy.

3) How could the US keep a conspiracy involving hundreds of thousands of people and dozens of contractors in perfect secrecy?

4) The documentation is *extensive*. You can get the source code for the Apollo computer. If you go to Norlin Library at CU Boulder, you can find bookcases filled with documents from the Apollo program. I know this because I got my degree in aerospace engineering from CU and we had one project where we designed the landing strut for the Apollo lander based on specifications from those documents. There are thousands of reports, each filled with hundreds of papers.

5) A little over a week after the Apollo 11 landing, Mariner 6 flew past Mars, sending back a ream of information back to Earth. Here's an excerpt from the NY Times published on August 3, 1969:

&gt; PROBE FINDS MARS IS UNLIKE EARTH

&gt; Planet Is Less Hospitable to Life Than Expected

&gt; Mariner 6's probing of the Martian atmosphere and surface has shown the planet to be utterly different from the earth and even less hospitable to life than previously believed.

&gt; However, infrared scanners of the surface have revealed areas that may be as warm in the Martian atmosphere as San Fransisco. At night, however, they presumably slip into a deep freeze.

&gt; One of the most surprising discoveries was the absence of any evidence of nitrogen in the upper atmosphere. Nitrogen is the chief constituent of the air on earth. It comprises 5 percent of the gas vented by volcanoes on this planet and appears in all life forms.

&gt; If the atmosphere of Mars had derived from volcanic activity, as is thought to have been the case on earth, it should how at least 5 per cent nitrogen. None was detected.

There actually is nitrogen in Mars' atmosphere, but is less than 5 percent as claimed in the article (it's 2.7% nitrogen).

Mars having an atmosphere of less than 5 percent nitrogen is not something they could have predicted at the time. If one accepts that we had the technology to send a probe with sophisticated instruments all the way to Mars and relay the information back to Earth in 1969, I can't see why they would presume that we couldn't possibly have sufficiently advanced computers to go to the moon. They are pieces of junk. What makes it really nuts is that Northrupp Grumman knew they were pieces of junk. They had to be, anything complicated could break.  
Think of a car that has to drive 220,000 miles and If it gets even a flat tire everyone dies.

That car is going to look like crap. But it works. The technology to compute a path to the moon has existed for almost 500 years.  I am referring to slide rules and log tables.  Computers do it *faster*, but it can be reasonably done by anyone with a slide rule (admittedly, the person needs to know how to use one, but people need to know how to use computers too) Forwarded this thread to my dad who worked in this.  His response:
"The thread is really interesting.  I didn't work directly on the on-board computer.  I worked adjacent to that group and partied with those people.  Don Eyles worked on that stuff.  I learned a lot about that computer reading the Reddit thread.  Margaret Hamilton was, indeed the head of that group.

The work we did was on the mainframe computers on the ground and involved mission planning type things.  I also worked some on a specialized computer that drove the hardware simulation of the optical sextant.

OK, first job story.  So today, we've got all sorts of maps we can view on computers.  Well we were looking for landmarks for sightings with the sextant, and there were no, none, nothing, like maps that were computerized.

So my very first job was to take maps, and pick points along a coast line, and punch up the latitude and longitude of each point on an IBM punch card.  Talk about grunt work.  So I helped create a deck of cards that had all the points on the earth, and then we had a program that would draw the map on a large pen and ink plotter.  My Great Lakes were truly a work of art.

My first computer hack (and maybe last?  I never really got into hacking) was to encode longitude and latitude points for a picture of Winnie the Pooh to place in the Pacific Ocean." Just let it go and say "Okay then". This is a lose-lose situation for you in that if he remains by his beliefs, then you will look like somebody stupidly oblivious to the obvious, and if you manage to convince him otherwise he will resent you for pointing out his own stupidity. Its not worth it for somebody like your boss. This is the only correct, pragmatic answer here. Unless setting his boss straight is somehow important to OP's job, there's no good way to correct the boss without potentially affecting OP's employment.  Well done page on CPU's in space.

A [CPU for use in space](http://www.cpushack.com/space-craft-cpu.html) must first be MIL-STD-883 (usually Class M or S, ground based is B). This means it has met the over 100 tests
that the Department of Defense has developed to insure reliable operation.
These tests include: thermal, mechanical, AC electrical and DC electrical tests as well as sampling
requirements for individual wafer inspections.


The Space shuttle uses the APA-101S computer (5 of them for redundancy). They run at about 1.2MIPS and still use a couple megs of ferrite core memory (which is impervious to radiation). The entire control software for the shuttle is less then one meg. The new glass cockpit in the shuttle runs on Intel 80386s As others have said, the formulas needed to land on the moon are not all that complicated.  It is a fallacy to compare the computational power of Apollo era computers to a modern pc.  Those computers did not have to devote any processing power to multi-tasking, graphics, complex audio or any of the host of other things a modern pc does.  They simply crunched numbers, something you can do on a slide rule. Just another person that thinks computers "do" everything.  

The engineers are what matter.  The engineers probably could have done 95% of the moon landing by hand if they had to.  Hell, how many parts do you think the engineers custom build specifically for this project?  I'd wager plenty!

Fact of the matter is, computing power doesn't matter that much.  Your average pocket phone has more power to compute than all those moon landing computers did, but nobody is doing very much with their pocket phone.  

It's about the engineer, not about the speed at which you can calculate the cotangent of something. Here's my favourite response to the "moon-landing was a hoax" people because it comes down more to their level instead.  They won't listen to the evidence so let's give them something else instead.

The only way the moon landing could have been faked is if either the USSR wasn't watching every single step along the way as close as they possibly could, and listening to the radio broadcasts (which they would have been), OR they were in on the conspiracy because if there was ever any doubt that it happened they would have taken full advantage of that.

To deny the moon landing you pretty much need to deny the cold war, and I can't picture there being many people who will go that far. &gt;  "Have you been to Florida to see those pieces of junk? No way we got anywhere near the moon with that."

Check [this](https://www.youtube.com/watch?v=1AD-DbC3e68) out. 

NASA recently pulled those things out of mothballs to test them and study them again so they can essentially re-learn some things needed for the next major rocket system. That's the F-1 engine's gas generator, just one of the components on each of the 5 main engines on the Saturn V's first stage. Each gas generator is capable of roughly [30,000 pounds of thrust](http://www.nasa.gov/exploration/systems/sls/f1_sls.html#.VNmEBfnF_iU) at peak output. So that's approximately 150,000 pounds of thrust in the gas generators.

*The entire purpose of the gas generator is to start the main engine and dump fuel into it fast enough to burn at maximum thrust.* The Saturn V rockets literally use five [jet engines](http://en.wikipedia.org/wiki/Lockheed_Martin_F-22_Raptor) just to shove fuel into the main chamber fast enough.

I don't know if that will be any use in convincing your boss, but it's ridiculously freaking awesome. Scientist's cameras find 5 flags on moon
By Anne Ryman, The Arizona Republic Updated 7/31/2012 4:41 PM
Comments
For years, scientists and space buffs have wondered what happened to the six American flags planted on the moon during the historic Apollo missions. 

  Now, thanks to high-resolution cameras orbiting the moon, the mystery is solved: All the flags but one are still standing. The exception is the flag for Apollo 11,
http://usatoday30.usatoday.com/tech/science/space/story/2012-07-31/flags-moon-apollo/56613308/1 Deniers (moon landing, 9/11, vaccines, etc) are often set in their way and any evidence you present may strengthen their existing beliefs. I would really recommend proceeding with caution here, you could piss him off and get fired. 

Sorry that's not a science comment, but I think that needs to be taken into consideration. This is a boss conversation, not a friend conversation, and this topic could be toxic.  /u/Overunderrated answered this well, but I'd like to take a few moments to discuss 'all' of it.

First off, the men they sent to the moon were some of the brightest, well-trained, general-knowledge people on the planet at the time.  They were true jack-of-all-trades types, with their knowledge gaps filled in entirely by massive rooms full of the absolute brightest nerds at the time.  These *teams* were setup, structured, and able to accomplish *any* task thrown at them.  Period.

Nutritionists calculated exactly how much food and water each person would need.  Biologists knew how much air they'd need, how much carbon dioxide they'd make, how much nitrogen to backfill with, and what levels would become unsafe.  Material design experts knew what kind of material would keep 1 atmosphere of air against a vacuum.  Astronomers watched the moon, knew how far away it was, and where it was related to Earth.  Rocket scientists knew propulsion to get that much weight that far in an acceptable amount of time.

That little list accounts for probably a couple hundred people, and we're no where near a complete list of just general titles.

There were *thousands* of people involved in the Moon landings.  Some had major jobs of the design of the capsule, some made the bolts, some weighed the ration packs, some mixed the rocket fuel.  It wasn't "3 men went to the Moon per mission," it was thousands, if not tens of thousands of people, with massive amounts of the wealth of our nation that sent them to the Moon.  In other words, every last citizen in America was directly contributing toward their success.

Are you going to sit there, and tell me, that the collective intelligence, funding, and resources of this country, at a time of absolute unquestioning nationalistic pride and patriotism, couldn't put a few footprints on the Moon?

That's not just daft.  That's insulting. There is evidence in the psychology literature to suggest that contesting a person's conspiracies in a confrontation only acts to makes them more firm-rooted in those beliefs. Instead, practical advice should be based on a non-confrontational approach. Show him understanding without head-on confrontation and subtly cast seeds of doubt.

You know we measure the distance to the moon by bouncing lasers off of mirrors set up during the apollo program? You can probably buy the required kit off the internet for a few thousand dollars. Did you know the Apollo program bought back something like 100kg of moon rock? It's used in research by geologists and planetary scientists all over the world. One of my favorite things on YouTube ever is [this guy's](https://www.youtube.com/watch?v=sGXTF6bs1IU&amp;list=FLKJ7gk27exklVL2ynj-04VQ&amp;index=3) explanation of why the Moon landings (there were more than one televised) were not a hoax. He's not an astrophysicist I don't think, and only gives a small history about rocket science leading up to 1969 that suggests at the very least the United States was spending enough money in a race against the USSR to make the rocket science seem legitimate.

But, he doesn't prove the landings weren't a hoax by analyzing the technology in the spacecrafts or explaining rocket science he doesn't know. He instead makes in awesome case for how faking the landing is actually **less** plausible than actually flying to the moon, with 30 years experience in film.

Basically, remind your boss that the lunar landing in 1969 wasn't a short clip seen straight to video or in a movie theater. It was a 2 hour, 23 minute continuous TV broadcast, that over 600 million people worldwide saw. The only feasible way to fake the moon footage would be slow-mo. Doing that kind of faking on film would require thousands of feat of it, and broadcasting it back then would have been too risky. Film-to-video (TV) back then could result in so many giveaways that it is just hard to believe (film artifacts that no one saw back then). Then, with the later moon landings, it would have been even more difficult to fake perfectly on film.

Digital slo-mo playback get around that problem since there wouldn't be artifacts of the conversion of film to video. But, the technology didn't exist for that long of a slo-mo shot. The most that could be done at once, known to be used at that time for football replays, was ~~30~~ 90 seconds of slow-motion playback. Something playing back 143 minutes of continuous slo-motion video in 1969 would basically be a device with many times more digital storage of what was known to exist back then. Then make it even more complicated for the next landings which had faster frame-rate video. You can't say NASA's didn't have devices advanced enough to put a man on the Moon, then claim they had devices that were more advanced than known to exist. Was their technology advanced or not? Pick one!

The guy in the video also goes over some about the shadows and stuff but basically summarized it that most people who claim the lighting and whatnot isn't right know very little about film exposure or light sources and perspective.

tl;dr It would be easier to put a man on the moon than fake it in 1969 due to the limits of video technology back then.

Edit: Last minute fact check and error correcting. effectively, it'd take far more computing power to fake it, than it would to do it for real. It was actually harder to fake the moon landing than actually do it. If you know anything about film technology back in the day. It would have been impossible to make a fake landing as the tech simply wasn't there yet.

People who say its fake generally know very little about cinematography and assumes that you do as well. I found [this to be a good detailed explanation](https://www.youtube.com/watch?v=_loUDS4c3Cs) - it concentrates less on computing power, and more on the fact that the state of the art in filmmaking wasn't up to faking it.

That said: you may not be able to do this without losing your job, so if your job is more important than being right, you may want to re-think the whole conversation.

Oh...and I'm sorry that you have to work for an idiot! Conspiracy theory people are nuts, don't bother. He's already made up his mind - note that he ignore the mountain of evidence that the moon landing happened and focuses on the few pieces of (incorrect) facts that it didn't happen. Every time you point one of these out as incorrect he will jump to the next one. When he runs out of these he will lean on speculation (for example calling the shuttle a piece of junk). You're wasting your time. I know because I've been down this road and it's infuriating. As with all moon-landing-hoax idiots, they base their arguments on completely subjective assessments of things they know nothing about.  So just ask him exactly how much computing power is needed.  What are the calculations needed to perform these maneuvers -- what factors are involved, what are the relations between those factors, and what accuracy is required?  And by "accuracy," not just to how many decimal points these things must be calculated, but how many samples are required -- Did they just point and shoot, or did they have to make course corrections?  If so, how often did they have to make these corrections -- every hour, every minute, every second?  If they were unable to perform the required calculations in, say, one second, would they go hopelessly off course in that one second?

Then ask him, what is the minimum memory capacity and number of floating-point operations per second required to perform the necessary calculations in less than one second?

You don't need to cite specifics.  You think that the moon landings were real, but he _knows_ that they were a hoax; so obviously he knows much more about it than you do.  _He_ has to explain to _you_ how he knows that it was impossible.

Then when he shows that he knows no more about it than you do, just quietly point out that the people who knew these details thought that it was possible; that he doesn't know about it and thinks that it's impossible; and you, who don't know any more about it than he does, prefer to believe the people who actually knew what they were talking about. And this is why humans didn't circumnavigate the globe until computers were invented. We just didn't have the computational power to do so until recently. All claims of such were faked by the explorers whose names we associate this with. Um...

....you can actually see the landing sites for Apollo 14 and 15 from the earth using a decent telescope on a clear, still night. Why bother arguing engineering when your boss won't even believe his lyin' eyes ?  No earth-bound telescope could resolve small enough features on the moon to see any landing craft. Not even the Hubble has sufficient angular resolution to see any Apollo gear. There's also a mirror you can point a laser at and receive a signal back.

At least that's how people like Sheldon do it  Yeah but NASA could have put a remote control robot on the moon and placed it there so they could claim that Neil and Buzz set it up and left it there and then the robot could have hid itself under a rock so it couldn't be found. 

I mean, the costs, mathematics and computing power to do that has got to be easier then actually putting someone on the moon right ?  Thank you everyone for your responses, I think I'll try and summarise this thread:
   
 * Schizophrenia consists mainly of audio hallucinations and varies    from person to person in terms of 'reality checking' themselves

 * Hallucinations are possible to have on digital screens, meaning the hallucination many continue when looking at a video camera

 * The person suffering with schizophrenia would likely come up with a delusion to explain the absence of the person, such as it being invisible to a camera

 * It all varies on the severity of the person's symptoms at the time

Hope that summary was adequate, another big thank you to all of the responses, especially to those who I have quoted.

EDIT - Phrasing [deleted] [deleted] [deleted] [deleted] They would likely think you are either lying or mistaken which is part of the disease.  It's also possible they would just say that the person is invisible to everyone but them.  The disease causes people to be more likely to dismiss evidence and create alternative explanations as to why the evidence is untrue.  So in the hypothetical of a person sitting in a chair and I showed them the camera I would likely be called a liar or be told I'm playing a trick.  Although I will say, I do work with people with schizophrenia on a regular basis and I have never had anybody insist that there was an invisible person in the room. Food for thought: How can you empirically prove that what that person sees or hears is not actually there? :) Its very hard because even brain scans will show activity in the auditory parts of the brain, as if someone is over their shoulder is talking to them during hallucinations. So empirically the brain shows that it's being stimulated. So.... They would have no reason to believe that what they're hearing isn't real or isn't there. :) The root of my question is actually in the philosophy of "brain in a vat" - namely, it is truly impossible for anybody to objectively prove that the reality they experience is *actually* reality. As such, it becomes impossible to argue both that what you see if there, and what someone else sees is *not* there.

I think the parallels between that philosophy and schizophrenia are rather uncanny :) [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Thanks for the summary. You went the extra mile! [deleted] Thanks for asking and even more for summarizing; interesting post! [deleted] As another poster has pointed out, those kind of full-fledged visual hallucinations probably don't happen very often. 

But I can say something to the more general question, in that there in research on how other kinds of hallucinations/delusions respond to this kind of evidence.  I'm thinking specifically of the case of [anosognosia](http://en.wikipedia.org/wiki/Anosognosia) for hemiplegia, in which a patient following brain damage is unaware that they have a limb that they can't move.  When asked to lift their arm, they insist that it has moved, even though everyone can plainly see that it hasn't.  

There are isolated case reports where patients have been put in front of a mirror, to make sure they are looking directly at their limb from a 3rd person point of view, and they continue to insist that it is moving. 

However, there is a [recent published study](http://www.ncbi.nlm.nih.gov/pubmed/19428388) in which a patient with anosognosia was shown video of herself, and this instantly resolved the condition.  That is fascinating, and now I'm curious to see how far the delusion would extend. If you asked them to switch on a lamp with their paralysed arm, would they think the lamp was switched on? If you asked them to play the piano with it would they hear piano notes? VS Ramachandran has done something similar to this by asking them to pick up a tray with a bunch of items on it.  The tray requires two hands to lift. The idea was to see how deep the delusion went. When you know you only have one hand, you pick the tray up from the center. The anosognosics, however, just lifted the right side of the tray with their good hand, dumping all the contents over as if they had been expecting the left hand to be helping out.   How did they react to that? Did they come up with a delusion to explain why that happened, or did they realize the arm was disabled? The general pattern is to explain it away rather than to acknowledge the disability. So if the water spilled they might say they just slipped, or sometimes they will complain that they are just tired and don't want to raise their arm, things like that.   [deleted] I would imagine that it depends on "where" the delusion appears. Like in a computer program - if an error appears at different levels it will incorporate itself into different systems. If there is a hardware level problem then it will potentially permeate through every single level (although software might work around it). But there could also be an OS level problem - this would be apparent in that specific OS, but not in others. It could also be an application level problem. They could all manifest for the end user in the same way, but depending on where they originate could end up being there on different levels of the software stack. 

I imagine it works in a similar way for the brain - that the delusion could appear on different fundamental levels and thus have differing effects. Eg if the delusion is that they perceive a person sitting on X chair at that moment then it wouldn't matter how you recorded or showed information about the scene - they would still perceive the person sitting there. If the delusion was, however, that their vision simply sees a person sitting there then it could be inconsistent with other senses.

Would something like this be a likely reason why people have experienced it differently? A different analogy would be a painting. With a high level disorder, just a few brush strokes are wonky but the rest of the piece is in order, accurate, and beautiful. A low level error has the mixing and chemistry of the paint poor, the color choice clashing, or the paint technique erratic, or the canvas is torn or flawed in manufacture, making the extent of damage more systematic. I believe Oliver Sacks has written extensively about everything you inquired. I would recommend checking out some of his work. I did think it was a Sacks-ish line of inquiry.  I've read The Man Who Mistook His Wife For A Hat, any others you'd recommend? I'd recommended An Anthropologist on Mars; and while I haven't read it yet, his new book Hallucinations probably touches more on the topic at hand.

Edit: Also check out his Ted Talk: What Hallucination Reveals About Our Minds. [deleted] [deleted] [deleted] Wait, does "resolved the condition" mean the patient overcame some mental incapacity to move their arm and was then able to move again, or did the patient become fully aware of the fact that they were not moving their arm as they previously perceived? She overcame the anosognosia, meaning she became aware that her arm was disabled.  [deleted] Piggy-backing on your comment:

###/r/AskScience does not allow: Anecdotes, speculation, personal medical information, or medical Advice.
###Comments containing these things will be removed as per our rules. Check out that thread on the Planck temperature then. That place is a mess.  Thanks for the report, I'll go run in with my trusty flamethrower. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Also as a caveat, visual hallucinations are rare in schizophrenia. Classically schizophrenics suffer from auditory hallucinations.  &gt;auditory hallucinations

So would a deaf schizophrenic who experiences auditory hallucinations know that they are hallucinating? [deleted] [deleted] More interesting: How would you agree on that he was hearing it? (assuming deaf since birth) Well, i take it you would just assume they aren't lying to you? It would be just as hard for someone to agree that someone is seeing a visual hallucination.


Or did I misunderstand your question/idea? The idea is how someone who never heard anything could tell it was "hearing" [deleted] [deleted] [deleted] [deleted] [deleted] Can a person suffering from delusions be rational in other areas but irrational in their delusion? E.g., if a rational person felt that they had a videotape of an alien, and they watched it with placebo recordings in a blind test and couldn't determine which video had the alien, they would immediately cast doubt onto the entire phenomena they felt they were perceiving. Do people suffering from delusions lack the ability to say "wait a minute, I have evidence this is wrong and therefore will dismiss my feelings about it?" &gt; Can a person suffering from delusions be rational in other areas but irrational in their delusion?

Yes. People with schizophrenia may consider other people with the same symptoms to be "crazy". 

&gt; Do people suffering from delusions lack the ability to say "wait a minute, I have evidence this is wrong and therefore will dismiss my feelings about it?"

Generally, yes.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Is paranoia a symptom of schizophrenia? Just curious because it seems like it would be the only thing leading a hallucinating person into acting that way (trying to accuse s/b else of manipulating them etc). I say this because I reckon there's a difference between hallucinating e.g. my dead mother, and suffering from a delusion (if I don't actually acknowledge that she's dead). You're right - hallucinations and delusions are distinct. However, both can be symptoms of schizophrenia. They're part of what we call "positive" symptoms, along with "negative symptoms" and "catatonia". [deleted] [deleted] [deleted] The vast majority of schizophrenic hallucinations are **not** visual, they are auditory.  It's popular in pop culture and media to portray hallucinations as crisp, realistic visual hallucinations- this doesn't really reflect schizophrenia accurately.  [deleted] [deleted] So what conditions *are* associated with visual hallucinations? Schizophrenia is associated with visual hallucinations. They are just not nearly as common as auditory hallucinations. Are visual hallucinations more common in DTs? Yeah, even when they're seemingly visual, they're usually mainly auditory.  Like, someone might hallucinate that a person in a painting is talking to them or something. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] An informative response,  but it doesn't quite answer the question. what about the 0.00001% who can get visual hallucinations? I'm curious if their brain would piece the imaginary situation back together when watching it on tape. An interesting question for sure!  So, somewhere around 30% of schizophrenics have visual hallucinations, but auditory is more prevalent and frequent. Also remember that "schizophrenia" is a class of disorders that have very different symptoms, and presumably causes, between people. 

If you put a schizophrenic patient in an fMRI while hearing voices, the auditory cortex will light up. If we extend this to vision, we (for the sake of this question, I'm on my phone right now so I can't look it up) will see visual cortex light up when experiencing visual hallucinations. Visual processing is based on perception of our environment, and if part of the perception of the environment do includes that camera/monitor, then yes, it is possible the person would see the image on the screen, depending on the severity of symptoms. [deleted] [deleted] [deleted] You are correct, but what you're describing is more delusions than auditory hallucinations. Often the individual is aware that the hallucinated voices are coming from inside his or her head. Thinking the radio/TV is talking directly to or about you is a delusion (through misinterpretation of what they say, like thinking they're talking in a secret code)  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I think a more relevant question would be if a schizophrenic person would suffer from the *delusion* that someone was sitting in a chair in front of them, and then looked at that chair through a camera. I'm not sure if that would make any difference, though. I've worked with a great deal of severe schizophrenic patients and there is just no convincing them that the delusions aren't real until proper antipsychotic treatment kicks in. The delusion, after all, is not perceptive, it is due to abnormal functioning of (amongst other things) the brain areas responsible for salience attribution (primarily the ventral striatum). In fact, a requirement for antipsychotics to reduce delusions is blocking of dopamine D2 receptors, the largest concentration of which are to be found in the striatum.

Source: Grad student in neuropsychology currently working on neuropharmacological studies of antipsychotics. Plus five years clinical work in high-security forensic psychiatry. 


 &gt; the delusion that someone was sitting in a chair in front of them, and then looked at that chair through a camera

I find this a little confusing. I thought delusions were "false beliefs" (for example, my neighbour controls my thoughts). How would the person you mentioned above describe their experience? Would they say something like, "I believe that there is a person sitting in front of me"? I'm assuming that before reaching for the camera, you would ask them if they could see the person sitting in the chair. A "yes", by definition, would then indicate that the person is hallucinating, right?  &gt; Would they say something like, "I believe that there is a person sitting in front of me"?

Exactly.

&gt; A "yes", by definition, would then indicate that the person is hallucinating, right?

Not really. There is no perceptual stimuli, real or imagined. Most theories point towards auditory and visual hallucinations as originating from within the auditory and visual cortices, respectively. As such, a visual hallucination would mean that the same areas are activated that would be if we actually saw the object. Sort of. It's a complicated and not at all an agreed upon phenomenon. More here: http://schizophreniabulletin.oxfordjournals.org/content/40/Suppl_4/S233.full

A delusion on the other hand is a *belief* that there is someone sitting in the chair. The belief occurs is due to aberrant salience attribution, itself due to chaotic dopamine signalling in the striatum. 

I've had patients ask me all kinds of things, like wanting me to remove snakes from the floor, rescuing their family from the tower outside, if there is blood pouring from their throat, why there are babies without eyes walking around the ward, why the news lady on TV, and so on. While they are convinced that all this is real, they are very rarely visual hallucinations but rather delusions. 

As an example, a patient came to me once and wanted me to cut up her arm cause she had hundreds of tiny spiders crawling just under her skin. I asked if the could see them crawling under there, because I couldn't. She couldn't either, but she *knew* they were right under there. &gt; Not really. There is no perceptual stimuli, real or imagined.

Why not? In order for something to be classified as a hallucination, there *shouldn't* be an external stimulus (if that's what you mean by perceptual stimuli) similar in quality to a true perception.

&gt; While they are convinced that all this is real, they are very rarely visual hallucinations but rather delusions.

How did you conclude that all those examples were delusions, rather than hallucinations?  &gt; Why not? In order for something to be classified as a hallucination, there shouldn't be an external stimulus (if that's what you mean by perceptual stimuli) similar in quality to a true perception.

I worded that poorly. I meant 'imagined' as abnormal activations of the visual cortex. That is a perceptual (in this case visual) stimuli originating from within the persons brain, without being subject to outside stimuli.

&gt; How did you conclude that all those examples were delusions, rather than hallucinations?

Mostly it comes down to asking if they see something or not, or having a conversation with the patient. Of course, this is not possible during acute phases where main priority is for the patient not to hurt themselves, other patients or the staff. After spending a lot of time with the patients though you get a "feel" for how their mental illness manifests. That said, you can never be sure. It's a complicated matter and there is a great deal of research to be done. The difference is between a situation where the person perceives a distorted visual image where someone sits on a chair, versus perceiving a visual image with an empty chair but having a distorted mental model that includes a person sitting on that chair. [deleted] Thank you for saying "was sitting". [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Edit: repost as reply to OP.

A very interesting note in this topic is the paintings of a man named Louis Wain.  Mr. Wain was a painter who's favorite subject was to paint was cats. (Ironically fitting for Reddit.)  Mr. Wain had Schizophrenia, despite some who claim he didnt, which must be mentioned.  

As the years went by, Louis' portraits of cats became more and more abstract.  It is important to note, as an artist of the period, his style was originally abstract.  Comparing various paintings by. Mr. Wain over the years (and simultaneous progression of his mental disease) opens an interesting, although non-objective, window into what the sufferers of this disease may see visually.  

[visual progression of cat paintings](http://imgur.com/JW3J7Ob.jpg)


If you notice , as his condition progresses, one cat in perticular is almost "fractalized."  This is similar to what some on larger amounts of LSD my visualize... could this possibly be one of the reasons doctors thought LSD may have medicinal effects on people with these specific visual hallucinations? I personally do not know.  

Here are some refrence links:

http://blogs.scientificamerican.com/creatology/2011/12/22/how-a-mental-disorder-opened-up-an-invisible-world-of-colour-and-pattern/

http://en.m.wikipedia.org/wiki/Louis_Wain I don't have the source right now, but I recall reading that the biggest argument against him being a schizophrenic was that even though his drawings underwent a severe change in style compared to his early work, they remained very orderly and organised, which apparently is uncharacteristic of schizophrenia.
The other issue is that the progression suggested in your picture didn't happen that way. Many of the more abstract paintings were painted earlier than attributed in the picture as well as some of the more realistic looking ones being painted very late into his condition. The picture of the progression was arranged by one doctor to suggest worsening of condition, however, the paintings used were undated, so it is a product of his own subjective perception. &gt; The similarity of Wains later paintings to fractals is striking. Fractal patterns exist, of course, in nature, and can be glimpsed in aerial photographs of coastlines and mountain chains, and even in the foliage of trees, but the earliest computer-generated images of idealised fractal patterns that we are familiar with today were not produced until the 1970s. There would appear to have been something about Wains condition that allowed him to perceive and represent these invisible natural patterns long before anyone else had seen them.

It makes me wonder how he had perceived that, and what it meant to him. The fractal cats also remind me of mandalas. Mental illness, or unfettered creativity? [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Interesting this came up. I wanted to r/askscience something very similar.

What would happen if a scientist guided a schizophrenic to experiment on one of their hallucinations. For example: a schizophrenic sees an ant. If he disects the ant and looks at it under a microscope. What will he see? [deleted] [deleted] I can try my hand at the strong force.

Its most exotic characteristic is that, unlike with gravity or electromagnetism, the magnitude of the strong force is proportional to a **positive** power of the distance. That means that it gets stronger as distance increases. Because of this, everything subject to that force tends to clumps up (the technical term is confinement). If you tried to separate a pair of quarks, for example, you'd have to pump so much energy into the system that you'd create two more quarks to pair up with the ones that you've separated (here you would be transferring energy to mass as per Einstein's famous equation).

While gravity only has one charge and electromagnetism has two, the strong force has six. Strong force charge is called "color". Fundamental units of strong charge are red, green or blue, while their anti-particles are anti-red, anti-green and anti-blue. To get something that is white, i.e. color neutral and not affected by the strong force, you need either all three colors, all three anti-colors or a color-anti-color pair. That's why hadrons are either made of three quarks (like protons and neutrons) or two (pions, for instance).

However, for any force you need a particle that will mediate it. For electromagnetism, that particle is the photon, which is massless and chargeless. For the strong force, that particle is the gluon. The gluon, however, has color, which means it is also affected by its own force. That's the main reason why strong force is way more complicated to treat than the two more mainstream ones, and can't have an equation derived from a potential.

Edit: Thanks for the gold, now I get to figure out what it does! There's something I definitely don't understand: If the magnitude is proportional to a positive power of distance, then wouldn't it increase to infinity as distance increases? Clearly the universe isn't a crush of matter due to the strong force, so there must be a term which decreases with distance and dominates the equation after a certain point. Actually, what happens is that as you pull two quarks away from each other, energy builds up in the gluon field.  Eventually, this energy is enough to pop out a new quark pair out of the vacuum, and you get two hadrons instead of two quarks. OH I see, now that we have two hadrons, the pair is neutral and doesn't attract other quarks. That's an interesting way for the universe to work! So if you're yanking apart a red and anti-red quark, a new anti-red quark would pop into existence next to the red, and a new red would pop into existence next to the anti-red?

If you tried to pull a red away from a green and blue pair, would you get a new anti-red quark attached to the red, and a new red attached to the green and blue pair?

This is really cool stuff. I wish someone had explained it in these terms back in college physics. Yes... or more exactly, you could wind up with any neutral color combination, since the quarks are always exchanging gluons. Any quark where you can see its color is called "naked" and that is not allowed. Quarks are aways "contained" within a neutral hadron.
  
And I think it has to do with all the virtual particles that pop in and out of existance.. once you has put enough energy into the system, one will change into a real particle. &gt; Any quark where you can see its color is called "naked" and that is not allowed. Quarks are aways "contained" within a neutral hadron.

Interesting! So is there actually any physical difference between a red/anti-red pair and a green/anti-green pair, or are they both just interchangeable pairs of net-neutral quarks, and it's effectively arbitrary what color we use to describe any given neutral pair? If the latter, it sounds like the red/green/blue system is just a way to express that quarks can be neutral in groups of two *or* in groups of three once they have a chance to polarize with each other, but never by themselves, which wouldn't be possible with a bipolar (+/-) nomenclature. &gt; are they both just interchangeable pairs of net-neutral quarks


Yes.  [This section of the wikipedia article on quarks](http://en.wikipedia.org/wiki/Quark#Interacting_quarks) says that each time a gluon is exchanged, the color of the relevant quarks changes.  If you look at a chart of the six quarks, you'll normally see columns for mass, electric charge, angular momentum, etc., but never color (since it's always changing).


Furthermore, the way color works means that there's a symmetry between each of the colors.  If we suddenly switched the colors 'red' and 'blue', it would have no effect.  (Wikipedia makes an analogy with the spatial symmetry of gravity, i.e. gravity works the same in the x-direction as it does in the y- and z-directions.) In some sense it's arbitrary how you assign the colors.  Unlike electric charge, particular colors don't seem to be associated with particular particle types -- i.e. color is a completely different quantity than the down/up/strange/charm/truth/beauty nature of a particular quark.  You can mix and match -- if you find a down quark it could be red, green, or blue, and none of its other characteristics depend on the color.
 So is it actually possible to measure if it's red, green, or blue?  Or can you only say "between these three particles, I have one of each", or "this particles has opposite of this other one"? I got that explanation back when I was still in school by my physics teacher. 

It turned out, all the way through my phd in physics, I never got a better explanation in simple terms... Wait, no. Hang on. I'm imagining a universe in which all matter is color neutral, but there is a pair of extra quarks far far away from one another, red and anti-red for the sake of argument. The force between them would be enormous. Are you saying, a pair of quarks would pop out of the vacuum next to each of the lonely quarks, creating two new hadrons? I'm not sure I can square that with conservation of energy. What am I missing? Because to get them that apart you'd have to inject a huge amount of energy into them. Though you'd never get them far apart - as soon as the energy required to stretch them out further was greater than the energy to produce new ones, they'd pop out of the vacuum.  Thanks for the reply, but let me clarify, I'm not suggesting we pull them apart. Just that there was not an even distribution of matter in the initial conditions. Like when a party ends and everybody seems to have hooked up with somebody except me. I'm imagining two such parties, far far apart, two lonely quarks separated by light years, and they still have a force between them which increases with a positive power of distance? If you assume that they START OUT far away from each other, then indeed, that poses a problem. But if you assume that they start out with no such isolated quarks then there is no way to create isolated quarks.

Which just pushes the problem back to this: when the universe started, were there isolated quarks? If the answer to that is "No", then there still aren't any today. Well, instead of the big bang, could you not have simply started with two quarks popping into existence on opposite sides of the Universe?  You might almost instantly have quarks popping up all over the place and filling the Universe. Interesting. So start with a massive amount of energy instead of mass, and then convert it. But then we'd have a steady state universe, not the expanding one we see. The problem with this is that as far as we can tell (yes there are other theories which are being explored though), space-time itself came into existence at the big bang and expanded from almost a point (a singularity). Therefore there is no universe for those quarks to be separated in, there is no space for them to pop into existence randomly, no space to separate them. Actually, you'd only end up with an empty but slightly colder universe with two more quarks in it.  As soon as the initial quarks "recognized" each other (cf. relativity), they'd be attracted so violently that you'd literally create two extra quarks out of vacuum energy to pair with each other.

At least, that's how I understand it, given that universes have baseline energy and modern physics means you can freely convert background energy (of any kind) into particles [though usually particle-antiparticle pairs].

Now, if you created a universe with only two quarks (in anti-color arrangement) and absolutely no vacuum energy, that might be interesting.  But I wouldn't even know if it's possible to create a universe that "clean", given what we know about our own universe. Do we have the ability to model what would happen if two quarks violently attracted at a distance like that? This is a total shot in the dark, but maybe they'd produce a characteristic high energy cosmic ray or something that we've observed. That doesn't work for several reasons:

1. The premise violates (local) conservation of color. There's no physical mechanism by which those quarks would pop into existence.

3. Using [wikipedia's estimate](http://en.wikipedia.org/wiki/Color_confinement) that they exert a constant 160kN of force on one another, this amounts to 160kJ of energy between them per meter of distance. By E=mc^2 , that is about 10^-12 kg/m. Spread out over a cylinder with the diameter of a lightyear this drops to a density of 10^-44 kg/m^3 , already less than the [density of the universe](http://hypertextbook.com/facts/2000/ChristinaCheng.shtml), 10^-39 kg/m^3 . So one gluon pair does not a universe make.

3. Even if the energy was enough to build a universe from, it would all exist in a single line in space, rather than the even 3D distribution we see in the universe, so it doesn't fit observations either. Are the quarks forming a neutral group considered to be occupying the same point? If not does that not mean that they radiate a small quantity of strong nuclear force oriented along the the vectors between them? The strong force does sort of 'leak' between hadrons. This is the residual strong force, which allows hadrons (like protons and neutrons) to form atomic nuclei.

The residual strong force is extremely short range, which is why nuclear fusion is difficult. Particles don't really occupy 'points', but states. They can sit on top of each-other and have different states, but ultimately the term 'on top of each-other' has to be defined in terms of states anyway, so that's just the wrong way to think about quantum physics.

Particles won't radiate unless they are losing energy. If they are losing energy, they are changing state. So what state are you supposing the particles would be in? This presumes open mingling during the party, but this doesn't sound like a party like that.  Everyone shows up at the party with a partner, or a partner is instantly provided the moment they walk in the door. Maybe some swapping occurs, but it does not involve any real ambiguous moments of singlehood - you let go of Kerry, just as Jessie takes your hand. An unpaired quark is like a magnetic monopole in this regard. Which I understand is possible, just not yet observed, correct? Many models predict that they should exist, and there have been claims but nothing conclusive. The LHC is actually busy searching for magnetic monopoles: https://en.wikipedia.org/wiki/MoEDAL_experiment [deleted] [deleted] Does this happen in nature? Quarks interchanging partners naturally Unknown, but generally doubtful.  Because quarks can change color, it's also hard to track what happens, especially when most of the interactions that mess with quarks directly are very high-energy and very short time-scale.

For example, if two hadrons collide and two hadrons emerge, we generally guess that the quarks in question move as little as possible, therefore not switching partners or any other hijinks.  Get the ability to see what happens in one of those interactions, and the world will love you for it. In order to reach any kind of answer to your question, you need first to define "initial conditions" of the universe. That's one of the most interesting questions faced in the study of physical sciences as a whole. There's currently no reason to believe that the initial conditions of the universe even allowed for quarks to get that far apart, except if some extreme amount of force (like a Big Bang) were introduced to a singularity. But the physical rules within a singularity are almost certainly totally wacky compared to our understandings of regular matter in regular space, so the most honest answer anyone can give is, "We have no idea if what you're suggesting is even contextually possible."

But yeah, if we can assume space behaves more or less according to our current understanding everywhere in the universe, that it's somehow possible to enter this universe's spacetime from some other "place" (or that it's possible for molecules to be spontaneously created), and that this actually happened such that an anti-quark were introduced with a nearest "matching" quark being *really*, *really*, *really* far away, there would exist an absolutely ridiculous amount of force between them. What would happen under those circumstances is anyone's guess. Who knows? Maybe the Big Bang model is correct and that's exactly the kind of thing that blew up the singularity. Or maybe not. We don't know (and also, since for reasons already explained we simply can't push "matching" quarks that far apart using conventional models of acceleration and travel through space, we can't possibly, as far as current knowledge allows, find out). I don't see why you think this is a problem for conservation of energy.  There's a LOT of potential energy in the system you described (even if it appears out of nowhere because you're creating this whole universe in media res.)  Having that energy turn into a whole string of (massive) hadrons doesn't violate conversation of mass-energy.  Well.. it would not work that they are so far apart... and "naked". Quarks are always "contained" and you never see a naked quark. As you try to pull the quarks of a neutron apart so you can see their color.. the strong force (with an asymptotic power law) resists so fiercely, and you have to put in so much effort (energy) to pry them apart... suddenly you wind up with three (or two) quarks in each hand (with another one also pairing off and getting away).
  
So yes.. all that energy you put into the system created a real quark from all the virtual quarks that are flooding the system. And so you get new hadrons.. A theory which I heard a few times would easily resolve this: According to that, the colors don't really exist in simple matter. They are only created when you try to pry those waves apart. Or in other words, they happen when you expose normal protons or neutrons to extreme conditions. That way, the original universe can't have singular red or other quarks, because only normal matter came from the big bang, while the exotic stuff only appears under extreme circumstances (near light-speed collisions). With a greater understanding of quantum mechanics, do you think it would ever be possible to manufacture loose quarks? I get that they are never found "naturally" but at some point during the creation of the universe they might have spawned in separately, right? I'm a bit out of my element if you couldn't tell.. Understanding Quantum Chromodynamics...we have a theory... it works.. if we ever see a loose or naked quark the whole theory crashes.
  
QCD works.really well so we don't expect it to crash. I'm out of my depth as well, but as I understand it, in hot enough matter you can have free quarks you have a [quark-gluon plasma](https://en.wikipedia.org/wiki/Quark%E2%80%93gluon_plasma). You have a "soup" of particles that is, as a whole, color-neutral, but the individual quarks aren't bound to each other. E=mc^2 . The amount of energy needed to pull the quarks away from each other is enough to create new particles. Yea.  This property has a name, which basically boils down to the fact that you can't have free color (no free quarks). If they're that far apart, then doesn't the system contain a massive amount of potential energy in the distance between them? How exactly does energy in the gluon field cause quarks to be created? (also what's a gluon field?) It's because most particles in the universe that you are talking about are color neutral, and as such, left unaffected by the strong force.  This is because the force-carrier particle has mass and self-interaction.

We feel electromagnetism at great distance because photons are massless; however the self-interaction especially of the gluons means that the strength of force being exerted by one nucleus never makes it so far as to be able to pull on something from another nucleus; their mass means that they can decay to more quarks instead of making it intact to the other nucleus.

Weak force is somewhat similar - it is only felt at distances comparable to a nucleus because the W,Z bosons decay before they get any further. Thank you! That was a really clear and understandable treatment, accessible to a lay person who understands basic concepts and identifying where the extra complexity lies. It was precisely the sort of explanation I was hoping for. &gt; The gluon, however, has color, which means it is also affected by its own force.

I had never heard of this. So this particle interacts with itself? Or with others of it's kind? Can someone give a more detailed explanation? Basically, two quarks will interact by having a gluon change their color. This is way easier with pictures, but bear with me.

Say a red quark and a blue quark are interacting. They will do so by exchanging colors: a gluon will take the "redness" and give it to the blue quark, and give the "blueness" to the red quark. Now, this needs to be done at the same time, so one of these exchanges is going to have to happen (bear with me) **backwards in time**: the gluon takes red while giving blue, and **then** takes blue while giving red (here taking blue happens after giving blue). Now a particle going backwards in time is just its anti-particle, so the gluon will either have to carry red and anti-blue, or blue and anti-red, depending on which quark gets its color changed first. That, however, means the gluon is not white.

On the other hand, you could have two red quarks interact with each other. In that scenario, the gluon would carry red and anti-red, and would be white. So mostly it depends on the interaction. Did I mention there's no way to differentiate colors?

Note that here I'm explaining why gluons see strong force, but not how they do it.

Edit: Clarification and spelling. Yes with pictures you can say go left or go right, being backwards and forewards in time.. So, would the gluons that mediate a red-quark red-quark interaction not be affected by other gluons (since it is red-antired=white), but the gluons that mediate a red-blue interaction WOULD be affected by other gluons (since it is red-antiblue=nonwhite)? Forgive me if this is foolish, but I am deeply confused by the time traveling gluon. During the period that it's traveling backwards are there effectively two gluons, one traveling forward and one traveling back? Wouldn't this result in more energy being in the system during that period, as you'd have the energy of the gluon as well as its time-reversed counterpart? Or does the gluon somehow reverse causality/history by rewriting what it was doing during that period? That doesn't seem possible: even in the weirdness of quantum mechanics, you can't erase a cause and still have an effect, right, there are always causes for actions, even if they're stochastic in nature? And if it's able to move backwards in time, wouldn't that mean that the interaction wouldn't be simultaneous, since the gluon would arrive at the original quark before it would have reached the second quark? Or is the explanation something simpler, like "we know that property X has to be maintained and if you reverse the time dimension in the equations governing the gluon's behavior it has the quality of maintaining that property, therefore the gluon must be simultaneously transferring color backwards and forwards in time"? And is there somewhere I could go to see the equations that govern this/get an explanation of how they represent the behavior that you're describing? Sorry to badger you with questions, but I find the whole matter fascinating. Ok, I couldn't find a diagram that served the purpose of the conversation so I made one [here](http://imgur.com/eHftLC6). Note that on that image, the time axis goes left to right (up and down is some position).

The bottom part (green and orange) is what happens to the particles. You can see an up quark and a bottom quark both being still (but moving through time), and a gluon moving between them (both through time and through space).

Now look at the top part, which is tracking colors. You can see the blue color being carried backwards through time, but the gluon (bottom part) is still moving forward. It's simply giving the blueness to the bottom quark before it's gotten it from the up quark.

The time-reversal thing is one way to see it, but you can also look at it this way: the bottom quark is giving its redness to the gluon, but it still needs to have a color. It becomes blue, but has to give anti-blue to the gluon (you can't just create color out thin air). The gluon then meets the up quark. The quark's blueness cancels out with the anti-blue, and the gluon gives the red to the quark so it has a color. Thank you, that clears things up and I appreciate the effort that you put into it. If I'm understanding the diagram correctly, the quarks don't change color at the same time, rather each quark changes color at the same time as it emits or interacts with the gluon, which makes a lot more sense.

One last question (I promise): it seems like this enables instantaneous transfer of information, something that I didn't think was permissible. If a quark changes color I know that there must be another quark nearby, and I'd know it before that second quark would actually have sent information which could reach me. Or is it not possible to observe a quark without somehow interfering with its ability to interact through the strong force with other quarks? Do color-changing interactions with gluons require quarks to be in unobserved/probabilistic states akin to the famous dual-slit experiment or something along those lines? Or is color simply not an observable characteristic? Or am I just wrong about the permissibility of instantaneous information transfer? I apologize for inundating you with questions (also, I suppose this hasn't been "one" question...), but it's just such an interesting topic and I'm not sure how to go about learning it on a more in-depth level without going back to school for a physics degree. As far as I know, you can't observe color directly. It's been brought up into the standard model for parity conservation reasons at first, and also some processes can only occur with a certain color so you observe them 1/3 of the time you'd expect to otherwise...

Say you could, though. If a red quark emits a gluon and turns blue, then you know the gluon will be red+anti-blue. What that tells you is that this gluon will only be able to interact with a blue quark (to turn it red). If that gluon passes nearby a green quark, it won't be absorbed. Basically, when a quark changes color, you know it's interacting with SOME quark, but for all you know that quark could be super far away. All it tells you is that another quark exists somewhere, but the whole idea of forces is that more than one particle exists to feel it, so I don't know if that really counts as information.

The observation would probably require detection of a gluon, though, so it would definitely bother the system, like with photons. How can we possibly know this stuff? Step 1. Observe behavior/pose question that isn't adequately explained by current body of knowledge.

Step 2. Do lots of really complicated math to come up with a description of a system that provides a consistent explanation for problem from Step #1

Step 3. Consider implications of the derived system. Determine testable effects (e.g. 'If gravity affects light according to this equation, then light passing the surface of the Sun would be deflected 1.75 arcseconds')

Step 4. Perform experiments to determine if those effects do indeed occur in the manner predicted. If they do, congratulations, you may have expanded our knowledge of the universe (or maybe not, do a lot more tests to make sure). If not, you've just started back at Step #1! &gt; Step 2. Do lots of really complicated math to come up with a description of a system that provides a consistent explanation for problem from Step #1

It should be "Do lots of math that is as simple as possible but as complicated as necessary". It often happens to be quite complicated after all though. There's also the luck derived way where step 2 is : Remember some really obscure and seemingly useless piece of math you heard about and suddenly realize it roughly describes your system.

That's how pure maths become applied In the case of the strong force, it was a case of trying other basic symmetry groups and seeing what led to consistent theory .  (EM is based on the symmetry of a circle, and weak force on another basic symmetry) What exactly are these colors? How would you explain this to someone who is colorblind for example? They're not exactly colors, but more a description of having three quantities that add up to neutral (green + blue + red light = white, green + blue + red charge = color neutral). 

It's similar to the concept of charge, which has two values adding to neutral (+ and - = neutral), except with three values. So basically it's a tri-polar system, where any pole is neutralized both by its own anti-pole and by the sum of the two other poles? Exactly. It's like how the different types of quarks are called flavours (up, down, charm, strange, top and bottom) despite not tasting of anything :) So what does it tell us that anti-X has the same effect as Y+Z? Think of it like a triangle. The opposite point of X is the midpoint between Y and Z. Its a little easier for me to visualize it more like a Star of David. One triangle is the color "axis" and the inverted triangle is the anti-color axis. A color and its anti color are on points across the star from one another. They are arbitrary names for a property which gluons have, the same way that positive and negative charges are just names for the two different flavors of a property which charged particles have.  "Color" was chosen because human vision uses three primary colors, and there are three types of color charge (well, six, I guess, but that's just including the anti- colors).  You could just as easily call them cyan, magenta, and yellow, instead of red, green, and blue, or even call them sweet, sour, and bitter if you wanted. I'm not in any way an expert, but I believe it's not color in the sense that an apple is red or the ocean is blue. It's simply a convenient analogy to indicate a system that has three "types". 
For example, numbers have only one type and it's inverse, positive and negative. We have rules about how numbers interact. Equal positive and negative cancel out (zero or neutral), two positives yield a greater positive, etc. For systems that have a single kind of charge and inverse charge (EM field) the positive negative convention is sufficient. 
Colors are helpful because you can create any other color from some combination of RGB (that's how your monitor works), so you have three types available. Combine equal parts RGB and you get a white (neutral). Combine a color and it's inverse (red and anti-red) and the two cancel out as well. The strong force has more than one kind of charge, so we needed a new convention to describe it, and color just happened to fit pretty well. 
Also if you're wondering how to mathematically express redness, just consider a vector [r, g, b]. So [1, 0, 0] is red, [0, - 1, 0] is anti-green, etc.  Gluon has color so one gluon can decay in two gluons, or two gluons annihilate imto one gluon. So a colored particle emots colored gluons around itself which then explode in number. So if you are close to the charge you see white and if you try and gey further you see color and run back to the white This is a very good explanation, coming from someone not in the matter having only concept of strong force as "keeps protons together despite their electrostatic charge". Thanks a lot. It actually also is responsible for the majority of the proton's mass. Protons are made of two up quarks and a down quark. If you take those quark masses at face value and add them up, you only get about 1% of the proton mass. The rest of the mass-energy comes from the potential of the strong interaction. Is this "extra" 99% the mass of the gluons? No, gluons are massless like photons.

The extra mass comes from the potential energy of the gluon field. Remember, energy is mass. When I hear "potential energy" I think "stored energy", like there's some way that energy could be released.  I think of a stick of dynamite, or a ball at the top of a hill.  Is that at all right in this case?  Or maybe the question I'm trying to ask is, this energy has the potential to do what, exactly? what an amazing time to be alive. elements the unchanging, simplest blocks of matter, but wait there are atoms!  atoms, supposedly the smallest unit of matter, but wait it those can split into these protons, which are composed of quarks!  but if you add up the weight of those quarks you don't get the full weight of the proton!!  how strange! In addition to holding the nucleus together, quarks also give protons and neutrons their electrostatic charge. Nucleons are made of up quarks and down quarks, the former having a charge of +2/3 and the latter a charge of -1/3. So two up quarks and a down quark would create a particle with a +1 charge, the proton (+2/3+2/3-1/3=3/3), while two down quarks and an up quark make a neutral particle, the neutron (because +2/3-1/3-1/3=0/3).

Weak force interaction can cause quarks to switch from up to down (Beta+ decay) or from down to up (Beta- decay), which is why elements have half-lives. What are the usual interaction "diameters", for the lack of a better word, of strong and weak force? I mean, how near do the particles need to be to exhibit the strongest strong and weak force, respectively? I understand that may not be a correct way to look at it, but I'd like to at least know order of magnitude, just for orientation. The strong and weak forces are actually "short range" for different reasons. The weak force's short range comes from the fact that its mediating particles (the W and Z bosons) are massive. If you try to calculate a potential from this force, you get a [Yukawa potential](https://en.wikipedia.org/wiki/Yukawa_potential) which looks similar to a Coulomb potential, except it falls off exponentially at a rate related to the mediator particle's mass.

The mediators of the strong force (gluons) are in fact massless, so in principle they should have infinite range. But because of confinement, it is really hard to pull color-charged objects apart. At a certain distance, the potential becomes strong enough to produce quarks out of the vacuum, and these create color-neutral hadrons. The simplest/lightest hadron is the pion (or pi meson), so these get produced the easiest. So in nature, rather than sending gluons out over long distances to "communicate" between color-charged entities, in practice what happens is virtual pions are exchanged. Now the pions "look" like the mediator, and they are in fact massive. Hence, they give rise to a short-range Yukawa (effective) potential. In fact, by estimating the range of the interaction "diameter" (essentially, the size of a nucleus) of the strong force, Yukawa was able to predict both the existence _and_ approximate mass of the pion! &gt; The gluon, however, has color, which means it is also affected by its own force. That's the main reason why strong force is way more complicated to treat than the two more mainstream ones, and can't have an equation derived from a potential.

Hmm, interesting. I've (stumbled through) a quantum field theory course in grad school and read about everything else you had said here recreationally in books like [The Cosmic Onion](http://www.amazon.com/The-New-Cosmic-Onion-Universe/dp/1584887982), but I never quite noticed this subtlety. **The force mediators for electromagnetism (photon) and gravity ("graviton") are both** ***charge neutral*** **to their respective force**, perhaps for a deeper reason of which I am unaware (both are massless and electric-charge-neutral).   
  
However, as you said, the gluon is not white (as only mesons and baryons can be) so it is intrinsically more complexly linked to the force it mediates. Though intuitive that this might cause *something* to result, are you certain that this is the *reason* why we can not write a classical potential type law for some limiting case of the strong force? Gravitons definitely self-interact. The equations for general relativity are non-linear. They are only linear in the Newtonian approximation, which is where we get the potential in the comic.

Gravity interacts with any source of energy and even though gravitons are massless they still carry energy.
 Are you sure that the graviton (assuming it exists) is charge neutral to gravity?  I know I've heard people talk about gravitational self-interaction before.  And if it has any degree of energy, it couldn't be, could it?  It would still follow geodesics through space rather than traveling in a direct straight line, I'd think. I don't claim to know much on this matter, but my understanding is that the graviton would have to be massless due to the following chain of reasoning:   
  
A force mediating particle requires virtual energy to be created from "nothing" if a mass or charge is to be constantly radiating force mediators without losing energy. Since energy and time are linked in an uncertainty relation, energy conservation can be "violated" for very short periods of time, provided that the product of the lifetime and the energy discrepancy is below hbar/2. Therefore, if gravitation has "seemingly" infinite extent, it must follow that the mediating particles are capable of reaching arbitrary distances from the source. Such would require arbitrarily large amounts of time if the particle were massive, and thus the uncertainty would force the energy of the mediator to zero. Conversely, however, if the mediator were to be massless, the particle moves with speed c and experiences purely space-like space-time motion, i.e., doesn't "experience" any time at all. Thus, the energy-time uncertainty relation allows for the violation of energy conservation.   
  
This explains why both electromagnetic and gravitation forces have infinite extent (massless mediators can travel for boundless distances since they experience no time). It also explains the 1/r^2 dependence, since a homogenous radiation of particles from a point source into 3-D space results in decreasing intensity like 1/r^2 as you move from the source.  
  
Conversely, since the strong force mediators have mass, they experience time and the uncertainty relation only allows them to exist in violation of energy conservation for a brief period, thereby allowing them only to travel a set finite distance from the source before vanishing. This might explain the sharp finite cutoff in the effect of the strong force (but not the r^(positive) dependence up to that point).   
  
Take all of this with a grain of salt. Most of this is my recollection of ideas from the cosmic onion, rather than rigorous details from my course in quantum field theory (which didn't give me any real intuition about the big picture stuff like this). But gravity interacts with energy, not mass. That's how we get gravitational lensing. Since the graviton would have energy, it seems to me that it would in fact experience a gravitational force on itself. I could very well be wrong, I have yet to take a QFT or GR course. The graviton (if it exists) indeed is self interacting as in GR it's not mass that causes gravitation, but massenergy. Classically this manifests as GR being *nonlinear* meaning it does not obey superposition.

For instance, in electromagnetism, you can represent the electric field due to two charges in space as the sum of the individual electric fields, i.e,  

* E(Total 1+2) = E(1) + E(2)

In gravitation, this relationship does not hold due to the self energy of the field.

* G(Total 1+2) != G(1) + G(2)

You can make a first order correction though to visualize the problem:  

* G(Total 1+2) ~= G(1) + G(2) + G'(1,2) So if I had an empty universe and two particles with opposite color very, very far away from each other, they'd accelerate towards the other at near-light speed? No. That system has so much energy, lots of real quarks will be created. This makes you wonder if the universe only started off with 2 quarks, but inflation took them apart so quickly that the rest of space instantly filled with particles (and this kept happening until inflation ended) Hmm.. once the quarks were clothed there would be no more need for more particles, so perhaps I should have said only two particles would be created.. but it is a cool idea and inflation does posit particles condensing out of the inflation field.. I like the explanation that you have to put soo much energy into separating them that you create two more quarks to pair up. I never knew that. Is the generation of new quarks instantaneous as soon as it passes an energy threshold? I'm actually not familiar with the dynamics of it all, but I'll just say that you have to be careful with the word instantaneous around all of this relativity. The timescale of hadronization is about 10^-23 seconds, far shorter than most timescales people encounter.  The top quark has a half-life of about 10^-26 seconds, so it actually does sort of exist as a "free quark" because it decays (usually into a W+ and a bottom quark) faster than the strong interaction can react. &gt; for any force you need a particle that will mediate it.

what's a particle? Thank you. The color analogy helps a lot for understanding. It's not an analogy. Or rather it's exactly how the model works, which is an analogy for the real world itself. We've got no idea how the real world actually works though.  When you say gluons interact with the strong nuclear, do you mean they interact with other gluons?  Wait... the strong force INCREASES with distance? Wouldn't this mean that there's an incredible force between the protons in my body and the protons on the other side of the universe? Much, much stronger than the force that actually binds the particles in the atoms of my body? 
Why am I not torn to bits by my protons being dragged off to far corners of the universe? Grad student in HET Physics here. Similar to what other answers have said, protons and neutrons are "color charge neutral". That being said, they do have a residual attraction, which is how protons and neutrons stick together in nuclei. 

The best analogy of the residual force keeping them together is it's like the van der Waals force in electromagnetism: two atoms that are each electrically neutral still attract, though it's a (relatively) very very weak attraction, it's still there. 
Wow. So all that talk about the Strong Force binding protons and neutrons together might be better put as "The Strong force binds quarks together, but on the side, as a minor side-effect, it also binds protons and neutrons together."

Am I getting closer? You are, yes! That's a pretty spot on way to describe it.  ...and as long as I've got the ear of a Grad student here:

Wouldn't my question still apply, but to quarks then? When scientists make quarks in, say, a particle accelerator, are those quarks really much more attracted to far-away galaxies than to the particles that immediately surround them? In this case, there's a difference on the length scales here. An analogy to make this make more sense:

When we point a telescope out to the night sky, we see a bunch of stars. Some of them, in reality, may be a binary star system, or two stars rotating each other. But when we're far enough away, it looks just like a single star.

The same deal happens with quarks in a particle accelerator. First off, though, in a particle accelerator, every step in the way there aren't any truly free quarks: if you smash two things together and you get a quark out, you're also going to get an antiquark (with the corresponding anticolor) too. Now, this quark may interact with something closer than the antiquark in the meantime, so on really short distance scales it looks like you have a quark by itself. But if you zoom out further away, it just looks like you have a quark-antiquark pair. 

To connect back to the analogy: the binary star system looked just like a single star, and pretending it's a single star until you get really close works well enough.

Similarly, the quark-antiquark looks like something that's color charge neutral, like a proton, so pretending it's color charge neutral until you get really close works well enough.

Just like the proton, though, the quark-antiquark pair doesn't interact with other things with the strong force, but it can interact with other quark-antiquark pairs with the (same) residual strong force that protons and neutrons stick together with! That's why the quarks aren't interacting really strongly with far away quarks in other galaxies.

tl;dr: Whenever you create a quark, you also create an antiquark, and when you're far enough away it looks like a single object acting with a residual strong force, just like how protons and neutrons stick together. i just looked it up. theres a bit of confusion about what is commonly called the strong force.

aparently no nucleid actually causes the strong force, but rather its quarks that make up the nucleids that cause it. nucleids themselves are overall neutral in the strong force. however, there is a sort of "leftover" force or a sort of "bleed-through", that is what is often called the strong force (even though its just a part of it). this leftover force is extremely short range, but on the order of magnitudes of atomic nuclei its strong enough to counteract the coulomb force which would usually push nuclei apart (since you have multiple positive charges in a relatives close space).

long story short: protons, neutrons and electrons dont cause strong force on even an atomic scale, which is why your nuclei stay together, but dont attract much beyond that with the strong force. Because the strong force doesn't apply to protons. Protons are made up of three quarks, and those quarks are held together by the strong force. If you try to pull the quarks apart, you have to pull against the strong force, which increases as you pull them farther apart. 

Eventually you would have to pull so hard (put so much energy in) that new quarks would appear to make new color-neutral hadrons. 

(I think. I'm not actually a particle physicist) The explanation "strong force doesn't apply to protons" is not compatible with the statement "strong force is what holds the protons and neutrons together in the nucleus of the atom". That would be because the statement is at best misleading, and at worst incorrect.

What holds together the protons and neutrons in a nucleus is a residual effect of the strong interaction, usually termed the "strong nuclear force."  It's akin to how the "Van der Waals force" is a residual effect of the electromagnetic interaction.

Neither the strong nuclear force nor the van der walls force is a fundamental interaction. Yes! This!!! Thank you for the clear and understandable analogy. Can you please explain how does this residual strong force exists and works? I am by no means a particle physicist, but I am 1/4 of a way to being a chemist, and can explain how the Van Der Waals force works which should allow you to extrapolate. Van Der Waals interactions occur whenever you have two overall neutral atoms/molecules (hereafter called "things")  attracted to each other via electrostatic force. There are three cases in which this can happen. First, two things which have an electrostatic dipole, that is they have one end that is "more positive" or "more negative" than the other, but overall the thing is neutral. The "more positive" end of one thing is attracted to the "more negative" end of another thing. The second case is where a thing with an electrostatic dipole *induces* a temporary dipole in a second thing. Imagine a bag of magnets (which don't interact with each other for simplicity's sake and because magnets can't be monopoles), if you hold another magnet up to this bag of magnets, all of the magnets inside the bag are going to flip themselves so that the side closest to the external magnet is attracted to the "exposed" side of the external magnet. The same things happens in "things". Imagine if you have an atom, if you bring a positive thing next to an atom, the electrons in the atom, which all move about individually will now be more likely to be found on the side closer to the positive thing, resulting in a temporary dipole in the thing that doesn't normally have one. The final case in which the Van Der Waals force applies is when you have two things which don't normally have a dipole, bring them close together, and induce dipoles in each of the things. This is like taking *two* bags of magnets, holding them near each other, and shaking. The magnets within each bag would arrange themselves such that all of the magnets, in both bags, would face the same direction. This happens on an atomic scale as well. If you bring two atoms close together, because the electrons are moving around, there will be areas of high electron density and low electron density at any specific time. If an are of low electron density faces a second atom, the other atom's electrons would be attracted to the low electron density and then would be more likely to be found on the side closer to the first atom. This results in two temporary dipoles. 

To extrapolate: even though neutrons and protons are overall color-charge-neutral, the individual "sub-color-charges" may (could/possibly/tell me if I'm wrong) arrange themselves such that there are fractional charge dipoles within each of the neutral bodies which attract themselves to the other "neutral" bodies.  I can't come up with any good analogies. The [Wikipedia article](http://en.wikipedia.org/wiki/Nuclear_force) is extremely basic but provides a simplistic version of the model that still might be more confusing than illuminating.

Sorry. I wish I could, but I just can't come up with a simple, good way to explain the mechanism in non-mathematical terms, which is usually an indication that I don't understand it well enough. (My understanding is that) quarks don't know that they are protons or neutrons. All they see is a bunch of other quarks around them and interact accordingly. thats a bit of an oversimplification. the stong force definitely applies to protons, cause otherwise atoms wouldnt exist (the strong force is commonly quoted as what keeps nuclei together).

its complicated, but are you familiar with dipole momenta?

if you put a positive and negative charge next to one another, from afar you wont be able to tell that there are charges there, cause they would cancel one another out, however, they dont completely cancel each other out, so theres something leftover called a dipole moment(um) (not sure about english terminology).

this is how i would explain it: the strong force gets canceled out inside the nucleid, but theres something leftover like a dipole moment, which is short range, so its more or less gone on the scales of atoms (10^-10 m) already,   but still strong enough to keep nuclei together Charge neutrality. The protons in your body have balanced charge, because they are made of complimentary particles, so they don't interact with other particles via the strong force. Then what's all that nonsense about the Strong Force "binding protons and neutrons together"?

If the Strong force gets stronger over distance, then why are my atom's protons bound to their neighbor and not to some distant quasar? The strong interaction binds colored particles together into color singlets, such as the proton and neutron.  If two nucleons are placed close enough together, their constituent quarks can perceive the existence of their counterparts in the each other, and we get a Van der Waals-type interaction mediated by the exchange of a pion, which is a color singlet meson with about 1/8 the mass of a nucleon.  But this can only happen if the nucleons are close enough to each other, within a few times the characteristic length scale of the strong interaction which is about 1 femtometer. &gt; for any force you need a particle that will mediate it

Does that mean if you block that particle, the force doesn't happen? So what particle mediates gravity? &gt; So what particle mediates gravity?

In a quantized theory of gravity, that's a graviton. As I understand it, though, we don't have a real quantum theory of gravity yet. We only really understand gravity in the classical limit (a la Maxwell's equations for EM). We can make a lot of statements about what a theory of quantum gravity ought to be like in order to fit in with the rest of physics, but we're still in a "blind men describing an elephant" stage.
 &gt; For the strong force, that particle is the gluon. The gluon, however, has color, which means it is also affected by its own force. That's the main reason why strong force is way more complicated to treat than the two more mainstream ones, and can't have an equation derived from a potential.

Adding to this, there are **8** gluons which couple to each other to make glueballs Yes. If you check all possible color combinations, you'll find 9 different gluons (red-antired, red-antiblue, red-antigreen and so on). However, it turns out the white bosons (color+anti-same color) are mathematically redundant, and only two of those are needed, which leaves 8 total. &gt;The gluon, however, has color, which means it is also affected by its own force. 

It's also massive, yes? No. The weak force mediators (W and Z) are the only massive mediator bosons. No.. "gluons are vector gauge bosons that mediate strong interactions. Bosons have no mass.  (W and Z bosons only appear to have mass) I see, thanks. From wikipedia on the strong interaction
&gt; Furthermore, most of the mass-energy of a common proton or neutron is in the form of the strong force field energy; the individual quarks provide only about 1% of the mass-energy of a proton.

So if the gluons have no mass, how does that work? The mass energy of a particle is the mass of its constituents, plus the energy that would be required to break it apart. The energy binding quarks in a proton is very high (to break it apart, you'd have to push against a force that gets stronger the farther you get), and hence makes up most of its mass. thank you for this. I've been familiar with these concepts individually for quite some time, but this short synopsis really helped me understand the bigger picture. i thought the strong force followed a yukawa potential cause its short range, or did i mix something up there?

we never covered strong/weak force that intensively... The yukawa potential is an approximation. Yukawa consider pions as the exchange particle holding nuclei together. Pions themselves are made of quarks, so it isn't as fundamental as a theory involving quarks and gluons.


 What causes two quarks to be "attached"? 

Asked another way: why doesn't a quark from the right side of my body feel an exceptionally strong attraction to a quark on the left side of my body?  Two quarks are "attached" because they exchange gluons. That gluon is going to be absorbed by neighbouring quarks before it is absorbed by faraway quarks. This is why I am saying a system of three differently colored quarks does not feel the strong force: there's always somewhere nearby for the gluon to go.

That being said, I do believe it is possible for, say, a proton to interact with another proton through strong force, just not very likely (the gluon needs to escape the proton). This is why you'll see people talking about a Van der Waals-type interaction in this thread. &gt; However, for any force you need a particle that will mediate it. For electromagnetism, that particle is the photon, which is massless and chargeless.

I apologize in advance for what are probably very basic questions, but what particle mediates gravity? Is it also the photon, due to its lack of mass? But photons are still affected by the gravity of black holes, right? So, does that mean they do have some small amount of mass?

I'd also assumed that neutrons were the particle that mediated electromagnetism. What's the difference between a neutral charge and no charge? - The particle that mediates gravity has not been found ; this is among the reasons why the comic mentions that gravity is the least understood of all forces. A new particle, the graviton, has been theorized.

- Currently, we model gravity as a curving of space-time. Imagine putting a bowling ball in the center of a trampoline, and then having marbles roll on the fabric. They'll be attracted towards the source of the curvature. Since this doesn't require them to have mass, you can imagine a photon would do the same.

- Photons are completely massless.

- No charge and neutral charge is the same thing. Neutrons, however, are a kind of fermion, while photons are a kind of boson. The difference between the two is hard to explain simply, but only bosons mediate forces. The gluon is also a massless boson. (Although you don't need to be massless to mediate a force. The boson associated with the weak interaction does have mass.) Let's say two quarks are separated, green and anti green. Now if they're pulled to the point where enough energy is available for another pair to pop out, where does it come into existence? Does it form in the midpoint of the distance and finds its way to its respective quark or do they individually come into existence next to their respective quark? Next to their respective quarks, because they would need energy to be far away, and the energy is pretty much all used up to make up their masses. Their distance to the other quark will depend on how much energy is left after filling the mass in. Don't be sad!  We understand the fundamental forces perfectly well (err, except gravity..  We're working on that one).  At the classical (i.e. non-quantum / first-year-physics) level, we're taught to think about forces F = {some function of position and time}, and we're taught that forces act on particles causing them to accelerate.  More often, we talk about the potential of a force, which is just it's integral.  So for newtonian gravity and coulomb interaction we talk about a 1/r potential (which leads to a 1/r^2 force when you differentiate).

First, let me try to describe how a force is different from matter from the POV of modern theoretical physics, then I'll get to specific examples.  In the language of quantum field theory, which is how we currently talk about fundamental forces, a "force field" is a field which is introduced into your equations in order to impose that some symmetry of the matter fields holds true.  The procedure of introducing forces into your matter equations is known as "gauging" the matter.  The whole procedure is called "gauge theory."  All of the forces that we understand well (i.e. everything but gravity) are described using gauge theory, and we don't know why it works so well.  But it does and we're big fans of that so we do it a lot.
Once you have a theory with "matter fields" and "force fields," you can extract classical potentials (like 1/r potentials) from the quantum field theory.  But the full quantum field theory is capable of much crazier behavior which is all insignificant at the classical level but is very significant at the quantum level (things like vacuum polarization). 

Specific example time.  The first force that we really understood properly was E&amp;M, so lets talk about that.  For brevity, I'm going to gloss over some details about the fact that electrons have spin.  If you write down the equation for electrons by themselves (with no forces), your electron field is a complex valued function of space and time.  I.e. your electrons are described by, 

phi(x,y,z,t) = some complex number

Your equation for the electron field is something involving phi and derivatives of phi.   Something like

your equation = |phi|^2 + |grad phi|^2

(if this equation is confusing, don't worry about it.  I just wanted to throw it out there).  Now you notice that if you multiply phi(x,y,z,t) by a constant phase everywhere in space and time

phi(x,y,z,t) --&gt; phi(x,y,z,t)*exp(i*C)

your equations stay the same.  This is known as a global symmetry.  However, if you let that phase vary with position and time,

phi(x,y,z,t) --&gt; phi(x,y,z,t)*exp(i*C(x,y,z,t))

your equations won't look the same anymore because you'll have extra terms from taking derivatives of C.  If the equations looked the same for C(x,y,z,t), it would be called a "local symmetry."
Here's the key point: in gauge theory, we INSIST (for no good reason!) that the local symmetry MUST hold.  In order to MAKE it hold, we introduce a new field which sucks up all the extra terms and makes our equations look the same as they did before the phase factor was introduced.  This extra field is a force field, by definition.  So a cute and kind of grandiose way to say it is "the symmetry of the electron field necessitates the existence of the electromagnetic force (light)."  The form of the electron equations and the symmetries therein determine everything about the electromagnetic force equations.

In a more complicated theory like the strong nuclear force, you start with a matter field, the "quark field," which has a much more complicated global symmetry built into the equations.  Then, when you insist that the symmetry hold locally, you get a force field with a much different character from the E&amp;M field -- in this case, you get the gluon field of the strong nuclear force.  The different character of the force arises from the different character of the symmetry of the matter.  (Aside: The reason quarks of three colors is related to the global symmetry of the quark field.)

So that's what force fields are and where they come from, but now what about all that 1/r potential stuff from classical physics that we're familiar with.  As I said, once you have the quantum field theory for a force, you can extract the classical potential.  It turns out that the form of the classical potential has a lot to do with whether the force field has a mass.  It turns out that one can show that any force field which is massless will lead to a 1/r potential.  Photons (electromagnetic force), gravitons (gravity), and gluons (strong nuclear force) are all massless and so all lead to 1/r potentials.  The strong nuclear force has a peculiar feature that the next correction to the classical potential is linear, i.e.

V_strongnuclear = a/r + br + ...

So if you try to pull two quarks far apart, the 2nd term eventually kicks in and the force starts to get STRONGER rather than weaker (1/r falloff).  This leads to quark confinement (trapping quarks inside of protons/neutrons/etc) as mentioned below.  Caveat: unlike the e&amp;m and gravitational potentials, which work well at long distance, the strong nuclear potential above works well only at short distance (~radius of proton).

The weak nuclear force field has a rather large mass, and this leads to a different classical potential known as the Yukawa potential

V_weaknuclear = a*exp(-m*r)/r

This type of classical force has a much SHORTER range than 1/r potentials because of the exponential fall off due to the nonzero mass.  Here's a sort of ELI5 explanation of how the weak force / yukawa potential different from E&amp;M.  Particle A wants to communicate with particle B via some force.  He happens to have a friend, E&amp;M, who is an Olympic runner.  Because he's so "light" on his feet (get it?) he can deliver the message very far.  The force has a long range because the force carrier has a small mass (zero mass, really, for light).  In a different scenario, particle C wants to send a message to particle D, but particle C hasn't chosen his friends carefully in life and can only get his friend the weak force to deliver the message.  The weak force is a heavy guy who doesn't work out much, so he's not willing to carry the message more than a few blocks.  The force has a short range because the force carrier has a large mass.  

Some fun caveats about the weak force.  Matter particles actually have two "pieces" -- a left handed and a right handed piece (not the same as antiparticles).  The weak force actually only talks to the left handed part of the particle, but the right handed part doesn't know anything about the weak force.  This is a big part of the reason why it is interesting that neutrinos have mass.  Massless matter particles only have a left handed piece and no right handed piece, so -- since neutrino's only interact via the weak force (and gravity) it's impossible to learn anything about the right handed piece directly.  So originally we assumed they were massless and that the right handed piece didn't exist at all.  But now we know it's there, and it's a big mystery. We can't probe it directly because the weak force doesn't talk to that part of the particle.  We can only learn about it indirectly.
Another interesting caveat is that the weak force actually has three different aspects to it.  If you want to think about it in terms of particles, there is not one particle that mediates the weak force, but three.  The neat thing is that two of them have an electric charge (one is postive and one is negative, the W+ and W- bosons respectively).  Its interesting because a particle, through interacting with the weak force, can change into a different type of particle with different charge.  This is how beta decay works: roughtly speaking, a neutron interacts with the W field and is able to change charge from neutral to positive and become a proton!

An interesting note: even though it is not a "fundamental" theory, the interaction of neutrons and protons via the strong nuclear force can be modeled by an approximate force field called the pi-meson field (this is called Yukawa theory).  The pi-field has a mass and so the classical potential looks just like the weak nuclear force potential above.  This was one of the early models for the strong nuclear force before quarks were discovered.


Edit: added more ramblings about the weak force by request and as a way of saying thanks for the gold! Hey, you are really GOOD at this (explaining things clearly).

I have completed a graduate level course on electromagnetics, but have never studied gauge theory, and your use of em to illustrate gauge theory was useful. You've made me curious to go out and try to understand what this symmetry is that gives rise to the strong force.

Your explanation of the weak force is pretty light, (giving the shape of the potential and really nothing else) but at that is still the most detailed explanation I have ever encountered. (It beats the heck out of "mumble mumble Radioactive Decay mumble mumble"!) Really helpful, thank you for taking the time to make it so understandable.
 Oh good!  I'm never sure if I'm making any sense at all.  If you've taken grad E&amp;M you should be able to understand gauge theories pretty well at least at the classical level (assuming you've seen lagrangian field theory).  Spoiler alert: the symmetry of the strong force is called SU(3).  You can find a pretty good treatment of basic gauge theory in griffiths "introduction to particle physics," or a more advanced treatment in Peskin and Schroeder chapter 15. To understand what each of the fundamental forces are, the first question we must answer is this: *What is a force?*

In the most general sense, **a force is any external interaction which changes the state of a particle**.

From classical physics, we know that any particle which is left undisturbed will travel in a straight line with constant velocity forever. Nothing interacts with it, nothing changes.

Then **gravity** comes in. A particle which comes near anything with mass will have its momentum changed. The heavier the mass or the closer the object, the faster the momentum will change. The particle will speed up, slow down, change direction, or some combination of those.

How? Every object that has mass/energy effects space and time. The details don't matter, but what is important is that heavy objects tend to "pull" on space. Which makes space and time bend in weird ways. When sometimes encounters this bent spacetime, it will still follow a straight path through that bent spacetime, but its actual trajectory will seem curved, sped up or slowed down.

So far so good for objects with no charge. But sometimes particles have an **electric** charge through which they can affect each other's momentum. They don't simply attract, but can also repel. The two types of electric charge are labeled (+) and (-), opposites attract and likes repel. How strongly? Well, the stronger the charge the stronger the force, and the closer together they are, the stronger the force.

But that's not everything. If you carefully measure the forces from these electrically charged particles, you would see that something is "off" when they're moving. The forces are not *quite* what you'd expect. It turns out there is another effect in play, that of **relativity**. When objects move fast, weird things start happening like lengths that become shorter or timescales that become longer. Again, the details don't matter, but they have a measurable effect on the kind of forces that these electric charges exert on each other. We call the difference between the force we'd expect from a static picture, and the actually measured force **magnetism**.

But how does this work exactly? This is the point where we start looking at microscopic stuff and things get **weird**. Lets forget everything we know about particles and forces and start from scratch. A particle can be considered as a very small chunk of highly condensed energy. As we all know, energy is conserved, but can be changed from one form to another. A particle like an electron, which is a small chunk of condensed energy, can be split into two different chunks of energy: a new^1 electron with different kinetic energy and a photon.

e^-  e^- + 

How often does this happen? All the time. Randomly^2. It just does, in every direction. But it averages out to zero, so we won't notice anything in a single particle. But this photon can be absorbed by another electron.

e^- +   e^-

Now the second electron has absorbed the momentum the photon was carrying, and the result is a force between the two electrons. Photons are massless and do not decay, so this charge can reach infinitely far. A bajigazillion (technical term) exchanges of photons produce a huge change in momentum, which we can easily see as a classical force. Furthermore, the photon has no electric charge, so doesn't interact with itself.

So much for the classical forces. But what about the others? We're getting into slightly unfamiliar territory, but the same principles still apply. Beyond electric charge, certain particles, called **quarks**, also have **color charge**. Instead of two, there are three types of color charge, labeled red, green and blue. These are the charges of the **strong force**. Obviously, these charges have nothing to do with actual colors, but they are named so because three of those charges are required to neutralize each other.

If you have a positive and negative electric charge and bring them close together, the effects you feel at long distance will be almost zero, because the effect of the two charges neutralize. The same happens with color charges, though you need three quarks of different color together to get **neutral**. Another option is having a quark/anti-quark pair with corresponding color/anti-color^3. You're probably wondering if this also works in terms of "likes repel and opposites attract", but the situation is slightly more complex.

Just as the electromagnetic force is carried by photons, the strong force is carried by **gluons**. What does this interaction look like? Does it change the momentum of the particles like the photon does? Yes, but that's not the only thing. Gluons are not color neutral. They carry a color and an anti-color charge. Tt effectively allows them to change another particles color charge. So for example:

blue quark  red quark + blue/anti-red gluon

And if a red quark happens to be nearby, it can absorb the gluon:

red quark + blue/anti-red gluon  blue quark

But that's not all! The gluons can also couple to *each other*:

green/anti-blue gluon + red/anti-green gluon  red/anti-blue gluon

Gluons are massless, like photons, meaning they can reach infinitely far. But because they can interact with themselves, that also allows them to multiply as they travel (just reverse the interaction above). So that means that the further two quarks are apart, the more gluons they will be sending to each other. This results in the force getting **stronger with distance**. Luckily this doesn't spiral out of control, eventually the energy in the intermediate space will become so large, it will condense into a quark/anti-quark pair, forming new neutral particles with the ones that were interacting previously.

Three quarks can form a **proton** or a **neutron**, each having a neutral color charge. But sometimes gluons escape, allowing them to interact with each other. These "leakages" are what holds atomic nuclei together, but the specific interactions are fiendishly hard to calculate.

Now what determines whether three quarks will form a proton or a neutron? The answer is quark **flavor**. The only two relevant flavors^4 for us at this point are called up and down. The up quark has an electric charge^5 of +2/3, while the down quark has an electric charge of -1/3. A proton consists of *uud*; two ups and one down. This gives it a total charge of +1. The neutron is *udd*, with zero electric charge^6.

Why is this relevant, you ask? Because of the **weak force**. It is the third^7 interaction that governs the quarks in the protons/neutrons in the nuclei, alongside the electromagnetic and strong force. And the question is of course what it does. It affects momentum, just like the electromagnetic and strong force, but that is the least important of its effects.

Because the weak force is the only interaction that can **change flavor**. Now this works the same as the other two. The weak interaction has three force carriers. The W^+, the Z^0 and the W^-. Their electric charges are +1, 0 and -1 respectively, and the two W particles are each other's anti-particle. I won't go into detail about the Z, so lets consider the W's.

A quark will spontaneously emit W particles, just as it emits photons and gluons. This works in the following way:

*u*  *d* + W^+

An up quark can emit a W^+ and change flavor to a down quark. If another down is nearby, it can absorb this W^+ and change itself into an up. This will have its usual contribution to change in momentum, but overall we will still have an up and a down.

But what if an up quark in a proton emits a W^+ and the W^+ escapes? Well, it will turn the proton into a neutron, because the total quark flavor will have changed from *uud* to *udd*.

p^+  n^0 + W^+

Likewise, a neutron can change into a proton by emitting a W^- or absorbing a W^+.

You might ask what happens to the W now. These W particles are quite heavy, so they will quickly decay (break into smaller chunks of energy). Which ones, well...

W^+  e^+ + _e

Okay, what happened here? The W broke up into an anti-electron and an electron **neutrino**. Neutrinos are nearly massless, neutral particles which only interact through the weak force. Although there are many interesting things about them, there isn't much to say about them in this context. They hardly interact at all with anything. They just kind of pass through everything.

This is the mechanism with which (beta) **nuclear decay** occurs. If an atomic nucleus would be more stable with a different proton/neutron ratio, a proton will change into a neutron or vice versa. Why specific ratios are more stable is then again determined by the electromagnetic and strong force.

I hope you at least understood some of that :)

^(1 How can we distinguish between a new electron and the same electron which simply bounced off a photon? It depends on your interpretation of "same electron". In essence, all electrons are identical and indistinguishable. But every time an electron's state is changed, such as its momentum or any other feature, it could be considered a completely newly created particle while the old one is destroyed.)

^(2 The probability of this happening is actually tied to the amount of momentum and energy the photon is carrying but the details of this are very technical.)

^(3 Anti-quarks do not carry color, but anti-color. They are aptly named anti-red, anti-green and anti-blue.)

^(4 There are six of them. Up, strange &amp; top have electric charge +2/3; while down, charm &amp; bottom have charge -1/3. There are corresponding anti-quarks with anti-flavors and opposite charges.)

^(5 These are fractions of the elementary charge *e*. The charge of the electron is -1.)

^(6 There are some wonderful experiments that map the position of + and - charge within the neutron. It also has a significant magnetic moment because the quarks are not stationary.)

^(7 Gravity is irrelevant here)

[TL;DR](http://xkcd.com/1489/) Before reading this, I had a 0.1% understanding of the weak force. Now, I have 2% understanding of it. So here's the deal: the weak and strong force are understood perfectly well, on a par with electromagnetism.  The xkcd is not reflecting the state of our knowledge, but rather the difficulty in explaining detailed scientific concepts in non-technical language.

One should realize that the descriptions of gravity and electromagnetism given in the xkcd are nowhere near the full picture of those forces; they are the little pieces of those forces that are easy to describe in simple algebraic terms.  But neither force is completely explained by those two inverse square laws.  At the classical (non-quantum) level, for gravity, we need the contributions of general relativity, and for electromagnetism, we need such things as magnetism and electromagnetic induction, things covered in any intro course.

In addition, because the weak and strong forces are short range, you can't really talk about them effectively, in terms of their behavior in the world, without quantum field theory, whereas electromagnetism and gravity have useful classical limits.  But explaining quantum electrodynamics is way more complicated than the inverse square law or the inverse square law plus magnetism and all that, and probably no easier than explaining the weak and strong forces; try to explain gravity at the quantum level, and we don't even have a technical answer, much less a non-technical explanation.

I know this doesn't answer your question directly, but I think the context is important.

Edit: Phrasing improved.
 If you read the associated text,

&gt;"Of these four forces, there's one we don't really understand." "Is it the weak force or the strong--" "It's gravity."

so it does acknowledge we actually do understand the weak and strong forces. I think his point is more that the cartoon acts as if the explanation given for gravity and EM is complete, when in fact it is a simplified lay-understanding version. There are just simply not good lay-understanding versions of the strong and weak nuclear forces.

[Relevant favorite Feynman video on the subject](https://www.youtube.com/watch?v=36GT2zI8lVA) But gravity and electromagnetic forces are the only ones we can directly observe without having very expensive equipment. So even though we don't understand gravity, we can express it, because we all have direct experience with it. Where do you see this associated text? Either hover or go to the mobile version http://m.xkcd.com/1489/ and click on it.  For others: every xkcd has a secondary joke as hover text; it's worth your while to make hovering over them a habit when you read them.  [deleted] [deleted] Addendum: to read the hover text on an iOS device, press and hold on the image.

The text will be along the top of the Save Image / Copy / Cancel dialog. [deleted] Many other webcomics do it now, too, so it's worth checking out on any webcomic you stumble across.  The alt text also comes through on the RSS feeds which is nice. 

The same applies to what-if [deleted] [deleted] [deleted] [deleted] I found the strong force part hilarious.  For the strong force being known supposedly so well, it is terrible for dealing with nuclear systems.  Predictions for cross sections and excited states for nuclei are all over the place.  Multinucleon interactions are barely understood since they are multibody interactions.  The strong force describes the fundamental interactions between quarks. 

Using the same strong force to explain the residual strong force between neucleons is akin to using electromagnetism/coulomb potential to explain chemistry and its compound's bulk material properties. 

 &gt;Using the same strong force to explain the residual strong force between neucleons is akin to using electromagnetism/coulomb potential to explain chemistry and its compound's bulk material properties. 

But that's totally possible.  There's an entire field called computational chemistry that's more or less dedicated to that exact proposition.  It's complicated, sure, but you can model a molecule and predict many things about it. There's a similar field for strong interactions and it's called lattice QCD, which basically tries to brute-force the equations numerically. They have come a long way from qualitative results of known results to making predictions that are taken seriously by the community.

They are still at the single hadron level - so the strong force analogy of the hydrogen and helium atom. But they might get to nuclear forces one day. Yes I know people that do lattice qcd. It is a long way from being useful for most nuclei, but it is advancing at a quick pace.  I realize that a *full* explanation of the forces can be achieved by nothing less than the full mathematical theory. But I can do a decent job of explaining gravity to someone by saying something like this:

&gt; Things attract each other in proportion to their mass, and the effect drops off with an inverse square law. In other words, "F = G * m1 * m2 / d^2". This approximation is accurate until you get forces or speeds that are not negligible compared to the speed of light; in that regime, a more accurate description is that 4-dimensional space-time is curved by the presence of energy (counting rest mass as energy using "E = m * c^2").

And frankly, I wouldn't be doing TOO badly if I left off the second half of that and just gave Newton's equation -- it would still give the reader a rough idea of what gravity is.

I cannot recall seeing such an explanation for the strong or weak force. Nor do I understand them well enough to construct such an explanation myself. Even if not telling the FULL story (as newton's law of gravity is imperfect) it would still give some useful insight. Have you seen such a "layman's summary" anywhere?
 I think part of the problem here is that gravity and electromagnetism have classical limits where they work as forces between objects that have  a relevant "charge" (gravitational charge being mass). There simply is no classical force analog for the strong and weak interactions (except perhaps for short-distance strong interactions, but that does not help describe anything larger than a proton).

The electromagnetic interaction does not *just* result in a force between charged objects. It is also responsible for particle-antiparticle annihilation and pair production, the radiation of accelerating charges, etc. Causing a force that goes like an inverse square law at large distances is just one of the things that it does. I think that if there will be a layman explanation of the strong and weak interaction that is on par with gravity and electromagnetism, you would have to throw out the types of explanations of the latter in terms of forces with an inverse square laws and instead re-explain them as fundamental interactions between quantum fields. That's the only way you're going to get any consistency. Part of the problem is that there is nothing by which you would need to reference the strong or weak forces in layman's terms.  As far as a layman is concerned, saying "the strong force holds the nuclei together" and "the weak force mediates radioactive decay" *is* the layman's description.  You can't really go into the descriptions much further without getting into some mathematical and quantum theory territory. Saw this video recently of [Richard Feynman (theoretical physicist) trying to explain how magnets work](https://www.youtube.com/watch?v=MO0r930Sn_8)

He give a very good explanation on why you rather quickly run into trouble trying to explain advanced psychics with "layman's terms". Really great video, and a terrific explanation to a question I often have As someone with a very basic understanding of advanced/modern physics (I'm a geologist, only took, like, 3 courses of physics during graduation), how is the strong force different from gravity?

Edit: I meant different in terms of how it works, holding the nuclear particles together, similar (to me) as to how larger particles are hold together in space, forming planets and such. I know that the strong force is orders of magnitude stronger than gravity. It's pretty different. The main difference between the strong force and say, gravity or electromagnetism, is that the particles which mediate the strong force, gluons, themselves have 'colour', which is to the strong force like mass is to gravity and electric charge is to the electric force, unlike the chargeless photon for the electric force.

This has the consequence that the strong force actually gets stronger the further you try to pull two quarks (quarks being the only particles other than the aforementioned gluons which have colour) apart. Which is why you never find free quarks, only particles made of quarks, like protons. 

If you try to split a proton apart, you end up putting in so much energy that you create quark/antiquark pairs from the energy. So one of the major things that comes out of the LHC in proton-proton collisions are vast sprays of particles made from quarks, because collision energy gets converted into quark/antiquark pairs. Hmm, nice, I'm surprised I actualy understood all of that haha, thanks.

I can assume that, like gravity, we don't know why the "color" of the particle generates force, right? Why gravity generates force is actually an easy one; it doesn't. Gravity curves space-time. An object orbiting the Earth is going in a dead-straight line in a space-time that's been curved by the Earth's mass, so it looks like it's going in circles. What feels to you like weight is the force of the floor pushing you up, causing you to accelerate. It's the exact same principle as, say, sitting in a car that's accelerating. The feeling of being pushed into your seat is because the car is accelerating you, pushing you off the constant velocity path you would otherwise take.

The main problem with gravity is that general relativity isn't a quantum theory, so it can't be the final description of gravity.

As to why particles with colour exert force on each other, that's a bit of a tricky question. Why does something called "colour" exist? For that matter, why does electric charge exist, and why do some particles have it, and some not?

The answer is, weirdly, often to do with symmetry. There's a theorem (Noether's theorem) which states that there is a conserved quantity associated with symmetries of physical laws. Electric charge is associated with a global phase symmetry of the wavefunction, for example (you can add a phase shift to every wavefunction in the universe, and physics would all work the same way).

The strong force is associated with a symmetry which is called in the wonderful notation of group theory SU(3), and the properties of that group give rise to colour, and the way that they interact. It's a similar principle for electromagnetism and the weak force, they have symmetries, and their symmetries determine their properties.

So the current best idea for why certain types of particle exist, and why they have certain properties (such as the ways they interact with each other) are all to do with these abstract mathematical symmetry properties. Why these exact mathematical entities are the ones which make up our universe is still an open question, but they're always looking for more symmetries, and ways in which the ones we know of could just be parts of a greater whole. A popular idea is that there might exist a symmetry which is known as "supersymmetry", and if it existed, there would be lots of new particles out there to potentially discover. So far, no evidence of it, but it was a neat idea. Being able to break things down into a fundamental layman approach helps even those who work in the field develop their knowledge.  For instance, my calculus teacher hammered into us the first week of Calc 1, "position, velocity, acceleration are the basis of derivatives". From there it was a small leap to understand that velocity was merely the slope of the curve from point a to point b. The given 'explanation' if you can call it is close, it just needs a little more to give it that basis through which students can truly grasp it and use it. Gravity and magnetism have it already due to their equations.  So, yes, you can (and did) do a pretty good job of giving a simple explanation of **how** gravity works. However (and please correct me if I'm wrong), we still really don't understand **what** gravity actually is. 

When you simplify it, Einstein's general theory of relativity posits that gravity is simply the geometric phenomenon that results when you place a massive object in 4d (or more if you're into *strings*) space-time. We understand **how** it works, because we can feel and measure the warping effects. But we really don't understand **why** massive objects have this effect on our space-time geometry.

 You can do something similar with strong or weak forces as well.

Strong forces are what's needed to hold nuclei together.  It's effect can be related to the binding energy of a nucleus.  The mass of a nucleus is:

Zm_p + Nm_n - E_b/c^2

where Z is the number of protons (atomic number) and N is the number of neutrons in the nucleus.  E_b is the empirically determined binding energy of a nucleus.  We can notice that E_b has a maximum near the atomic number/mass of Iron.

Want to know more about how to predict those numbers?  Here's some math - start calculating.

Weak nuclear forces are involved in radioactive decay.  When nuclei have larger atomic numbers/masses w.r.t iron, then can be put into precarious configurations where it is advantageous for them to disintegrate into smaller fragments, each with a lower atomic number of larger E_b.  The simplest such processes involve the release of an alpha particles (emission of a helium-4 nucleus), the conversion of a neutron to a proton and an electron or the capture of an electron to convert a proton to a neutron.  During most of these, any excess energy is usually released as gamma radiation.  These processes are usually follow zero-order kinetics: i.e the chance of a single nucleus undergoing a reaction is independent of the concentration of atoms.  This gives us the familiar half-life equation.

Sure...  the above explanations are simplifications and lies.  But *shrug* so are the others.  I omit criticality and chain reactions just as the original explanation ignore magnetic interactions.  I ignore quarks just as the original explanation ignores photons and non-classical statistics.  And all of the above area already covered in a good high-school physics curriculum, right along side an equivalently targeted lesson on E/M, gravity, thermodynamics and relativity. What is considered not negligible compared to the speed of light? &gt;0.1c? Well, ANY speed at all produces SOME level of errors. Many of the equations for special relativity (a simplified version of general relativity) use the term "1 - v^2 / c^2", and the simple Newtonian understanding of gravity just uses "1". So I guess as long as you think "1 - v^2 / c^2" is "close enough" to 1 the speed counts as negligible. It all depends on how accurate you want to be. Its the square root of 1 - v2 / c2 which makes it even more negligible at small velocities &gt; It all depends on how accurate you want to be.

And what you are doing. You can ignore special relativity in normal life, right up until the time you can't. Same with general. It's perfectly possible to stray from a 'negligible' regime to one where relativity plays without realising - which really screws you up until you click what's going on.

And that's often when you are looking at the difference/interferometry (just a rule of thumb for you).  A ballpark estimate for the error of using non-relativistic equations is &lt;speed in multiple of c&gt; squared.

So 0.1c is about 1% error. [deleted] [deleted] [deleted] [deleted] [deleted] For me the idea of weak interaction as a force in terms of an attraction between two particles is unclear.

Let's say that we have beryllium-7 atom that has has a probability with a 53 day half life to undergo electron capture decay to lithium-7. This decay is explained using weak interaction between one of the protons in the beryllium-7 nucleus and one of its electrons. In that sense there is no mystery.

But now, let's say that beryllium-7 have not and will now decay via electron capture for days. Is there a force, in terms attraction or repulsion, between the nucleus and electrons. Meaning if we were able to turn off and on the weak interaction in our universe, would that change the localization or the wavefunction of the electron. Would we be even able to say a number in newtons for the force due to weak interaction in addition to the electric attraction between the nucleus of a beryllium-7 and, let's say, 2p^1 excited electron?
 I thought that our knowledge of strong interactions was not that great, that we could only hope for ~10% accuracy with our calculations. 10%?  That is really good in nuclear physics.  Some measurements in nuclear physics are lucky to get to 30%. Exactly, how is that as accurate as qed calculations where we can measure the magnetic moment of an electron and it agrees with theory to 12 or so decimal places? To be fair, science has issues trying to accurately predict multibody systems in general.  We know the hydrogen electron shell structure very well, uranium is another story.   That is a good point. I think part of the problem is that we start by calling them all "Forces", which is more or less an empty concept at the quantum level. So when we get to the part about describing the nuclear forces, we wave hands because they're not forces. Not in the Newtonian sense that we've just prepared the listener for with Gravity and EM. I like /u/iorgfeflkd 's description of the nuclear interactions.

Actually... I tend to think of the strong force as kind of an anime tentacle-monster. Another thing that a lot of people don't realize is that **the** nuclear force actually isn't one of the fundamental ones, it's the vanderwaalized version of the strong force. What do you mean by "the nuclear force"? Are you talking about the residual nuclear force holding nucleons together? Yes Can you please expand on your anime tentacle monster analogy? [There was a thread last month asking how protons and neutrons stuck together in the nucleus, and I gave a sort of ELI5 explanation of field theory and the strong force, so that might be an interesting read for some people.](http://www.reddit.com/r/askscience/comments/2q9yb5/how_do_protons_and_neutrons_stick_to_one_another/)

Admittedly a few parts are gross oversimplifications, but I think it might give you a flavor of how these things work if you've never heard of them before.  The strong force is like a spring that connects quarks, but when you try to pull it apart it makes more quarks. The weak force is like a tennis ball that you throw at a basketball to turn it into a ping pong ball.

The thing about not understanding gravity is a bit overblown. Saying "gravity as a quantum field theory is non-renormalizable" is not the same as saying we don't understand gravity. &gt; The thing about not understanding gravity is a bit overblown.

But we also don't understand dark matter, right? So it seems like we don't understand gravity at the very small scale *nor* at the very large scale. If dark matter is an undiscovered particle (which seems very likely), then it isn't a problem for our understanding of gravity - it has mass and obeys GR just like anything else.  Well that's more a matter of not knowing the composition of the universe. &gt; The strong force is like a spring that connects quarks, but when you try to pull it apart it makes more quarks. The weak force is like a tennis ball that you throw at a basketball to turn it into a ping pong ball.

The spring analogy helps me understand that the force increases as you pull the quarks apart, but doesn't help me understand that a new quark just pops into existence at some point.

Does this make any sense at all:

The strong force is like a magnet that "connects" a North and South pole. When you divide the magnet in half, you get two more poles. Can you elaborate more on the weak force?  I feel like I have a decent understanding of what all these forces mean except for the weak force. Can anyone please explain that in somewhat simple terms? (assuming high school level physics + background knowledge on physics enough to know that gluons mediate the strong force) I thought it was funny. \*shrug\* Okay, to be honest, so did I. But if there are no better explanations than this (and until I saw /r/LArlesienne 's [response](https://www.reddit.com/r/askscience/comments/2wjonl/xkcds_fundamental_forces_isnt_funny_its_sad_can/corku10) to this story I hadn't heard a better explanation) then that's pretty sad also. The issue is that, when people hear the term "fundamental force," they immediately assume that we're describing a force in the classical sense  or, more accurately, something which creates a classical force. Gravity, electromagnetism, and the strong force all create forces on different particles and objects (e.g. Newton's law and Coulomb's law), which is why people have this paradigm, put it's not a complete way of looking at things.

More accurately, a force is a set of rules that determines how a certain class of interactions take place. For example, the electromagnetic force is a set of rules that determines the interactions between charged particles and photons, and between photons and other photons. Some of those interactions result in a force (e.g. Coulomb's law), but there are many cases where this doesn't happen.

When you start looking at a force as a set of rules, rather than as something which creates a classical force, then the weak force stops being problematic. It's just a set of rules governing how W and Z bosons interact with other particles. Calling it a force seems to be a way to understand these interactions in the role they are changing the world every moment, as what forces do to a body classically.  
Besides it's cooler. The gravitational force holds the universe together.  The electromagnetic force holds atoms together.  The strong force holds nuclei together.  And the weak force is the one you can't explain to your non-physicist friends.

(I'm a physics professor and this is my tried-and-true introductory explanation.) I'm actually reading "Brief History of Time" and have just got to this chapter. I haven't finished yet, but it's a very good book in explaining the issues we currently face in unifying the theories of the 4 forces.  
Sorry I can't answer here but thought you might like the read.  I'm also a huge XKCD fan too! When two nuclei touch, nuclear fusion occurs, so ignoring reality the two would fuse together.

Bringing reality back, in the process of getting those two nuclei to touch has more than likely ~~annihilated~~ obliterated you, the table, and anything nearby, because fusion takes an insane amount of energy.

Edit: Since people keep mentioning it I don't mean literal annihilation in the term of a particle and antiparticle colliding, just on a macroscopic scale. Let's just go with obliterated.

So many questions. I'm sorry everyone, I'm just too tired to answer them all. So fusion reactors are basically just trying to make the atoms touch? Yes, the only problem with them currently is because of the energy requirements to fuse nuclei the reactors have a negative net energy. There's been a lot of work and research on lower energy fusion but none of it has resulted in a reliable power source, yet.

Edit: Yes, stars, hydrogen bombs, and other fusion based weapons produce a positive net energy, I was referring to a sustainable form of power generation such as a power plant. If you know of a reliable, sustainable form of fusion reactor that exists today, on earth, I'd love to read about it, and be informed as to why it's not being used to power our cities over polluting sources of energy like oil. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Lockheed Martin's Skunkworks division recently came forward after lengthy research with a [compact fusion reactor](http://www.lockheedmartin.com/us/products/compact-fusion.html) they hope to be operating in the near future  I saw an article from an academic who works on nuclear fusion that was extremely scathing about that news story. Essentially he pointed out that they had only done a paper exercise and until you build a prototype you've really no idea if you can get net energy production. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] My comment will most likely be buried, but I'd like to point out a small detail. The energy produced by nuclear fusion is actually greater than the energy we use to induce it. The loss of energy that makes fusion power currently inefficient is not in the reaction,  but in the way we hold the reaction in place.  We use super conductors. Super conductors take a large amount of energy to keep extremely cold so that they don't lose their super conductive properties. So you are still correct.  I just wanted to clarify that the energy loss is not in the reaction, but the "container" of the reaction.  Its more that the plasma is constantly dumping the energy in the form of heat, light, UV, and even X-rays. So its incredibly difficult to keep it hot. 

If we had a magic force field that reflected all that EM radiation back into the core, things would be considerably easier. 

For electrostatic confinement devices, the losses are impingement on the framework/meshes as well. This is what the polywell device is/was attempting to overcome. &gt; be informed as to why it's not being used to power our cities over polluting sources of energy like oil.

I wonder the same question about fission reactors. The water vapors coming out of the cooling towers, and the word 'nuclear' are scary!  I was under the understanding that we've been seeing net positive power from fusion, but just not enough to make it economically feasible. A billion dollar 9-volt battery isn't going to power the world. Is there really any chance of fusion ever producing net positive energy?   Generally speaking, fusing atoms smaller than iron produces energy and fusing larger atoms requires energy. Splitting small atoms requires energy whereas splitting atoms larger than iron produces energy.

But thats not really what the problem is with fusion reactors today. Both fusion and fission require huge temperatures and huge pressures. Getting those initial conditions is the challenge of scientists today. Why is iron the threshold? Iron is simply the point at which the nucleus is so big that the electrostatic repulsion between protons is roughly equal to the strong force attraction between them, since the strong force has a comically short range.Add any more protons and they eventually start kicking each other back out.  The more protons you add, the faster they escape. Really nice analogy.  Answers a question I never knew I wanted answered. Because iron is the breaking point, you do not see elements heavier than iron being created during normal fusion processes in stars. All elements past it are formed during supernova events. That we have a lot of heavier elements is evidence that our sun is not a first generation star. 

All the precious metals (or simply coinage metals) that we use have an atomic number heavier than iron. This means that the jewelry you wear is actually a piece of a dead star.  It has to do with the size of the nucleus and type of energy binding it. 26 protons is the "tipping point."  Could you explain why that is in more detail, please? The strong nuclear force is much much stronger than the electromagnetic force of protons repelling each other, but that electromagnetic force acts over a longer distance than the strong nuclear force. There becomes a point where they are "cancelling each other out" per se because the size of the nucleus gets large. Because of the size of nucleons and the strength of the forces, this happens to be at Iron/Nickel. Above that, fusing atoms requires an input of energy, therefore fission releases energy. The atoms that already exist that are that size are holding this "extra binding energy" that was given to it when it was first created. Split it into smaller atoms and it releases some of this energy. Why don't atoms above iron fission spontaneously? What keeps them together if the strong force is overwhelmed by the electromagnetic one? Thank you. I always have wondered how two inverse phenomena (fission, fusion) could produce energy.  Think of a spring.  If a rope is stretching it and you cut the rope, that releases energy.

On the other hand, the spring might be compressed.  But the result is the same.  Opposite actions, but both release energy.

In the middle, where no energy is being stored by compressing or stretching the spring, is basically where iron sits. There's an experimental plant under construction, called [ITER](http://en.m.wikipedia.org/wiki/ITER), which is expected to start operation in 2027, producing 500 MW with a 50 MW input And after ITER is [DEMO](http://en.wikipedia.org/wiki/DEMO) and PROTO, which will aim for sustained fusion (running as long as there is fuel available) and actually function as a demonstration power plant.  It's exciting to think that this may happen within our lifetimes! Are we still at the point of just producing sustained heat for steam turbines?  Yes, because steam turbines are the most efficient way we know how to turn heat into electricity. The best steam turbines are around 37% efficient. Some googling shows that there are some other techniques that can offer slightly higher theoretical efficiency, but they're not dramatically better, and they're still only theoretical. Not to be pedantic but the obvious answer is yes, look up at the sun and you'll see a huge fusion reactor. More reasonably, yes, we'll get there eventually, in fact we're already pretty close; progress would have to stop entirely for it not to happen eventually. 

Keep in mind, all those "50 years from now for the past 50 years" jokes are based on estimates from half a century ago and an expected level of funding several times higher than what has actually been available. If someone dumped a couple hundred billion into it over the next 10 years I'm confident we'd be energy positive. To be fair, the way the Sun accomplishes fusion isn't really all the feasible for us here on Earth. The core of the sun is thought to only be about a bit under 16 million kelvin. That's pretty hot compared to Miami, but it's not all that hot compared to what we're producing in our fusion reactors today. 

At the temperature in the core of the sun, the actual amount of fusion happening as a percentage of the available fuel is very small. If you took a volume of the sun's core the same size as your body, the amount of heat that that core volume is producing is smaller than the amount of heat your body is producing via your regular metabolism. It's just that the core of the sun is absolutely huge, so overall it's creating a ton of energy constantly. 

Even if we could create perfectly matching conditions to the sun's core in a reactor, it wouldn't be very useful, because it would require an ridiculously large machine to create significant amounts of energy. 

So in our fusion reactors, we aren't really trying to recreate the Sun's core. What we need is a much higher rate of fusion, and that means much higher temperatures. Well over 100 million kelvin. 

Also the Sun just uses the gravity of an immense amount of mass to create the necessary conditions for Fusion. That's not feasible for an Earth based reactor, so the Sun isn't really proof that it's possible to build a working fusion reactor, only that fusion itself is possible. 

 No argument from me, that's why I gave the sun only as my pedantic answer. One of my favorite science factoids is that the sun's power per cubic meter is about the same as a compost heap's.  It's just that the sun is unfathomably huge.

The reason I say its inevitable is because most of the theoretical problems with designing a reactor have been solved. What's left is increasing the scale, a bit of new science, and a ton of engineering.  &gt; It's just that the sun is unfathomably huge.

And then you compare the sun to the likes of, say, [UY Scuti](http://en.wikipedia.org/wiki/UY_Scuti), and your mind is completely blown. Not really. That star weighs roughly 32 solar masses, but occupies a volume 5 billion times larger. This means that the vast majority of the star will be much less tenuous than earths atmosphere, and approaching a decent approximation of a vacuum.

Those supergiant stars have as much in common with a nebula as they do a star.  How would one go about research on fusion as a career? I'm looking to study nuclear engineering next year in college and I want to know where I can go (if you know).  UC berkeley has one of the best nuclear engineering programs. They also have a great EECS-Nuc if you're up for it http://www.iter.org/ A mini sun super suspended by magnets that should power itself once it's on and will provide a crazy amount of energy. yay future stuff &gt; If you took a volume of the sun's core the same size as your body, the amount of heat that that core volume is producing is smaller than the amount of heat your body is producing via your regular metabolism.

Whoa... cool fact. Are you saying pound for pound I produce more heat than the sun? You said "volume" - is the sun more dense than I am? Yes, have you heard of a star? Or a hydrogen bomb? :) [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Yes. JET and TFTR produced roughly 70% of the energy used to sustain the reaction. ITER is being designed to get 5x energy out in "steady state" (averaged over a ~500 second shot length) with a peak  gain of 10x. Even if those are not achieved exactly, it would be a big surprise to everyone involved if breakeven is not achieved. ITER will begin experiments sometime late next decade (currently under construction).  I believe that the research fusion reactor JET in the UK currently gets out 70% of the power put in and there are plans going ahead to build one in France that should be give net positive power in 15 - 20 years.

when all is said and done its predicted we could realistically get out about 20 - 22 times as much power out as we put in. We're [building one right now](http://en.wikipedia.org/wiki/ITER) that should produce 500MW from an energy input of 50MW. If it's successful, the plan is to [build one](http://en.wikipedia.org/wiki/DEMO) that produces 2-4GW from an energy input of 80-160 MW and actually functions as a commercial power plant. Correct me if I'm wrong, but I believe they're currently building a fusion reactor in southern France called ITER.

And according to them it will produce 10 times more power than it uses. Is it like trying to push two magnets together on the same poles? Like they normally repel each other and to get them to connect means pushing them really hard? It is very similar to pushing two magnets together. The reason fusion creates energy though is the strong force. Imagine with your magnets that they were incredibly powerful and you had to push insanely hard to get them to touch, but then, when you finally got them to touch, they suddenly were attracted to each other and all that energy you were using to force them together, along with some extra energy, comes flying back out again. That's what happens when the strong force takes over. But it can only do in when nuclei get *really* close to one another. Cool! How similar to a magnet is it? Because when you try pushing two magnets together at the same pole they get the urge (- wrong word,  but i don't know the correct one) to flip around. Is fusion just flipping around at the last instance to create that massive, sudden attraction? It's not that similar, actually.

Magnets have two poles, electrons have only one (they're strictly negative). All negative poles repel each other, so all atoms do as well. There's no other pole that could be flipped. Isn't the biggest problem cooling the supra conducting magnets that hold the plasma in its place? As far as I know we are already able to heat plasma to the point that the fusion keeps the plasma hot enough. I really do think ITER will prove it's possible. [this](http://en.wikipedia.org/wiki/National_Ignition_Facility) says that they achieved positive net energy in their tests (I'm probably misreading it) in 2013, but apparently still isn't a viable alternative yet. Would it be theoretically possible to "turn off" the electrostatic repulsion? I don't believe they have a negative net energy. My understanding is that they produce a net positive energy, but because of cooling and overheating concerns they can only run for such short periods of time that they're not viable for anything. &gt;Yes, the only problem with them currently is because of the energy requirements to fuse nuclei the reactors have a negative net energy. 

~~That's a common misconception, [we've actually mildly out done it recently](http://en.wikipedia.org/wiki/Fusion_power#2010s) (see citation 100)~~

It's probably the most exciting thing to have happen in my lifetime, so far. My science teacher didn't like that I corrected her on that.

Edit: Crossed out portion is potentially misleading, see below.
 We're still quite a way off net energy output from fusion im afraid. The result from NIF, while promising, does not mean that we can get more energy out of a fusion reaction than we put in (at the moment). They were able to deposit less energy **to the fuel capsule** than the reaction released, but this is still way off ignition (more energy out than **total** energy in). The total energy to the lasers was ~1.8MJ, whereas they got out 14kJ, a gain of 0.0077. Once they are able to get this figure above 1, they will have a net output of energy - ignition.
Its definitely exciting for fusion, and a necessary milestone, but still a good way off energetically viable controlled fusion. making *nuclei* touch.

The atom, i'd assume, includes electrons and the nuclei. Its not enough for the atomic radius to touch, you need them to move close enough such that they are on the order of nuclei distances, even then, it still takes tunneling for fusion to occur then. 

Just for scale, the average "radius" of a hydrogen atom is 53,000 times its nuclei radii, which can be thought as a bare proton.  [deleted] Then why does our skin cells rub off on everything, and how to we get cut? Does the knife part our skin like the Red Sea? That doesn't happen at the subatomic level. It happens at a cellular or at most molecular level  &gt; because fusion takes an insane amount of energy.

For one atom? ["The energy released by fusion of 1 atom of Deuterium with 1 atom of Tritium is 17.6 Mev = 2.8 X 10^-12 Joules."](http://www.mpoweruk.com/nuclear_theory.htm) A single fusion event will not yield very much energy. Whether you're dealing with a single event or N events, it takes *relatively* large thermal energy to get the reactions going. The energy require to make two nuclei touch won't destroy anything and statistically may happen (tunneling etc.) despite being close to impossible. But if we try to make every atom on the sufraces of hand and table touch that would require huge amounts of energy. Fwiw, really appreciate an "ignoring reality" response nose in addition to your scientific explanation. It's so satisfying to get that 'whoa dude' feeling that you hope for with a major hypothetical, and doubly interesting to get an in depth answer as well. Well, *touch* is a bit of a problematic term due to some quantum mechanical stuff that maybe someone smarter than me will get into.

So instead, let's just talk about what happens when the nuclei get REALLY REALLY REALLY close to each other.  Like, 10^-15 meters, or a millionth of a millionth of a millimeter.  Atoms are really tiny, but the electrons are more on the order of 10^-11 meters from the nucleus.  That's *ten thousand* times larger than the distance we're talking about.

So *if* a nucleus were to overcome the insanely powerful repulsion of another nucleus, something called the *strong nuclear force* would kick in.  This is an attractive force between nucleons like protons and neutrons, and it is about a hundred times stronger than electromagnetic forces, but tapers off to nothing if you get more than 10^-15 meters away from it.  The result is that the two would fuse into a new nucleus and, depending on the makeup of the new nucleus, would either be a different stable element, or would quickly decay into something else.

So for instance, if a carbon-12 nucleus in your hand *somehow* fused with a carbon-12 nucleus in your table, you'd have a Mg-24 atom in their place.  24 is its standard weight, so likely that would be the end of it. Basically, this is nuclear fusion- over coming the electrostatic repulsive force so that the nuclear strong force could take over. This is why normally for fusion to occur you need incredibly high heat- so hot that the particles get moving fast enough so that their kinetic energy can overcome the electrostatic repulsion. 

If you do this for light elements (anything less than iron, on the periodic table), by doing this you will also release energy.  Why is iron special? It's really abundant in space too isn't it? Has it got a specific special property making elements under it "light"?  Iron is the 'dividing point' in terms of binding energy. Basically, elements lighter than iron will release energy when their nuclei are fused together, and elements heavier than iron will release energy when their nuclei are split apart. I seem to recall reading that this was (in part) because iron has the most efficiently packed nucleus of all discovered elements. They discussed how this was different from "density," but I don't recall, exactly. It's not the density, per se.  
There's nothing special about the density packing of 56 spheres within a sphere.

When more particles are introduced to the nucleus, the strong force acting on outer protons quickly saturates to only neighboring nucleons due to its tiny range.
Meanwhile the electromagnetic force continues to increase as more electrons are introduced.

Specifically, Iron (Fe56) has the third highest binding energy **per nucleon** of any known nuclide.  
Below iron, the nucleus is too small. Above iron, the nucleus is too large.
As a consequence, **iron  potentially releases energy neither from fission nor fusion.**

=
Only the isotopes Fe58 and Ni62 have higher nuclear binding energies. Ni-62 actually has that distinction. It has the highest binding energy per nucleon. Fe-56 is a close second though, and weighs less per nucleon because it has a lower proportion of neutrons.

http://hyperphysics.phy-astr.gsu.edu/hbase/nucene/nucbin2.html#c1 Oh! Thanks for the correction.  
I was just restating from memory but it turns out to be a common misconception in astrophysics. So this is why massive stars are "doomed" when they finally begin fusing iron? I'm assuming energy was once expended to creat the iron atoms in the first place was it not? 

Therefore to split it back up it would require an input of energy. If I'm understanding this correctly.  [deleted] A more important clarification is that it is actually Nickel, not iron.

http://hyperphysics.phy-astr.gsu.edu/hbase/nucene/nucbin2.html#c1 The key property for iron is that it has the highest *binding energy per nucleon* of any element. [This chart](http://www4.uwsp.edu/physastr/kmenning/images/gc6.30.f.01.mod.gif) illustrates the point well. Note that iron is at the peak. So if you fuse nuclei lighter, or fiss *(snicker)* nuclei heavier, energy will be released. It is actually Ni-62 that has the highest binding energy per nucleon, but iron-56 is a close second.

Fe-56 does weigh less per nucleon because it has a smaller proportion of neutrons.

http://hyperphysics.phy-astr.gsu.edu/hbase/nucene/nucbin2.html#c1 The nuclear binding energy per nucleon for iron is a maximum if you were to graph that value for all possible atomic configurations from lowest number of nucleons to highest number of nucleons. This is due to in part the packing of the nucleons in iron and the strength of the nuclear forces each nucleon feels. Because potential energy in this case is ultimately negative, a stronger binding energy results in more kinetic energy, thus heat. So when nucleons pack together more closely, they shed energy to their surroundings. This is similar to how gravitational potential energy is negative, with the magnitude increasing towards the center of the gravitational mass. So when a particle comes closer to the Earth, its potential energy increases in the negative direction, so to compensate its kinetic energy must increase. This is because energy is conserved.

In the graph below, you want to move your nuclei towards the top of the curve where iron is. Moving up the curve gives you more net thermal energy per nucleon since the magnitude of the binding energy for each nucleon increases, resulting in lower potential energy and thus higher kinetic energy.

Source:

http://www4.uwsp.edu/physastr/kmenning/images/gc6.30.f.01.mod.gif

For reference, nucleon = proton or neutron.
 Thanks for the in-depth response. Within days of the point where it starts to create iron, a star will explode. 

This is because once Iron and Nickel are produced from the fusion of silicon and sulfur in the core of a massive star, fusion no longer produces energy. The binding energy of these atoms is so high that the star loses energy fusing them. Once the core loses energy, it is no longer "pushing out" against its own gravity. The star begins to collapse in on itself and explodes. Atoms heavier than iron and nickel are produced by the energy of the resulting supernova.  Usually, energy is released when two atoms fuse. However, fusing two atoms of iron takes up more energy than it releases, putting it into a kind of energetic pit.  This is not true. Energy is released when the two reactants make a nucleus that is around Fe-56 or lower.  Otherwise, the reaction is endothermic.  You can fuse carbon with iron and that would be endothermic.  You could also fuse hydrogen with iron and that would be endothermic.   It doesn't actually overcome the electrostatic repulsion though, does it? AFAIK most nuclear interactions involve tunneling.  Correct, I made a simplification. 

The atoms are normally not going fast enough to overcome the full electrostatic repulsion, but they do still have to be traveling fast enough to get close enough that they can tunnel- since the probability of tunneling decreases rapidly as distance increases.  Very simple question from someone whose brain is not particularly science-oriented (but I try!)  -- is the feeling of 'touching' something from the electrostatic repulsion?  Someone said in another comment that you are TOUCHING at the cellular level it's just once you get down to the molecular level that you're not? I don't quite understand that :-P but if this is particularly dumb just ignore it! You're correct. Two things can never truly "touch." When you feel like you're touching something, it is really the electrons in your skin repelling from the electrons in the object you're touching.  Crazy, thanks so much for answering! Where is the energy released (when light elements fuse) coming from?  &gt; So for instance, if a carbon-12 nucleus in your hand somehow fused with a carbon-12 nucleus in your table, you'd have a Mg-24 atom in their place. 24 is its standard weight, so likely that would be the end of it.

Plus a huge amount of energy would be released, something like a thousand times the explosion of the same weight of dynamite as the objects touching.
 Except it would be tiny because atomic masses.  

If somehow you got the rest of your finger skin atoms to fuse, you would then be annihilated. which would be pretty small for just two atoms of carbon, if my gut is right.  But if you continue with OPs hypothetical...  And then you have all the atoms from the fingers surface area colliding with an equal number of tables atoms...   To briefly address 'touch' on quantum scales, subatomic particles jare not 'solid' in the way that we understand solidity.  They're more like tiny clouds that are very dense in the center and rapidly become less dense as distance from the center increases.  The radius of an electron is the radius to a particular density level in the electron cloud.  The cloud itself does extend beyond the radius but the density is so low that we can pretend it is zero (sometimes).

If we assume that the extremely powerful repulsives force between two fundamental particles did not exist, then their 'touching' would be when the clouds partially overlap.

This is a drastic oversimplification but it should give some idea of how nebulous 'touch' is on quantum scales. I thought that electron cloud referred to the cloud-like distribution of probabilities in locating an electron in space so it's actually a misconception that electrostatic repulsion is what keeps our hands from touching a surface. The repulsion actually comes from something called Electron degeneracy pressure which is a result of Pauli's exclusion principal. for instance the force that keeps two electrons from preoccupying the same quantum state is the electron degeneracy pressure. Check out the wikipedia article for a much more in depth understanding

http://en.wikipedia.org/wiki/Electron_degeneracy_pressure How hard are you touching this table that you've forced all your electrons into ground state already? Pauli exclusion prevents that from happening under everyday conditions.  

Pauli exclusion is part of why we don't "melt" through chairs.  For instance, Rutherford scattering describes how two nuclei pass by one another, so if it was just electrostatic repulsion we could kinda pass through like liquid through a sieve. This is correct. The classical picture of interacting solids was electrostatic repulsion, but in 1967 Freeman Dyson and collaborators showed that electron degeneracy pressure was the dominant mechanism for the "imperviousness of solids" as Wikipedia puts it. 

Dyson's three publications on this topic are below (probably paywalled if you're not at a university) . 

[Stability of Matter I (1967)](http://scitation.aip.org/content/aip/journal/jmp/8/3/10.1063/1.1705209)

[Stability of Matter II (1968)](http://scitation.aip.org/content/aip/journal/jmp/9/5/10.1063/1.1664631)

[GroundState Energy of a Finite System of Charged Particles (1967)](http://scitation.aip.org/content/aip/journal/jmp/8/8/10.1063/1.1705389) Thank you posting these links, I was about to point out Lieb's
book [The stability of matter](http://www.amazon.com/The-Stability-Matter-Quantum-Mechanics/dp/0521191181). This idea that the "solidity" of matter is mainly electrostatics seems to a persistent misunderstanding of the underlying physics. I thought the Pauli exclusion principle was just that bosons can't stack in the same 3 spacial parameters, to be possibly incorrectly simplistic. Nitpicking: fermions (bosons can); and up to two of them can stack, if one is spin-down and the other is spin-up. I wouldn't call that nitpicking; that's practically the defining distinction between bosons and fermions. Also, the parameters that each "stack" goes into is not just determined by spacial parameters.  Energy plays a part too.

[Link](https://en.wikipedia.org/wiki/Quantum_number#Spatial_and_angular_momentum_numbers) Here's a good explanation:

http://www.quora.com/Is-it-the-Pauli-exclusion-principle-or-electrostatic-forces-that-explain-why-I-do-not-fall-through-the-floor

Two electrons cannot have identical quantum numbers in the same system. Pauli Exclusion is always repulsive, so when orbitals start to overlap, electrons get too close and are forced apart. You can prove via quantum mechanics and some relatively simple integrals that identical fermions are on average separated more than non-identical particles and identical bosons are closer apart (if you only account for the spatial part of the wavefunction, things get tricky when accounting for spin, but if two fermions have the same spin they will repel). This is something called the exchange force. If not for the Pauli Exclusion principle, and if electrons were bosons, atoms would be able to form chemical bonds willy nilly because the exchange force would produce configurations where electrons are closer together.  This may be a bit of a buzzkill, what with people talking about stuff like:

&gt; When two nuclei touch, nuclear fusion occurs

But in truth, what you're talking about wouldn't cause fusion, it would cause repulsion from between the two nucleii from the exactly same electromagnetic forces that cause the electrons to repel each other.

Consider:  If, by some miracle, you've pushed a single atom of your hand through to a single atom in the table.  At that point you've broken past the coulomb repulsion between the two electron shells and now the nucleus of your hand-atom is inside the electron shell of the table-atom, and (probably) vice-versa.

* As a little aside at this point, the force required to do this exceeds the intermolecular forces holding the molecules of your body together, so you'd rip your hand and the table apart before this happens, but no matter: It's a thought experiment.

Once the nucleii are past the electron shells - and they really never get **completely** past the electron shells because they're not true, spherical shells; they're [more complicated than that](http://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Electron_orbitals.svg/2000px-Electron_orbitals.svg.png) - the electron shells are no longer shielding the two positively charged nucleii from each other.

So the two nucleii would repel each other from coulomb forces once you got them to within 0.25 Angstroms, at which point you've pushed past the Bohr radius.

* (Before anyone takes it into their head to quibble about exactly how far you need to go to get past the electrons shielding the nucleii, remember this is a back-of-the-envelope conversation involving multiple nonsensical postulates:  The 0.25 Angstrom number is a brown number.)

On the other hand, the strong force really doesn't begin to kick in until about 1-3 femtometers.  0.25 Angstroms = 25,000 femtometers.

So yeah, if you got the nucleii to **touch each other** (the diameter of a nucleus is 1.75-15 femtometers), you might see fusion, but long before that you'd have to overcome a second round of coulomb repulsion. Are those the shapes of the orbits? I took Chem last semester and when we went over those shapes, i didn't understand. I asked a bunch of TAs (grad students ) what it represented and they couldn't explain it. So, what do they represent?  Well, keep in mind, we call them orbitals, but strictly speaking the electrons aren't really *orbiting* the nucleus in the same sense, say, the ISS orbits the Earth.  It's all wibbly-wobbly quantum mechanicy probabilities.  The electron is never actually **anywhere** at any given time, except when you measure it.  The rest of the time it's a wibbly-wobbly wave function.

But as you can see in the diagram, the first orbital is the *1s* orbital.  You can fit two electrons in there, an up and a down.  (Pauli's exclusion principle prohibits any more than that.)

And the second orbital can accomodate 8 electrons.  2 in the *2s* orbital which is spherical (I'm pretty sure that's where the "s" in 1s and 2s comes from:  **spherical**.)  just like the *1s*, and then 6 more in the 3 *2p* orbitals.  The three *2p* orbitals are barbell-shaped orbitals.  [This image](http://wps.prenhall.com/wps/media/objects/724/741576/Instructor_Resources/Chapter_01/Text_Images/FG01_01-39UN.JPG) makes their shape a little clearer, and also illustrates how we are able to jam **6** electrons in there:  Because the orbital is not symmetrical across rotations, you can have them oriented in the x, y, and z directions.  Three directions, three orbitals, and again two electrons in each, one up and one down.

As you get to higher energies, you get additional degrees of freedom that the electrons enjoy, so you end up with 5 additional orbitals added, once you're in the 3rd electron shell and get past the initial 8 in *3s* and *3p*, good for another 10 additional electrons that can fill up that orbital.

Also, note, even though I've referred to the *1s*, *2s*, and *3s* orbitals as if they have identical shapes, they're not **exactly** identical.  They're all spherically symmetric, but there are minor differences.  For example in the *1s* orbital you're roughly equally likely to find the electron anywhere within the sphere of the orbital of radius R^o, all the way from r=0 to r=R^o.  But in the *2s* orbital, you're much more likely to find that electron either in the center, (r ~&lt; 0.1R^o ) or on the edges (r &gt;~ 0.8R^o ).  So in that respect it's much more like a hollow sphere than the *1s* orbital.  In general you find the symmetries remain when going from *1s* to *2s*, or *2p* to *3p*, but some details may change a bit.

http://en.wikipedia.org/wiki/Atomic_orbital#Orbitals_table Just to add to what /u/garrettj100 said, The orbitals are probabilities of finding an electron there. To measure something, for example, look at a bacterium in a microscope we need to add energy to it (light) and detect the interaction of the energy and your object (in that case light interacts with cell wall, being absorbed, and that's how you see the wall being darker). If you illuminate something, like your hand, it'll get warm (thus your hand gets extra energy). Now to take it back to the electron, say you want to know its position and movement (impulse). By measuring it, you'll give it extra energy to "fly" around more, so you don't reliably know its original speed. If you measure speed, you won't reliably know its position. So there you get your uncertainty principle of Heisenberg. To solve this problem, really smart people calculated the area in space where you'll have 95% chance of finding an electron. So those orbitals represent an area around the nucleus where if you'd measure 100 times, you'd find an electron 95 times. I hope this sounds somewhat comprehensible. When nuclei "touch" each other it would considered a nuclear reaction, namely a form of fusion. To illustrate that point, the infamous "cold fusion" fiasco of the early 90's was the claim that under certain conditions nuclei can be coerced to get close together without feeling the typical electrostatic repulsion that prevents them from getting near enough to fuse, usually that requires a large amount of energy (heat) to basically bang them together hard enough so that a few will actually fuse. 

To demonstrate the energies required to bring two nuclei together, [here](http://www.nature.com/nature/journal/v445/n7124/images/445156a-f1.2.jpg) is a graph of the potential energy of two nuclei as they are brought together well past the electrostatic repulsion (the values will depend on the nuclei, but the shape is very standard), at tiny distances there is another asymptotic repulsive force to keep the two nuclei apart, at some point if you push hard enough something will break, in this case strong and weak bonds holding the nuclear quark soup together, the result is that the two nuclei will ostensibly fuse for a short period of time (a "virtual" nucleus) and the new nucleus will either be stable (unlikely), or unstable and break apart into new daughter nuclei, usually by shedding a lighter nucleus. In the simplest case, an alpha particle - He nucleus is emited, likely several times in quick succession, but occasionally catastrophically into two more-or-less even nuclei with other lighter particles as happens in a nuclear fission reactor.

The energies required to force nuclei together are many times more than needed  to break inter-atomic bonds, so it makes little sense to talk about a "bulk" material "touching" the nuclei of another material, at those energies the bulk material will disintegrate, its atoms will ionize and shed all their electrons and all that will remain are the constituent nuclei and the process will occur statistically as though the particles of your hand and the table were put in the sun or the reaction chamber of a  fusion reactor. 

The question of how such an interaction occurs is relatively well understood in nuclear physics, and there are many nuances and little technicalities when talking about fusing nuclei. But effectively you are asking what happens if your hand can undergo fusion with the table.  Atoms are basically empty space and the nuclei want to repel so the amount of energy it would take to get the nuclei to touch would literally incinerate you. Once they touched they would fuse together and release even more energy due to a decrease in energy or an increase in stability and this again would incinerate you. So you would be incinerated^2. Wouldn't recommend it.  Other good answers so far. I would just add, technically that electrostatic force you feel is what touch is. There's no such thing as 'touching' in the literal occupying the same space at the quantum level, only the forces exhibited that you feel. 

If two atoms got close they would go through a series of repellent forces and assuming you ignore them all as not existing, then in the end they would share the same quantum position, or their quarks would. Not sure what would happen then, singularly perhaps?  [deleted] You would meld/fuse with the table and create a new material or composite. It would look like your skin is glued to the table, then it all depends at what speed/rate the atoms would decay. Chances are you'd lose your fingers. There's also a possibility that some atoms get displaced and your fingers move right through the table. There's also the chance of a chain reaction of any kind. Keep in mind that some smart ass has redefined "actually touching" to mean something different than what normal people consider "touching".  When I poke my coffee mug, there is a point of contact where my force is exerted on it, and it's force is exerted back on me.  As far as I'm concerned, that is touching.  

I might adopt a redefinition if I was using a quantum tunneling microscope to nudge atoms into particular arrangements, or modelling electron flow through a solid. You define touch to mean "exerts a force on"? Am I touching something I breath on? &gt;It's my understanding that when we try to touch something, say a table, electrostatic repulsion keeps our hand-atoms from actually touching the table atoms

You are overthinking this. You need to consider what "touch" means when we say it, because its the phenomenological description of electron clouds between atoms that stop overlapping at a certain point. Touch literally means electrostatic repulsion and it makes no sense to say that the atoms don't touch each other.  Magnets don't touch when they are repelling each other at macroscopically-visible distances,  so I think it does not make sense to say that "touch" is a synonym for repulsion existing.

The repulsion would get stronger as the atoms get closer; the issue would be whether the electron clouds have gotten close enough to overlap or not when our hand is resting on the table.

 He means if the nuclei physically came into contact with one another, so there would be zero space between them. Don't be an asshat.
 [deleted] Ignoring practical issues like being able to brace the wounds together for the weeks it'd take to heal, you would have to go beyond just matching blood type--the two people would need matching HLA haplotypes or else each person's immune system would try to reject the other person's tissues. (There may be ways around this, for example if each person were put on immunosuppressants.) Perhaps it could happen with identical twins, whose HLAs would be perfect matches. Somewhat related question: if I cut off both of my hands and held the wounds together, would the same thing happen (get one continuous "loop arm")? Many people with damaged or burned hands have them sewn inside their abdomen. There they heal and new growth takes place. Whoa, that's absolutely insane. Could you explain that a little more please? "Inside?" It's sewn under the abdomen skin, over the fat, not INSIDE the stomach. Like this (NSFW): http://file.scirp.org/Html/6-1930016%5Ca40a0103-1a91-4fae-aa4a-a1d29df61a94.jpg

Being burned doesn't only destroy the outer layer of the skin, but also causes small blood vessel in subcutaneus tissue to clot. This way hand is nutrioned by the skin of the abdomen and the skin can be later cut out as a sort of graft to make new hand skin. 

As for someone's question about bacterial growth - the main reason for burn infections are lack of protection of the skin and low blood flow due to clotting - this prevents both. 

This is another example (NSFW): http://www.ijps.org/articles/2011/44/2/images/ijps_2011_44_2_227_85344_f12.jpg

Edit: Spelling and NSFW/NSFL? (I'm really sorry for not tagging this- I'm a young doctor, so this is literally W for me :D) (also forgive me any grammar, spelling mistakes - English isn't my first language) 

Edit 2: I'll answer some of the questions here. 

Do the nerves grow in? That's a question for a whole new post, or even a seminary, but I'll try to do a tl,dr. For starters they don't grow in the subcutaneous tissue - you can feel things thanks to the nerves in your skin. When this skin flap is cut out, the nerve connections are destroyed. IF there is a large enough nerve in this flap you can try to connect them to the nerves in the arm - if there are any left. If successful, there are still a lot less nerve endings in the stomach (or any other part of the body) skin, than there are in fingers. Yet you can train and the nerves will grow new endings. 
This is all if you are lucky. In most cases you won't have much sensivity in that hand, I guess. 

Skin gun - I have heard of it, never seen one in use. As far as I know these are used in stage I and II burns, but I'm no expert here. 

Growing a new nose on the forehead. - yes, actually, I have heard of it. It is believed, that people from territory of India were inventors of some sort of plastic surgery about 2 millenia ago (not sure exactly). There was a custom at some point of cutting noses of defeated soldiers/ citizens by victorious rulers. This left thousands of people without noses. A skin flap was cut from the skin of the forehead with a part of it attached between brows, bent over and sewn into cuts in place of old nose. This was nothing like real nose, but covered the hole in the face and probably reduced a chance of infection a little (that is, if they survived the operation).  Wow, that's incredible. Do some of the nerves grow back to regain sensivity in that area? What's the rate of success on these procedures? Thanks for your answer.  That's a question for a whole new post, or even a seminary, but I'll try to do a tl,dr. For starters they don't grow in the subcutaneous tissue - you can feel things thanks to nerves in your skin. When this skin flap is cut out the nerve connections are destroyed. IF there is a large enough nerve in this flap you can try to connect them to the nerves in the arm - if there are any left. If successful, there are still a lot less nerve endings in the stomach (or any other part of the body) skin, than there are in fingers. Yet you can train and the nerves will grow new endings. 
This is all when you are lucky. In most cases you won't have much sensivity in that hand, I guess. 

Depends on what you call a succes. If the deep tissues of the hand are intact, then in most cases you will remain with a deformed, but functional hand. However partial amputations are often needed, so you still have a hand, but with less function - succes, I guess :)  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I don't get it. The hand is amputated, attached to the abdomen to heal, and then back to the arms? Why would that help?  No. The hand stays attached to the arm and they are sewn into the abdomen. Much faster healing at the cost of not being able to move that arm for a bit. Neat, what do they do about finger nails? I'd take a wild guess and say that when your arm is burnt so bad you need to sew it inside your belly to avoid amputating it, finger nails, and even fingers, are not only the least of your concerns, they're probably a little heap of ash somewhere between the location of the accident and the hospital. [deleted] [deleted] [deleted] [deleted] [deleted] Yes, you would get a "loop arm."

Cosmetic surgery after WWI used a similar technique, with some amazing results.

http://i.imgur.com/k2Avoyg.jpg

Flesh would almost be cut off the body, leaving one edge attached.  Then it would be rolled into a tube and the other end sewn wherever the extra flesh was needed.

After a few months it would "merge" with the old flesh in the area and could then be reshaped.


 That's disturbing, so there is a open wound his back or shoulders, and a piece of skin connected to the chin? Its quite amazing it worked. There was a post a couple of weeks ago by a guy who got his nose badly bitten by a friend's dog. Doctors peeled off some skin off his forehead and connected it to his nose to reconstruct it -and it was pretty awesome. He even said that, for a moment, touching the tip of his nose felt like touching his forehead. This is amazing. I'm still really confused where they got that man's skin from though lol wish there was a video - as NSFL as that might be [deleted] [deleted] [deleted] [deleted] [deleted] They'll sew one part of your body into another if you've lost a lot of skin and they need time to grow a graft.  That way your skinless hand (for example) can still receive blood flow and is protected from infection. I don't think he was asking what doctors currently do, he was asking if he could theoretically grow a loop-arm. That would be the answer, though. If they sew parts of your body to new regions for safe keeping, then they can sew your arms together to make a "loop-arm". At least that's what we can assume. [deleted] [deleted] What would happen if you didn't bother matching them? Just find two random people? 

With an organ, if it's rejected it dies. But two healthy humans, each trying to reject the other ... Rejection, high probability of infection the longer the wounds stay open and open wounds that never heal.  I apologize if this is a stupid question, but if you somehow had a super controlled environment/super clean room, with no outside influence, would it still be possible to get an infection?  

I guess my question is, can an infection come purely from the two incompatible people in this scenario? There are millions of bacteria in your body that are absolutely essential for it to properly function. An imbalance of those could easily lead to a harmful infection and even necrosis. Infections do not necessarily always come from the outside. One of the reasons antibiotics should be prescribed in moderation is because of the potentially negative consequences of an imbalanced gut biome.

Edit: It is also definitely not a stupid question. Seeking knowledge is never stupid. When you say Gut Biome, do you mean like an actual Biome? I should have said human microbiome to be more technically accurate, but the studies that came to my mind when thinking about it were specifically for gut bacteria. http://en.m.wikipedia.org/wiki/Microbiome for more info. Well, it's not a biome in the specific way the word is usually used in the geographic sense of the word, but the two concepts share almost everything in common ... environment (pH, temperature), food sources (the stuff we can't digest), interspecies relationships (competitive, symbiotic, etc).
 &gt; There are millions of bacteria in your body that are absolutely essential for it to properly function. An imbalance of those could easily lead to a harmful infection and even necrosis. 

True, but people could probably survive without the bacteria - there are bacteria free strains of mice, for instance, and they live despite having a lot of problems. Basically, for the sake of this thought experiment you could use bacteria free people. Yes. The immune system of one person will fight the other persons cells. However, infection traditionally implies a disease is causing the affliction. In this case, the toxicity would be from the cells destroying one another and not being able to clean up or behave normally. It would be a constant battle, which is why the would would never heal. Eventually both people would die if the contact area was great enough because of the strain it would put on both people's immune systems, possibly causing septic shock.  In addition to bacteria within your body that /u/romulusbc described, there are plenty of bacteria that exists as a normal part of skin flora that can cause infections in people if they breach the skin. Staphylococcus spp, Streptococcus spp, and Pseudomonas aeruginosa are all examples of this. They wouldn't attach and the wounds would close on their own in the best case scenarion. 

In reality you still have an open wound to treat and such. But I don't think it would be worse than just having an untreated wound on a single person. You don't want wounds to stay open, infection, gangreen, death. To this point, I recently saw an episode of *The Knick* where a woman facing loss of her nose tissue following leprosy infection has her arm incised and attached to her face via a strange contraption. I assume it would take weeks for that to heal properly.

Did they have immunosuppressants of the sort you speak of in the early 1900s?

**EDIT:** apparently, she'd contracted syphilis, not leprosy. You dont need immunosuppressants when the tissue is from your own body. What about external infections? That flap coming off the arm and sewed to the nose-hole was nowhere near sealed. All your cells have protein markers on their outside that basically say "this is one of ofthisworld's cells". If your body finds some cells that don't have those markers, or that have different markers ("this is one of John's cells" or "this is a bacteria cell") then it's like "this shouldn't be in here, let's kill it". With a graft from your own body, all the markers are the same so your body just lets it chill and do its thing. In that case, the only thing immunosuppression would do is make your body more likely to ignore other stuff, like really nasty bacteria. If you got an organ from me though, the markers wouldn't match and you'd need to take immunosuppressants for the rest of your life to keep your body from killing it. That's why when they do a transplant, they try to find someone with similar genetics, since the body freaks out less if the markers *mostly* match. If they *mostly* match, you can use less immunosupressants, so your body won't try to kill the organ but will still attack outside bacteria and stuff. In theory, you could make a transplant where the markers didn't match at all if you loaded the person up with a fuckton of immunosupressants, but by that point the person would be so prone to infection that someone could sneeze on them and they would die, since your immune system is basically the only thing keeping you from rotting like a dead corpse.

This is also why stem cell research is so important. If we could use a person's own cells to grow, say, a new heart, we could make perfect heart transplants for anyone that needed one. Beautifully-explained. Thank you for your time. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] It wasn't leprosy, it was Syphilis, an STD, which is why she was so embarrassed about the situation. And they didn't need immunosuppressants as they were grafting her own tissue.  Look into Nazi experiments. Josef Mengele did all sorts of things like that, his 'specialty' was twins. As soon as I read this question I thought it was some Mengele type stuff  It's called graft vs host disease, where the graft attacks the body instead of the other way around. Happens all the time with bone marrow transplants. I would assume it would be essentially like having it become infected, and eventually the tissue would die and become gangrenous. The body will try to rebuild a hand stump while simultaneously trying to kill the other body ALSO trying to make a hand stump. Blood will have a very hard time passing between, and if the two ends SOMEHOW managed to grow connecting blood supply then they would immediately begin killing their own bloodstream. They wouldn't heal together, the tissue area would just infame, and fall away from each other rather than fusing, with each side eventually forming a calloused skin barrier, even if they were held together the whole time.
 [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I know absolutely nothing about biology so forgive me if I'm asking an obvious question, but is it at all possible for two people who aren't twins to have matching HLAs? It's possible, but pretty rare. HLA's are immune markers for your body to tell friend from foe, and are *one of the things* what doctors look at when trying to find matching donors for transplants. HLA types don't have to match up perfectly (they rarely ever do if the transplant receiver is not a close family relative with the donor) but the closer the matchup the less likely acute rejection is to happen. How many types of HLA there are? If the matches are rare, it's got to be a huge number, right? I don't know how many different types there are, but there are several main subtypes grouped together by their analogous MHC class (HLA-A,B,C for MHC I, HLA-DP,DQ,DR for MHC II are the ones we need to be aware of for medical school immunology). I think the number of variances per HLA varies, but there are enough different types and variances that there is a very large number of possible combinations. Also fun fact, certain HLA haplotypes are implicated in different autoimmune conditions- such as HLA-DQ2 or HLA-DQ8 for celiac disease Is this currently what they check for in the blood test for celiac? If not, do you think there will be a way to diagnose someone just based on their HLA in the near future?  No, they look for the antibody which attacks the gluten in the first place. The HLA groups which kef mentioned are risk factors, but they don't mean you'll definitely get coeliac so they wouldn't be much use for diagnosis. That's kind of disappointing. I was hoping there might be another option besides eating gluten for the blood test or having a biopsy done. I appreciate you taking the time to respond though, thank you.   Tissue typing for transplant matching looks at the Major Histocompatability Complex class I and II receptors (MHCI, MHCII).  There are 3 classical gene representations for each, Class I MHC has HLA-A, B, and C encoding for the heavy chains, Class II MHC has HLA-A, DP, and DQ with encode for the alpha and beta chains, all of which are located on chromosome 6.  You get 1 chromosome from each parent, so you have 12 different alleles (genes).  When they test for compatability they only test 10 of these alleles (not HLA-DP) to see if you are a match, and siblings have a 1:4 chance of being matches for the 10 loci (assuming no recombination).  The current number of known alleles is always increasing as we find more, but for the HLA-B there are around 600 different alleles, which is the most studies allele.  Others like HLA-C only have around 150 known and the class II MHC only have from 6- 45.  If you average all the alleles, you get (very) roughly 191 different for each of 6 loci, you have 12 loci so the number of combinations is upwards of 191^12 (I think, I haven't taken stats in a while).  However, there are alleles that are much more common than others, so the real number of observed combinations is much lower, however this is still a very large number.  This is great news for defending against pathogens, but bad news for people who need tissue transplants.  This puts into perspective the need we have for donors, there are about 8 million registered bone marrow donors, (which is awesome!) but most of the donors are Caucasian, so the haplotypes aren't as reprentative of the total population due to population genetics, which is a whole other discussion.  This is why people look mostly to their relatives for transplants because there is a much higher likelihood of being a match.  I hope this helps, also if anyone wants to check accuracy of my figures I just threw it together quickly so there may be errors.

There is a nice table of the known frequencies of certain haplotypes on [wikipedia](http://en.m.wikipedia.org/wiki/Human_leukocyte_antigen).

**TL:DR** : There are a crap ton of possible combinations, sign up to donate bone marrow!

Edit: Numbers You mention that Causasian donors don't give accurate representation  of the population. Is there a big difference between the HLAs of people of different ethnic origin? For example (I hope this shall remain a hypothetical forever), if I am half European and half mixed with a nationality/race not so common in Europe, would you guess that I would have much harder time finding a match if I needed one? I can't say for an individual basis how hard it would be to find a donor, but yes your ethnicity plays a part in what your HLA haplotype is.  Interestingly your haplotype can be used to trace your ancestry to where your family presides from.  A cool example of this is that people from Easter Island have haplotypes that are also found in the Basque region of northern Spain, which shows that a spanish explorer at one time in history deposited his/her (but most likely his) genetic material into the Easter Island population.  So because most people in the bone marrow registry, at least in the U.S., are Caucasian it makes it even more difficult for people of other ethnic descent to find a viable donor. There are also a ton of minor HLA loci, which is why even people who match on all the major ones still need to take immuno-suppressants following transplant to stop rejection (unless they're twins). http://en.m.wikipedia.org/wiki/Human_leukocyte_antigen#Tables_of_variant_alleles

Multiply all those numbers together for a rough estimate of how many total combinations there are.  Yes, pretty much. To be eligible for an organ transplant (at least in Europe), the donor and the recipient have to have 3 of the main HLA-Types in common. And that is not easy to find. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Thanks! So this would also be possible if a single person tried to do it with both of his/hers hands? [deleted] [deleted] [deleted] So on another question... If I cut identical areas of skin off say my hand and my thigh, then attached them together for a period of time, could my hand and thigh essentially fuse together? [deleted] [deleted] Is it wrong that I now want to try this with my identical twin? Yes, I imagine without proper immunosuppressants, the bodies would basically be trying to kill each other. Would be an interesting battle to watch if we assume the blood scabbed up and "sealed" the two stubs together. I imagine the blood vessels wouldn't line up very well though. Would be interesting if the blood vessels did line up, the hearts would be pumping blood to each other's body, I imagine that would really mess up the immune system, and possibly they would both become really weak, and die. [deleted] This raises so many questions:

Would one person be able to survive without eating and drinking if the other one did in his place since they share the blood?

Would the immune system be weakened or strenghtened by this (would the power of both immune systems add up)?

If one person has a heart attack, can it still survive thanks to the other person's hearth that still pumps the blood? Another challenge is just simple anatomy.  The blood vessels would not be aligned which would cause significant difficulty in providing proper circulation.   [deleted] As a matter of fact, it is possible. It's called [Parabiosis](http://en.wikipedia.org/wiki/Parabiosis). But as some others here have explained, it would not work so easily in humans.

almost every cell in the human body has a series of proteins known as [Human Leukocyte Antigens](http://en.wikipedia.org/wiki/Human_leukocyte_antigen), or "HLA" for short. These HLA proteins act like identification and inspection sites for the human body: Cells which lack them are targeted by natural killer cells (a type of white blood cell). HLA also function as a snapshot of what is inside the cell. You can imagine HLA like a hotdog bun, and inside the hotdog bun, the HLA presents a random protein segment from inside the cell. If that protein segment is something the immune system sees regularly, it will ignore it. If it is something odd or foreign, the immune system will attack it through a  T-cell response. And if the HLA itself is a different setup, this will result in an attack as well. So in the example of non-identical humans, the T-cells of one human will attack the other.

In rats and mice, however, scientists use historically inbred mouse lines that are nearly (if not completely) genetically identical, like the [C57/Black-6](http://en.wikipedia.org/wiki/C57BL/6) mouse. When we make a gene knockout mouse on this background, the only difference is the gene we are studying.

**Parabiosis was a useful tool** in discovering how the adipokine [Leptin](http://en.wikipedia.org/wiki/Leptin) regulates satiety. In an intriguing experiment, scientists took two types of genetically altered mice with similar phenotype, and parabiosed them to see what happened. The Ob- mouse lacked ability to make Leptin, while the Db- mouse made leptin but lacked receptor for it. Both mice overate and became really, really fat. But when parabiosed, the Ob mouse lost weight, and the Db mouse remained fat. Interestingly, a wildtype mouse parabiosed to an Ob- mouse made the Ob-mouse lose weight, and a Db-mouse parabiosed to WT caused the WT mouse to lose weight and die. [This (SFW) image](http://www.diabesity.eu/images/parabiosismice.png) summarizes the findings, but through this mechanism, we discovered that Leptin (produced by fat cells) can inhibit food seeking behavior if the mechanism is preserved. [deleted] That's correct-- if I recall the exact details right, they fused their femurs. Didn't the Nazi's try something like this during ww2 to humans? Yes, I believe Josef Mengele experimented on sets of twins, and one of the experiments was to attempt to fuse twins to each other by cutting them open and sewing them together. I think I remember hearing the story of a fellow prisoner who euthanized a set of twins who had suffered through one such experiment. Oh, was going to ask what happens if they use twins.....now I feel too close to Mengele for comfort.   Mengele was the first person that sprung to mind when I read the question. There is no such thing as a thought crime, and discussion is merely collective thinking. Once it becomes a movement, things are different. Do you think that somewhere, somebody is conducting these crazy experiments? well, there are 7 billion of us. Do you think maybe one or two of us are crazy enough to do that kind of thing for fun? Im still waiting for the news report where they find a human centipede.  Your hotdog bun analogy went nowhere.  Okay, I imagine it's a bun.  Now what?  You abandoned the comparison. That's actually the shape. Imagine the protein segment is the hotdog: It could be kosher, it could be pork, it could be a bratwurst-- and the T-cells will look at it and say "Yup, that looks normal" if the protein is something it's used to seeing. But it could also be something else that fits that shape-- like a small hammer or piece of shit. If you saw something like that, it would make you go "wait a second, that's not right" and then attack the host. Similar idea here. I know my first response when I see someone carrying around a hot dog bun with a deuce in it is to scream bloody murder and attack them with the hammer I had secreted away in my own hot dog bun. It's simply a natural reaction. I understood what he meant.

Basically imagine a "hot dog bun" as the "showing tray" and the "hot dog" as a peice of protien from inside the cell. He was just showing how the HLA "displays" the protien to the outside. 

Its hard for me to explain too apparently.  &gt; In rats and mice, however, scientists use historically inbred mouse lines that are nearly (if not completely) genetically identical

That's fascinating. So it's possible to have stable inbred lines of mice where the males and females are able to produce offspring which are nearly genetically identical to their parents?  That's exactly what happens when you [maintain a mouse colony](http://ko.cwru.edu/info/musfrming.html). You keep a stable population of mice to be used for research, without having to order more from the supplier. this should be the top rated.  Good paper came out not to long ago reviving parabiosis to reverse ageing.  What if you used two identical twins? Maybe as a way to keep a body part alive if the other twin loses it and can't get it attached right away. I can't answer for humans exactly, but these studies have been done in mice and do work. It's called [parabiosis](http://en.wikipedia.org/wiki/Parabiosis), see [parabiosis protocol](http://www.ncbi.nlm.nih.gov/pubmed/24145664). 

In essence, two mice can be surgically grafted together with a shared circulatory system. Blood cells and even circulating stem cells derived from each animal can be found (functioning) in both. Because both animals retain their functional immune system, they share their circulating antigens and develop [immune tolerance](http://en.wikipedia.org/wiki/Immune_tolerance) to the other's antigens as though they themselves were expressing the new. So, in mice, HLA mismatches do not lead to rejections or graft-versus-host disease. 

Parabiosis has been used in [diabetes research](http://www.nature.com/nm/journal/v16/n10/full/nm1010-1097.html) with mutant animals, demonstrating that a specific mutant ([Lepr^db/db](http://www.nature.com/nm/journal/v16/n10/full/nm1010-1097.html)) grafted to a normal wild-type lean mouse or even an obese [Lep^ob/ob](http://www.informatics.jax.org/allele/key/568) will cause the non-db mouse to starve to death due to circulating satiety factors. This was the discovery of leptin.

More recently, in [aging studies](http://www.nature.com/nm/journal/v20/n6/full/nm.3569.html), young mice grafted old rejuvenated the old mice! The old mice had noted improvement in the brain (learning, memory, circulation, neuron density) as well as muscle, liver and heart function. That seriously sounds like the basis for a horror film. The aging villain has discovered immortality, but only by sewing live infants into his flesh. The article I read about it was pretty creepy, constantly referring to "young blood"  and how it could be the key to immortality. Seems like having two hearts connected to the same circulatory system would cause blood pressure problems. its not one circulatory system. its the full circulatory systems of both mice. still full double volume for full double pumping power. they are just connected Immune systems would become aggressive to the foreign entity and attack cells growing the wound together. We see this problem with transplants all the time even if they're a direct tissue match and blood type. It is really Really REALLY hard to get immune systems to play nice with foreign objects because it is so good at identifying what is and isn't an original part of the body. The problem is mainly the difference in DNA between the people attempting to do this but we don't fully understand the immune system and how it differentiates hostile and safe entities so who knows, maybe in some weird world of advanced medical science this could be possible? I have a twin. I always assumed we would be each others best back-ups if one of us ever needed a skin graft for a burn or something. Or a kidney. Now being an adult I of course realise we as fraternal twins have as much chance of that as just a regular brother and sister. However wouldn't it be the best bet for monozygotic twins? I know a pair of mirror twins, which I was always taught split into twins really late compared to 'normal' identical twins. Don't they basically have the same DNA?  
 Yes, identical twins have the same DNA, as they are split from the same fertilized egg. How do fraternal twins work? Two sperm into two eggs? Fraternal (dizygotic) twins is when two eggs are released instead of one, and are fertilised by separate sperm. The twins have separate placentas. 

Identical (momozygotic) twins is when one egg is fertilised by one sperm, but splits into two embryos in the early stages. The twins share a placenta. 

When two sperm fertilise one egg (pretty rare) the woman develops a molar pregnancy. This is a pretty awful situation, and involves the placenta cells dividing into lots and lots of cysts. (Some clinical images are NSFW) &gt;Identical (momozygotic) twins is when one egg is fertilised by one sperm, but splits into two embryos in the early stages. The twins share a placenta. 

If they split early enough they actually can implant separately. It's much rarer, but it happens. ~~One sperm, one egg, but during the early stages the zygote splits into two, both of these continue to form a baby.~~

**EDIT:** My mistake, turns out I should read questions before I answer them, just wanted to be helpful :c

**EDIT 2:** I know that this is identical, not fraternal, I simply thought that /u/kitchenmaniac111 was after the definition of identical, and due to that, gave a definition as such.

I have kept it up so anyone looking for the definition of identical can read it as such. Nope. Assuming you were answering the fraternal twins question and not the identical twins.

From: [here](http://www.betterhealth.vic.gov.au/bhcv2/bhcarticles.nsf/pages/twins_identical_and_fraternal)

Identical twins are from the same ova &amp; sperm:

This occurs because the fertilised egg divides in two while it is still a tiny collection of cells. The self-contained halves then develop into two babies, with exactly the same genetic information.

Fraternal twins are 2 eggs 2 sperm
Two separate eggs (ova) are fertilised by two separate sperm, resulting in fraternal or dizygotic (two-cell) twins [deleted] [deleted] [deleted] [deleted] [deleted] given sufficiently good tissue, blod and HLA haplotype matches and/or sufficient immunosuppresion, then certainly.

sewing animals together so they share circulation is well known and characterized research model used in rodents, called parabiosis. In inbred mice (almost all research animals are inbred for homogeneity) it even works without immunosuppressants, so it might work off the bat for homozygous twins. Going Beyond this, say if a person with a immune system disease, and someone who was immune to the disease were melded together. Would the healthy immune system defeat the disease of the non healthy patient?

I.E. - Would the immune system of a healthy patient be able to fight the battle inside the body of a none healthy patient if all conditions matched for this t be possible? [deleted] No, because every human has a unique indicator in their cells that tell them that these cells belong to them. You can see this in the immune system where our immune system attacks viruses and bacteria in our body. Essentially, same thing goes for this scenario.  What if the humans were identical twins? [deleted] [deleted] They were hunting and gathering - the normal state of being for humans.  Population densities were low, there wasn't much pressure to feed a lot of people confined in a small range.  There was abundant game and wild foods.  So there was really no need or reason to bother with planting or domesticating, and there weren't usually enough people around to build any large structures.

It's not so much that they couldn't figure out how to domesticate animals or plants, it's just that it didn't make sense to bother going through the work when you could reliably get food from the wild.

Here's a paper on the topic that posits a favorable climate encouraged population growth, followed by climatic downturn forcing people into higher population densities in remaining favorable locations--and that higher population densities spurred people to settle down and start planting things.

https://www.aeaweb.org/assa/2006/0108_1300_0404.pdf Or, to see how cultural and technological evolution resemble that of biological evolution, there was no *pressure*.

Humans had no need to adapt these measures, so they didn't. I've read speculation that the pressure to farm and domesticate might have arisen from the need to feed large communities at megalithic building sites.  Are you referring to research on Gobekli Tepe? Yes, although I didn't want to go check my source, and so used a bunch of vague language. 

Edit: I don't know why my admission of laziness went over so well, but I'm bemused.  I wrote [this piece](https://sweettalkconversation.wordpress.com/2014/11/20/did-a-change-in-rhetoric-give-rise-to-cities/) a while back on some of the research on this subject.  Very good and concise piece,  and thank you for introducing me to a website that I'm quite sure i will spend a lot of time on. I think it went over so well because so many of us have dobe the same.

I hate it when you read an interesting study, that seems sound, but you don't have a link later when you bring up the information. The other person thrn thinks you are talking out of your ass of course.

The worst is having no links for studies and stuff you have actually read on paper. Why build though? Why make a large community? A popular theory for this questions comes from looking where the first state societies appear: The [fertile crescent](http://en.wikipedia.org/wiki/Fertile_Crescent). The area is, as the name implies, very fertile and great for agriculture. But the question remains, why even bother? Well, the area was quite possibly so fertile and provided so much food that the hunting and gathering lifestyle which usually involved moving from place to place started to become more sedate: With so much food around, there wasn't much of a need to move, so many people stayed put. The theory goes that the land was so supportive as to have lasted generations before resources began to deplete, and by then many of the secrets and practices involved in the traditional hunting/gathering lifestyle were lost. Without the knowledge of how to return to the lifestyle of their ancestors and only knowing a stationary life, the people did what they could to survive, in this case, trying to make their own food via agriculture.  I.e we domesticated ourselves? Possibly a nonsequiter, but one of the hallmarks of domesticated animals compared to their wild equivalents is called [neoteny](http://en.wikipedia.org/wiki/Neoteny).  It is also a hallmark of anatomically modern humans, and is often studied in relationship to, for instance, chimpanzees.

So while it might be a bit glib to say that we domesticated ourselves, we can say that some of the physical characteristics of domestication are present in us. Neotony was present in evolution long before there was domestication.   It's not that I disagree, but domestication implies pacification through human selection and that is not synonymous with neotony.   [deleted] It's easier, less moving. Honestly though would have never looked at it that way.  I always thought climate or migration changes or something along those lines forced people to gather together for an extended period of time, so they started building communities/farming/etc to sustain living there, and once they could leave again they didn't really need to, so many stayed.  The problem here is that so many fail to realize that social development &amp; biological evolution go hand in hand. Without the means of speech and communicating we are not human. We have vocal cords and inbuilt brain structures/functions which make us able to speak. Those took a LONG time to evolve to where they are now.

It's become clear that human evolution sped up when a gene relating to microcephaly was mutated about the time when H. erectus became early sapiens. We still see this gene today in an earlier form, too.

Without enough functioning, connected cortical cell columns, we get the great apes and H. erectus. With the modern convolutions of the brain where the CCC's are packed and organized, we do. This thin neocortex and what goes on there makes us what we are, if it's used properly.

All of our agro and modern civilization arose within this latest Interglacial period, of the last 12k-13K years. That allowed humans to finally use their potential and create agriculture and then the high density, competing societies which are so necessary to our development. Once that got going, well, here we are. And the climate change of the late medieval period propelled us via the Viking raiding and the much large populations that global warming allowed.

Consider what would happen to us if we were hit by a Toba kind of calderic eruption, which would create a global winter for 5-10 years, where most agro would be frost damaged below 32 deg. latitude. We'd have only a few weeks of warning at best on that, and maybe less. So we are here at the forebearance of geological processes as well as climatic change. Because within 200-300 years, and we'd not know it or even recognize it, earth could go back into the full glacial period which has marked climate for the last 2-3 megayears.

Within that time, most civilization would collapse, too. These dangerous issues are not well appreciated by the many here.

So modern man actually came into existence the last 5K-10K years. Not earlier &gt; a gene relating to microcephaly was mutated about the time when H. erectus became early sapiens

It was about a million years before that.  Long before the split from Neanderthals ~500,000 years ago.   [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I like  this theory better: http://mobile.nytimes.com/2013/03/17/opinion/sunday/how-beer-gave-us-civilization.html?_r=0 One theory I read awhile back was that the discovery of alcohol was a big push into sedentary farming. They needed to grow grains and whatever they used for alcohol and wait for it to ferment so they became sedentary.   But wouldn't there ALWAYS be food pressure? Family size would be determined by available food supplies, right? If there was ample food, there would be a population explosion by families having 10 kids and their kids having 10 kids until all available food was exhausted and you have some people dying off from the occasional draught or bad hunting season. Saw a documentary on an African tribe of hunter gatherers. Name escapes me unfortunately,  but on the gathering side, the woman gathered in one day ( fruit vegitables, small game and insects ) enough for her family for 3 days. Unfortunately we only tend to see these peoples when they are in drought, or pushed to the edges of their territories . [deleted] Why does agriculture make people unhappy? From my understanding the big issue was that when people started farming their diets became less diverse. Grain was abundant, so they relied on that for the most part. Over time people actually became shorter interestingly enough. Additionally, people were living into close proximity to livestock which caused disease. So essentially people just became less healthy. I would also add that farming is a lot of hard work.  Just like life nowadays, we have to work for most of the day, just for a few hours of comfort or "me time".

Prior to farming, I'll bet life was like one prolonged happy adventure.  Just hanging with your bros or girlfriends.  Going on hikes.  Chasing a deer every now and then for the thrill and food!  Not a care in the world!...but then farming came, and damned if that wasnt the equivalent of a college kid entering the real world. Why does this sequence of events always remind me of the Adam and Eve story?

Lived in paradise, then once they ate the fruit of 'knowledge' their lives became endless toil and childbirth? Then they put clothes on (which comes in handy during an ice age). Seems... appropriate. [deleted] You're probably right. People were extremely good at hunting. Evolution had done it's job making the average human quite athletic and very skilled, so that along with the abundance of animals would have made for a good time. Once they gathered all of the useful resources from the area, they could just move on. The only thing though is they were more susceptible to the elements and dangerous animals. With farming also came the ability to build better living structures and protection to keep things out. [deleted] There isn't any evidence that life was easy in a more primitive state.  Life for chimpanzees isn't easy, for example.  Ancient hominid skeletons show broken bones, a lot of wear, and disease.  There are isolated tribes today that lack agriculture, and it's no park.  I'd rather work at a convenience store with heating and air conditioning. More work, longer hours, the risk of weather/insects/whatever ruining your yields, so you end up starving in the winter.   And why would we produce more offspring if life is worse?  Ironically, to "make life easier". The same principle would most likely have been true of then as it was even in more modern times for farmers. Large families made the work load of farming less burdensome, being able to spread the workload amongst family. Problem is if you have every farmer following the same idea, the population grows exponentially and then you MUST have large families because the work load has ALSO increased exponentially. You can see this basic idea at work if you compare family bonds and structures in developed an developing countries.

In developed countries family bonds don't provide essential support so it's easy for nuclear groups to drift apart.

In developing countries family bonds *are* the source of essential support so nuclear groups can't separate. Agriculture is significantly more work that gathering and hunting to gain the same value. Consider - you have to plow, plant, pray for rain, and gather your crop weeks/months later, while watching over it to see it isn't destroyed/eaten. With gathering, ignore all that and skip directly to collecting whatever is already ready to eat in the area. Hunting is also a fair amount of work, but something we're well suited for, and with a big payout in food and materials. 

Due to the labor intensive nature of farming, it helps to have lots of kids, so you can have more people helping out with the work. Most estimates I've seen are that hunter-gatherers spend 3-4 hours a day working, while we spend twice that today, never mind in years past without labor laws and the like.  Agriculture creates a concentration of immobile property, people, and animals. This leads to more frequent and lethal violence, concentration of wealth, inequality, disease, and a ton of other stuff.

The upsides are fairly numerous as well, at least.

I'm drawing these conclusions from the books Guns, Germs, and Steel and Sex Before Dawn - which aren't without their critics. [deleted] Could you please name the author? 

I can't find it without, definitely want to read it though  [deleted] [deleted] [deleted] &gt; If there was ample food, there would be a population explosion by families having 10 kids and their kids having 10 kids until all available food was exhausted and you have some people dying off from the occasional draught or bad hunting season.

Well, people generally can't reliably have 10 kids per couple even with enough food. Health, infant mortality, complications of childbirth, plagues and wars all constrain population growth. That's actually what agriculture brought: Much higher fertility rates, along with higher mortality rates (infant especially). H/Gs would have a couple of decent kids with two making it to reproduction but a farmer would have 10 weak ones with three making it to reproduction.  [deleted] &gt;Family size would be determined by available food supplies, right?

No, humans aren't that fertile by default.  In a culture where women breastfeed naturally, the child on their hip and feeding every 15 minutes or so for a short time, prolactin levels are kept high in women by this and they are only likely to be able to ovulate once every 4 years or so.  Even with their first birth coming as soon as they were reproductively able, it results in far fewer babies than is possible in later cultures with different practices.  

Also, we're talking about hunter-gatherer tribal situations.  Thinking in terms of 'families' is incorrect.  Children were not understood to come from one mother and one father.  It was believed that many men fathered a child, and children were raised in common amongst the tribe.  If food ran out, you simply walked over the next hill. Humans weren't necessarily at the top of the food chain. There used to conspiracy theorists who posited that round holes found in early human skulls were "evidence" of aliens or civilizations with guns or at least arrows. The holes were actually caused by the fangs of great cats preying on humans. This may have had an impact on populations.  
Cites: [A Hominid Skull's Revealing Holes]( http://connection.ebscohost.com/c/articles/7953911/hominid-skulls-revealing-holes)   

  [ Eocene Biodiversity: Unusual Occurrences and Rarely Sampled Habitats]( https://books.google.com/books?id=iKMc-eLFgNgC&amp;pg=PA182&amp;lpg=PA182&amp;dq=holes+in+hominid+skull&amp;source=bl&amp;ots=q_6HtFs8vL&amp;sig=tSp2U6s7mszAYtO7vd6XLD6mIuM&amp;hl=en&amp;sa=X&amp;ei=DofUVMm2IIuQyQTDqYKACg&amp;ved=0CCUQ6AEwBDgU)   
Edit2: google "leopards and hominid skulls" to get more cites. It's kinda unobvious how to get this topic in google so as to avoid a wall of conspiracy theorists and creationist websites Could it be compared to how in current day we aren't trying to build cities over the sea due to the fact that we don't HAVE to?  the region of modern day lebanon, where they believe agriculture was first discovered, actually discovered it by accident. the climate part is true, but what they believe happened is that they would harvest wild grains which grew in abundance. when the climate changed and it became harder and harder to harvest wild grain, they noticed that the seeds from the wheat they harvested would grow around the village and thus began experimentation with agriculture.  [deleted] [deleted] [deleted] [deleted] Do you have any reading on what they primarily ate?  The thing about humans is that they will live off _anything_.  Humans taken all together probably eat the widest variety of food of any species that has ever lived. For hunters and gatherers, you've got Inuit living almost entirely on marine meat.  You've got peoples eating whatever range of edible plants and catchable animals are in their area.  Once agriculture got going, you have whole populations living mostly on grains.  But despite certain diets claims to the contrary, hunter gatherers ate grains too (the paper I linked above has some discussion of this, and here's something discussing [grain consumption by Neanderthals](http://www.mnh.si.edu/highlight/Neanderthal_Diet/)). Before farmers took all the really good land for growing crops, the stuff grew wild in thick stands and where it was common, people ate it. 
 &gt;*Humans taken all together probably eat the widest variety of food of any species that has ever lived.*  
  
I find that absolutely fascinating. We even eat stuff that has specifically evolved to irritate only mammalian tissue, to the point of excruciating pain, vomiting and diarrhea....like Capsaicin.  
  
[In Finland, during the great famine, people literally ate the bark off from trees and kind of survived on it.](http://upload.wikimedia.org/wikipedia/commons/thumb/2/23/Barkbrod.jpg/640px-Barkbrod.jpg)  
  
What is so special about our digestive system, that we can eat, digest and survive on such wide variety of food sources that might be poisonous to others or just completely inedible to many? I don't know that were particularly special. Look at dogs, they can eat just about anything as well. Perhaps what helps to make our digestion "special" is that we have the ability to prepare, preserve, and alter foods to make them fit for consumption. Oh there are a lot of things that are poisonous/harmful/not really food for dogs but they will still eat it regardless.  
  
Dark baking chocolate for one (*can outright even kill a large dog or severely poison them*), onions will kill their red blood cells, garlic, caffeine, grapes (*kidney failure danger*), raisins, dairy stuff, some nuts, **even fat straight from the meat** (*cooked or uncooked*) can give them pancreatitis, peaches, plums, persimmons, eggs....etc. 
  
Dogs will eat about anything, but it doesn't mean they can digest or process it like we can :)  
  
If you are a cat, you are out of luck and can (*and should*) pretty much just eat meat and nothing else. Also, don't forget that dogs are a domesticated species which adapted to our diet. Wolves eat meat, not much else. Well, exactly what they ate I couldn't say. However one of the human advantages is being able to eat a lot more varied than other animals, so presumably they ate what they could find near them. They also ate better than most people did the next 10 000 years, as you can see from hunter gatherer skeletons that we've just started to catch up in average height to their levels. Would that be because the vast majority of people throughout early civilization ate mostly bread? And thus didn't get a lot of protein or fat?  Kind of. Human numbers grew larger than what the local wild could sustain naturally, so people survived with very little food and most of it was just single type...like bread. Reminds me of Childhoods End; if you live in an utopia and have everything you want, why change anything?

That book made me a little afraid if having it too good... You know, humans living like 100,000 years ago didn't exactly live in a utopia. They would have lived in tribes struggling to survive and many millions of them would have died for not being able to survive the elements. Average life span would have been super low, too. Well there have been 100 billion people who have come and gone on this planet, so millions isn't really that much. If you mean millions every few years, that's unlikely, since the human population of the planet was only about a million for most our history. True, but this is over the course of 190,000 years, prior to the most recent Ice Age. There have been other ice ages during that 190,000 year period... so I'd like more information on how this might have been a rubber band over time. And they only "worked" something like 4 or 5 hours a day.

It was a glorious time on the planet Earth. I will just add [this paper](http://www.des.ucdavis.edu/faculty/Richerson/AgOrigins_2_12_01.pdf) to buttress what you said. Lots of people are suggesting a lot of hearsay.

To clarify some points, it is widely accepted that anatomically modern humans would have possesed language every bit as expressive and complex as our own, so language acquisition almost certainly does not explain the technological transition to agriculture 14k years ago.

For most of human history humans lived in tiny populations and were hunter gatherers, often nomadic too. There isn't much scope for storing knowledge during this period as you have to remember everything your group "knows". And there isn't much scope for coming up with lots of ideas as there aren't actually very many of you.

One idea about the neolithic period and the agricultural transition is that it is the first time in human history where we reach critical mass intellectually. There's enough of us that we can store lots of knowledge via memory alone and there are enough of us that we're generating lots of ideas. Once both those are in place we've hit the point in history where good ideas can accumulate reliably and not just get lost/forgotten.

This economics/anthropology paper is about this very idea

http://www.jstor.org/discover/10.2307/2118405?sid=21105271099901&amp;uid=4&amp;uid=83&amp;uid=2&amp;uid=3738032&amp;uid=2460337935&amp;uid=2460338175&amp;uid=63 Probably the biggest change is that [about 10,000 years ago the climate got a lot nicer](http://joannenova.com.au/globalwarming/graphs/vostok-ice-core-50000.jpg).  We've been in a nice, stable, warm climate system for about 10k years now, which is probably pretty much the ideal climate for doing agriculture in.  Predictable seasons, no ice everwhere, pretty good for plants in general.

Given that agriculture appears to have been invented in several different places independently around the same sort of time frame, I don't think it's unreasonable to speculate that people were smart enough to figure out how to do it for a good long time, just that the climate wasn't quite right. What happened 17,000 years ago? I thought the end of the last ice age ended roughly 12,000 years ago, and that ice ages were cyclical in nature. I think, though someone can correct me if I'm wrong, that the dominant forcing regarding what causes ice ages is changes in the characteristics of earths orbit, know as Milankovitch cycles.  There are changes in oribital eccentricity, obliquity and precession, which alter how the Sun's rays hit the earth.  If you do a spectral decomposition on a sufficiently long temperature time series then you get [spectral peaks](http://www.nature.com/nature/journal/v399/n6735/images/399429ad.eps.2.gif) at around 100k, 40k and 20k years, which I think correspond to the various periods that these cycles act on.  Of course there a lot more complexity going on under the hood that isn't well understood. Not to be pedantic, but it's "hearsay". I mention that only because it took me a beat or two extra to parse what you were saying in that initial sentence. This phenomenon is called an ["eggcorn"](http://itre.cis.upenn.edu/~myl/languagelog/archives/000734.html), named after a particularly endearing mis-learning of the word "acorn". There's even [a database of eggcorns](http://eggcorns.lascribe.net/). It's a natural and perfectly reasonable part of language, and people shouldn't feel bad when they realize they have an eggcorn or two in their personal dialect:

&gt; It would be so easy to dismiss eggcorns as signs of illiteracy and stupidity, but they are nothing of the sort. They are imaginative attempts at relating something heard to lexical material already known. One could say that people should look things up in dictionaries, but what should they look up? If you look up eggcorn you'll find it isn't there. Now what? And you can't look up everything; sometimes you think you know what you just heard and you don't need to look it up. Someone says something about "the Oxford/Cambridge boatrace" and you just assume that Oxford and Cambridge hold a race that involves boats of some kind (correctly, as it happens). You don't go rushing to the dictionary to look it up, to make sure they didn't say bone trace or beau treize rather than boatrace. You're an intelligent native speaker; you have a right to just trust your ears and your brain sometimes. And sometimes in consequence an eggcorn is born.

http://itre.cis.upenn.edu/~myl/languagelog/archives/000621.html And nothing is wrong with correction. Better on reddit than on a published paper or other serious literature. People can only know things if they learn them somehow. A published paper would have been corrected though, by at least the first reading. Unless it's obvious that it's a slip up on the keyboard and not some chasm in the commenters knowledge. Then it just comes across as derailing someone's thought out point and focussing in on an irrelevant mistake.

Edit: if you don't agree with this statement, please comment and leave a reason rather than (or in addition to) downvoting, because I'm always open to having my mind changed. &gt; One could say that people should look things up in dictionaries, but what should they look up? If you look up eggcorn you'll find it isn't there.

Interestingly enough, this part is now obsolete in a lot of cases.  If you google an eggcorn (particularly a phrasal one), you can very often get a suggestion for the correct phrase (just try googling "here say").  The coverage of this technique is even higher when you throw in a couple of context words around which you first heard the word. Would be interesting to know the effects Google (or similar sites) have on this. I know that I just hit up Google on words I am not so familiar and see if it recommends something else How does that database not already have "Knowledge is Power, France is Bacon"? [deleted] I remember "hearsay" because to me, it sounds like what it is. You "hear," and then "say" something without the middle step of verifying it. That makes it unreliable, which is what hearsay means to me. so is this why people confuse "then" and "than"? no, those are homophones.  that does come down to illiteracy or just not paying attention. They are not homophones, at least in North America.  The vowel sounds differ in most (but not all) usages.

 Then you've never lived in the South, where the two words are identical, as are the words "pen" and "pin." ;) I don't pronounce them as homophones. Some people do? Are they really homophones?  They are close, but are different.  For quick/lazy speech, I suppose they might be. Depends which dialect you speak; in some, the vowels in those two words have collapsed together, in  others they're distinct. &gt; For quick/lazy speech

Most speech that takes place is in informal registers (what you're calling quick/lazy speech).   My gut wants to say that's different, but I can't put into words exactly why  What about the very irritating "defiantly" instead of "definitely"?(Shudder.) Don't know about you but my spellcheck seems to want to translate any misspelling of "definitely" as "defiantly" and on quick glance they look similar.  Part of the problem with this is that the way we speak then and than is very different than the formal rules for written grammar.  When we talk, we typically don't double the flat A vowel sound, so we'll say "I have more sand then you."  Grammatically we should say than, but that sounds and feels weird (say it aloud and you'll see) so when we write it out, we second guess what we're saying and write the wrong one.   It is not clear that anatomically modern humans had language. Estimates of when language emerged generally say 50-70,000 years ago, right around the same time as the population bottleneck and leaving Africa. how do people come up with these estimates? is there evidence for spoken language before the development of writing systems? Genetic evidence is one. Without the FOXP2 gene none of us would be talking like we are now. So when it first appeared, it is a good indicator that there was heavy selection/need for it to become the norm and people most likely began naturally communicating in a very complex manner.  
  
Basically going from: "*Ugh, fruit, tree, me, eat, give!*"...to "*hey Adam, can you give me that fruit up from that three right there I might need that later on....k thanks I'll pay you back later...don't step on that snake...how's Mary doing by the way?*" Is it possible that sign language developed before speech? Babies who are exposed to sign language actually can sign before they can speak, but that's because of the articulators involved (babies learn to use their hands before their vocal cords). Since humans have had basically the same arms and vocal tracts for the past 200k years, and signed languages are  of equal cognitive complexity as spoken languages, it seems unlikely that humans started signing first without speaking. Language in this context is capacity for forming more and more complex "mental symbols" and eventually manipulating these internally. How  these were socially communicated is important since the symbols only gain meaning through social interaction, but the specific form is not important.

Which is to say that sing language and speech are the same thing in this context. The emergence of behavioral modernity is dated to be complete around 50-70,000 years ago but that is by no means the same as the date for the emergence of language. Language diversification/proliferation  and phoneme diversification studies typicall place the origin of human type languages at least before 100,000 years ago. I'd be interested to know how they define 'language' in those estimates (and how it differs from the vocalizations humans must have used before language). There are so many factors, but a big one that hasn't been mentioned is climate.  The last "Ice Age" at the tail end of the Pleistocene era last from about 100K years ago to... drum roll please... 12K years ago.  Even before that periods of what's know as "climate volatility" created less then ideal conditions that would have limited population growth.  

The first modern homo sapiens would have began venturing out of the Ethiopian area around 125K years ago, though it is also then believed that their was a "retraction" back into Africa around 75K years ago due to climate change and possibly conflict with Neanderthal tribes more adept at surviving in a colder climate.  

That retraction also coincides with the eruption of Lake Toba... the largest volcanic eruption of the last many many millions of years, and a "climate event" that most likely caused a dramatic reduction in total human population.  Some estimates put the total number of humans that survived in the  sub 20K range.  

That still does give us a huge amount of time that people were living in tropical regions of Sub Saharan Africa... so why no agriculture development there?   Well... a big reason could be that Africa is a really difficult place to develop agriculture.  It had almost no large seeded grasses, which are the basis for almost all grain agriculture.  It had almost no easy to domesticate animals.  It was very wet... which is the enemy of trying to preserve foods you do manage to save.  If you're into the whole geographic theories behind why agriculture developed where it did Guns, Germs, and Steel is a fantastic read. 

Basically... the world just wasn't a very easy place for us to develop the first couple hundred thousand years.  We tend to think of the world as it is today, but the world a long time ago was a very different place... both climatically, and in terms of how agriculture would be nearly impossible in many places without technologies and species developed in relatively few places.  

*edit... couple hundred thousand... not couple hundred. 

It's really fun to think about.  Great question.   Just as a follow up... the Lake Toba theory is an interesting one, but not exactly widely accepted.  Where and how the last genetic bottleneck occurred is still widely debated.  

However there does appear to be a pretty dramatic population explosion around 50K years ago when venturing out of the tropical regions and into the rest of the world would have been greatly assisted by a much better climate for human survival as the ice age ebbed.   &gt; a "retraction" back into Africa around 75K years ago due to climate change and possibly conflict with Neanderthal tribes more adept at surviving in a colder climate.

Do you have a source for this? As far as I'm aware, Neanderthal people weren't more adept at surviving the colder climate. In fact, they went extinct during the height of the last glacial period, when their last refuges in the mediterranean became too cold and dry to support communities of animals as large as people. 

 Doesn't the existence of Neanderthal DNA in modern humans mean they merged, not went extinct [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] We do have plenty of (albeit spotty) evidence of what homo sapiens sapiens were doing before the agricultural revolution. Cave drawings, tools, teeth, and so on. [From this we can infer to some degree how they lived, and what they ate](http://www.npr.org/blogs/thesalt/2014/01/06/260185944/looks-like-the-paleo-diet-wasnt-so-hot-for-ancient-hunters-teeth) (link is an example, not an exhaustive review). [deleted] &gt; Sure, maybe people invented rocket ships 50,000 years ago, but with no evidence it is purely speculation

The lack of evidence of anything near such activity is also telling us something. Our current civilization, for example, couldn't go under without plenty of archaeological traces.  If  Neolithic  Ned  was  screwing around trying to  get a [rhinoceros](http://en.wikipedia.org/wiki/Woolly_rhinoceros)  to  settle  down or whatever, then  he  was  going to  miss the  berry  harvest  or the  salmon run  or  something,  and  his  family  was  going to  go  hungry. 

Neolithic  people had  cultures  that  were  very  well  adapted  to their  environments, and  didn't have much of a margin  for  trying  new  and  different things. 

People in  grain-producing  areas  got lucky  -  grain was a resource that was practical  to    grow a  lot  of and then store,  and that  gave them a storable surplus  so they could start  large-scale experimenting  with  other things.  Not only was wheat the perfect plant to harvest, the cow was the the perfect form of cattle to compliment. It provides meat and milk by eating the plants and part of the grain unfit for human consumption. They were also bred to do hard work, such as plowing the field, carrying a yolk, and transporting the food.

They were so important that most early religions represented their top gods with the bull (Baal of Babylon, Zeus of Greece, arguably Jehovah of the Hebrews) or revered cows as the most sacred animals (early Egypt, Hinduism, East Asia). They were usually associated with the harvest.

DNA testing of modern wheat and cows found that both originated in South East Turkey. It was the perfect storm of factors creating the agricultural revolution there. Just a correction, the word is 'yoke' not 'yolk'. Although that might well have been auto-correct, I doubt many people use the word yoke enough to get it into their phone's dictionary. It is also entirely possible that Neolithic communities did not necessarily see technological advance as a good thing. Many modern-day hunter-gatherer communities are contemptuous of settled, agrarian societies and fight to maintain their traditional lifestyles against modernity. This does promote the survival of 'the group' entity by slowing assimilation. Even in the West, technological innovation has only recently been seen as 'progress'. Classical and Medival European societies thought that humanity was degenerating from a golden age or prelapsarian state respectively. Our increasing reliance on technology was considered to be a symptom of moral, mental or even physical decay. Well, look at rising rates of obesity and preventable diseases. Were they right? A couple things:
 
1. The assumption that modern society or civilization is better than previous hunting and gathering societies is fundamentally flawed. That's way outdated anthropological/archaeological thought from the 19th century. The idea of cultural evolution is an outdated concept that was based on a miss understanding of how biological evolution actually operates. 

That would be natural selection. Which operates on 4 basic principals. Inheritance of acquired traits, reproduction, Variation of genetic material and competition. Throw in evolutionary forces such as mutations, gene flow and genetic drift. 

Culture is not a biological organism and does not "evolve". 

Louis Henry Morgan propagated that nonsense.  But for some reason it's still floating around in even the scientific community. 

2.  Since around the 10k mark population has grown, knowledge accumulates and so on  but looking at human Osteological material from most agriculturally based cultures ( including and especially our western past) we are mostly unhealthy and disease ridded. More people died of the Spanish flu than there were people alive in 200,000 bc.  Also, I guarantee most of you fellow reditors never farmed and if you have I could bet you didn't use digging sticks and rocks to sew your crops. It's obscenely hard work. This also results in shortages and mass starvation. As where a hunter and gatherer might have seasonal hunger. They herds will reliably return, unlike a failed crop.  That's  right before Walmart if your crops failed you died. Most archaeologist do wonder why we didn't discover agriculture sooner but they also wonder why we stuck with it. There were no dictators or kings before the accumulation of resources (Neolithic revolution) as far as we know. 

3. On that note. People. CLIMATE CHANGE. Climate is not static it's been quite tumultuous for all of earth's history. It's no mystery that during the last ice age ( which had 15 cooling and warming cycles) people dispersed throughout the world.  Land bridges  were everywhere. The UK was not an island chain it was straight up attached to the rest of Europe. Most of Europe stretching from England to Russia was a great plain kept cold and dry by the Scandinavian ice sheet. This grassy plain is referred to as a steppe tundra and below it was a park tundra with stubby bushes and in the Mediterranean there were boreal then deciduous forests. 

This plain was filled with an astounding number of plants and animals because of the daylight hours which contrasts current day tundras. Paris is in line with New York ( kinda) most Americans don't realize that Europe is actually a much "higher" relative to them. But as where current Alaskan or Siberian tundras count their winter daylight  in minutes the ice age tundras would count them in many hours. This means that the land could support more species. 

The ice age hunter would have access to not only mammoths but a variety of deer, rhinos, hippos, lions, bears, hyenas, small game. They likely exploited marine resources too but those site are all deep under water so we'll never know for sure. And they didn't frequent the large game until other Han groups entered europe and increased population pressure.  It was us crazy anatomically modern humans that likely started regularly hunting the large and dangerous animals. The Neanderthals didn't need to risk they're lives with all the safe game around. Though they too hunted big game on the occasion. 

The short answer to why they didn't become sedentary and start growing stuff is because why would they need too?! 

The answer? 
 
The climate changed. What was 3,000 feet of ice in Central Park, New York would have melted in as little as 11 years. Imagine that all over the northern hemisphere.  

As the forests from the Middle East moved north ( in the course of only a couple hundred years) the large game were choked out. By the way out ancestors were not idiots. As they noticed what was happening they "encouraged" certain biotic communities to grow per region. Grains like wheat were encouraged to grow and later domesticated in the Middle East as where oats were in the north. Wheat requires a wet winter and a dry summer to germinate. Traditionally it could only be grown under specific climactic conditions. Goats and sheep were also domesticated in the Mediterranean and cattle in the north. Also, don't forget about the funguses and bacteria we domesticated to preserve all this food. 

People didn't just say. Ok let's do this. It was a long process that involved humans manicuring the land. The idea of wilderness is fundamentally flawed too. Most of the earth, including the the amazon rainforest ( huge pre Colombian sites are being uncovered that reveal controlled burning and maintenance of rainforest land) , has been a manicured "garden" since the end of the Pleistocene. Nobody domesticated anything sooner( aside from dogs) because we "created" the species through careful observation and selection of plants and animals we liked until our modern species exited. We're still genetically selecting and modifying our domesticates today. GMO's are NOT a new thing. Everything you eat is a GMO. Haha

We don't have any idea what ancient corn or wheat looked like genetically. There are some good candidates but realistically they were created from a species that no longer exists. 

- Just some long thoughts from an archaeologist. 

 &gt; Culture is not a biological organism and does not "evolve".

Biological organisms aren't the only things subject to Darwinian forces. There's a tonne of recent research indicating that [culture does literally evolve](http://rstb.royalsocietypublishing.org/content/366/1567/938). Note that cultural evolution in that sense has nothing to do with either Morgan-era linear social evolution or 1950s neoevolutionary anthropology. Great post! Your fact of 3000 feet of ice melting in 11 years is phenomenal - could this rapid "De-icification" as it were, have led to the multitude of stories behind "The Great Flood?" (Noah, Gilgamesh, and the like) Are the ancestral humans intellectually similar to us? Can I say time-travel and take a baby from 100k years ago and raise her in a modern environment and let her pass as any other 21-st century toddler? Good response - matches what I learned as well when getting my degree in archaeology.

In regards to point 1, its a bit more complicated that that in that you need to mention about the importance of low pop densities.  In some areas of the world where game was plentiful, H&amp;G wouldn't need to have large tracts of territory to utilize - but could actually stay in one spot permanently (ex. Pacific northwest coast tribes).  

Theoretically, this could invariably lead to conflict, formation of social hierarchies, trading of surplus, etc (basically civilization), but the counter argument is that low population density made it easier for tribes to just move to a different spot when conflicts did arise.

Secondly, thank you for also making note of the fact that GMO's are not a new thing.  Sometimes, I suspect that people think corn and wheat have always looked the way they do, 

Lastly, I realize that you partially alluded to the impact of climate change which defiinitely had a role, but it should also be pointed out that many areas where people originally settled are currently underwater.  Meaning, there are large chunks of possible neolithic history, including previous attempts at cultivation and domestication that we aren't aware of, and thus we cannot be absolutely when exactly the start date was in some of the key regions of the world

Otherwise, I pretty much agree with everything else you mentioned.  Its good to see someone who studied archaeology is actually still doing it professionally.   Haha yes thank you I'm glad to see you here too. I find it really hard to explain things to non Anthro/arch people without lecturing everything. 

I should have thought of the Pacific Northwest. My focus in the post was mostly in the old world.  

The sad thing is that most of those sites we may never see. But what's even more upsetting is that current climate change is washing away sites as we speak. Neolithic sites in the Orkney islands, for example, are close to complete loss. 

The other thing to mention is that,  regardless of what's underwater, we may have domesticated plants and animals several thousand years before without any apparent morphological changes. For example,  could have domesticated ovca(sheep/goat) 10-14 thousand years ago but their morphology may not have reflected that until 10,000 bc. Same with plants. 

But it's all educated speculation until we find more conclusive site/evidence. 

Every time I explain the GMO thing to people I get a blank expression. It's both humorous and frustrating. We have been genetically modifying organisms for thousands of years we just have the tools now to do it more effectively. Whether it's for better or worse. 

Glad to see your comment! Is it really likely such dramatic changes on Earth happened as quickly as you indicate in this post?  3000 feet of ice gone in 11 years?  Almost unrecognizable shifts in plant and animal life in a couple centuries? [deleted] [deleted] [deleted] &gt; mestication, they were wild animals that could easily kill you. Especially the horse, I'm kind of surprised that it went through anybody's head

pre-domestic horses were much smaller. the size of smaller ponies. still potentially dangerous, but not nearly as much as a modern horse.

IIRC, horses were more useful as pulling animals than riding animals up until a couple millenia ago, and it wasn't until the early middle ages that horses became large enough to carry a man in full plate. Horses have become much larger in the last 1200 years.

IIRC, early/pre domestication horses were about 10 hands high at the shoulder. a modern light riding horse is going to be 15-16+ hands high at the shoulder. A Clydesdale is going to be around 18 or even more for the big ones. The one that surprises me is the Aurochs. THAT was some kind of big primeval ancestor animal. 

Not that cattle the size we are used to now are necessarily mild customers. Some of it's the breeds, naturally, (not a lot of Jersey Milk Cows out grazing out in the national forest and stuff) and some of it is the whole "range cattle" thing. They are familiar with the concept of people and (unwillingly) deign to be herded, but they don't like it any even if they don't actively try to kill you most of the time.

 They were probably draft animals for a long time first.  But even small horses are well suited for riding.  The last sub species of wild horses are about 12-14 hands and are damn strong. I worked with them during my zoo internship,  I love horses but these guys were kind of scary and violent compared to domestic horses. 
http://animals.nationalgeographic.com/animals/mammals/przewalskis-horse/ &gt; ...it wasn't until the early middle ages that horses became large enough to carry a man in full plate.

What about Parthians and their cataphracts? They were roughly at the time of the roman empire before it split, well before early middle ages...

Edit: They didn't have plate armor, but both rider and horse were armored, so the horses must have been big enough. Yup, and Alexander's companions, I don't think their charges were done on ponies, further investigation needs to be had about these horse breeders. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Ok here's what I don't understand. How did modern humans figure out how to cross a sea and get to Australia 90,000 years ago but we couldn't figure out "plant this seed" till about 12,000 years ago?

Something seems jacked up about the human time line. Firstly sea level was lower, island chains in indonesia would have been connected and it wouldn't have been as far of a trip to Australia.  The concept of making a canoe or fishing offshore isn't that complex and 12,000 year ago people were just as smart as people today in terms of problem solving. Many native american groups were hunter gatherers up until they had contact with Europeans. 

Secondly, the connection between planting a seed and agriculture is vast. While, yes, there are wild plants you can eat and plant, hunter gathers weren't spending a long enough time in one place to cultivate them. Additionally, the predecessors to cultivated plants like potatoes or corn are vastly smaller and less nutritious. There wasn't just wild fields of wheat that they just needed to plant and wait. They had would have had to plant only the largest/best plants and continue that processes over many generations. It wasn't worth the time and effort.

You need to think of hunter-gatherers as having an economy of calories. The cost of living for a hunter-gatherer is the calories burned getting food. They pay they get back are the calories from that food. If the land can support a group of people cheapy in terms of calories spent by hunting deer or fishing, they have no reason to look for alternate means feeding themselves. 

 Hunter gatherers work a lot less for the same amount of calories. You don't switch to agriculture until you need to, because it's hard work. Rather, until you're forced to. As farming peoples expanded, their populations grew, and the land they farmed quickly degraded. Agricultural expansion was often very violent. How come writing took so long to come about?

Surely people sitting around 150k years ago were like "alright this eating and drinking stuff is good but I want to think"

Was writing really that difficult of a concept for them to grasp? Or was there just no purpose for them to write anything?

Sorry different question should really be it's own thread I guess. A list of additional points:

- Settling down makes you an easy target for hunters/gatherers around you. You need a lot of organisational, cultural, technological, and other factors to come together to have a balance where you can be successful with that. Even large cities have often been destroyed by relatively small nomadic groups, until their armies had become strong enough that only a city could have hopes of successfully attacking a city.

- Disease spreads more easily when lots of people are coming together in small spaces. Some advances in the human immune system, in humans caring for each other, and so on, where needed to allow larger settlements.

- Diseases, climate changes, and other factors often reduced populations so much that people reverted back to the hunter/gatherer life style.

- People simply didn't have the plants necessary to support the settled life. Rice, wheat, and so on, are very new human made variations of plants which were before nice to have as an add-on to your main food, but not producing enough to support a life style without grazing or gathering in large areas. The path to now seems much shorter seen from here than seen from there without foresight.

Basketball is a wonderful game. It only took four years for someone to say, "Lets knock the bottoms out of these baskets. We can play faster." How long would it take for you to suggest that?

There are still groups in Africa who do not want to farm or herd. Why do all that work when you can hunt for a few hours?

These groups are being crowded out by farmers and herders who will work harder.

Improvements do make it easier for other improvements. Neanderthals lasted three hundred thousand years. But they may have used thrusting spears. Homo Sapiens may have used throwing spears which reduced personal injuries. But the climate was changing too. Atlatls were developed. Then bows and arrows came along, but not in North America until about a thousand years ago.

The age of the oldest in the group may have raised from thirty to old age which increased the social memory of the group tremendously. A grandfather could speak of his grandfather relating stories from a hundred years before rather than forty. Increased population density meant they knew other grandfathers.

Farming occurred that long ago. But the yoke which made plowing with animals better than with people did not develop until the middle ages. Jethro Tull vastly increased the yield from seed no too long ago.
 It all depends on your definitions. Some broad points for you: There is zooarchaeological evidence suggesting dogs were domesticated 30,000 years ago. Agriculture as a main food source doesn't mean life was better. Dental problems exploded with starch agriculture. It is argued that hunting is much easier that farming. A successful day hunt can give you food food a week, whereas maintaining cross takes hours a day for months to yield crops. The is evidence for technological advances in tools and weapons, such as transitioning from chipped stone points to core flake tools. Geologically, areas of exploitation may not have been accessible due to glaciation. I would like to point out that even as a hunter-gatherer one can suffer dental problems by still having a high starch diet

See,

Louise T. Humphreya, Isabelle De Grootea, Jacob Moralesc, Nick Bartone, Simon Collcuttf, Christopher Bronk Ramseyg, and Abdeljalil Bouzouggarh

2014 Earliest evidence for caries and exploitation of starchy plant foods in Pleistocene hunter-gatherers from Morocco. Proceedings of the National Academy of Sciences 111(3): 954-959. Perhaps surviving winter is much easier with Agriculture?

Or maybe the combination of Agriculture and hunting? You would definitely exploit different resources seasonally. Salmon fishing in the summer, for example. People have used horticulture to supplement food supplies, but it should not be implied that people did not store food for winter before agriculture. Agriculture meant you could support a much larger population and far fewer starved to death. Dental problems and less free time were a minor nuisance in comparison to starvation. Dental problems are more that a nuisance. Dental caries can abscess, which can lead to infection and death. Less free time can be debated, would you rather work 8 hours to get your food or 40? Like you said, agriculture allows for a few individuals to provide for many, but if your village is 15 people, it makes more sense to hunt a deer than plow fields. An important point though is moving to agriculture is not part of a cultural "evolution." There are societies that still practice horticulture, pastoralism, or hunting and gathering. [deleted] There was [a study](http://www.jstor.org/discover/10.2307/2694241?sid=21105272321581&amp;uid=4&amp;uid=2) that showed how the Pleistocene climate was too sporadic for the amount of time necessary to kickstart agriculture from the ground up. Pun intended. I need help.

Anyway, the idea is that up until about 11k years ago, weather changed too rapidly, too starkly, for humanity to settle for the time it needed to domesticate cereals. So out of sheer necessity and primordial habit, Pleistocene humanity lived off the hunt.  One point that I haven't seen yet is that the idea of 'progress' being a good thing, is relatively new. In a way people have always been scared for changes - even now many people are. 

But in our civilization there is basically a cultural need (and appreciation) for permanent change. 

Your question can also be reversed: why do people these days (the last 1 or 2 centuries) want permanent change? Why are people no longer satisfied with the way it was and always has been? [deleted] [deleted] [deleted] The planet warmed up about 15,000 years ago.  Ice sheets receded and all that.  Humans made it from Asian to Alaska across the ice-bridge before it vanished.

There are probably a number of things, but that's always struck me as a likely catalyst. Beringa was not an ice bridge. It was a land mass that connected modern day Russia and Alaska. With water still locked up in the continental ice sheets, ocean levels were considerably lower. As the ice sheets melted, Beringa was submerged. It wasn't something that happened over a couple years. It is possible that at the time, people inhabited the land for considerable amount of time, but we can't really prove it archaeologically. This theory could explain mammoth remains found in St Lawrence Island though. There is also the theory of coastal migration to explain humans coming. Following the "kelp highway" along the Pacific coast down as far as South America. Correct on every point as far as I know.  I was keeping it simple.  Thanks for the addition.

Point still stands.  Planet much colder, and massive ice sheets extending down into some pretty low latitudes.  Not surprised if that changing led to better conditions and triggered the advent of civilization. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Ok fair but then you're saying we were basically dumb mutes for 190k years and then suddenly, collectively, we discovered language, an overnight success. Nothing personal but lightning is a weak analogy because there's always been lightning on Earth, for the most part. But to stretch this a bit, since we actually dont know when language was discovered, couldnt it also be possible that maybe we always had some sort of language for most part, primitively evolving since the dawn of our existence, kind of like lightening on Earth? I think so.

So I mean if that's possible, then what else could have triggered a rapid advancement of our species after such a looong time of basically nothing? And I can't really think of anything.

I mean isn't this just a bit odd to you, despite the explanation you've put forth? Maybe its just me. [deleted] Ah, ok. Gotcha. So a certain amount of percolating, and slow, progress has to be always going on over hundreds of thousands of years until reaching critical mass that precipitated our advancement. That's the leading theory, I suppose, right? Seems thats what others are saying. [deleted] It's not so much that physics breaks down or that it's the hottest possible temperature, but rather that we can't really understand things that hot without knowledge of quantum gravity (because particles could be colliding with such great energy that they form black holes), which we don't understand well enough. Temperature is related to the speed of the Brownian motion of particles, right? Wouldn't that imply a maximum possible temperature when all the particles are going at c?

I am aware that that isn't actually how temperature is defined, but I've never understood the more technical definition. &gt; Temperature is related to the speed of the Brownian motion of particles, right?

More precisely, it's related to their average kinetic energy. The distinction is that there is no limit on how much kinetic energy a particle can have (if it has mass). 

&gt; Wouldn't that imply a maximum possible temperature when all the particles are going at c?

[As you keep adding energy you get closer to c, but to accelerate a particle with mass to c would require an infinite amount of energy.](http://hyperphysics.phy-astr.gsu.edu/hbase/relativ/releng.html) So the answer to his question is yes, the maximum possible temperature is when all particles are going at c. But particles with mass cannot ever reach c (only approach it infinitely), so there is no upper bound on temperature. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Wouldn't it be that temperature approaches absolute hot asymptotically but never reaches it? Yeah, but what does asymptotically approaching infinity actually mean? No the answer wouldn't be yes, for the same reason that the function y= x^-2 doesn't have a maximum value at x = 0 I don't know if it really is that informative to say that there is a maximum temperature, but that temperature just happens to be infinitely hot.

Generally then some value can go all the way to infinity we just say that it doesn't have a max value. &gt; so there is no upper bound on temperature.

To be overly technical, there is an upper bound on temperature (and, assuming this upper bound is finite, there are actually an infinite number of upper bounds on temperature). The lowest of these upper bounds is the supremum of the possible temperatures, and the question is to know whether this supremum is the maximum temperature or not.

For instance, particles with mass must travel slower than c, but can theoretically approach that speed. Therefore, there are many upper bounds on their velocity, e.g., 2c, c+4m/s, or c. These are upper bounds because they are larger than the velocity of any particle with mass. Now, the smallest number that is an upper bound is c, and c is therefore the supremum of those velocities. Now, if c could be reached, it would be the maximum velocity. Since it can't be reached, there is no maximum velocity, but there is still a supremum.

Nomenclature tends to be boring, and it's not a very interesting distinction, but I think it can still be useful to know about it. Someone took real analysis. Way to promote precise language in technical discussion. This is about the about the maximum temperature and not the maximum velocity. Temperature depende on the kinetic energy mad the kinetic energy approaches infinty as the velocity approaches c, so that there is no finite supremum for the temperature I have a question maybe you can answer. So someone posted the other day that .999.... is equal to 1. So if a particle is acclerating infinitely close to the speed of light 99.999....% isn't technically going the speed of light if we use the definition .999....= 1?  It'll be getting things going 99.9999% or whatever, but not 99.999...%. 0.999... is just a mathematical construct. Are you saying that individual particles have temperature?

E.g., a lone particle in a void.  [Yup](http://en.wikipedia.org/wiki/Temperature#Generalized_temperature_from_single_particle_statistics). It also has a pressure based on (among other things) the size of the void. Though if we're talking about a particle traveling through space, you would need to define a reference frame. Though it's important to understand what that actually means: you take "snapshots" of the particle at different moments in time and treat those snapshots as a collection of particles for purposes of calculating the temperature. So just to confirm my understanding, no particle with mass can be accelerated to c. Is that correct? That's right. It would take an infinite amount of energy to accelerate a particle to *c*.   THAT IS NOT MORE PRECISE! ITS WRONG!

Temperature is NOT related to their average kinetic energy! It is the ratio of change of energy to change in entropy of a system. Negative energy systems must first approach an infinite temperature before they reach negative temperatures. And will transfer energy to ANYTHING with a positive temperature. ie. Theyre HOTTER than ANY system that has a positive temperature.

All this stuff about the speed of light is nonsense. All of the high temperatures in this thread are exceeded in a laser pointer as it turns on. [deleted] [deleted] Have we come up with any theoretical ways around that yet other than the bubble warp drives? Does that mean that photons have infinite energy? Preface: Not knowledgeable in physics. Just using algebra wildly.

If e=mc^2, and assuming photons have 0 mass, then m=0. Therefore, (m)(c\^2)=0, and e=0. Sort of the opposite of infinity.

Of course, photons do have energy, or else you wouldn't be warmer in sunlight instead of shade.

Epilogue: Feel free to correct any of this. It was Sesame Street-level explaining with amateur assumptions and half-remembered community college science.

Edit: Formatting. OK. That makes sense. I had assumed that temperature was related to speed, but if it's related to kinetic energy that explains the issue. There is an finite amount of energy in the Universe, so there has to be a limit to temperature. Not so! There are simple systems for whom their heat capacity decreases with increased temperature, in such a way that infinite (and negative) temperature can be reached with only a finite amount of energy added. To elaborate on this, in most systems as we increase the energy there are more possible configurations of our particles, which corresponds to a higher entropy. Temperature is actually defined as 1/(dS/dE), the inverse of the derivative of entropy with respect to energy. Because in most systems the entropy is a monotonically increasing function of energy, the temperature is always positive.

However, there exist systems were the the entropy can DECREASE with increasing energy; this tends to happen when the system has a maximum possible energy. As an example, we can consider a system of non-interacting spin 1/2 particles in a magnetic field. The energy of the system is proportional to the number of down spins minus the number of up spins. There is only one configuration for minimum or maximum energy (all spins up or down, respectively), but tons of configurations for 0 energy (half up, half down; if there are 2N particles, we can do this in (2N)!/(N!)^2 ways). Therefore, for positive energy we are decreasing the entropy as we increase the energy, and dS/dE, and thus the temperature, will be negative!

It is worth noting that negative temperatures are "hotter" than arbitrarily large positive temperatures (in the sense that energy flows from a hot object to a cold one). This is basically an artifact of the fact that temperature is the inverse of a derivative. Using 1/T would in some sense be more natural. But we know that the entropy of the universe is always increasing, and for a system to have decreasing entropy it needs to make the entropy of its environment increase (like the heat radiated by the condenser pump of a refrigerator). So for something to have infinite temperature and decreasing entropy, wouldn't that imply that is causing an infinite entropy increase and the ultimate heat death of the universe?  We don't need to actually change the entropy to define the temperature; we just need to imagine changing the energy, and see what the corresponding change in entropy would be (so we can get the derivative). The system I described will tend towards increasing entropy, just like any other system; it just happens that that maximum entropy is in the middle of the possible energies for it (E=0). In fact, because this system is bounded it actually has a finite maximum entropy, so it's definitely not going to cause an infinite entropy increase! [deleted] [deleted] Could you please back this up? Perhaps with some delicious math?  /u/VGramarye has given a good response detailing the canonical system in which this effect occurs just below. There is?! 

I've seen nothing to suggest that we have discovered that the Universe is finite, when did this happen?  Source?
 We don't know whether it's finite or not. It doesn't matter, because the observable chunk of the Universe is finite. Parts that are not observable from each other cannot interact (that is, exchange energy), so the amount of energy any given observer can "see" is finite. Does that mean that the heat capacity of a mass with extremely high temperature increases? 

And does the same change in average kinetic energy always correspond to the same change in temperature? 

 &gt; Does that mean that the heat capacity of a mass with extremely high temperature increases? 

So long as we're talking theory here (not practice) the heat capacity would be constant. For a "particle in a box" temperature is a measure of energy, so if you add energy, you add temperature (linearly).

&gt; And does the same change in average kinetic energy always correspond to the same change in temperature? 

As other commenters have pointer out, no, it doesn't. It comes down to other degrees of freedom, especially for systems that are more than one particle. Temperature is also definable as the derivative of free energy with respect to entropy. If particles have other degrees of freedom (positional, vibrational, rotational, configurational, etc) then temperature gets complicated. No, because the correlation between speed and energy changes. Eventually, at high enough energies, the idea of well-defined, single particles that move at a certain speed no longer makes sense. I could go into detail about certain examples of this if you like, but the issue is that before you reach the point where "all particles are moving at c," such a description would no longer even make sense. So this is why you don't reach a fundamental maximum temperature that way. Brownian motion of a particle is the motion it undergoes while suspended in a fluid due to the thermal motion of the fluid particles as they interact.  So the speed of brownian motion is related to the temperature and the specific properties of the particle and fluid such as particle mass and fluid viscosity.

I would say that the speed limit c places an upper limit on energy stored in vibrational and translational motion, which will limit temperature to some degree but this would be well into plasma physics where I won't speculate exactly how it occurs, and production of new particles as more energy comes into the system is probably a factor in the energy to temperature relation at these levels. Way past Brownian motion... temperature barely has meaning when nuclei collide or when extraordinarily cold.  It's not so much that physics breaks down as the math of the physics is insufficient to explain the phenomena.   Don't think of particle motion in terms of kinetic energy, their velocity is often relativistic and you have to calculate the gamma factor. Use momentum instead, it's linear and nice. 

You can basically add as much energy as you like to the momentum, you will never reach c no matter what you do. i was under the impression a theoretical maximum temperature has to do with radiation whose wavelength is planck length.  Is there a maximum temperature for composite particles? If I supply enough thermal energy to a proton will it eventually decay into quark-gluon plasma? Yes, for much the same reason that if you supply enough thermal energy to an ice cube it will eventually "decay" into liquid water. The transition from protons and neutrons etc. to the quark-gluon plasma is much like melting. I've heard in undergrad that the binding energy of quarks is higher than the energy to create more quarks. So if you try to pull a quark out of a proton, you'll actually just create a quark anti-quark pair and the proton will stay a proton. Am I misremembering? It seems you could define a maximum possible temperature (roughly) as the point at which new particles are spontaneously being generated so fast that the temperature stops increasing no matter how much energy you put into the system. Yeah that's at like trillions of kelvin. So physics don't break down (that we know of), our understanding of physics breaks down.   You're raising a philosophical point here more than a scientific one. What is the difference between those two alternatives? What we call "physics" basically consists of the laws we can write down, and if those laws stop working we say that the physics breaks down. It's not that reality suddenly stops functioning (as far as we know), but it is the case that our "physics" stops functioning in a well-defined way. A real example of this is the ultraviolet catastrophe: we knew the black body didn't have infinite energy even though our physics told us it should.  [In case anybody else is wondering](http://en.wikipedia.org/wiki/Ultraviolet_catastrophe).

I still don't understand it, but The Ultraviolet Catastrophe is the name of my next band. Semantically he has a point though.  We don't have separate terms in common parlance to separate "our known physics" from "the fundamental physics" we're trying to describe with that math.

In theory we could have a word for the physics of reality and a separate word for the accumulation of models we've built to represent it, but we don't. I would argue that in "common parlance" we don't have any pressing need to separate those ideas. Even in the majority of the scientific community, there is no need.

It is an interesting idea, look you. Quantum physicists, and other people pushing the edges of understood reality should have something for this. Definitely. One reason why quantum mechanics are considered so confusing and weird, IMO, is that there's no simple, easily understandable metaphor that people can latch onto (regardless of how true it actually is). Like the 'mini solar system' idea of atoms, which couldn't be farther from the truth. But because people can think 'oh, it's like the solar system' they can feel comfortable with it. Quantum mechanics doesn't have that, at least not yet. It is worth mentioning that we actually have no clue if our theories even do "break down" at these scales - were just stuck in the less than satisfactory situation of having two incompatible theories that appear to simultaneously be of relevance at these scales. Basically we found the scales by just shoving together some numbers that pop up in the theories and (drum roll) out comes some ridiculously large (or small) numbers. 

It seems to me that there's little reason to believe that a complete breakdown of the physical reality is possible - it hasn't so far, right? Seriously though, from the point of view of natural science there's not much of a point in discussing the possiblity of a completely breakdown of reality, i.e. a crash in physical laws (because what would cause them - what governs the crash? Which interaction has occured that caused it to happen? and so on. Also, we can't really establish an empirical measurement proving that a complete break in the laws of physics will happen.). how did we arrive at such that relatively precise number? By multiplying fundamental constants together. The plank temperature is hbar^(1/2)c^(5/2)G^(-1/2)k^(-1), where hbar is the reduced Planck's constant, c is the speed of light, G is Newton's gravitational constant, and k is Boltzmann's constant. It turns out there's one and only one way to multiply the standard set of fundamental constants together to get a temperature, and this temperature thus represents a natural temperature for all other temperatures to be compared too. More precisely this represents the temperature at which gravity merges back into the other fundamental forces, and we have to take quantum gravity into account. Since we don't have that theory yet, our understanding of physics "breaks down" at that temperature. What would be the wavelength of black-body radiation at this point? I heard that this was when the wavelength is the planck length, which would mean it couldn't get smaller, but I don't know if that was just a gross simplification Well if you plug that temperature into Wein's Law you get that the peak blackbody wavelength is 2.04510^(-35) meters, which is just a little bit above the planck length (which is 1.61610^(-35) meters). But it doesn't really make sense to do that, because the assumptions that go into Wein's Law will break down way, way before you get to that point. No one actually knows what an object that hot would do, because of the above "breaking-down" of known-physics. It's not, it's just an order of magnitude estimate. Also don't forget that as things heat up, they give off radiation. When something glows, it is radiating with wavelengths that we can see. Once we reach absolute hot, the wavelengths are so small, that they cannot get smaller...the Planck length. Above this temperature, we have no idea because those lengths would have to be smaller.  Why would they create black holes by virtue of colliding with a lot of energy? Black holes have always been described, as I've seen it (edit: from my layman's reading of the subject), as a collection of enough mass that light cannot escape its gravity. Energy has mass, according to E=mc^(2), and it's really *energy* which gravity couples to, so having a large chunk of energy in a small space is going to have the same effect as putting a large chunk of mass in that space. Are there any examples of energy being concentrated densely enough in a chunk of matter for this effect to be significant, compared to the gravitational pull of the mass itself? Electrons *[could](http://en.wikipedia.org/wiki/Black_hole_electron)* be examples of this, where the energy effectively becomes mass, but we'll probably never know without a unified theory on quantum gravity, or until we can measure to 10^(-57) m with any accuracy. From the article you cited:

&gt; In them, he showed that if elementary particles were treated as singularities in spacetime, it was unnecessary to postulate geodesic motion as part of general relativity.[1]

They link to an article that is over my head. How does elementary particles as singularities eliminate the need for geodesic motion as part of general relativity? I can only take a semi-educated guess (so take it with a grain of salt) since I can't access the article, but if I were to take a stab at it, it's that it would essentially help prove geodesic motion rather than assume it. It would explain why objects don't travel through fundamental particles (singularities), rather than assume they can't.  I was going to ask how we know it's energy (not mass) that gravity couples to, then I realized that (massless) photons are influenced by gravity, which made the idea plausible for me... But, is there some other, deeper, way we know this? Also: since EM fields have energy, I guess this implies that two 'separate' EM fields would be drawn together by gravity...?  What is so difficult about quantum gravity? I keep seeing that brought up as a problem but why is it such a problem? Well, let's try to do the obvious and add gravity to the Standard Model. And woops, it just becomes gibberish, things break down, energies become infinite, men marries dogs, and cats.. well, don't even get me started on cats, you know cats!

For a concrete problem, see the [Landau pole thing](https://en.wikipedia.org/wiki/Ultraviolet_fixed_point), which is a problem when you try to come up with a [renormalization group](https://en.wikipedia.org/wiki/Renormalization_group#Elementary_theory) (or group action as the renormalization flow), but [gravity is not renormalizable](https://en.wikipedia.org/wiki/Quantum_gravity#Nonrenormalizability_of_gravity).

This means roughly that there is no mathematical machinery that can collapse general relativity into a simple system with a few (finite) number of variables that we can then fine-tune (based on measurements in labs).

But don't worry, it's not that all hope is lost. If you threat gravity as an effective field theory, you can get some predictive power out of your model. [see](https://en.wikipedia.org/wiki/Quantum_gravity#QG_as_an_effective_field_theory)

What this boils down to is that seemingly we have problems with gravity, but actually the problems are with quantum physics, because it's the messy thing with all of those couplings and quasi-finite parameters (both in number of them and sometimes in value), and we want to get gravity to somehow just work well with that madness, which depens on a lot of things, such as a fixed gravitational background (a fixed flat spacetime -- understandably, if quantum physics were spacetime independent it would be easy to just pop in the right tensor generated by the Einstein Field Equations and bamm, quantum gravity all the way baby).

So there are ways to try from the more elegant (more flexible) theory (general relativity), and try to build "particle fields" onto it. That's [loop quantum gravity](https://en.wikipedia.org/wiki/Quantum_gravity#Loop_quantum_gravity). But it's so elegant, that it's even independent of time. And .. well, that means nothing moves. [see](https://en.wikipedia.org/wiki/Problem_of_time)

And that leaves us with string theory. And that's why most of research is happening roughly under the umbrella of it.




 The mathematics of gravity from relativity are not miscible with quantum mechanics. Mathematics aside, an insight into why quantum gravity is so difficult is due to the effective field of gravity at Planck scales. The effective field encompasses a much larger space of probability, energy, and matter, than the effective field of gravity at conventional scales. Since this thread is discussing that graphic anyway, I had a question. Since the image is here, rather than start a new thread, I'll just ask my question.

The graphic indicates the hottest man-made temperature was the collision of lead ions. How were they able to get this reading? With very sensitive detector panels that surround the collision region. These ultra hot particles live just long enough to be measured, but not long enough to destroy the panels. 

Think of it like holding a lighter to your palm for a fraction of a second, as opposed to letting the flame sit on your skin for 10 seconds. Instead in the case of a particle collider, the heat only lasts for some tiny fraction of a fraction of a second. Enough to allow the detector panel layers to capture a measurement, then relay the data to computers.  [deleted] To continue the analogy, you can use knowledge of how sensitive your skin is to infer the temperature of the flame even if your skin doesn't heat up to that temperature.

What this means in a detector in a collider is that the decay products after this very hot plasma has dissipated are what are being detected, not the plasma directly. From the slew of resulting particles, the energy of the plasma can be inferred, and models linking binding energy to temperature are what gives the value provided in the picture. Has it ever been calculated what the absolute maximum temperature would be for one single electron, if all the other particles in the universe would be converted into energy which would then be transferred to that electron? Would this not be exactly the same as the point at which the universe was 'founded'? Or am I wrong? Temperature is a bulk property of matter, so it doesn't really make sense to speak of the temperature of a single particle. I'm not sure that it makes sense to talk about the temperature of a single particle. Maybe a better question would be if it were all transferred to, say, a mole of hydrogen gas in a closed system. But in the chart/infographic they list "hottest man-made temperature, created by the collision of lead ions in the LHC". So do two ions colliding in the LHC not have a temperature? Seems that at least they do in the sense that they certainly have an net kinetic energy, but not with respect to their average kinetic energy(?!?). I'm confused. Individually you can't really measure their temperature but their kinetic energy. And you said this temperature was created by the collision, right? So it doesn't necessarily have to have been in the particles, but generated by the collision of the particles. It might be worth noting that when particles are collided in an accelerator, it isn't one particle smacking into one other particle.  Rather, it's two clouds of particles passing one another going opposite directions, with many interactions occurring.  Maybe this is why they can assign a temperature in this case?  I honestly don't know though. Wow, and all the years I had this image that they somehow took exactly two particles, accelerated them, and somehow guided them to smack each other. The clouds make sooooo much more practical sense. Kind of echoing the point that "it makes no sense to talk about the temperature of a single particle in a vacuum".  Temperature is essentially a measure of the variance of velocities of all of the particles.  Something at a very high temperature would have some particles at rest, some moving very quickly away in one direction, some in the other direction, etc.

From a given reference point, you could have a vast sea of particles all moving with the same velocity.  This sea is at absolute zero, (from all reference frames).  If this sea were to slam into an object, they would scatter, and suddenly be at a very high temperature.

So, if all the energy in the universe were transferred to a single electron somehow, that electron would be likely moving very near the speed of light relative to where it was before being energized, but I'd argue it is still at absolute zero.  That is, until it hits that planet that we missed and transfers all of its kinetic energy to it.  Boom.
 As a physicist, this thread is immensely frustrating. I'm rephrasing a comment i made from the other thread: Everyone else is taking about the amount of kinetic and potential energy. That is NOT temperature, if we're being technical. 

**THERE IS NO MAXIMUM TEMPERATURE**

For a lot of things we experience, temperature can be considered pretty much the same as the amount of kinetic and potential energy. But this breaks down at very low and very high temperatures. And certainly wouldn't make sense with negative temperatures, which I've seen mentioned a few times. 

Temperature is thermodynamically define as the inverse of how much the order (entropy) of a system increased with energy, proportional to the energy you put it (T=-dE/dS). Usually, when you add energy to a system, disorder increases. And this makes sense, because things have more energy, and bounce around and make things all disorganized.

 At small temperatures, it doesn't take much energy to make things get a lot more disordered. So, the rate of change of disorder relative to the energy is really high, and the inverse of that (the temperature) is really low. 

As things get really really hot, adding some energy won't really change much, since it's already really disordered. So this is the opposite of the above example, and temperature is high. 

In negative temperature systems, like a laser gain medium, you end up creating systems where things get MORE ordered with the more energy you put in. So with more energy, disorder decreases. However, to get to this point, you first have to cross over the boundary from getting more disorder with more energy to getting less disorder with more energy. Somewhere in between, there is a point where if you add a tiny bit of energy, the disorder doesn't change. Making the ratio of the change in energy to change in disorder (aka the temperature) approach infinity, before becoming negative. 

So that means that all the talk of a maximum temperature being about energy density or short wavelengths or Planck is based on speculative misunderstanding of the science.  Would you mind providing a visual aid with entropy and enthalpy on a logarithmic graph? This is what some of the responses seem to be missing. So if I understand what you're saying correctly - There is no maximum temperature, because at really high temperatures, regardless of how much energy you put into the system the entropy only changes by a small amount?

So does that mean at really high temperatures the rate of change of temperature with energy input gets smaller and smaller?

Also, on a related note - How do you define the lowest possible temperature? The fact that there is no maximum temperature comes from the fact that as you put more and more energy into certain systems, the entropy will reach a turning point. Not *just* because the entropy changes by a small amount, but because there is a point where it doesn't change at all. 

&gt;So does that mean at really high temperatures the rate of change of temperature with energy input gets smaller and smaller?

It doesn't necessarily imply this, no. Usually it's true - but that's due to the fact that with more energy, you make more states available. 

&gt;Also, on a related note - How do you define the lowest possible temperature?

The bottom of the temperature scale, for the positive values, is absolute zero. 0K. But this, like the speed of light, is a limiting value. You can approach it, but can't actually reach it.  So does this mean that there's no minimum temperature either -- that "absolute zero" is essentially just the most ordered that a system can be? &gt;So does this mean that there's no minimum temperature either -- that "absolute zero" is essentially just the most ordered that a system can be?

There is a minimum positive temperature - 0K. But there isn't a minimum negative temperature. Absolute zero isn't actually achievable, but is the limiting value. You could approach it and get really, really close. But like the speed of light, you can't actually get there.  &gt; THERE IS NO MAXIMUM TEMPERATURE

Respecting you field of expertise, I would like to ask for a clarification here.  Saying there is no maximum is fine, but there absolutely must be a maximum that the universe is capable of generating, correct?   I mean the big bang itself, and the temperatures created then, could very well be the absolute maximum that has ever been achieved.  Wouldnt that technically be  the maximum?  Anything beyond that would just be hypothetical? [deleted] not to thread steal, but looking at that chart I have another question. If the earths core is mostly an iron nickel alloy and the boiling point of iron is 2861c and the temp of core of the earth is 6000c wouldn't that mean an whole lot of bubbles or something?

Or is the pressure exerted from the surface enough to keep from the boiling iron from forming bubble expansion?


excuse me if my terminology is not correct, im not a sciency guy just interested.

edit:spelling [Diagram](http://i.imgur.com/tcaXVM1.jpg)

This is a phase diagram for water, but everything has a diagram similar to this.  The left axis is pressure, the bottom axis is temperature, and if you look on the graph at a given pressure and temperature you will see what state that substance is in.

The melting and boiling points you normally see are at that 1 atm line.  To get what those are at the earths core you would have to move way up.  At those pressures, despite the high temperature the core would be solid.

Neat tangent:  Looking at the infographic that OP posted, you can see that hydrogen turns into a gas at just a few degrees above absolute zero.  It's hard to imagine getting it cold enough to turn solid.  But, the pressure inside Jupiter is so high, that despite the heat (see infographic again) there is a layer of liquid hydrogen that goes down into a layer of solid, metallic hydrogen.  There is so much pressure inside Jupiter, that the lightest gas in the universe is a solid.

Edit: Put in the right diagram did you mean helium, b.c I dont see hydrogen on the chart near absolute zero. As for the layer of liquid then solid hydrogen, does that mean its a hot solid layer of nitrogen, just under pressure?

back to the graph with helium near absolute zero, is there no tempture at which it becomes a solid? or is it just that 1.15c range where a solid is possible (under 1 atmo)? I meant hydrogen, but you're right it isn't on the chart.  It's just a little further down the chart (ten degrees or so).  You are also right that it's a 24,000 K core of solid hydrogen.  It's that massive pressure that keeps the atoms squeezed together.  

And I think /u/udiniad is right about the helium.  Helium is a funny beast b/c it's atoms really don't want to interact with anything, including other helium atoms, so they really resist being forced into a solid.  IIRC Helium become a [superfluid](http://en.wikipedia.org/wiki/Superfluidity) with some really strange features when cooled to extremely low temperatures (~1-3K at low pressure). So no, helium can only exist as a solid in high pressure systems. Isn't this phase diagram for carbon dioxide? Under 1 atm of pressure,  the diagram has sublimation occurring at -78.5 degrees C. You're dead on, it's the pressure. The boiling point of any liquid is affected by the ambient pressure. This intuitively makes sense: boiling is turning a liquid into a gas, which greatly expands its volume. If the "container" (in this case the Earth) has a higher pressure, then it requires more work to "make room" for the new gas that's being generated from the boiling, so the temperature needs to be higher. You have to keep in mind of the immense pressure that the earth's core is under. 
The boiling point of iron is 2861c at a spesific pressure, most likely at sea level. 
The boiling point of iron will be different at the pressure of the core, which according to [Wikipedia](http://en.wikipedia.org/wiki/Inner_core#Temperature_and_pressure), is 330 to 360 gigapascals. This will change the boiling point of iron.
                                                                 It is not that physics break down, but that current experiments have not been able to reach anything near the planck temperature so while some theories can make predications at that level, there is no verification of those prediction, and the energy range that has been verified is so much lower as to be non-applicable.  

Some theories will say that poorly understood areas of physics like gravity, such as it is quantized, does it have a force carrier like the standard model forces, and so forth become relevant, others that phenomenon that are not occurring at the low energy scale start to occur.

Planck and others have made a set of natural units based on 5 universal constants, the speed of light c, the gravitational constant G, planck's constant, boltzmans constant, and coulomb's constant and setting these to 1 followed by appropriate units.

G = 6.673 m^3 kg^-1 s^-2

or in planck units

G = 1 L^3 M^-2 T^-2

where L is the planck length, M the planck mass and t the planck time. 

For example the gravitational force between two objects is  F = G m1 m2 /r^2 or in planck units F=m1 m2 /r^2 so two objects of planck mass at one planck distance exert one planck force.

The usual units of meter, second, kilogram are human scale units and a constant of proportionality, G, is needed to relate human scale units to how the universe works, so by redefining the length, distance, time, and energy scales the constants of proportionality can be made equal to 1 (with appropriate units following).

In the same way that the speed of light in a vacuum, which is the planck speed, gives a maximum speed to any object in the universe some people theorize that the planck distance and time, or temperature, give minimum or maximum limits to the in those areas.  As these are so far beyond present day experimental observations it can only be said that current theories don't describe what occurs there.  Predictions can be made but there is no experimental verification. [deleted] Physics break down as we understand them. The strong/weak/electromagnetic forces merge into one force, or that is what super string theory predicts. 

In theory, when the universe started cooling, moments after the big bang, the forces started to "crystalize" so to speak and started to separate into what we have now. It's a little weird, but that's one of the best theories we have right now.

Edit: english mistake corrected. My grammar isn't the best at 1am in the morning. *per se
Which doesn't mean so to speak, but rather, something like "in and of itself" This all fascinates and excites me so much. I wish I had gone into physics.  As an object gets hotter, it radiates shorter wavelengths of light. We know of warm objects losing heat through radiation. Heat is just long wavelengths of light. Hotter objects glow red because the wavelength has gotten short enough to enter the long side of our visible spectrum. As temperature continues to rise, even gamma rays can be emitted. Absolute hot is point where wavelength of emitted light is the Planck length. A hotter temperature would dictate an emitted EM wave with wavelength shorter than the Planck length, suggesting two points in the universe closer than one Planck length. By our understanding of physics, this is impossible, so clearly SOMETHING has broken at such high temperatures, or it's just not possible.

Physics is a constructed concept. If we cannot understand something, then physics breaks down or seems to break down. That is to say, physics and our understanding of physics are the same thing. We do not yet have perfect knowledge of the universe, so we cannot know 'true' physics, instead we come up with laws that are only applicable in common (from out standpoint) conditions, yet break down at very high temperatures or the subatomic scale. I'm curious of what something heated to the point of having a wavelength equal to or shorter than planck length would look like. As you mentioned stuff glows red and yellowish when it heats and give off shorter wavelength radiation. Do we have any idea of what this would look like? Would it just be a liquid? Gas? clear?  &gt;Would it just be a liquid? Gas? clear?

It would be non of these. Its hard to say but you could look at what the early universe would be like to get some ideas.  Because of an inverse proportion to something's temperature and the wavelength of electromagnetic radiation it's emitting, at the Planck Temperature, its radiation would have a wavelength of one Planck Length; the shortest possible length you could ever measure.  Therefore, going beyond this temperature would seem to produce radiation that's shorter than a Planck Length, which is seemingly impossible without abnormal effects we've never observed before taking hold.

This, of course, is just one of quite a few reasons why we have no idea what would happen, which other people have discussed here. When you heat something up, it begins to emit light. When something is slightly hot, it glows a dull red - the longest and lowest energy wavelength of light that we can see. When you heat it up more, it starts emitting higher energy, shorter wavelength light.

One example of a highest temperature we can understand with our equations would be one where the black-body emission spectra (what color it glows) is the smallest possible length, a planck length. We cannot talk meaningfully about the radiation coming off of anything hotter than this, no such radiation can exist as far as we know.

The universe continues to work fine, our model of the universe as expressed in equations fails. We tried to divide by zero and got a meaningless result. Physics doesn't break down.  As others have pointed out, temperature is defined as (dE/dS), where E is the internal energy and S is the entropy.  This just means that temperature is the change in energy with respect to entropy, that is: the more energy required for a diffferential change in entropy, the hotter it is.  

Conventional physics "break down" because there is a finite (but huge) number of states of any given system. The concept of absolute hot is that a thermodynamic system composed of matter will compensate by various new processes -- pair production, etc. -- creating new, lower energy pathways to raise the entropy, thereby reducing temperature.  

All of these theories apply to thermodynamic systems; it is in fact possible to create non-thermodynamic systems.  These can have negative temperatures.  Lasers can be considered such a system, and they must pass through this "absolute hot" temperature when they are turned off (but not necessarily turned on).
 A question that I think is maybe more interesting is "what is the relationship between the total mass of matter in any given universe and that specific universe's Planck Temperature." 

Is the relationship linear? Logarithmic? Constant? Is the a limit? I dunno, it's been WAY too long and my physics brain has turned to porridge.  [This case study from the 1970s](http://ldx.sagepub.com/content/8/5/32.short) found that Braille was a big help to one severely dyslexic girl.

But [this experiment](http://www.sciencedirect.com/science/article/pii/S0010945276800305) found that dyslexic children struggled to learn letters in both Morse Code and Braille compared to non-dyslexic children.

[Dyslexia-like difficulties have also been observed in blind children who exclusively used Braille](http://jvi.sagepub.com/content/16/2/61.short) -- which suggests that dyslexia isn't exclusive to sighted reading. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Also, in completely blind people, the vision centers that fire up when reading in sighted people is rewired to fire up when [they read braille](http://www.sciencedaily.com/releases/2011/02/110217124903.htm). Which means that a problem in a similar spot along the reading pipeline could manifest itself in braille readers. So does this mean that the affliction is centered in the comprehension center of the brain? Have they done any research into dyslexic-friendly fonts?(if such a thing exists). OP has me genuinely interested here. They have! [This](http://www.dyslexiefont.com/en/dyslexia-font/) font is supposed to be easier to read. Essentially, they distinguished the letters more - so where a standard font would allow you to change a d to a p, q, or b just through rotation and reflection, ask of those letters are slightly different. It is also more bold toward the base of each letter, further helping define the correct orientation. 

*edit: links on mobile are rough. [deleted] There's also [OpenDyslexic](http://opendyslexic.org/), which is essentially an open-source/royalty free version of this font and uses similar principles. However plenty of people with dyslexia find fonts like these difficult than normal to read compared to 'normal' fonts; there's a lot of individual differences. 

Generally speaking, people with dyslexia tend to find serif fonts (e.g. Times New Roman) easier to read than sans serif fonts (e.g. Arial) because the serifs make it easier to tell similar letters apart. But this isn't a hard and fast rule either. That link is not doing what links should be doing. You switched the order of the link and text to display. [deleted] [deleted] Do braille readers read at the same speed as visual readers? one study about braille helping a girl back in the 1970s...how can one case be used as a proponent when most studies indicate that braille is difficult for those who are dys I'd like to interject with a description of what is really going on in the brain of a person with dyslexia. 

The act of writing involves taking an idea, putting it into words and then transcribing these words using symbols, which we call letters. Making this process even more complicated is the issue of spelling: in order for the symbols to be comprehensible, they need to conform to a standard order. When reading, this process runs in reverse. Your brain needs to "decode" the symbols to get the information they contain.

Most people use specific sections of their brains to read, write and process language. Dyslexic people use a different part of their brains to try to accomplish these same tasks. This has been demonstrated using studies where brain scans are taken while a dyslexic person reads and writes. 

Professionals in the field describe this as having problems with symbol decoding. When a person mixes up b and d, it actually isn't because they are mentally reversing the letter in some way. Rather their brain has difficulty assigning the phonologic meaning /b/ to the symbol b. 

These language difficulties frequently are accompanied by difficulty breaking words into their component syllables and are characterized in many children by a lack of interest in language games and nursery rhymes. To put it more bluntly, the reason many dyslexic kids don't like Dr. Suess is because the fact that cat and hat rhyme isn't something that they notice instinctively.

So, how does this affect blind students or could a person with dyslexia read Braille?

No, the dyslexic person would not find Braille any different than reading letters they could see because they still need to associate a symbol (though in this case, one they can feel) with a sound (decoding) and then piece together a word and meaning from the sound. This is also why fonts which claim to "make the letters stop moving" are a load of hogwash. They don't address the underlying issue of decoding problems.

Dyslexia is found in all groups of people, including those who speak languages such as Chinese which are largely pictographic. While it doesn't have an alphabet, reading and writing these languages still necessitates going from symbol to sound and meaning and that's where the problem is.

Sources: http://www.interdys.org/ewebeditpro5/upload/Definition.pdf

http://www.interdys.org/ewebeditpro5/upload/DyslexiaBasicsREVMay2012.pdf

TL;DR: Yes. Dyslexia means that a person has trouble "decoding" symbols and connecting a specific symbol with a sound. This wouldn't change if they were feeling the symbol rather than seeing it.
 [deleted] [deleted] [deleted] [deleted] How would this argument explain why dyslexia does not affect language comprehension via speech and hearing?  You are still parsing and interpreting information from auditory signals ("symbols").  Doesn't this suggest that the problem of dyslexia has more to do with a faulty pathway in the brain, than solely the problem of "translating" the symbols?  

For instance, Broca's aphasia and Wernicke aphasia are considered distinct from Dyslexia.  To me this is a distinction between processing information in different areas of the brain.

Therefore, I would expect that Dyslexia has much less effect on reading Braille, since it is altogether a different sense, and therefore a different pathway.  (Although, do people with Broca's or Wernicke's aphasia exhibit difficulty reading? The comorbidity would be interesting to note.)

I think your answer provides some insight, but to say that someone with Dyslexia has no problem with Braille a bit of an overstatement or generalization.  If you could clarify based on what I said, or explain the differences in more clarity I would be appreciative.

Edit: Ironically, I got my wires a bit crossed in my conclusion.  Thanks for the replies.  I actually did confirm with some of my own digging that Dyslexia is a language-processing disorder, not a visual disorder.  Dyslexia is in the same family as aphasia, and Broca's area and Wernicke's area are both involved in Dyslexia's pathology.  Therefore, yes, the medium should not matter, and yes, in fact, people with Dyslexia can be slow in both reaction and expression of speech.  Thanks for the clarifications.

 I would like to clarify somewhat because I don't think that you fully understood my first post. 

A person with dyslexia would have trouble reading Braille because the trouble they have reading is not found in their eyes, but in their brain.

To quote the International Dyslexia Association:
"Spelling problems, like reading problems, originate with language learning weaknesses. Therefore, spelling reversals of easily confused letters such as b and d, or sequences of letters, such as wnet for went are manifestations of underlying language learning weaknesses rather than of a visually based problem. Most of us know individuals who have excellent visual memories for pictures, color
schemes, design elements, mechanical drawings,
maps, and landscape features, for example, but
who spell poorly. The kind of visual memory
necessary for spelling is closely wired in to the
language processing networks in the brain.

"Poor spellers have trouble remembering the letters in words because they have trouble noticing, remembering, and recalling the features of language that those letters represent. Most commonly, poor spellers have weaknesses in underlying language skills including the ability to analyze and remember the individual sounds (phonemes) in the words, such as the sounds associated with j, ch, or v, the syllables, such as la, mem, pos and the meaningful parts (morphemes) of longer words, such as sub-, -pect, or -able. These weaknesses may be detected in the use of both spoken language and written language; thus, these weaknesses may be detected
when someone speaks and writes." (See ["Just the Facts: Spelling from the International Dyslexia Association."](http://www.interdys.org/ewebeditpro5/upload/SpellingRev.2011.pdf)) 

The short answer is that sounds are not symbols. Auditory information is not "decoded" to form words in the same way that letters are. Consider this. You "sound out" words you don't know and likely "hear" what you are reading in your head, but you don't hear a word and see letters.

Learning disorders do exist which affect how the brain processes what it hears (the language comprehension via speech and hearing that you mentioned). In some individuals these are present alongside dyslexia, however they are not always present. [deleted] [deleted] &gt;How would this argument explain why dyslexia does not affect language comprehension via speech and hearing? You are still parsing and interpreting information from auditory signals ("symbols")

I'm not OP, but the symbols he/she talks about are letters. When the listener hears sound, it is translated into phonological information and then meaning. When the listener reads ink, it is using several strategies to recognize words and sentences. It is then translated into phonological information. It seems perfectly reasonable to me.

I can't seem to find the study right now, but it was quite recent, and it showed that dyslectics had a deficit in an area of the brain that non-readers used for facial recognition. If that is the case (which the study suggests although it's way early to say), then the early processes of reading could be more understandable as face recognition than hearing. does this mean deaf people would be skipping a step while reading?

or does phonology not necessarily have to involve sound-related parsing &gt;an area of the brain that non-readers used for facial recognition

The FFA (fusiform face area) is typically the area associated with facial recognition. Are you saying that non-readers may use an additional area (presumably an area typically adapted to reading) for facial recognition? I wonder if this area is found in poor-sighted individuals who read with braille and similarly use touch for facial recognition? Yes, some research suggests so! Except the poor-sightedness-thing, that I don't know.

[Literacy acquisition reduces the influence of automatic holistic processing of faces and houses](http://www.sciencedirect.com/science/article/pii/S030439401300801X)

[How Learning to Read Changes the Cortical Networks for Vision and Language](http://www.sciencemag.org/content/330/6009/1359.short)

More free-form article: [Inside the Letterbox: How Literacy Transforms the Human Brain](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3704307/)

It's intriguing because humans don't develop literacy spontaneously as with language, so there is no designated "literacy system" in the brain. [deleted] [deleted] [deleted] [deleted] Anecdotes are not allowed on /r/AskScience.  

&gt;I think your answer provides some insight, but to say that someone with Dyslexia has no problem with Braille a bit of an overstatement or generalization.  If you could clarify based on what I said, or explain the differences in more clarity I would be appreciative.

&gt;

Maybe I am misunderstanding what you are saying but his answer clearly stated that a dyslexic person would not be any better of with Braille then with the written word.   &gt; person would not be any better of with Braille then with the written word. 

Correct, because it's about symbol interpretation, the medium doesn't matter.  But aren't there are some individuals who are dyslexic in some languages but not in others? Does that not count as medium-based? No, still symbol interpretation. If a person is dyslexic in French but not German, it's all with how the brain processes those symbols.  if the efficacy of the symbolic interpretation is dependent on the medium, wouldn't that be based on both medium and symbolic interpretation? 

i don't quite understand how the medium doesn't matter simply because it is about symbolic interpretation. the written word 'fish' is a different symbol from the spoken word 'fish' from a cartoon of a fish from the written or spoken word 'poison', though they may point to the same idea of a 'fish' in one's head. but those symbols may be interpreted with greater or lesser ease depending on the individual, and depending on specificities of the medium such as the modality, the font, the accent, the level of noise, etc.

what lead to that theorized exclusion between symbolic interpretation and medium/modality? So someone reading Braille and sighted people reading tradtionally have been shown to use the same areas of the brain for reading.  That is, the only difference is that the non-sighted reader is using tactile sense to relay that information to the same area the eye would for a sighted reader.

The difference is that when you see a picture of a fish, this is a representation of the idea of the fish.  It is a straight association.  However, in English, the word "fish" is composed of letters.  Each letter carries a sound.  These letters must be interpreted in the brain as separate sounds (especially when learning to read for the first time, sounding it out), identified as the correct sound (as English has many arbitrary rules for how a letter sounds in the context of the word), and then assemble all of these sounds to give meaning to the word, and then converted to speech.  

Dyslexia is a small part visual decoding dysfunction and a large part language processing dysfunction.   People with Dyslexia first have trouble processing the shape of the letter, which is manifest in that d is confused with b, and p with q.  There is an inability to see this difference clearly.  Normally, this would not be such an issue if it were the only problem, because this information passed on to the part of the brain responsible for decoding the information into sounds and meaning could correct this mismatch through context clues, etc.  It would be obvious that the word "blood" could not be "dlood" in a sentence, since I would know that sound has no meaning, and blood makes much more sense in the context of the sentence.  

Well this does not happen either.  The area of the brain responsible for decoding those shapes into meaning and sound is also impaired.  Wernicke's area receives this already garbled visual representation, and further fails to decode it into meaningful sounds.  Then this mess is passed onto Broca's area, where the brain then tries to sound out all this information, and it can't since it makes no sense.  

It turns out sighted people that can read Braille treat it almost like a pictographic language, similar to Chinese, where the symbols are associations with whole meanings, rather than a composite of sounds.  Non-sighted people read Braille the same as a sighted person would read English.

Other than the wiki and google searches, this is a good explanation too: [link](http://theeclecticreadingteacher.com/2011/07/22/what-exactly-causes-dyslexia/)

Yet another great explanation: [link2](http://www.braillesc.org/blog/2010/11/11/braille-and-dyslexia/) You are correct, I had somehow changed my conclusion halfway through writing.  Thanks. [deleted] Forgive me if I'm just seizing the bits I understand whilst bypassing the rest of your post, but if dyslexia is a problem rendering a glyph as a sound in the brain does this mean deaf people are unaffected? I oversimplified a bit in my answer for the sake of clarity. The key step in decoding a glyph is going from symbol to meaning. For a hearing person, it's easiest to understand this step as symbol to sound, but that is an oversimplifcation. A deaf person would have trouble with this same decoding process although they wouldn't be "hearing" anything. So the b/d/p/and occasionally q difficulty is a sign of dyslexia?  Even if it's inconsistent? Just curious, I know it's slightly off topic.  The short answer is, it can be. 

You might be interested in poking around the International Dyslexia Association website. A few good paragraphs from one of their publications explains your question this way:
"Spelling problems, like reading problems, originate with language learning weaknesses. Therefore, spelling reversals of easily confused letters such as b and d, or sequences of letters, such as wnet for went are manifestations of underlying language learning weaknesses rather than of a visually based problem. Most of us know individuals who have excellent visual memories for pictures, color schemes, design elements, mechanical drawings, maps, and landscape features, for example, but who spell poorly. The kind of visual memory necessary for spelling is closely wired in to the language processing networks in the brain.

"Poor spellers have trouble remembering the letters in words because they have trouble noticing, remembering, and recalling the features of language that those letters represent. Most commonly, poor spellers have weaknesses in underlying language skills including the ability to analyze and remember the individual sounds (phonemes) in the words, such as the sounds associated with j, ch, or v, the syllables, such as la, mem, pos and the meaningful parts (morphemes) of longer words, such as sub-, -pect, or -able. These weaknesses may be detected in the use of both spoken language and written language; thus, these weaknesses may be detected when someone speaks and writes." (See "Just the Facts: Spelling from the International Dyslexia Association.")  [deleted] [deleted] [deleted] Thank you! This is a wonderful definition! I teach students specifically with dyslexia and people always ask me to explain dyslexia to them and I sometimes have difficulty putting it into words. 
 Would this mean that people with dyslexia have a much harder time reading music because of all the similar symbols that could get jumbled up? [deleted] Yes, blind people can have dyslexia. But it's rare - you have to take in to account the *very* small number of children learning braille and that only a percentage (3 to 6% of sighted kids meet the criteria for dyslexia in The Netherlands) of them will have dyslexic treats.  
  
However, a thing like switching the letters **d p q b** is less likely, but for example the **h** and **g** are each other's mirror image in braille.  
  
https://translate.google.com/translate?sl=auto&amp;tl=en&amp;js=y&amp;prev=_t&amp;hl=en&amp;ie=UTF-8&amp;u=http%3A%2F%2Fwww.rug.nl%2Fscience-and-society%2Fscience-shops%2Fvraag-12-tcc&amp;edit-text=
 **TL;DR - Maybe yes, maybe no, depends on the type of dyslexia they have**

Dyslexia is considered a problem with [orthography](http://en.wikipedia.org/wiki/Orthography)-to-phoneme processing or, more specifically, [grapheme](http://en.wikipedia.org/wiki/Grapheme)-to-phoneme processing. (Wydell &amp; Butterworth, 1999; [Wydell, 2012](http://www.migraine.dk/InTech-Dyslexia_a_comprehensive_and_international_approach/Dyslexia_-_A_Comprehensive_and_International_Approach.pdf#page=13)). 

Wydell (2012) notes that as dyslexia is largely caused by a problem with phonological processing skill, the language one speaks can change the prevalence of dyslexia. For example, there is a roughly 10% incidence in English, 12% in Dutch, but much lower in other languages with more "transparent" and "coarse" grapheme, like Japanese and Italian, have much lower incident rates. This was exemplified in the case study of AS, an English/Japanese bilingual who was dyslexic in English, but not in Japanese (Wydell &amp; Butterworth, 1999). As Braille is not it's own distinct language, it may have similar issues between languages (which would show a link between developmental dyslexia and braille reading ability) 

However, [Viespak, Boets &amp; Ghesquiere](https://lirias.kuleuven.be/handle/123456789/342016) (2012) found that there may be differences in the expression of reading difficulties in Braille and in those with Developmental Dyslexia. Though, they [later found](http://www.sciencedirect.com/science/article/pii/S0891422212002181) that there was no significant difference in the auditory processing of those reading Braille and those reading text, suggesting that these difficulties may translate across.  Dyslexia, like many learning disabilities, has a spectrum to it, in which an individual can be minimally, moderately, or severely dyslexic. Braille is a kinesthetic means of reading (meaning you feel a shape or assortment of dots and you can interpret them as letters or contracted phonetic sounds). Some dyslexics really need a highly differentiated representation for a letter or symbol to be able to distinguish letters or words. Others learn letters/words by feeling three dimensional models (like constructing a letter our of playdo for example) to finally conceptualize its shape. Or they might need a visual index to commit to memory which can accompany a word in order to decode its meaning (similar to autism) which is useful for words like cat (which is easy to envision an image of a cat) but difficult for a preposition like "he" or "they". I can envision a dyslexic person benefiting from Braille for its kinesthetic value, but many of the braille symbols are very similar which I can't help but think might not provide the differentiation needed to distinguish between symbols (similar to getting "d's" and "p"s mixed up). So as with trying to gauge learning strategies for many individuals with learning disabilities, it still really depends on the individual and their unique needs.  [deleted] Check out the book Reading in the Brain by Stanislas Dehaene. It has a whole chapter about dyslexia and also discusses how visual reading and physical reading methods like braille operate in different ways. Essentially, common dyslexia would not affect the areas used in braille reading, but as with many neurological disorders, both dyslexia and some physical problem hindering braille could occur together. Dyslexia doesn't make you mix up similar looking letters and words. This is just the view most lay people have of it. It's really just the condition of having significantly below average reading skills. In the DSM it says this very clearly. Attention folks: **Do not post anecdotes in this thread,**  *especially* when they contain medical information. Anecdotal answers are not allowed in /r/AskScience and will be removed. 

Thank you very much for your help in keeping the comments scientific and on topic! [deleted] So many poorly written explanations on here so I'll try to explain it a bit better. 


First let's talk about the glass on a car. Most of the windows (except the windshield) are made from tempered glass. Tempered glass is known for being quite strong, but also fails quite spectacularly, instantaneously shattering into an enormous amount of little pieces. Why does it do this? Well let's understand the processing. This glass is cooled rapidly from liquid to solid. Glass that cools more quickly ultimately ends up at a lower density, hence a higher volume compared to glass that cools slowly. [graph](http://www.benbest.com/cryonics/tg.jpg) Well guess what, there is a thermal gradient in a pane of glass as it cools. Meaning the outside rapidly cools and the inside does not. This puts the outside of the glass in compression and in the inside in tension. This acts as a crack inhibition method, meaning that the stress necessary to propagate the crack must first overcome the compressive stress on the outside (since glass will fail in tension well before compression). So what do we get? A glass that is ultimately very strong, but has a massive amount of stored internal energy through the tempering process. 

[Stress Profile in Tempered Glass](http://failures.wikispaces.com/file/view/wiki_nickel_sulfide_fig01.jpg/177204681/292x132/wiki_nickel_sulfide_fig01.jpg)

Let's say we want to break this glass though. How do we go about it? Well if we can force a crack to propagate through this thin compressive stress layer on the outside and into the stored tensile stress region, then this crack will immediately cause catastrophic failure. The easiest way to do it? Use something small and hard to act as a stress concentrator. This can amplify the force applied and help penetrate this region. So in the case of the spark plug shard, which is made from a hard ceramic (likely an alumina based material) the impact from the ceramic is enough to form a crack and cause it to penetrate the glass deep enough. That is also why you can buy punches (firefighters and other emergency responders also carry these) that are essentially hardened steel or diamond tipped and do the same thing.

Hardness of the glass compared to to impact material is definitely relevant since this interaction is very similar to a hardness test (Rockwell, Vickers, Knoop, etc. Indent tests). The material needs to be harder, or at least close to the same hardness as the glass. I highly discourage people from using the Mohs scale to get actual numbers. 

Sources: Shelby, "Introduction to Glass Science and Techonology"

Varshneya, "Fundamentals of Inorganic Glasses"

Fun fact: your windshield is engineered to break before a human skull will. [Here is an interesting study](http://www-nrd.nhtsa.dot.gov/pdf/esv/esv20/07-0101-W.pdf) talking about injuries associated with laminated vs. tempered glass in auto collisions

Edit: Added sources and some graphs

Edit 2: Updated some relevant information about impact with windshields and took out the sensationalist comment about side impacts

Edit 3: Thank you so much kind redditors for guilding me twice!  The Moh's hardness scale is used in geology, and as geologists, we totally accept that it's useless in every other area. haha I'll give you that! As a materials scientist (and one that specializes in ceramics) it always frustrates me when people compare most advanced ceramics to diamond on the Moh's scale. Since it's a relative scale its not always the best thing to getting good numeric comparisons. I totally understand that it's much more relevant in geology. The Mohs scale is super-useful for identifying minerals in the field.  Its nice because if you have a few references of known hardness (A streak plate, a knife blade, a piece of quartz, your fingernail ect. all common things for a geologist to have on hand) you can quickly narrow down what mineral you may be looking at.  From a materials perspective, the Mohs scale is useless.  I was astounded that the actual difference in hardness between diamond (10 on Mohs) and Sapphire/Corundum (9 on Mohs) is almost the same difference as Sapphire from Talc (1 on Mohs). In geology, relative scales are important because we're usually trying to verbally, or in prose, describe and compare the hardness of something with something that the reader is able to conceptualize in their mind. 

Like, is this mineral harder than talc? Yes. Is it harder than diamond? No. Is it harder than quartz? Yes. Then it must be blah blah blah. Plus crystallinity, habit, faces, etc. Oh, well then it must be this... 

It helps us, in real-field terms, how to identify and understand a bit of rock that you're folding on your hand. 

Coincidentally, your finger nails are 2-3 hardness. A steel knife is about 7 (depending on whether or not it's foreign or domestic steel). These are tools in the field that help make these determinations on hardness.  What is the difference in foreign and domestic steel? I noticed you mentioned this in your reply and I am wondering how these two forms of steel are different.
Thank You &gt; What is the difference in foreign and domestic steel? I noticed you mentioned this in your reply and I am wondering how these two forms of steel are different. Thank You

Well, strictly speaking, nothing. Steel is an alloy, a combination of different metals (iron and carbon, in particular), and steel made according to the same "recipe" of ingredients and process will be the same, wherever it is made. 

That said, various shorthands have emerged, maybe similar to the way that people might refer to "Hollywood movies", even for something filmed in New Zealand or Toronto. There are only so many companies in the world that make raw steel, and language and geography mean that you tend to get certain localized cultural norms.

Traditionally, "Japanese" steel implies high carbon content, high hardness, but also increased brittleness. There are exceptions to every rule, but the Japanese steelmaking industry is an old and proud one, and in Japan, "steel" typically and traditionally refers to a very hard metal, capable of keeping a sharp edge for a long time. 

 "German" steel, OTOH, traditionally means a softer, more pliant and flexible metal. Something resilient, that will bend, not break under stress. A German-steel knife will traditionally require more-frequent sharpening than a Japanese knife, but it will also be much more resistant to cracks, chips, and actual "damage". 

"American" can be either a compliment or an insult to steel, depending on the context, since it tends to imply an alloy that was purpose-made for the thing, rather than made to an ideal. "Chinese" is basically never a compliment, when applied to steel.  &gt; Well, strictly speaking, nothing. Steel is an alloy, a combination of different metals (iron and carbon, in particular), and steel made according to the same "recipe" of ingredients and process will be the same, wherever it is made.

to provide a (likely useless) slightly more specific explanation of this, these specific recipes are typically called "grades," and while grades often have specific chemical values and physical properties, they are also governed by (largely) global "specifications" or "standards."

as a for instance, 316 is a very common, popular grade of stainless steel.  you can typically expect that it will contain 62-72% iron, 16-18% chromium, 10-14% nickel, 2-3% molybdenum, up to 2% manganese, and smaller amounts of silicon, nitrogen, carbon, phosphorus, and sulfur.

when people/companies want to buy 316 stainless, they often have a specific application in mind.  they know what they expect from their material, and they know what it must be capable of.  in order to promote uniformity, specificity, predictability, and a few other cool words, companies like ASTM International exist.

ASTM is a standards organization that develops technical specifications (ie: a list of specific requirements that must be met) for a huge variety of things.  from metals to safety equipment to concrete to bicycles to test methods to children's toys, ASTM specs allow purchasers to demand compliance and know how their product will perform in advance.

so, using the above examples, an aerospace company might decide that they need a piece of 316 stainless steel plate, in compliance with ASTM-A-240.  316 tells us about the chemical composition of the material, but the ASTM-A-240 is what really tells us about the metal's properties.  in order to say, "yes, this material complies with A240," one must be able to show that the material not only meets a very specific chemical composition, but also has a specific tensile strength, yield strength, elongation, hardness, and (occasionally) reaction to Charpy impact testing.

knowing this in advance, mills creating the 316 stainless will perform a battery of tests on each "batch" they make (usually called a "heat" or a "lot" in the industry, and assigned a specific heat number), and report these results on a document called a (wait for it...) Test Report.  the test report will show the info of the producing mill, the specifications they claim compliance to, the heat number, and the actual chemical composition and physical properties.

so yeah, while that rambled pretty well off course, let me bring it back home by saying that earlier today, i handled a bunch of 316 a240 plate, some of it produced in Brazil by Aperam, some of it produced in the USA by North American Stainless, some of produced by Outo Kumpu in Sweden.  you could reasonably expect them all to perform very similarly.

on a final note, many american companies (especially those that work with the government) will only accept material produced in the USA, or from DFARS (Defense Federal Aquisition Regulation Supplement) approved countries, which ends up being almost anywhere but Asia.  while this is mostly political, there has long been a bit of perceived disdain for asian metals, writing them off as inconsistent, unpredictable, or sometimes just simply inferior.  as someone who simply buys and resells metals, i can't comment on the accuracy of this last bit, but it's definitely a common perception in the current american metals market. [deleted] From my prior experience in machining, Chinese steel has a tendency to contain more internal stress, which would seem to implicate the annealing. Also more pockets of impurities. 

The internal stress is annoying, because it's variance from piece to piece is often the major factor in having difficulty holding tolerance, rather than backlash or anything else that could be attributed to your machine tool. You can help yourself out with spring-passes, but there's always someone whipping you to carve seconds off the cycle time.  Aside from the alloy composition, how the steel is made also affects its properties. Annealing (heating then cooling) decreases the hardness for examples.  Mechanical work on the steel also effects properties(like cold rolling, shot peening, etc). Shot peening is often used to add compressive stresses to the exterior of parts much like tempered glass.   
Heating then cooling describes almost every heat treatment though  so to add a little, the temperature reached and the rate of cooling end up being the biggest variables(other variable tend to be depend on the parts and the process equipment more). There are a couple of different processes that get called annealing and some processes that might as well be annealing but aren't typically called such which muddies the waters somewhat.    I know nothing on this subject, but I'm guessing they are referring to the general consensus that Japanese steel is very hard and German steel is softer. It is known to people who are very into knives. But it seems rather subjective. I'd imagine All different kinds of steel could be made in all different countries. This is just a guess. Your guess is correct. Steel is whatever you put into it. That whole Japanese-harder/German-softer thing is a bit silly, perhaps it pertains to knife making, but you can't make a quality car without purpose-made alloys. Driveshaft on your car? Japanese, German, or American, it's probably a carbon-boron alloy, induction case-hardened to a depth of about 2 to 3mm (deeper at the bearing raceways), and induction tempered on the splines to make them less likely to chip. Body panels? Has to be malleable enough to draw properly when you stamp it. The list goes on, but basically if you state a specific set of requirements, then a particular alloy is going to be your best option, no matter where you're from.  The reputations really only apply to more traditional applications like knives and wood working tools and are only maintained now for tradition. Although they may have originated from quirks in the material and processes available to the ancient cultures they have no real relevance with modern refining processes. Now this is only a guess, but I'm guessing that application had more to do with it than materials or processes. The Japanese were really big into slicing, whether you're talking about katanas or food prep knives. So you need a blade that's going to keep it's edge, but that blade needs special treatment to stay useful. For instance, you didn't block a sword blow with the sharp edge of a katana, you blocked it with the side or back. 

The Germans had to deal with metal armor and group combat being more likely. (Compared to the combat style of people who had katanas) A sharp sword was great, super against the peasants, but it needed to be durable against armor. You don't have to cut through the helmet, all you have to do is crush it in enough to break some eye-socket bones. Who cares if it's dull after that, the hardened point is what you need to stab the guy through his gorget.  I feel as if 'domestic' and 'foreign' steel has huge variations depending on where you're located in the world. It probably refers to the primary constituents of the steel and how they're made. 

Steel is generally made up of iron and carbon, but their percent composition, as well as their inclusion of other elements, such as aluminum, chromium, manganese, etc. depending on what they're used for (i.e. Stainless steels must have 10.5+% chromium, tool steels have 0.5-1.5% carbon, etc. Even within these subsections there are further specifications). While Wikipedia generally isn't considered a 'scholarly source' I feel as if the [classes of steel articles](http://en.wikipedia.org/wiki/Steel) cover this topic pretty well if you want to learn what makes the different steel types unique (disclaimer, it's dryer than the Sahara).

As well, the way steel is treated also contributes to its hardness, strength, and other characteristics. If you're interested in the different treatment methods, check out [this link](http://books.google.ca/books?hl=en&amp;lr=&amp;id=yu2r5uqJBGIC&amp;oi=fnd&amp;pg=PA1&amp;dq=treatment+of+steels&amp;ots=Ks4Rshog3-&amp;sig=wgIR2yu6WPAzxg7btukyp69AhM4#v=onepage&amp;q=treatment%20of%20steels&amp;f=false). There's way more ways to treat steel than you'd ever imagine!

So going back to the original question of 'domestic' vs. 'foreign' steels, it's probably pretty arbitrary what those definitions mean. It's likely more to do with the above qualities and how they relate to hardness, strength, brittleness, etc.  Two questions:  
1- Domestic relative to whom?  
2- Which steels are we talking about?  
(I fear that I am on my way to becoming a knife snob and I want to know.) [deleted] [deleted] [deleted] Why not make all the windows the same as the windshield? You couldn't escape using the special glass breaker if they were all like the windshield.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Good question, though I'm not entirely sure why I can take a stab at it.

The windshield is laminated panes of glass, which means if you get a crack in them (like a rock hitting your window) it won't shatter into a million pieces. It also isn't a single sheet of non tempered glass so if it does fail you don't get impaled by a massive shard of broken glass. There are advantages to having tempered glass on the side windows, notably that emergency responders can break through them easily with punches. You can as well in case you and your car are submerged in water. Most cars nowadays are equipped with side impact airbags as well, which helps mitigate the risk of a collision between your head and the side windows.  actually it DOES shatter into a million pieces. the lamination prevents those million pieces from "going all over the place" including into your face IE it holds them together (layer of plastic inbetween IIRC) What are you talking about? Have you never gotten a chip or crack in your windshield? If it shattered like tempered glass, then you wouldn't be able to see anything when a rock or something hit it. That wouldn't be very safe. It's not tempered, at least not like the safety glass, which means it's weaker and gets cracks easier, but it doesn't shatter when it does get a crack. But if you've ever had a windshield actually shatter, you'll realise it does fall into a bunch of little pieces - just that they're held together. I was speaking about collisions. (which seemed to be what was being talked about) in which case they do shatter but are "held together" by the layering. They do shatter, but in a different way. Tempered glass, when something breaks the external layer, will cause the *entire* sheet to shatter at once, regardless of point of impact, since the interior stresses will force everything apart. Normal glass will break around the point of impact as the force of impact is distributed throughout the pane. Anything not directly affected by the impact force, or spreading of cracks (I've no idea the correct term here), will not break.

Laminated glass will shatter more similarly to "normal" glass. However, the layer that is impacted will not be able to flex as much, leading to the force of the impact being unable to spread to a larger area, limiting the length of cracks that can form. What happens to that kinetic energy, though? Some will be spread into lower layers, potentially causing damage, while the remainder will be transferred entirely into the area that *did* manage to flex. Unable to dissipate further this will cause more local damage, resulting in your typical spiderweb pattern.

(note: I really should be sleeping right now, so apologies if my phrasing doesn't make a lot of sense) Correct, most windshield glass is three layers I think. They can adjust the strength by varying the thickness of each individual layer. The outermost layer is usually non tempered. I think at least one of the other layers is tempered. And you are right, the lamination helps keep them from impaling and/or harming you. Generally none of the layers are tempered.

You don't want a deep crack or hole in the glass to spider across the entire thing in a billion tiny cracks. An interesting way to find tempered glass is to put on polarized glasses. If you look at the glass, you'll see a checkerboard like pattern. You will see this in car side windows. You won't see this with the car windshield. The windshield is not tempered glass. [deleted] [deleted] Safety.  Tempered glass is a lot safer because it doesn't form sharp edges when it breaks, which is important in a crash.  The reason your windshield is laminated is because it takes so many impacts that it would blow up too often if it was tempered.  Also, I think windshields have to be a lot thicker and therefore heavier.  [deleted] [deleted] [deleted] [deleted] For auto class I came late and my punishment was to take apart a car without breaking the windows. Well, I broke one and we decided to turn it into a science experiment. New park plug porcelains and used spark plug porcelains were used. The used ones went straight through the window whereas the new ones bounced off. Is there a difference between them? Does having an electrical charge in the porcelains affect the glass at any rate? Hmmm interesting experiment. Can you give me a bit more details? I doubt it has anything to do with electrical charge or properties. My guess is it has something to do with the temperature profile that the used spark plug has seen while in service. It could effect the microstructure and from their the mechanical properties. It could also be a difference in material. The newer spark plugs could be made from a different ceramic than the old ones The heating cycles it was exposed to may have made it harder. When a material is heated up, it expands and the material grain gets torn up and when it cools, the grains come back together but smaller. This leads to having more grains. More grains = harder material. This is an extremely simplified explanation. Also the basic theory behind heat treating metals. 

Ceramics are special though, because they are very good heat insulators, and the effects of heat treating would be very small. [deleted] [deleted] [deleted] I think your fun fact at the end is a little off. I studied automotive engineering and was a mechanic for a couple years. The windshield is not supposed to break before a human skull. Older windshields did just that. The problem was that in an accident the person's head would go through the windshield but the rest of the body would not which caused many people to be decapitated. Or be caught in some glass bear trap of death type thing. 

As for the side windows I have never seen them cave in a human skull. I worked as an EMT and I'm currently a paramedic and I've seen tons of accidents and those side windows shatter with ease. Most are designed that way and will shatter when the car scores a decent hit.  If you think windshields are not still designed with the human head taken into consideration then I'm afraid you're sorely mistaken. Just because the failure mechanism has changed does not mean it is not a major design point. Yes, older single pane windshields ran into problems with this criteria which you pointed out. Modern windshields mitigate this problem by using multiple panes laminated together. Making it hard to go through, but still easy to fracture. 

While most instances of a head hitting a side window won't result in caving your head in, the side windows are still much stronger than the windshield. Not all crashes and not all impacts are created equal. The force of impact, angle, age of the window, age of the driver, and other external factors can all contribute to deciding who wins the fight between head and window. I'd also say that it is very likely that there are other loading conditions on the window in an event of a collision such as the distortion of the car frame which will apply significant stress to the window in the moment of an impact.

You are not wrong though, and I could have definitely worded what I said a bit less dramatically I have been told by an EMT that what often looks like someones head smashing into and breaking windows is actually the airbag, hopefully meaning it breaks before the persons head arrives. So what about the video of the guy who was doing a news report about breaking car windows with a sledgehammer and couldn't do it? Are you saying that the larger surface area of the sledge hammer isn't as effective as say a ball peen hammer?  &gt; Are you saying that the larger surface area of the sledge hammer isn't as effective as say a ball peen hammer? 

For the purposes of breaking tempered glass and the side windows of your vehicle, no, it is not. The objective is to cause a crack in the glass. Given the same amount of energy, this is easier to accomplish via concentrating said energy at a single point (in your case, the ball-peen hammer) rather than spreading it over a larger surface area (the sledgehammer). [deleted] Hope you're feeling ok! Yes in the fight between your side window and your head the window can definitely win. It's not always the case though. As glass (or any material) ages, cracks will inevitably develop. These microcracks can also act as stress concentrators, slowly reducing the actual strength of the material.  Not necessarily caved in - but a decent crack isn't out of the question. Why does it work if you put a piece of cloth over the window and then hit it with a hammer? The comments in this video explain it pretty well. https://www.youtube.com/watch?v=QhlmKHbPFhU

&gt;  
This happens because ceramic is extremely hard, brittle but hard. The glass to you seeing cars is made by super rapid cooling of the glass which creates tension between the outer wall of the glass and the inner core.

&gt; The ceramic is harder than outdoor wall which enables it to make a fracture, and because there's so much tension on it the window basically implodes.

EDIT: [Wikipedia](https://en.wikipedia.org/wiki/Ninja_rocks) For a demonstration of the phenomenon in an easier-to-digest form, [watch high-speed footage of prince rupert's drops](https://www.youtube.com/watch?v=xe-f4gokRBs). I want to know what is the largest prince Rupert's drop ever made. Someone should drop a car sized glob of molten glass into a swimming pool.

Also, has anyone ever smashed a prince Rupert's drop without breaking the tail? What happens if you use a massive sledgehammer or an hydraulic press?  It will break -- it's just far less spectacular.  The thing that makes Rupert's so impressive is that it's quite a large glass explosion for the small amount of input energy (breaking the tail).

If you smash it in a big press or something it'll break, but so would any other piece of tempered glass, so it's a bit less interesting. Does anyone know where to buy these drops? The first glassblower you find, you just need to drop molten glass into a bucket of cold water. I don't expect they're shipped much because any shock nicking the tail and your package is full of shredded glass. Since diamonds are higher on the MOHS scale than the ceramic from a spark plug, could you use them the same way? You can break your car window with a pen, so I'd only assume that a diamond could work in a similar way.

I'd be interested to find out if it would be any more efficient, though. You probably mean a [center punch](http://www.amazon.com/Neiko-5-Inch-Adjustable-Automatic-Breaker/dp/B008DXYOLC), which is usually hardened steel.  This is what firefighters use to pop windows, and it works on the same principal.

Hard to imagine a pen would do this as easily, thought some 'high end' pens are advertised as window breakers as well.  Probably mostly advertising. EMT and (onetime) volunteer firefighter.

I think the idea behind the ball point pen is that the tip is exposed to friction during writing, so you want it to be hard enough that it doesn't wear. [The Bic Biro,](http://www.coursestuff.co.uk/ENVT1010/designed-world/bic-ball.html) just to cite one example, uses a tungsten carbide ball in the tip. Tungsten carbide would prove quite useful in trying to pop a tempered glass window.

[Wikipedia](http://en.wikipedia.org/wiki/Pen) notes that the ball in the tip is "usually 0.71.2 mm and made of brass, steel or tungsten carbide," citing "How Stuff Works" as the source for that bit of info.

I suppose you might end up very sorry if you tried to punch through a tempered glass side window if the ball in your pen was a brass one. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] The center punch [has a spring in it that will cause a shock load](http://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Automatic_center_punch_operation_animation.gif/100px-Automatic_center_punch_operation_animation.gif) as well.  As you push it compresses the spring, then at a certain load, the spring gives way and the handle slides forward, making contact with the chisel point.  

This mechanism is actually what cracks the window, not the static pressure.  It reduces the strength it takes to crack the glass by a lot, as the hard contact of the handle to the chisel can make really high (500g+)  instantaneous accelerations. Yeah, center punches are pretty badass. They are typically used to create a dent in a material so that when you are subsequently drilling into it, the drillbit settles into the dent and does not move around. It serves this purpose well on almost all metals a typical workman would use. A centerpunch would probably be overkill for breaking car glass-- I don't know about pens, but as far as punches go that huge spring loaded impact is what does it.  [deleted] Due to the holding mechanism of the window, there is less flex to the window at the bottom, so a bottom corner works best for the center punch break. For the record, a center punch is not exactly the correct tool for this. There are purpose-built window breakers that are similar, but do the job better, which is probably what you'll see firefighters and EMTs using.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Also, there's electric windows on most cars these days. Do they work submerged? [deleted] [deleted] [deleted] I just meant could they be used so effectively as this ceramic or is there something special about the ceramic in how sharp the pieces can be or the like.  If you had a larger piece of industrial diamond and flung it at a car window, would it explode the same way? I don't think it's so much as "flinging it against the car window" as it is applying pressure. Maybe someone who is actually qualified can correct me, but I'm pretty sure that the only thing you need is a hard object with a relatively low surface area that you can press against it.

Edit: Just saw that the question was about flinging it, so I guess this comment and my first reply is/was pretty useless. Many ballpoint pen tips are made of Tungsten carbide, which is extremely stiff and hard. The question speaks to what the difference between a rock and a "ninja rock" is.

A broken piece of spark plug has a Mohs hardness approaching that of diamond and most likely has sharp edges. this combination allows it to break the layers of the tempered windown.

A rock has a lower hardness than aluminum oxide and most likely has a more spherical shape. does it have the same effect from inside the curve on the inside of the car? Might be useful to have a small piece of ceramic in the car if you ever get trapped. There are punch-tools with a hardened steel tip you can buy for exactly that. Some are even spring-loaded so you just hold it against the window and press a button.  you can get these, http://www.brand-tech.dk/cm-fotoarkiv/2-0112201217-34-20lifehammer.jpg  
hard points to break a window and a knife to cut seatbelts  So if it's just the ceramic that does the job couldn't I just superglue a piece of hard ceramic to my car alarm fob and have an instant emergency window breaker? The glass in car doors is made from tempered glass. Some people refer to it as "safety" glass. The glass is designed to break into small pebbles rather than large shards which would cause injury when broken.

Tempered glass is required in all car windows in the U.S. with the exception of the windshield which is laminate glass. Tempered glass is also required in a wide variety of residential/commercial construction projects/products in the U.S. If your home is built to code in the U.S. and you have an exterior door with glass in it...the glass is tempered. Tempered glass costs more than normal glass because of the additional labor/manufacture time associated with it. 

http://en.m.wikipedia.org/wiki/Toughened_glass As **Hatecranker** says, with tempered glass, any damage to any part of it destroys the entire piece.

This is partly done for safety, because there are no sharp shards to stab/slice through you, the glass disintegrates into a shower of "pebbles".

However, tempered glass is phenomenally difficult to chip or crack.  You can hit it with a blunt hammer and it will neither chip nor crack so it will not break.

The hardness of the attacking tool is critical.  A steel point might be able to destroy it, but it's difficult.  The edge needs to come to a point to scratch it, but a fine point on steel will bend a bit under the high forces.  Ceramic is very different, it's much harder than steel.  It's more brittle, but that doesn't matter here.  It's not a thin cutting edge of course- a broken spark plug is not a knife- but you can scratch concrete with a broken spark plug much easier than you could with a knife.  It's like that. comparison to metal implement, thank you, that's what i was looking for here. Try scratching glass with a knife.  It's very difficult. A razor blade can.  A screwdriver probably can't.  A rock usually can.  A diamond, piece of carbide, or broken ceramic spark plug certainly can.

Would a large diamond break a car window?  Probably, but why bother breaking into a car when in possession of a huge diamond? It's summer, you just bought a a diamond wedding ring in Arizona but forgot that you locked your fianc's 8 month old kid in the car.

You're in Africa. The family that nursed you back to health is in the back seat of a greedy diamond lord's gang's car awaiting execution for housing a foreigner. You must save them and repay the debt you have to the family.

Just a few scenarios in which you need to use a diamond to get into a car. Question: If you made the tip of a bullet ceramic would you be able to shoot through bullet-proof glass? If the bullet were to not break being fired, still no because bullet proof glass is multiple pieces of glass laminated together (similar to a windshield but thicker and more layers of glass). Bulletproof glass is not the same as tempered glass.  Windows are made from tempered glass and shatter easily.  Bulletproof glass is made from layers of polycarbonate plastic and the kind of glass in your windshield.  Basically the glass is strong while the plastic is resistant to shattering.  The glass won't shatter regardless of what the bullet is made of. [deleted] To break (most) standard-thickness sized car windows, especially with a blunt object, and in this specific instance, a metal tipped baton... 

You need to flick the wrist back upon impact. A single forceful swinging motion that carries the inertia and follows it through on the forward stroke isn't bueno at all. Flicking is better. Just for your future reference, because medical bills suck to get unexpectedly or otherwise.   [deleted] So the stuff in movies where guys just punch right through car windows with their fist and strangle the driver can't happen in real life?  It would only break if the window wasn't closed all the way. When they are closed, they distribute the force along the edge of the glass into the car body. If you lower the window, you reduce the amount of contact, making the glass more vulnerable to shattering. [deleted] When the glass is tempered (or toughened in the UK) it is heated slowly allowing the whole pane to reach a uniform temperature just short of the melting point of the glass where the pane is malleable (this is usually done over moving rollers in the case of commercial or domestic glazing in order to allow the glass to remain flat during heat treatment, or in since use (or multi use) forms in the cases of autoglass) then the whole pane is quenched with cold air at a very specific speed, this cooling cools the outside of the glass at a much higher rate than the inside of the glass, and due to the expansion and contraction of the material when heated being essentially frozen as the glass solidifies it creates a tension across the full pane. Prior to toughening, the glass is arrised (edges chamfered) to reduce imperfections in the glass and reduce the risk of accidental breakage. 

The reason spark plugs are so effective at breaking the glass is because a ceramic spark plug is considerably harder than glass, glass only hits around 5.5 on the mohs hardness scale, whereas ceramic is around 9 (lead is around 1.5 so ceramic is MUCH harder than glass even though glass seems very hard) Because of this hardness difference, hitting a piece of ceramic on a piece of toughened glass causes damage to the structure of the glass, and because toughened glass is under constant pressure (from the processes mentioned above) damaging a part of the structure releases the energy stored and causes a chain reaction across the full pane causing the glass to explode into "dice", this is considered a safe alternative to large dangerous shards since none of these "dice" are large enough to hurt someone, this is why toughened glass is generally referred to as safety glass. 

A car windscreen however is made from laminate glass, this is to prevent foreign objects getting into the car at high speeds and killing the occupants, Laminate is formed from 2 pieces of glass bonded to a PVB interlayer which holds the shards in place and acts like a net to stop that guy you just hit at 70mph from flying through your windscreen and killing you.  [deleted] [deleted] [deleted] [deleted] The key is that when broken, spark plugs create very sharp, very hard edges and points.

That lets it easily damage a tiny part of the tempered glass, which interrupts the structural forces holding the tempered glass together, causing the rest of the pane to fall apart. Celestial velocities may be huge, but at least for orbits in the galaxy they top out at hundreds of kilometers per second. Since the speed of light is about 300,000 km/s, the stars' velocities relative to us introduce only a very very very miniscule change in the passage of time. 

The amount of time dilation is proportional to the Lorentz factor, 1/sqrt(1-v^(2)/c^(2)). Even for an object traveling at 10% of the speed of light relative to us, this means that the time dilation we see for that object is only about a 0.5% change.

To clarify: in any object's own reference frame, time passes at a normal rate. It's just that when objects are moving at high speeds relative to each other, e.g. trains moving past each other, a passenger in one train will look at the clock on the other train and see it ticking slower than the clock on her own train, and vice versa. This goes both ways. Great answer. Follow up: How do we know how fast, say, the milky way galaxy, is moving through space? I know that the speed of light is the same for all reference frames so it leaves me wondering what we use to determine the speed of celestial objects. If we use other objects as a baseline, how did we determine the speeds of those? For a long time, we didn't. You just quoted objects' velocities with respect to something else. For objects within our own galaxy, you reported (and often still report) the objects' velocities relative to the sun, known as their Heliocentric velocities. For more distant objects, astronomers usually report galactocentric velocities, where the center of the Milky Way is treated as "at rest."

Defining an absolute reference frame is hard. In fact, if one of our assumptions about cosmology is correct (homogeneity) it should be impossible. However, the discovery of the Cosmic Microwave Background allows us to define a local velocity reference frame. If you were moving with respect to this frame, you'd see the CMB as slightly hotter in one direction and colder in another! So by subtracting off the dipole moment of the CMB from your velocity observations, you can transform velocities into this frame. Fascinating. So if someone was measuring the velocity of a not-so-distant galaxy, they might first measure it with respect to the milky way, and then convert it to the standard local frame using the CMBR? If the universe keeps expanding, eventually the CMBR will fade away and future observers will be unable to detect it. I would suspect the CMB will always be detectable in any realistic terms of human existence. It's expanded with us, so it will continue to redshift as it's wavelength stretches and eventually will be overtaken by stronger radiation sources, but it's been there for 14 billion years, so probability wise I suspect it will be there forever in relation to human existence. Our ability to detect it will also only get better, offsetting the loss from expansion.


 Could it have existed for 14 billions years, but maybe not always in the exact same state? We see the CMB as it currently is, which may present a temporal slice of a dynamically changing landscape The CMB was 'set' in place the moment the universe cooled enough for it to propogate. But since then, with the expansion of the universe, it has gradually been 'smooshed' downfrequency/energy. red-shifted to the point of microwaves would be more accurate? Potato potato. The wavelength of the light was stretched, the frequency/energy was reduced- that's redshift. But it was caused by the expansion of the universe, so saying that is more accurate. I was trying to explain as best I could whilst also keeping things simple enough to be understandable by lots of people. Yes, and it will continue to get "redder". Technically, it's radio waves. The further away an object is, the more it will appear red-shifted to an observer. As you get towards the extreme 'red side' of the electromagnetic spectrum, the wavelength of the photons becomes thousands of kilometres. In fact, because the speed of light is around 299,793 km/sec, any electromagnetic wave with a frequency of 1Hz will have a wavelength of 299,793km! As you can imagine, the amount of energy at such high wavelengths is infinitesimal.... The temperature of the CMB has decreased from 3000K shortly after the big bang down to 2.7K today due to the expansion of the universe. It will get harder and harder to detect as it approaches absolute zero (0K). But we're talking about timescales of hundreds of millions of years at least to see measurable changes.

The temperature decreasing is directly related to the wavelength stretching that /u/imaredditloser mentions. Wait, since the CMB is so far far away, don't we see it as it was at the time the radiation was emmited from it? Just like we look at the "stars" in the sky, we see them how they were when they emmitted the light and that light traveled to Earth? No, because it's been travelling through space, and space has been expanding, stretching the photons along with it. This is known as 'red shift', and was actually one of the first major pieces of evidence we had that the Universe is expanding  Hubble noticed that more distant galaxies had increasingly red light.

The microwave background has cooled from thousands of kelvin to only a couple of kelvin above absolute zero. The *distribution* is still the same as it was when the light was emitted, but the frequencies are not. This is correct. The CMB is at a redshift of z~1100, meaning that we observe it at a wavelength ~1100 times longer than when it was emitted. This makes me think: what would have happened if we were "born" too late to discover CMBR, we would have no idea it was ever a thing?

What if a long time ago there was something similar that we can't detect anymore and will never know? A cosmic neutrino background is though to exist but it's so low on temperature that it's impossible for us to detect. impossible for us to detect with current technology.
We could speculate that with sufficient advancements in the ways we understand mass and mass interactions, we **may** be able to detect neutrinos based on their negligible mass more easily.
(we aren't going to magically detect them based on charge they don't have of course.) You meant tought to exist? Haven't we already detected neutrinos with [these?](http://en.wikipedia.org/wiki/Neutrino_detector) Way to typo the same word you were correcting. Neutrinos have been detected, of course, but with discernable sources, just like microwaves were detected long before CMBR. Sorry english is not my main language, I tend to mess up with the h in some words. Are these what we're trying to detect deep underground? No, those are solar or human  made neutrinos. The cosmic neutrino background is too low energy for us to detect. That won't happen for billions of years though, right?  That's awesome, and put in a way that I can understand with my very limited physics knowledge. Well done. Does this mean we can quantify our speed relative to the CMB in m/s? If so, what is that speed? Indeed it does. The local group, which includes the MW, Andromeda, and all of their various satellite galaxies, is moving at about 627 km/s relative to the CMB rest frame.

See [here](http://en.wikipedia.org/wiki/Cosmic_microwave_background#CMBR_dipole_anisotropy) for more details. If I understand everything said... We would still be unable to distinguish between our entire universe being on average at rest, though flying apart and around itself, from the situation where the whole shebang is shooting off in one direction, because even the CMB would be moving with us and there would be no other reference frame from which to gauge that the whole big bang had momentum before/during its explosion. If I'm understanding your question correctly, no, there's no way to determine if the entire universe is moving coherently in a particular direction at any particular speed. This is a consequence of special relativity. Wait, are you certain of this?

I always thought that since it comes from the opacity threshold, which originates *everywhere* at a particular time in the past, the CMB will always be in your reference frame. That is, the source of the light will appear to "move with you" since it appears to originate from a sphere centred on your location. Is that not right? You're correct on most counts. When photons decoupled from the primordial plasma back at redshift ~ 1000, it created a radiation background that was roughly the same everywhere. That background radiation expanded with the expansion of the universe, getting less and less energetic over time. But between then and now, things have changed *a lot*. Overdensities of dark matter and gas have collapsed to form groups of galaxies. Complex gravitational interactions have flung bodies around, merged galaxies together, etc. And in that time, we've picked up a slightly anomalous velocity. That's the anomalous velocity that we can measure in the CMB dipole.

It still doesn't tell us anything about our position in the universe, but it does give us an idea of how fast we are moving relative to the rest frame of the CMB. I thought that we famously discovered that the CMBR is isotropic. Was that image corrected for our velocity? If you were to measure the CMBR without correcting for our velocity, would it appear anisotropic? There exists a reference frame in which the CMBR is isotropic. The local group of galaxies is moving relative to that reference frame.

See [here](http://en.wikipedia.org/wiki/Cosmic_microwave_background#CMBR_dipole_anisotropy) for more details. So our group of galaxies could be moving at 99% the speed of light to some other galaxy? Something like that, yes. We've known for quite a long time that the further away a distant galaxy is, the faster it's moving away from us. For galaxies several billion light years away, the value of these speeds are *huge*. This is what's known as [Hubble's Law](http://en.wikipedia.org/wiki/Hubble%27s_law). How big of difference would we expect to see. And do we have the sensitivity to currently measure it? The difference is about 627 km/s for the local group of galaxies. See [here](http://en.wikipedia.org/wiki/Cosmic_microwave_background#CMBR_dipole_anisotropy) for more details. Is there also a minimum velocity?  Like an absolute zero of velocity?   All velocities are relative. If you are moving at the same speed in the same direction as me, then your velocity is zero relative to me.

You can always define a reference frame in which you are not moving. thank you for explaining this so well I assume that observers in galaxies that are moving relative to us also are still relative to the CMB they see? Yes. The CMB ought to be isotropic everywhere in space if we're correct about where it came from. It has expanded uniformly with the expansion of the universe. So if there are observers somewhere else in the universe, they see an isotropic CMB just like we do, despite the fact that their galaxy is moving away from ours quite rapidly.

That's why I said that the CMB allows us to define a **local** velocity reference frame. Relativity tells us that space by its nature has no preferred rest frame, but if you fill space with stuff, that stuff could have an average "at rest" frame.  Our universe is one example where this is true, and we can measure the "average at rest" frame through the Cosmic Microwave Background (CMB) which is the remaining, all pervasive, dimming light from the big bang. If you are at rest relative to the CMB, it will look the same in every direction. If you are moving relative to the CMB, it will be blue-shifted in one direction and red-shifted in the other due to the Doppler effect.

When we measure the CMB from Earth, it indeed has this exact redder-in-one-direction, bluer-in-the-other structure. [here's a NASA link showing it](http://wmap.gsfc.nasa.gov/universe/bb_cosmo_fluct.html)

Then we just infer that we are moving in the "bluer" direction at about 600km/s relative to the CMB to account for it. Thanks for the explanation, but this raises a question for me:

Does that mean there is a center? If you follow this gradient would you come to some point where it radiates from? There isn't a centre necessarily, just a frame where everything is, on average, at rest. Basically a reference frame where the total momentum of the universe is 0. &gt;Does that mean there is a center? 

Yep, and for us it's [Earth](http://en.wikipedia.org/wiki/Observable_universe) (at least for the observable universe).

[Here](https://www.youtube.com/watch?v=i1UC6HpxY28)'s a video that explains it. What bothers me about that explanation, is that the balloon _does_ have a center.  So while it nicely explains why every observer feels like he's at the center, it doesn't come close to suggesting that our universe lacks a real and absolute center.  The confusion you're having here is the idea of a space (the balloon) embedded in a larger space (the room we're blowing it up in). Space can exist on its own without being in a larger space. So if you looked at the balloon as if it were the only thing around, it would not have a center. 

Our universe has three possible shapes predicted by General Relativity (Einstein's theory of gravity that also gives us all our current understanding of the shape of the universe) depending on how much stuff is in the universe. It can be infinite and flat (this is what we believe we have and it's a very special thing that we do end up having it), infinite and saddle shaped (like you put on a horse), and a finite, compact 3-sphere. A circle is a 1-sphere (not what is inside of it just the outside), a ball is a 2-sphere (just the balloon not the air inside), and this larger 3-sphere object is a bit stranger. So if I take a circle and put it on a flat piece of paper and it has a center on this piece of paper. If I take a line through the center I would get two dots. If I took a normal sphere (2-sphere) and put it in the center of a room and put a plane (like a flat piece of paper) through the middle I would get a circle out. Now if I  take a 3-sphere and put it in the middle of a 4D room and take a 3D cut in the center, I'm going to get a 2-sphere (a balloon) embedded in that 3D cut. This is one of the possible shapes of space our universe could take and it's probably the least intuitive but it's just like a balloon or the Earth in that it's compact. This means if you walk in the same direction for a long long long long long long time you will end up in the same place you started. In the other two possibilities, you'll never come back.

The balloon example for expanding space analogy works for all three of these possibilities. And none of them require to be embedded in a larger space. And none of them require a center. But the analogies we use to understand them often require us to embed them in a larger space and we must be careful not to assume properties we see are from the object itself are from the object or just a weird property of how we choose to picture it. 

TlDr; the center you think you see in this analogy is a property of the analogy not the object itself.  Just on the point of the prediction of the shape of space, wouldn't it be more accurate to say the three possibilities were given by Riemannian geometry? That predates relativity by a good chunk of a century. The spacetime metric being proportional to the stress tensor gives you the local geometry not the topology of your spacetime. To be perfectly honest, I can't recall from my own knowledge why those three shapes are the ones permitted - specifically how one goes from the Einstein equation to the topology of the space. As far as my limited knowledge is concerned, a general space of dimension N with a metric put on it can have any number of possible shapes.

These are just so many words for, you are maybe right but I can't tell you either way.

Edit:

So some quick Wikipedia-ing seems to indicate you are correct. http://en.wikipedia.org/wiki/Sectional_curvature
That you only need Riemannian Geometry to get this but I'm also not sure historically if the entirety of Riemannian Geometry was "done" (or at least these results) before GR came up.  It's a feature of the brand of geometry you use. I don't really know anything about the physics terms, but the existence of a Riemannian metric (on tangent vectors) is actually a hidden global topological condition (for instance, you can create geodesics and globally define a metric on points). If you then assume that curvature is constant and behaves the same in any direction (given at larger scales by isotropy), you end up with a very limited set of isomorphism classes of geometries. In 2d you get the sphere, plane and some model of hyperbolic space, corresponding to positive, zero and negative curvature.

I'm pretty sure there are non-isomorphic geometries with negative curvature in 3d, but haven't looked into the specifics since before I understood them. Space is the surface of the balloon. The "center" you are describing is therefore not in space. Is using this CMB as this "average at rest" frame sort of akin to the aether that people assumed to exist prior to the creation of special relativity theory? No. The aether was proposed to provide a medium for observable phenomena like electromagnetic waves to travel through, in much the same way that waves travel through water or air. No theory depends on the CMB for this purpose.

If the aether had existed, depending on its exact properties it might have been possible to use it as a "preferred", absolute reference frame. However, the CMB is not such a frame. The point about relativity is that the laws of physics are the same in every reference frame, so no frame is preferred in that sense. The CMB is no exception. That would not have been true for the aether. I see. Thanks for clearing that up. I wish I had taken the SR courses back at uni! If there is a universal average at rest frame, why isn't that the preferred frame of reference for the universe? General relativity says that theres no 'preffered' frame in that the laws of physics appear the same to any observer in any inertial (non-accelerating) frame. So fundamental things like the speed of light, the passage of time, the properties of the forces of nature etc. cannot tell you whether you're at rest or moving at constant velocity. Of course you can pick a reference frame outside your immediate area to define as zero velocity (the earth, the sun, the milky way etc.) but that doesn't make them truly fundamental - it's just a convenience. The CMB is just another convenient way to define zero. Because its the average frame for "stuff" in the universe rather than for the universe itself. I just found this short article while searching for some things your question made me think of, which you might enjoy. 

http://www.scientificamerican.com/article/how-fast-is-the-earth-mov/

I found it interesting that our entire galaxy is moving at around 1,000 km/s! If we assume some planet X is moving at v = 100km/s relative to Earth, then the Lorentz factor turns out to be about 1.00000006 - this means that if we take the age of the Earth to be 4.5 billion years old, then we would see X about 270 years behind us.  Moreover, the immense distances to planets dictates that light take many, many years just to get here, and we are effectively seeing them in their past.  If we assume X is about 100ly away, then this adds to our running total of about 370 years!

But the interesting question is would that 370 year gap make a difference in the detection of intelligent life?  If X were inhabited by humans, the answer would be yes because 370 years ago, we'd barely discovered calculus and elementary physical theories.  However, intelligent life sprouts up so quickly and unpredictably on astronomical timescales that 370 years would be extremely insignificant in the grand scheme of the universe.  So unfortunately special relativity is a terrible explanation of the Fermi paradox. I read a theory or talk somewhere that life may be common in the universe. The problem is that they flourish within time scales so minute that two intelligent species may never be close enough in proximity or time to discover each other. 

Even if it were possible for them to traverse the interstellar distances may end up becoming extinct or running out of resources.  Also, I may be wrong about this, but doesn't gravity affect the passage of time more than speed? Or is it simply easier to get nearer to large gravity wells than it is to get up to "relativistic speeds" that would have similar effects? Gravity and speed both affect the passage of time. There's no way to definitively say which affects it more, since it's hard to compare a gravitational acceleration to a velocity.  Thanks! The 0.5% helps put it in perspective. So even in the long term, somebody on another planet would only vary about +/-5 years for every 1000 years we spend here on Earth, right?

I guess I was thinking about it in terms of how much "extra time" civilizations on other planets could potentially get (compared to an observer on Earth). Although if we are talking about the *really* long term:

Say there was another planet which, to a theoretical observer on Earth, experiences time progressing 0.5% faster than we do, and that life began on that planet at the exact same moment as it did here on Earth. That was (according to [Wikipedia](http://en.wikipedia.org/wiki/Abiogenesis#The_earliest_biological_evidence_for_life_on_Earth), at least) about 3.5 billion years ago. Unless I'm way off, that'd mean that (again to an observer on Earth) life on that planet would have experienced around 17.5 million years *more* than we have here.

**Edit**: More precise language. Also, I understand that, based on what /u/Das_Mime said, 0.5% is super generous and improbable at best. That's if it's 10% speed of light, which it isn't. If you go with 500 km/s as the difference (about twice the speed of our solar system around the galactic center) that gives a time dilation of 1.4x10^-6 which means after one earth year the clocks are only different by about 44 seconds.

Which means after 3.5 billion years the difference is less than 5000 years. Yeah, I did realize that using the 0.5% mark was super generous. This is an excellent answer to my question, thanks! doesn't gravity affect it more ? ie; the movie Interstellar..  If you're practically a stone's throw from the event horizon of a supermassive black hole which is rotating at 99.9% of its maximum speed, yeah. Needless to say no habitable planet would ever exist in such a place, nor could a black hole achieve or maintain such a rate of rotation. A stone's throw toward the event horizon of a supermassive black hole which is rotating at 99.9% of it's maximum speed could be a pretty far throw.  Yeah. I mean, if nothing is in the way and the gravity field is even vaguely net-pointing at the black hole, you could throw the stone from light years away and it would eventually get there. &gt;Say there was another planet which experiences time progressing 0.5% faster than we do

There is no scenario, excluding gravitational time dilation, in which that statement makes sense. Special relativistic time dilation can only cause time to progress *slower* elsewhere. If another world is traveling at 10% the speed of light with respect to us, then we are traveling at 10% the speed of light with respect to them, and observers on either world would observe time progressing about 0.5% slower on the other world.

This is basically how the twin paradox came about, which you can read about in depth on sites like wikipedia. The resolution of the paradox is to recognize that in order to travel from one of the worlds to another, the traveler would have to accelerate, in which case the traveler's reference frame is no longer inertial and is governed instead by general relativity, which clearly defines the passage of time for non-inertial reference frames as well. The ultimate difference in ages of the planets when the traveler finally arrives at the other planet would depend on the particular path through space-time taken (i.e., how long &amp; at what rate the observer accelerated). Not really.  I replied to the post, but you cant gain time in one frame or another.  All this is relative from one frame watching another.  A good way of thinking about it is rearranging the lorentz factor equation.

(t'/t)^2 + (v/c)^2 = 1.  This means if you observe a frame at rest, t'=t.  The passage of time is equivalent.  In the case that v=c (photons), t'=0.  Time is not passing.  Local clocks all work at the same rate. So maybe the terminology I'm using isn't correct, but I think the logic behind what I'm saying is sound. I'm using Earth as a frame of reference observing other planets, and I'm not talking about a situation where the relative velocity of one body to the other is zero.

In my example above, to *us* here on Earth, it would appear that this other planet has aged an extra 17.5 million years, would it not? No, you have the time dilation factor reversed. It would be that the other planet has experienced 17.5 million years less than us (from our perspective), not more. I believe you should consider thinking about information and communications between the two civilizations... That's where special relativity comes in. I would also suggest that you should try to grasp the most basic concepts of special relativity. Considering your background I believe the math of special relativity won't be a problem.

However, short answer for your question: everyone perceives their own time independent of their velocity. Time dilation happens because of the velocity of one observer in a reference frame, which can be chosen depending on how you/he see/s the issue. In you reference frame, his time progresses slower. In his, your time progresses slower. I am purposely *not* talking about communication between two civilizations, and I am not talking about how anyone experiences time in their own frame of reference. I am talking about (for example) an individual on Earth as a theoretical observer of the passage of time on another planet. I think that /u/Carequinha understands you, or I do not understand you. Observation in this case should be synonymous with communication. Earth and planet X move at some great velocity with respect with each other, great enough for special relativity effects to be very apparent. An observer on Earth looks at planet X. That observer sees that time is moving slower on planet X. An observer from planet X looks at Earth. Planet X's observer sees that time on Earth is moving slower. 

If either Earth or planet X, or both, accelerate in some way so that they are in the same reference frame, then observers will see that "more time has passed" on Earth or planet X with respect to the other planet. Which one this is is dependent on the details of the acceleration, and details can be found on articles on the twin paradox. I always thought if we were observing from earth,say through a telescope, we would b seeing the past of the second planet because of the light traveling over vast distances..? [deleted] I guess I am saying that it almost surely *wouldn't* read the same number and, depending on how long those stopwatches sat on those planets (and depending on the planets), the difference between the times could eventually get into the millions of years. If the other civilization's time passes faster than ours and we were somehow able to see them through a telescope, would we be viewing them working in a high speed mode of sorts? Their time does not pass faster than ours. That is not possible in special relativity. Say two observers are moving very fast with respect to each other at a significant percentage of c. When they look at each other, they both will see that the other person's time is moving slower. As to how this can be possible, look up the twin paradox. But what if you are on the other planet looking back at us. Are you ahead or behind? I think you are confusing time dilation due to relative velocity and time dilation due to being in a large gravity well. They are two very separate phenomenon I'm a little bit upset but mostly surprised that this has not been mentioned: General Relativity. Special relativity had been adequately dealt with here, but it appears as if the top commenters have entirely neglected effects of gravity. 

I'm not in a place where I can do the math, but even a small change in gravitational force causes a large time dilation (relative to velocity changes). 

Let's take satellites, for example. They have to account for both General (gravity) and Special (velocity) relativistic effects. 

Typical GPS satellites orbit the Earth at 20,000 km above the ground. Because of the lessened gravity they feel, their clocks run about 45 microseconds faster a day. 

They also orbit at a velocity of approximately 14,000 km/hour. Due to this, their clocks run about 38 microseconds slower a day. 

Do some complex mental math, and this nets out to 7 microseconds faster per day.  May not seem like a lot,  but after 2 minutes they would be wrong, and after one day GPS coordinates would be off by up to 10km. 

Coming back from a bit of a tangent there, the point I am trying to make is that the effects of gravity should NOT be ignored when considering time dilation. 

So, to answer your original question, a supermassive (or superlight) distant planet absolutely could have time (relative to our own reference frame) run far slower or faster than Earth's.  Yep, this is as good an answer as you're gonna get. The Lorentz Factor is basically the mathematical function behind Special Relativity, and is used in a variety of ways when figuring out the effects of ultra high-speed movement.

Basically, at any speed up to 50% the speed of light the Lorentz Factor shows almost no change at all. Even up to 90% the speed of light, time dilation is still minimal. Only once you go above 90% do you start seeing substantial changes, the kinds that could produce the hypothetical time machines theories by guys like Stephen Hawking.

To put it all in perspective:
- Earth rotates at ~1,600km/h at the equator
- Earth orbits the sun at ~107,000km/h
- The Sun orbits the centre of the Milky Way Galaxy at ~792,000km/h
- The Milky Way Galaxy is moving through the CBR at ~2.1 million km/h

Now, let's assume that the planet in your question is in the same galaxy as us. Let's also assume that it's right on the edge of the spiral arms, so that it's barely orbiting the centre of the galaxy at all. Let's also assume that the same is true of it's orbit around it's sun, and that it doesn't rotate. This means that the cumulative speed difference between Earth and 'planet X' is:

792,000 + 107,000 + 1,600 = 900,600km/h = 250.17km/sec

250.17/299,793,000 = ~0.0000008, or roughly 0.000008% the speed of light.

When I put these figures into a scientific calculator, it simply gives me the figure "1". It's actually 1.x, where 'x' is an extremely tiny decimal value, but it's so small that my calculator can't display it. THAT'S how tiny the Lorentz Factor is here :) further to OP's question, how would the difference in mass of planets affect time on different plants?    What matters isn't the planet's mass but the gravitational acceleration that you're undergoing. Earth's surface gravity is 9.8 m/s^(2), and [most of the other planets' surface gravities are roughly similar](http://www.smartconversion.com/otherInfo/gravity_of_planets_and_the_sun.aspx). This effect is miniscule, something like milliseconds per year.  This may be a silly question, but how 'real' is that time change? Let's say that 0.5% time change were something like 5 or 10%. Would we feel or perceive anything differently? Would our clocks automatically change pace with the new reality, or continue counting at its original pace? That time change is as real as anything can be. We've actually done experiments where we sync up atomic clocks, put one of them on a plane, fly it around, and then compare it, and less time has passed for it than for its earthbound counterpart.

One of the first hard pieces of evidence for special relativity was [muon decay](http://hyperphysics.phy-astr.gsu.edu/hbase/relativ/muon.html). Basically, we see particles moving at high speeds relative to us, and we know that their natural half life is very short. But when they're moving fast relative to us, we see them as lasting longer, having a longer half-life, than normal, because less time is physically passing for them than for us. [deleted] I really like your analogy for "proper time." I've never heard it said that way, and is an excellent illustration of the effect. Not very precise, but great for an initiation into the weirdness of relativity! What about solar systems? Would life developing in a solar system on the outskirts of a galaxy evolve faster than life in a solar system closer to the center of the galaxy?

Galaxies travel really fast, but wouldn't math tell us that time passes even faster for a solar system on the outside of a galaxy? Or for a more extreme case the movement of galaxies relative to eachother. Galaxies in the near vicinity of each other have nonrelativistic velocities. Galaxies very far away from each other are redshifted not due to relative velocity but due to the expansion of space in between them. This still creates a relative time dilation effect between them, but neither galaxy is progressing any faster than the other. Both of them see the other as progressing slower, but in their own reference frames they're both normal. In the cosmic rest frame they will proceed at basically equal rates. If two reference frames are moving very quickly with respect to each other, then when one observer in one of those reference frames look at the other reference frame, the second reference frame appears to be moving slower in time. This occurs for both reference frames. As to why this is not a paradox, read up on "the twin paradox". Sorry, another followup. Foes that mean the difference in time passing in Interstellar was greatly exaggerated?  The time dilation in Interstellar was due to general relativistic effects, specifically the gravitational time dilation and [frame dragging](http://en.wikipedia.org/wiki/Frame-dragging) due to being in the immediate vicinity of a supermassive black hole spinning at hyper-relativistic speeds. However, you would have to be incredibly close to the event horizon (much closer than the distance portrayed in the movie's visual effects) for anything close to that to happen. if 2 light rays pass each other going opposite directions, are their relative velocities, from each others' perspective, lightspeed x 2? You can't construct reference frames for an object traveling at *c*. However, for relativistic velocities, velocity addition is nonlinear. See the [wikipedia article on velocity addition for the formula](http://en.wikipedia.org/wiki/Velocity-addition_formula#Special_theory_of_relativity). The upshot is that nothing is ever going to move at more than *c* relative to anything else. Can I hijack this comment for a second to ask about the relativity of simultaneity? I've never understood how this doesn't mess with causality in the universe. If we look at the famous Einstein's Train thought-experiment, I can understand why we might *see* the lightning occur at different times, but isn't that just perception? If two objects pass each other at the same velocity in opposite direction is the time dilation canceled out or doubled? Adding to this, it would end up not making much of a difference for synchronicity because presumably they would measure time using some similar elemental radioactive decay constant like we do with Caesium, but these elements would just decay at a faster (or slower) rate, so our clocks would still stay in sync.

EDIT: This is wrong, the clocks would not stay in sync. Not sure why I thought this. You'd have to account for the time dilation when establishing some universal time standard. [deleted] [deleted] Sorry if the following had nothing to do with the original question, but I've been wondering: if an object is accelerated to c, they become heavier, ant harder to accelerate, in that it takes more enrgy, right? Where do those extra mass comes from? They don't really get more mass. It's just that as you add more and more energy, you don't get as much velocity gain out of it any more. This is an effect of special relativity limiting the speed of objects such that their speed asymptotically approaches *c* as their kinetic energy goes to infinity. The question is not the velocities, but whom is moving with respect to whom?  I.e. , in the twin experiment where one twin blasts off and ages slower than the other twin - the one that blasts off ages slower BECAUSE he entered a non-intertial frame of reference (one in which he was accelerating) - and therefore, HE is the one who has aged less when he returns.  Quite aside from the velocities involved - my question is, how does anyone know who was non-inertial, during the early expansion of the universe?  Because that is what we need to know in order to know who is aging slower/faster, right? The expansion of the universe is not motion. It's not an explosion, there's no center, etc. See the FAQ for more. Yeah, they would be different, but not even close to "completely different". But 0.5% over the course of hundreds of years is still a noticeable change right? For example, if you're willing to do the math, could you tell me what the difference on Uranus over the course of a thousand years would be compared to our time? Sure but there are no planets in the galaxy traveling at even 1% of the speed of light relative to us, much less 10%. 

Uranus' average orbital velocity is 6.8 km/s, whereas Earth's is 29.8 km/s. Relative to the center of mass frame of the solar system, Uranus has a Lorentz factor of 1.00000000026, and Earth has a Lorentz factor of 1.0000000049. This is, of course, ignoring gravitational time dilation effects, which are also quite small. So I have to wonder why it it would matter. If I were standing on another planet in another galaxy with a different rate of time, wouldn't I experience it in the environment? Wouldn't I be subject to the same laws and it would feel like normal time? The only way it could make a difference would be if you were to travel there AND BACK... or you know... faceTime home.  Yes, due to relativity it would all seem exactly the same to you, because any references to time in the physical environment would also be sped up. So what would it be like if you were to Skype/Facetime home? Would those at the Earth end appear to be talking slow/fast? That's a good question, I'm not sure. I would imagine you'd have to account for the time dilation in encoding/decoding the transmission, and the practical work around would be to have response latency kind of like when a news channel is interviewing a correspondent halfway around the world. Well, it would be a fun job getting the radio waves to synchronize...

Since those protocols are digital, likely not? Maybe? You'd just end up with a lower framerate or dropped frames. The signal transmission/processing that would have to happen for this to occur would be insane.  It only really becomes an issue if colonies were setup all over the place. Trying to keep time with other worlds would be annoying. The time difference is quiet small so it wouldn't really be a big deal for most people but trying to set up any kind of exact schedule would be annoying.  That's the idea, yeah. Everyone seems to be moving at 1 second per second from their own point of view, it's only other people they see moving more slowly. I think this question has been sufficiently answered by other commenters. 

I want to pose a similar question that I have often wondered about. What if due to biological reasons aliens perceived time on totally different scales as us. Like trees, but on even slower time scales yet still as intelligent as us. Is this possible? If so how would we communicate with them?? We might actually kill and dissect several of them over the course of years before we realise they are sentient, and that could all happen in what they perceive to be their equivalent of microseconds.

This is also an interesting question to ask about humans. Do we all perceive time similarly, or does what feels like a minute to one person feel like 5 minutes to another person. Maybe this is getting too philosophical.  It is believed that, with some variation of course, larger organisms generally perceive time more slowly. So mice and small birds perceive 1 second as being more time than we do, while elephants and whales perceive it as being a little less.

It seems unlikely that a naturally occurring intelligent organism of a similar scale to use would perceive time *much* more slowly. If it did, its intelligence wouldn't be very useful, because things would be happening in its environment too fast for it to keep track of and respond to. In other words, an organism's speed of thought is simultaneously bounded above by the physical limits of the kind of brain it uses *and* subjected to selection pressure from below by the fact that it is more valuable to react quickly to events in its environment.

One possible scenario might be if the organism evolved in a very cold environment (such as Titan's hydrocarbon lakes, or similar sites elsewhere in the Universe) where *all* living activity occurs much more slowly than it does on Earth. However, life like this may not have had enough time since the Big Bang to evolve intelligence yet. &gt;It is believed that, with some variation of course, larger organisms generally perceive time more slowly. So mice and small birds perceive 1 second as being more time than we do, while elephants and whales perceive it as being a little less.

How did we arrive at that belief? It seems like a matter of qualia to me, and so essentially unknowable. To some extent you can observe it in action. It is very difficult to surprise a small animal with your own movement. See a little bird sitting on a twig, try to grab it, and it's gone long before your hand reaches it. Not because it's physically faster (for instance, baseball pitchers can impart speeds of 150km/h or so to a thrown baseball with their hand, faster than the bird can possibly fly), but because its brain is able to notice your movement and begin its escape sequence so quickly.

There was some sort of study done on the matter recently. Check out [this article](http://www.theguardian.com/science/2013/sep/16/time-passes-slowly-flies-study) for some details. my guess is because as brains grow larger, neurons have to travel further to process information?
 I've thought about this too! What we consider life is so dependent on our own definition that we could easily overlook another form. I was even reading an article the other day about if the earth itself could be considered "alive".  There's a short story by Alasdair Reynolds which is amazing - it's the second one in "Galactic North"  I'll look into it! Thanks! This question was the topic of several original Star Trek TV shows!  I still find that the original series introduced very intelligent and controversial topics. i have no idea but i'm just throwing this idea out there... maybe it has a lot to do with the speed that it takes for your neurons to go through a full cycle, to create one conscious instant for you to experience - your brain's hertz, if you prefer. 

maybe a human brain is only able to cycle through conscious "frames" 1,000 times per second, while the brain of a mouse, because it's smaller and has less complex structure for defining it's consciousness, has a "framerate" of 2,000 times per second. 

so the mouse would experience 2,000 instants of consciousness per second, so a second would seem to last twice as long as it would for a human. Very interesting way of looking at it. I'm very curious what the consciousness of a mouse feels like to experience. If a mouse's brain has a "framerate" of 2000 fps, I want to know what those frames feel like. I know what mine do - I know how much context, emotional momentum, short-term memory, body awareness, etc. I have from moment to moment. Strange to thing that it's different for different creatures. I also want to know what a larger brain's framerate/consciousness feels like. Not actual science, but I know science fiction has dealt with some of these questions.

One of George RR Martin's Tuf Voyaging stories ("Guardians") deals with this. And the Ender's Game series is almost entirely about possible communication breakdowns with various types of aliens. There is a case in which the general relativistic time dilation becomes interesting in a practical sense that we might actually care about relatively(ha!) soon.

If we set up a permanent colony on Mars, their clocks will run slightly faster than ours.

If we want to keep Earth Time and Mars Time synced to the same "Unix Time", then our colony there will have to periodically add "leap ~~anti-~~seconds". I did the math on this once, and I seem to recall this would be needed every 10 to 100 years or so.

~~In practice, this would probably just be a case of Mars **not** adding a leap second on some of the occasions where the Earth time-keeping agencies do add them.~~

Actually, that's backwards. Mars would need *additional* leap seconds to cover up their "fast clocks" and let Earth "catch up." But I think the "every 10 to 100 years" part is correct.





 Couldn't we just make clocks run a bit slower? I think for purposes of running scientific experiments, etc. we would **not** want to redefine the "Martian second" as something longer than the standard second. (As well as for just conveniently shipping them standard clocks and other hardware.)

They should keep the standard units in their reference frame. And just "sync up" by adding a leap second every few decades. I mean, on Earth we already add leap seconds every decade or so and most people neither know nor care.

The difference is so small that it's no big deal on a day-to-day basis. As far as I know, NASA completely disregards this even for our nearly decade-long rover missions.

 That's pretty cool. When do we add leap seconds? Other than things like leap years or changing the time at winter/summer, I never heard of it. [deleted] Oh, awesome! I'm glad to hear that someone else had this thought as well. I've often wondered why it never popped up in any of the SF I have read.

Thanks for the recommendation! &gt;So it seems to me that all of those factors (the planet's velocity around its star, the system's movement through the galaxy, etc.) would vary widely across the universe.

Not really. The Sun only moves around the Milky Way at about 220km/s, which corresponds to a time dilation of only 0.000027%, or one extra second every six weeks. This isn't a very significant difference from our everyday perspective.

Pretty much the only way habitable planets in the Universe move *really* fast relative to each other is by the expansion of space. However, the rate of this is estimated at about 2.27\*10^(-18)Hz, which means it takes quite a large distance to correspond to a substantial difference in speed. To even get a dilation factor of one second every hour, the relative velocity would have to be 7070km/s, corresponding to a distance of about 300 million light years.

Long story short, at pretty much any distance, the time taken to travel or communicate between planets is a much bigger issue than the different rate of time passing on each planet. We're in a local group of galaxies that are orbiting about one another.  There are extended structures further out that are tied to our local group. Beyond that the Hubble constant helps to define the velocity of our local group relative to the rest of the universe.

Planets, suns and further galaxies are generally tied to the comoving frame. That frame has time moving at the same rate as our time frame. They never accelerated relative to us. They inflated away. Its acceleration not inflation that makes things have different time frames. If they are a billion light years from us and they sent a fast ship towards us just as we sent an equally fast ship towards them those two ships would meet at halfway with the same understanding of how old the universe is.

A lot will say,, "no they're in an accelerated frame". Well we see them that way in their past. Let's say we both saw something worth investigating that's 500 million light years between us. And we both built ships to investigate, and got there in about 510 million years.  From our perspective their ship would be slowing down towards that thing 500 million light years away. From our perspective we'd be speeding up. As we're in symmetrical situations the time frame would coalanse into an agreed length for the age of the universe when we met.  What if aliens looking at our planet see nothing but lava, since they are billions of years ago. And we look at them, and they are a mere nothing also, when in reality our civilizations are both highly developed. The light just has not reached us or them yet. Most likely an alien civilization that would be viewing our planet in such a way that they could discern geological or atmospheric conditions would be located within our galaxy.  In that case, the lookback time is at most tens of thousands of years not billions and they would be aware of the presence of life on the planet.  Any sufficiently intelligent civilization would be aware of evolution and expect more developed lifeforms in the present time.   [deleted] Someone else suggested that book somewhere in this mess. I'm definitely going to check it out, thanks! You are correct, but you'd also be correct if you said "Time is moving at a completely different rate for my next door neighbor." The rate that time passes changes based not only upon relative speed, but upon relative gravitational fields. More gravity = slightly slower time.  Since the gravitational field of Earth (and everything else) has variations in it, and we all spend our lives traveling through different regions of that field at different times, we all experience time at a unique rate compared to everyone else in the universe.  The differences are extremely small though, and not something that can be observed without extremely accurate instruments. On the ISS, the astronauts experience slower time than we do on Earth because they are orbiting at more than 7.5 km/s, but that is partially offset by them experiencing less gravity.
 yes and no.

technically yes but in reality the difference is so inconsequential that it is not really relevant.

that is. until you go outside of our galaxy. there are galaxies that are moving away from us faster than the speed of light. (because they are moving fast and because space itself is expanding)

for life in those places yes the time differential would be quite substantial.

but for anything in our own galaxy NOT orbiting a black hole or otherwise moving at relativistic speeds? no. no real difference to write home about even after millions of years. As a follow on, one of your ideas isn't exactly accurate of I understand you correctly.  You are correct that special relativity affects the perceived passage of time from one observer to another.  This does not mean, however, that if I were on a ship traveling at relativistic velocities that I would "perceive" time more slowly than someone at rest.  In other words, you don't induce "bullet time" in your own reference frame by being on a planet/ship with high velocity relative to Earth, lol.   However, the twin paradox does exist and you might observe time to pass at a different rate for a fast moving object.  It just doesn't mean the person at rest in their own reference frame sees a slowdown or a speedup.

TLDR: Relativity requires an observer and isn't apparent in and of itself The difference in velocity between the Earth and any other planet in the galaxy will be so small compared to the speed of light that the relativistic differences will be miniscule. They exist, and to communicate things would have to be made to deal with this issue, but it would not matter to beings such as us. I read the question completely wrong, I guess. What seemed to be the question was wether or not time is experienced the same way on another planet? My immediate reaction was based on who's measurement? Then I thought, relative to however long a day/night cycle (assuming there is one) is and how long a year is, etc. THEN I bothered to read through the comments and I just kinda died a little.  I don't understand how local events or the durations between these events would have any difference to what happens out of the local area since it would all be the same in the universal event. How I see it even if you were on a speed of light ship where 8 years would be say 100 years, the universe would still see it as 100 years even to the speed of light ship, that traveled from one event(location) to another. The ship may have traveled to another location but to the universe it still took 100 years to get there. Am I looking at this right? &gt; So it seems to me that all of those factors (the planet's velocity around its star, the system's movement through the galaxy, etc.) would vary widely across the universe. And, since that is the case, an individual standing on the surface of a planet somewhere else in the galaxy would, relative to an observer on Earth at least, experience time passing at a much different rate than we do here on Earth.

Other stars in our galaxy are moving at tens to hundreds of km/sec relative to us. That's fast by human standards, but relativistic effects aren't significant until you get close to the speed of light, 300,000 km/s. The difference would be negligible. I think what you are misunderstanding is 'relative rate of time' doesn't refer to relative movement to the universe itself, but to another frame of reference. 

So saying

&gt;we, as individuals, are moving through the universe and hence the speed at which we experience the passage of time

is incorrect. Hmmm.  But those speeds you talk about: the spin of the earth, speed of the planet around the sun and the of our galaxy through the universe... Those all have to add up to quite a good deal of speed right? 
 So then when we talk about moving through space in a rocketship, even a fast one, why would it make any significant change in the relative passage of time? It's like adding .1% to your speed right? Possible. But your science is off. your idea of general relitivity is sort of an angle of perception of Space-Time. I.E. The sun if 8min19seconds away. Andromeda is even older. Your now is Andromeda's ancient past.

However it's not impossible to find a species that finds time as a spendable asset of sorts, or even move across spacetime into the past or present while creating paradoxes.  Would it not depend on the mass of the planet (and interaction with the rest of it's solar system) in relation to that masses distortion of space-time? 
The mass of the planet distorts space-time around it creating it's unique/relative flow of time. Unless the planet was a similar mass as earth, around a similar massed star at similar distances you could end up with a similar gravity. But each system would be pretty unique and therefore space-time distortion will be unique, therefore the perception of time would be unique to them, compared to us.  Isn't it "relativity" because you have to be moving at a certain speed relative to something else?  For instance, time will pass more slowly for someone who leaves this planet and travels somewhere far away.  However, you would never know that the time was passing more slowly unless they eventually returned back here to see that people on Earth had experienced a longer period of time than whoever left. You have to have a reference point.  [Alveolar macrophages](http://en.wikipedia.org/wiki/Alveolar_macrophage) residing in the lungs will break down and destroy any debris or foreign material that is inhaled or makes it down the wrong pipe.  This is only half of the complete truth. in fact, particles that are large enough to be called "crumb" are not even able to be eaten by alveolar macrophages, let alone actually reaching the alveole. It would block parts of the bronchiole tree and not get further.

There are generally 3 different mechanisms of clearing airways and lungs, and which one is the predominant one depends on the size of the particle in question: coughing, mucociliary clearance and alveolar phagocytosis.

Coughing is probably the most well known one. Larger particles (including what would be understood by as crumbs) touch the surface of the airways and stimulate special neurons inside of the walls of the airways (the neurons are very close under the surface, directly under the so called epithelium). Once stimulated, the signal is sent to the brain where the breathing muscles are ordered to coordinate in such a way that air is very quickly and strongly expelled in short bursts; this causes a high degree of turbulence with which larger particles are sent flying outside.

Second one is mucociliary clearance. This pertains to particles (and microorganisms) that are typically microscopically small and/or so lightweight that they don't stimulate the "coughing neurons", but are large enough to not be eaten by macrophages (although there is quite a bit of crossover). The airways are covered in a thick film of mucus. Underneath the mucus are very very small hairs that rhythmically beat in the 'up' direction (towards the throat), called ~~kino~~cilia. What happens is that most particles attach to the sticky mucus layer and the mucus is transported to the throat where the mucus gets then reflectively swallowed (thus landing in the digestive tract). Another way to picture this is that the airways are covered in a large sticky "fly trap" that gets automatically cleaned and cleared via a conveyor belt principle. This is probably the most important mechanism to keep your lungs free of e.g. dust and pathogens. Depending on how exactly small we define our hypothetical crumb, this could be the dominant mechanism for our scenario as well. 

The last one is the aforementioned phagocytosis from alveolar macrophages within the lung. The particles they clear need to be small enough that they a) reach the alveoles of lungs without sticking to the mucus and b) the macrophages can actually eat them. Phagocytosis becomes also increasingly more important the higher the load of the particle is in the breathing air since the mucus is not 100% efficient in catching every particle if you are breathing a whole lot of the particles at once, for example during smoking.

EDIT: I'd like to add that the system is not perfect, and in the comment discussion below are various examples when these mechanisms fail.

EDIT 2: it's been brought to my attention that apparently the hairs in the respiratory wall lining are called cilia, not kinocilia, whereas the (motile) cilia in the inner ear are called kinocilia. This is unusual to me because at least in German literature (take a guess where I am from), kinocilia are generally called cilia with a distinct architecture of cytoskeletal filament proteins (a ring of 9 pairs of microtubules and a pair right in the middle, or 9x2+2). The cilia of the respiratory tract fulfill that criterium and therefore are commonly called kinocilia here. Does anyone have an idea where that discrepancy stems from? There was that story a little while ago of the guy who had a pea plant growing in his lung [(article).](http://www.bbc.com/news/world-us-canada-10945050)

How would something like this bypass all the defensive mechanisms you've mentioned? Awesome question. There are a few things that *may* have factored in this case (based on pathophysiology of this man's disease).

Foremost is the nature of COPD, which he has. **C**hronic **O**bstructive **P**ulmonary **D**isease is defined by "air trapping", usually through a combination of decreased elasticity of the lung tissue (emphysema) and blockage of the larger conductive airways (usually chronic bronchitismucus and cell hyperplasia). This man's COPD means he is predisposed for stuff (air, mucus, and even peas) to get caught in the air sacs. In fact, COPDers can have *huge*, single air cavities in their lungs called *bullae*. These airspaces make it really hard for your body to clear foreign material, leading to pneumonias, abscesses, and "COPD exacerbations".

Second, COPD is usually caused by smoking/smoke exposure, which also leads to fibrosis of the conductive airway tissue and loss of mucociliary clearance. It also causes loss of sensation in the airways, diminishing the cough reflex. This is why we often have to treat COPDers for aspiration pneumonias and abscesses. This man had a typical case of aspiration, especially in the setting of a recent hospitalization for an exacerbation. The only weird thing about it is that instead of chewed food/saliva/secretions (the usual stuff aspirated), he aspirated a whole pea. Peas and other legumes will start to sprout if they get wet, even if not in soil. Try putting some raw beans on a paper towel and keep it wet for 2 days to see what I mean. Same thing happened here, but in a lung. So...... um... What about a watermelon seed? Haha don't worry, watermelon seeds need dirt. It would've just stayed a seed.  Why do some need dirt to sprout, while others don't? [deleted] I'm afraid that's almost entirely incorrect...

In fact, nearly all seeds (orchids being an interesting exception to this rule) have what is called an endosperm (or tissue that serves a similar purpose) that provides a growing embryo/seedling with all the nutrients it needs to germinate and grow to to a size where it can reach light and begin photosynthesizing.  That's what the vast majority of the mass of an average seed is - analogous to the yolk sac inside a bird egg.

The fruit itself tends to serve a purpose in the *distribution* of seeds, rather than as a source of nutrients for a growing seedling.  In many cases, the fruit tissue contains germination inhibitors, compounds that stop the seeds from growing until the fruit is eaten, rotted away or destroyed.  When a seed germinates inside a fruit, it's usually a misfire, a fluke.  A typical fruit would have a *much* greater concentration of seeds than should ever be planted next to each other.  When you seed a garden, you usually sow seeds a couple inches apart and thin them even further from there.  Much closer, and the resulting plants compete with each other and end up stunted and unhealthy.  Similarly, if the goal of a fruit was to provide nutrients to the seeds it carries, all the seeds would have to grow right next to each other, leading to extremely dense patches of unhealthy seedlings.  This wouldn't be a very good strategy for spreading the species around.  One unlucky footprint, and there goes an entire generation of seedlings.

In the specific case of a pea, there isn't really even a fruit involved.  The 'fruit' of the pea plant is actually the pod the peas grow inside, not the peas themselves.  Peas and beans are actually seeds, just like the seeds of watermelons, apples, sunflowers, broccoli, wheat, (wheat berries anyone?), and nearly every other crop we grow.  They just happen to the main part of the pea plant that we eat, snow peas and pea shoots notwithstanding.

Most seeds do not actually need dirt or soil per se to germinate.  What they do require is the right combination of moisture, temperature, gas exchange and light to stimulate germination. (This is, of course, a gross oversimplification of the number of potential factors involved in germination, from local mineral content, seasonal temperature cycles, to smoke exposure, fungal breakdown of the seed coat, to the presence of neighboring plant species, to name a few.) For some plants, light level doesn't matter.  Peas and other legumes are often like this - they'll germinate anywhere, with water and oxygen.  Others, like poppies, actually require sunlight in order to germinate.  I can't speak well to the specific case of the watermelon, but horrifyingly enough, I can't think of any specific reason why it *couldn't* germinate inside a lung under the right conditions. It doesn't need light to germinate and isn't inhibited from germinating by the high temperatures inside the body like, say, a lettuce seed, would be.

Now the upshot to this is that cases like this are *extremely rare*, but please do feel free to continue worrying about watermelon seeds in the lungs. You might also want to keep on the look out for earwigs while you're at it.... 

Edit: Fixing late night typos. So, what about orchids, then?
 That's not true. Most fruits are there to entice animals to eat them and then expel the seeds far away from the plant after digestion. Germination doesn't require nutrients. It only requires moisture, oxygen, specific temperatures or light/darkness. Why can you put pretty much any seed in a wet paper towel and it will sprout? Or can you not do this with all seeds? [deleted] Sorry I just had to come and tell you what a great people you all are.  People being so kind and informative,  is a big part of what  keeps me loving this reddit community.  Thank you for sharing your knowledge with us!  [deleted] This is actually a good thing to discuss, as I have had patients ask me numerous times before.

Once you stop smoking, your lung function declines at *around* the same rate as someone your age that hasn't smoked. The problem is that your lungs are damaged already. Think of it like scooping water from a bucket. Everybody scoops water (good lung function) from the bucket (our lungs) at a mostly constant rate through time. Father time is a cruel bastard that way. If you smoke or have some other means of lung damage, it's like you have a hole poked in the bottom of your bucket. The water drains from the bottom while you scoop from the top.

Quitting tobacco plugs your bucket's leak, but you keep scooping from the top because time marches on. Your buddy who never smoked scoops along side you, but has more water because his bucket never had a hole in the bottom.

So quitting is always good, but unfortunately you can never refill your bucket. Our bodies just don't repair themselves that well.

[Here's a graph showing what I describe.](http://www.bmj.com/content/bmj/336/7644/598/F1.large.jpg) from:

&gt;Parkes G, Greenhalgh T, Griffin M, Dent R. Effect on smoking quit rate of telling patients their lung age: the Step2quit randomised controlled trial. BMJ. 2008 Mar 15;336(7644):598-600.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] COPD is what Leonard Nimoy died of :(  Cool! Thanks for the answer. Good to know I'm not in immediate danger of having a pea/legume start growing in my lung!! [deleted] [deleted] [deleted] I have another question: What happens with blood? My question goes in the sense that since it's a liquid and I believe the first two mechanisms  would have a minor impact in preventing the blood from reaching the alveoli and the last mechanism seems worthless since the macrophages will not recognize most of the blood as a threat (If they would it wouldn't make sense would it?), the blood would end up having an impact (good or bad) in your lungs and there is little to nothing that could stop it. And vomitus?  So many people die in bed after inhaling their own vomit.  8 hours of top hospital care didn't save an elderly close relation.  Does it start digesting the bits that matter?  What best can a non-expert first responder (me) do, apart from recovery position, to improve chances? [deleted] [deleted] ^^ This is a good answer.

Thanks for expanding. &gt; Underneath the mucus are very very small hairs that rhythmically beat in the 'up' direction (towards the throat)

Only in the conductive airways. If something is small enough to make it to the tertiary bronchioles without getting stuck along the way, the ciliated cells of the respiratory epithelium give way to non-ciliated Clara cells, which will eventually give way to pneumocytes involved in gas exchange. Distal to cilia transition it's phagocytosis by a resident macrophage. The airways at this point are quite narrow (&lt; 1mm)

[Bonus picture of cilia](http://i.imgur.com/DBuqDzP.png)! From (Wheater's functional histology)

edited to clarify terminology. I'm nitpicking here, but I just want to point out that we call the ciliated parts with goblet cells "respiratory epithelium," and that ends when the conducting portion ends and the respiratory portion begins. So the epithelium of the respiratory portion is not called "respiratory epithelium," which I think we can agree is really dumb.  &gt; I'm nitpicking here, but I just want to point out that we call the ciliated parts with goblet cells "respiratory epithelium," and that ends when the conducting portion ends and the respiratory portion begins.

You're the best kind of correct, as this is even spelled out in my reference from which I pulled the pic. Correcting my comment now. Thanks for the tip. Of course. I just started pulmonary Phys this week and I really appreciated your explanation about how COPD could lead to the pea plant in the lung. Thanks for all the info! I've always wondered what cilia in the lungs really look like! In the description of the photo,  it mentions the cilia cells are vulnerable to smoke,  etc. Any idea what the replenishment rate would be for cilia destroyed by something such as smoking?  Last time I looked it was about thought to take around ten years to clear squamous metaplasia (the change from ciliated to flat epithelia) following withdrawal of the stimulus, but that's only a ballpark figure and doesn't take into account severity of damage. It also doesn't include clearing the mutations that have been caused, those can hang around even if your airways look phenotypically improved.
 While the above is worth the read:

**TLDR;**

1) Coughing up large crumbs

2) Lung mucus that naturally works crumbs up and out of the lungs or 

3) ~~White blood~~ Lung immune cells that break down smaller particles

edit: A *macrophage* is broadly defined as [a type of white blood cell](http://en.wikipedia.org/wiki/Macrophage) but I'd take GrafKarpador's word for it. little nitpick, but alveolar macrophages aren't really traditional white blood cells though. They're immune cells descending from monocytes from the blood, but they're pretty much consistently in the lung and don't go back into the system. I'd rather go with lung immune cells or something similar, but thanks for the summation. For those of us who are easily lost in big words, thank you. To your edit: yeah, normal macrophages that frequent other tissues usually go back into the blood, but alveolar macrophages don't really apart from frequenting back and forth between lung tissue and lymph nodes. They're fairly specialized in that sense. Just to add some numbers to this, in general particles 10-15 micrometers get trapped in the upper respiratory tract so they never make it to the bronchi or anything, particles 2.5-10 micrometers get swept up by mucociliary clearance, and particles less than 2 micrometers are engulfed by alveolar macrophages. /u/changetip 1 Dollar Thanks for the excellent explanation  Is asbestos too big for macrophages to handle or somehow impervious to the kinocilia? Asbestos fibers are very fine and surpass the mucociliary apparatus. The ones that become REALLY hazardous are small enough to get into the alveoles and small enough for the macrophages to attempt phagocytosis, but too long and needle thin that the macrophages can't sufficiently engulf the fibers (called frustrated phagocytosis). There is a certain size for asbestos fibers sometimes called the WHO fiber, I forgot the dimensions though [EDIT: or at least that's what they're called in my language, apparently after a quick bit of googling it seems to me that they're not refered to as such in the English literature, for whatever reason]. Anyway, macrophages pattially eat up the fiber, but can't break it down. The macrophages still try to engulf it, and as long as they're unsuccessful (read: forever after exposition), they secrete cytokines, chemokines and other inflammatory related immune substances. The chronical inflammation stimulates the lung tissue to increase its content of connective tissue as a protective measure, and the person develops asbestos related lung fibrosis. Additionally, the inflammation in conjunction with direct damage of the fibers to the lung epithelium and its genomes (they kind of mechanically pierce the cells) leads to the formation of lung carcinoma.

EDIT: I shouldn't say they surpass the mucociliary apparatus, that's unreasonable. below a certain exposition threshold (that is set very low), asbestos is unlikely to cause damage, and at least some of it gets transported by the cilia. However, they're small enough to reach the alveoles and once they're in there, they stay there for good (the respiratory portion of the airways/lungs doesn't have any cilia or glands to produce mucus).

EDIT2: corrected a bit on the mechanism of pathogenesis &gt; There is a certain size for asbestos fibers sometimes called the WHO fiber, I forgot the dimensions though [EDIT: or at least that's what they're called in my language, apparently after a quick bit of googling it seems to me that they're not refered to as such in the English literature, for whatever reason]. Anyway, macrophages eat up the fiber, but can't break it down.

If I have it right, [the CDC says](http://www.atsdr.cdc.gov/csem/csem.asp?csem=29&amp;po=9) this consists of particles over 15 microns in dimension.

&gt;With increasing particle dimension greater than about 15 microns, phagocytosis by macrophages becomes increasingly ineffective. The inability of macrophages to engulf such particles results in "frustrated phagocytosis" [NIOSH 2011a].  Asbestos fibres are also light and linear and tend to end up right down in the lung periphery where they're already deep in the alveoli beyond the reach of the mucociliary elevator system. They cause chronic irritation near the pleural surface, which is mesothelial, which is one reason why mesothelioma of the pleura is associated with 
asbestosis.

 So what happens if a particle is too large for mucus and alveolar and coughing wont get it out.  
Will it stay in your lungs forever? It won't reach your lungs, but be stuck in your airways. If you are unable to cough it up, you either suffer from something known as cough insufficiency (which is a result of weakening of the breathing muscles from neurodegenerative diseases such as ALS) or the object is so large and heavy that it's stuck in one of the larger branches of your airways, maybe even in the trachea. The portion of the lung that is ventilated by the branch of the airways where the object is lodged will be shut off. Also known as aspiration, this situation is actually acutely very dangerous and leaves you susceptible to suffocation and death if you don't receive immediate care. This is relatively rare in adults because their airways are fairly large and developed and a healthy adult's cough is quite forceful enough to get even fairly large objects out, but this is one of the most common causes of death for children because their airways are fairly small, their breathing muscles being relatively weaker and because of certain eating behaviors typical for the age like not thoroughly chewing and eating too fast etc. This is the best answer. Also worth noting that sometimes a person cannot clear the crumbs from their airway and this can lead to aspiration pneumonia.  Same thing if you happen to inhale a fly? if you inhale a fly, it's most likely coughing. I'd assume it's possibly for a larger particle to get stuck in there and not come out through coughing. Is that possible and if so what happens to it if it doesn't get coughed up? Depends on the size of the particle. The airways are kind of like a fractal tree - there are are generations upon generations of iterations that each get smaller. Very small microscopic particles might reach the alveoles, larger would get stuck in the respiratory bronchioles, larger in the conductive bronchioles and so on. Depending on where it gets stuck, a portion of the lung proportional to the segment of airway becomes non-ventilated.

Do note that coughing is very, very forceful and gets pretty much everything out that is not a chicken leg stuck right in your trachea (or in other words, the particles need to be below a certain weight/size to be effectively coughed out). Particles that meet that size certainly don't get very far into your airways, but if anything like that gets stuck in your throat you are in dire need of a person who remembers their first aid class and knows how a heimlich maneuver goes, otherwise you will suffer from asphygiation and die if it's large enough to obstruct large portions of your airways. I just looked up kinocilia out of curiosity, and Wikipedia describes it as part of the auditory balance system, no mention of lungs/respiration.

Is there an alternate name for this system? What about really fine particles like drywall dust? for fine particles, it depends on whether your immune system can deal with it or not and how high the exposition load is. Drywall dust, depending on the composition, is a health hazard in the sense that the contained compounds (like talc and silica) are not managable by the immune cells, which causes them to develop a chronical inflammation which will lead to remodeling of the surrounding lung tissue. Awesome answer, thank you. I'm sorry to be picky, but it isn't Kinocilia that move the mucous up. Kinocilia are the cilia in the cochlea/vestibules that are responsible for their activation:

http://en.wikipedia.org/wiki/Kinocilium This is a really strange occurence! In German literature (I am German) the cilia of the respiratory epithelium are distinctly called kinocilia; kinocilia are generally defined to be cilia with a microtubuli architecture of 9x2+2, which the cilia of the respiratory epithelium do have. I don't think we even have a different name for the kinocilia of the inner ear (other than stereocilia, but those aren't real cilia, right). I'll edit it in accordingly, thanks. I think it may have to do the function of the cilia specified. In the mucociliary escalator, the cilia's purpose is motility of the mucus containing exogenous material. However, with kinocilia, they serve as sensory organelles which depolarize upon mechanical stress (in this case, movement of the endolymph), and signals through the vestibulocochlear nerve to understand your spatial location and translational or rotational movement. What do you mean by "actually can eat them"?  Does this indicate that there could be a pile of foreign particles sitting in our lungs that cannot be eaten, and are also too small to be cleared via the first two methods?  Does this tend to cause complications?   There is a large overlap between the particles that get caught in the mucus and the particles that can get eaten by macrophages. You usually don't encounter problems. I just meant that macrophages can't take up particles that are larger than its own cell body. There might be some chemical weapons used in warfare (or that are forbidden in the Geneva convention) that fill inside of your lungs and that can't be cleared because of their particle size and chemical interactions, but I am not knowledgable in this.

One thing to note is that macrophages can't break everything down. For example, soot and tar (from smoking and being exposed to unclean urban environments) accumulate in your lungs and get eaten by macrophages, but can't be broken down and apart from migrating to different spots of the lungs, pretty much stay there. This causes the well known phenotype of the black "smoker lung" (the soot in itself is relatively harmless, but the plethora of other chemicals and radicals in the tar and the smoke destroy your system). Another important example is industrial dusts, for example quartz dusts (mostly industries dealing with sand and glass) and asbestos fiber dust, which accumulate in the lungs, get incompletely eaten by macrophages and cause chronical inflammation leading to severe lung diseases. Are there any weak spots in the system? Some size of particle that can make it through the mucus but not get eaten by the macrophages?  The human body really has thought of everything. Thanks for the great answer! [deleted] [deleted] [deleted] Cilia is just any kind of cell hair. First example that comes to my mind is unicellular algae which use cilia for mobility &gt; The last one is the aforementioned phagocytosis from alveolar macrophages within the lung. The particles they clear need to be small enough that they a) reach the alveoles of lungs without sticking to the mucus and b) the macrophages can actually eat them.

When you get particles which are small enough to reach the alveoli but of a material which the macrophages can not digest, the macrophages signal fibroblasts to "wall off" the foreign particle with scar tissue. This is a very effective measure, and you can live a long life with a lot of harmful junk in your lungs with no ill effects, because the harmful stuff has been sealed up and locked down. However, if you inhale a tremendous quantity of this sort of particle, then the scar tissue buildup will become so massive that it interferes with lung function. This condition is generally called pulmonary fibrosis, and it's what asbestosis and black lung are.  There's a lot of back and forth on the term cilia/cilium, and I for one don't like it at all. An unambiguous term for the (9*2)+2 organelle you speak of that my old boss Lynn Margulis used to use is undulipodia/undulipodium. For some reason, it hasn't really caught on :P Do the same processes work for small amounts of liquids? [deleted] sorry! I am absolutely not allowed to give medical advice here. You should go see and get examined by a local medical professional, probably your family doctor or a GP. I apologize, I didn't mean to ask for specific medical advice, I was just curious whether mucus that causes coughing has already "done its job" or not Not a physician.  Just practical advice.

Don't see how prematurely clearing the lungs would be bad.  However, if there's also lung inflammation along with the mucus buildup, and it requires a lot of force to expel the mucus, you could end up inflaming your lungs more.  From my experience, there's usually an uncomfortable component to these things driven just by constant coughing/lung clearing. Clearly just another one of the body's extremely simplistic systems magically brought into existence by evolution.   So that sunflower seed I inhaled a few years ago isn't growing in there? :( Unfortunately no, but that sounds like a fantastic Banksy portrait: an Alien-esque chestburster that's actually a sunflower. No, sorry. What about that tiny bit of pool water?

That mosquito? 

Concrete dust? Is this why I sometimes have phlegm coughs after a meal or is that allergic? Some foods are mucus-forming anyway. Any kind of colloid emulsion, like milk, mayonnaise, or gravy, for example. I've often wondered that and now I know, thank you.  what about metal or wood? Hi, this is actually something I know about, I'm a speech and swallowing therapist. I work with patients who have trouble swallowing.

If you inhale food or liquid particles into your airway ("aspiration"), your body will respond with reflexes to clear the airway, i.e., you'll cough. Coughing causes highly pressurized air to push through your vocal cords and upper airway. Then, after you cough, you'll reflexively swallow, which brings those particles down to your esophagus where they belong.  (Try it: touch the front of your throat and cough. You'll notice that you probably swallow right after you cough).

If the particles aren't coughed up and swallowed the right way, two things could happen:

1. You could choke. If the particles are big enough to occlude your airway, you can't building up a strong enough cough clear the airway. This is why choking victims don't make any noise (no air going through vocal cords = no talking, no coughing) they just silently clutch their necks.

2. The particles could descend into your airway, pulled by gravity. There are cilia lining your airway which will try to move the particles up and out. And your immune system will attack the particles, too. But if food/liquid particles descend far enough into your lungs, you could end up with a gnarly case of aspiration pneumonia. Basically, the particles cause an infection and your lungs fill with fluid to fight the infection, but then the fluid prevents you from breathing good.

TL;DR no, you do not have crumbs in your lungs. It's not true that choking victims make no noise.

I used to have attacks of paroxysmal nocturnal laryngospasm.
Basically I had sleep apnea plus gastric reflux. 

Sometimes when I was asleep, taking those huge gasp breaths, and there was some stomach acid near the upper airway, some of that acid would get swept up in the gasp and land on my larynx, which reflexly closed - air-tight!

I'd suddenly wake up completely unable to take a breath. I'd be on hands and knees, making super-strong breathing efforts.

But the air just went into my stomach, making horrible raspy gurgling sounds, even though I was choking.

After 2-3 minutes of zero air intake, the blood CO2 built up to where it reflexly caused the larynx to open up and I could breathe again, and start belching the air from my stomach.

Finally got a CPAP machine, and it hasn't happened since. It also relieved the reflux, probably because of the increased pressure in the thorax. that honestly sounds so terrifying, i'm sorry you ever went through that. that's a different sort of situation than what he/she was referring to, he/she was talking about large food particles blocking the passage, not liquid causing your larynx to close. He/she should have been more specific when saying that. While food particles is the most common form of choking (thus him being able to say what he said) it is not the only type and next time he/she should clearly say which situation he is referring to. Oh man, that sounds awful and terrifying and I'm sorry you've had to go through that! I'm glad the CPAP is working. I hadn't heard of your condition before, so thanks for brining it to my attention. I didn't realize people had sleep apnea at the level of their vocal cords (I had always assumed it was the soft tissues of the upper airway, pharynx, velum, etc) that were falling inwards due to decreased muscle tone. I hadn't heard of the vocal cords spasming!

It's interesting (terrifying) that your vocal cords spasm closed, but then don't reflexively open back up for the cough part of the reflex. Has any doctor been able to explain why that is? I might go do some more research.

Also, I hope you're getting the GERD under control. Even with the CPAP, make sure you sleep with the head of your bed elevated. and check in with your GI. A lot of folks still has silent aspiration with GERD because they sleep so soundly they don't feel the reflux coming up. Hi fellow SLP! I also am an SLP that works in acute care. Just wanted to add that it's not the actual aspirated food or drink that causes the pneumomia- it's the bacteria-tainted oropharyngeal secretions that are aspirated along with the food/drink. Keep your mouths clean, people! This is true for the most part. I preach the oral hygiene gospel. But I've heard of people aspirating whole pieces of food, too. Someone in the comments above mentioned someone aspirating an entire pea, which proceeded to sprout in the person's lungs. Surely the immune system would try to attack these particles? Nursing student who just covered the digestive and respiratory systems in the last week here. Just chiming in to vouch for what redrightreturning said. Spot on. [deleted] Acute medical speech pathologist here. Short version, you could get aspiration pneumonia, and if you're old or ill enough, potentially die. Part of my job in a hospital is to help stop mostly old people and patients with neurological damage from stroke, traumatic brain injury, or degenerative neurological diseases from aspirating their food or drinks and potentially getting aspiration pneumonia.  [deleted] [deleted] What is the difference between the combined MMR vaccine and getting the three separately?

Why aren't all vaccines (DTAP, MMR, HPV, etc) combined into one? In terms of your immune system, there's little difference. However, the combined vaccines allow you to be vaccinated for multiple things with one needle stick and (potentially) reduces the number of times a patient needs to be seen. [Here's on old but relevant explanation from the CDC \(see pg. 2\).](http://www.cdc.gov/mmwr/PDF/rr/rr4805.pdf) So why not combine more?  Would it be too hard on the immune system? There's the issue of scheduling. You would only want to combine vaccines that are supposed to be administered at the same ages and with the same number of doses. You can see [That the overall scheduling is highly complex and there's not many vaccines where all doses are administered at the same times](http://www.cdc.gov/vaccines/schedules/downloads/child/0-18yrs-child-combined-schedule.pdf) There is also a logistical reason why more aren't combined; any new combination vaccine would be required by many health agencies to undergo new rounds of clinical trials and testing for safety and efficacy. These trials are very expensive; it doesn't make a lot of sense for a manufacturer if they already have approved, safe vaccines in production. This so much.  I do a lot of work on these tests, and it is crazy that you have to prove that Vaccine X and Vaccine Y work if you inject them at the same time... then repeat the study again multiple times in multiple countries since none of the countries like to believe the other ones (or because of genetic differences, take your pick). [deleted] Not only that you get blamed but the damage could be catastrophic like a nationwide epidemic. 

If there is something to be over caution about is health stuff, specially when it's nationwide [deleted] But when hasty introduction of the drug could, say, *cause* HIV or Ebola*, I'd rather wait.

^(*Or HIV- or Ebola-like symptoms, they might not actually cause the virus itself.)

 There have also been cases where anti-HIV drugs have been pushed to market without enough testing. See the case of ritonavir being pulled from shelves in the late 90s because it would spontaneously become inactive. There is also a pharmaceutical-technological reason: Not every vaccine needs the same adjuvants, and some may be incompatible with others or the vaccines themselves might be incompatible. This would have to be tested for each component individually or the whole list of ingredients had to be adapted, which is quite an effort (and probably not worth it money-wise, for the company). Not to mention, the vaccines might need separate preparation and different preservation conditions.  Like attentuated vaccines being combined together, recombinant vaccines being combined together, or one needing refrigeration while another doesn't. The point of combining vaccines is that it allows you to vaccinate for multiple diseases with a single injection rather than 3, and anybody who has worked with kids knows why this is a good idea.

It would be great if everything could be combined into one supervaccine injection, but most vaccinations consist of a course of 2-3 injections at specific intervals.  The intervals vary depending on the vaccine, so there's really no way to put them all on one schedule. Not really related to your question, but one of the reasons Wakefield faked his study correlating vaccines to autism is because he wanted to release his own vaccine that was a single measles vax so he could profit from it.  He was also paid by lawyers so they could sue the pharma company that created the MMR vaccine. He also paid children at his son's birthday party to give blood for him to use in his study. Are there any scientifically proven negative side effects to vaccinations?  As nearly any drug, vaccines can have several different side effects and can cause allergical reactions.

http://www.cdc.gov/vaccines/vac-gen/side-effects.htm From above link, a description of one of the vaccines, for those interested in an example without wanting to read through all of them/click to another site: 

Any vaccine can cause side effects. For the most part these are minor (for example, a sore arm or low-grade fever) and go away within a few days. Listed below are vaccines licensed in the United States and side effects that have been associated with each of them. This information is copied directly from CDC's Vaccine Information Statements, which in turn are derived from the Advisory Committee on Immunization Practices (ACIP) recommendations for each vaccine.

Remember, vaccines are continually monitored for safety, and like any medication, vaccines can cause side effects. However, a decision not to immunize a child also involves risk and could put the child and others who come into contact with him or her at risk of contracting a potentially deadly disease.

**Adenovirus vaccine side-effects**

What are the risks from Adenovirus vaccine?

A vaccine, like any medicine, could cause a serious reaction. But the risk of a vaccine causing serious harm, or death, is extremely small.

**Mild Problems**

Several mild problems have been reported within 2 weeks of getting the vaccine:

* headaches, upper respiratory tract infection (about 1 person in 3)

* stuffy nose, sore throat, joint pain (about 1 person in 6)

* abdominal pain, cough, nausea (about 1 person in 7)

* diarrhea (about 1 person in 10)

* fever (about 1 person in 100)

**Severe Problems**

More serious problems have been reported by about 1 person in 100, within 6 months of vaccination. These problems included:

* blood in the urine or stool

* pneumonia

* inflammation of the stomach or intestines

**It is not clear whether these mild or serious problems were caused by the vaccine or occurred after vaccination by chance.**

As with all vaccines, adenovirus vaccine will continue to be monitored for unexpected or severe problems. 

*This information was taken directly from the [Adenovirus VIS](http://www.cdc.gov/vaccines/hcp/vis/vis-statements/adenovirus.html)*

---

**NOTE: this is one of the very many vaccines listed on the site, but a lot of at least the mild side-effects are similar.** In addition, soreness where the shot was given, loss of apetite and tiredenss are also common. Fainting or allergic reactions are some of the more common more severe problems, and are typically pretty rare (but this is why, after a vaccination, you generally have to wait 10-30 minutes to leave the dr's office. If you don't after a flu vaccine at a pharmacy, it's probably because you indicated you haven't had adverse reactions to other vaccines). Are there any data directly comparing these adverse events with placebo injection? Definitely. A quick search has a lot of them, at least for influenza vaccines, which makes sense because they're probably the most frequently searched-for.

From [this WHO information sheet, 2012](http://www.who.int/vaccine_safety/initiative/tools/Influenza_Vaccine_rates_information_sheet.pdf):

&gt; *Mild adverse events*

&gt;*Local reactions*

&gt;In placebo-controlled blinded studies, the most frequent side-effect of influenza vaccination is soreness at the vaccination site (affecting 1064% of vacinees); which lasts up to two days (Govaert et al., 1993; Margolis et al., 1990). These reactions are generally mild and transient and resolve spontaneously within two to three days and further medical attention is not required. Analysis by gender of 14 studies has revealed that females (both young and elderly) report significantly more local reactions (Beyer,
1996). Several studies have shown a greater frequency of local reactions of whole cell, adjuvanted and intradermal vaccines compared to split virus vaccine and subunit vaccines (Beyer et al., 1998). Local reactions are also more frequent with vaccines that contain a high HA antigen content compared a low those that contain a low HA antigen content. Vaccines with 180 mcg of HA antigen resulted in solicited local reactions in 36 per 100 vaccinees compared with a standard dose of 45 mcg was associated with 24 per 100 vaccinees (Falsey et al., 2009).

&gt;*Systemic reactions*

&gt;Individuals without previous exposure to the vaccine antigens, such as children, may show fever, general discomfort and muscle pain (Barry et al., 1976). These reactions occur within 612 hours of vaccination and generally persist 12 days (CDC, 1999). Fever was noted among 12 per 100 children aged 15 years, 5 per 100 aged 6-15 years (Neuzil et al., 2001). **In adults the rate of these
events is similar after TIV and placebo. (Fiore A et al 2010).**

&gt;**Among older persons and healthy young adults, placebo-controlled trials demonstrated that administration of inactivated influenza vaccine is not associated with higher rates for systemic symptoms (e.g., fever, malaise, myalgia, and headache) when compared with placebo injections (Bridges et al., 2000; Cates et al., 2008, Govaert et al., 1993; Margolis et al., 1990; Nichol et al., 1996)**. Systemic adverse events among persons aged 65 years were more frequent after vaccination with a vaccine containing a high dose of 180 mcg of HA antigen (36 per 100 vaccinees) compared with a standard dose of 45 mcg (24 per 100 vaccinees). Typically, reactions were mild and transient, resolving within 3 days in the majority of subjects. (Falsey et al., 2009).

The live influenza vaccine was also compared to placebo groups in multiple studies, and the side effects were not apparent in the control group (it's further down in the article). &gt; at least for influenza vaccines

Influenza also has a [special clinical process](http://download.thelancet.com/flatcontentassets/H1N1-flu/vaccination/vaccination-37.pdf) with rolling studies as it has to be updated every year so it gets studied a great deal more, even the 4 year expedited process wouldn't work.

The process for all vaccines does involve placebo groups and the incidence of side-effects is checked across groups, its how safety is demonstrated. To add on to everyone else replying, the government has set up the [Vaccine Adverse Event Reporting System](https://vaers.hhs.gov/index), or VAERS, to compile any adverse effect from vaccinations.  This data is made public as it is compiled.  It includes a large amount of information on the patient.  Anyone who receives a vaccine can fill out a VAERS form and submit it if they see any side effects.  This ranges from minor swelling to more acute events. Just as a note, the VAERS system is unrestricted in terms of input - anyone can submit reports.  Some of the reports cannot later be verified.  Also, according to a [CDC-FDA report](http://www.cdc.gov/vaccinesafety/Vaccines/HPV/jama.html) published in the Journal of the AMA:
  
    "The 32 death reports [from the HPV vaccine] were reviewed and there was no common
    pattern to the deaths that would suggest they were caused by the vaccine. In cases
    where there was an autopsy, death certificate, or medical records, the cause of death
    could be explained by factors other than the vaccine. Some causes of death determined
    to date include diabetes, viral illness, illicit drug use, and heart failure."
    (from summary)
  
...meaning that if you receive a vaccine, and get hit by a bus on the following day, that may be reportable to VAERS. &gt;if you receive a vaccine, and get hit by a bus on the following day, that may be reportable to VAERS.

Which is great, because then they can do followup reviews, like they did, to determine if buses are attracted to vaccinated people. Or more realistically, If being hit by busses soon after the vaccination ends up being a trend somehow, then they could try and see if the vaccine causes a loss of coordination or absentmindedness or something. And in practice, most people wouldn't report bus accidents in relation to vaccination anyway, so if we took the reports that seriously, we'd probably get the impression that vaccines reduce your risk of getting hit by a bus. One possible risk is that we are increasing the numbers of Th1 cells (which are usually in balance with TH2). There are currently no vaccines that exploit cell mediated immunity. Thus we are left increasing Th1 and reducing Regulatory T c ells (FoxP3/CD4/CD25). This is by no means conclusive and an interesting area of research, but it is possible this is leaving us more susceptible to autoimmune diseases. 

That is not to say that the benefits aren't worth this risk-- but it is something to consider as we continue to develop new vaccines.  In an IAMA with a professor of immunology who specializes in vaccines, [she notes](http://www.reddit.com/r/IAmA/comments/231pia/hi_reddit_im_dr_ellen_vitetta_biomedical/cgsq5ex) there is some interest in whether the adjuvants found in vaccines could facilitate sensitization, resulting in diseases of molecular mimicry.

This remains theoretical. I have an ongoing disagreement with my girlfriend regarding vaccines. She's very suspicious of them, not because of the supposed autism link, but because her uncle contracted polio a short time after being vaccinated for it. She believes he got it from the vaccine. 

What could you surmise really happened? It's a tough one to argue because of course the facts are, he had the vaccine, he got polio. There was a chance ([1/750,000](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3147355/)) of contracting "vaccine-associated paralytic poliomyelitis (VAPP)" from the live, oral form of the polio vaccine. When polio was rampant, the risk of contracting the disease "out in the wild" was considered worse than than the risk of contracting it from the vaccine. Today, only inactive, injected polio vaccines are used in the US (the oral form is still used in other countries). [Source](http://www.cdc.gov/vaccines/vpd-vac/polio/)

Additionally, it's possible to contract the disease just prior to vaccination or before the vaccine is effective. Polio can incubate for about a month before symptoms show, and multiple doses of the polio vaccine are needed to confer immunity. [Source](http://www.immunize.org/catg.d/p4215.pdf) There's also a small percentage of cases where the immune system doesn't respond to the vaccine, so the person is not immune after receiving it, and they can still catch the diseases.  This is one of the reasons herd immunity is important, the people who can't be vaccinated are protected by the fact that the people around them are not carriers. Other reasons why herd immunity is important:

* Some people cannot receive vaccines for medical reasons. They are protected by herd immunity - if they never come in contact with the disease, they can never contract it.
* The existence of herd immunity enables doctors to perform conservative medicine. A personal example: I had a pretty bad adverse reaction to the MMR vaccine as an infant. My pediatrician recommend to my mother that I not receive further courses. I would likely not be immune to those infections, but I would be protected by herd immunity. Sure enough, I had a titre later in life, and was negative for measles and mumps antibodies, though was positive for rubella antibodies. Perhaps today the pediatrician may have been tempted to recommend a potentially dangerous second course?
* Vaccines are constantly developed, and prompt, widespread deployment of new vaccines in children helps to prevent the spread of the infections among unvaccinated adults. Chickenpox is a good example. The vaccine against varicella zoster, the virus that causes chickenpox and shingles, only came to market in 1990. There are millions of adults who grew up before the vaccine was available, did not have chickenpox as a child, and as a result are susceptible to varicella zoster infection (which tends to cause both worse symptoms and increased incidence of serious complications in adults, especially pregnant women and their developing fetuses - the concern is serious enough that the CDC recommends that pregnant women who may have been exposed to varicella seek medical attention). However, we have nearly eliminated one of the main reservoirs of varicella - schoolchildren - and therefore initial varicella infections in the United States have decreased by 90% since 1990.
* We can *eliminate* these diseases! Measles *should* have been eliminated in the US and Europe by now - it was *so close* to being eliminated before Jenny McCarthy flapped her idiotic tongue in front of lots of cameras. Rubella has been eliminated in the Americas, but imported cases continue; in 20 years, when we have a bunch of unvaccinated mothers, will we see a spike in congenital rubella syndrome - a terrible disease that inflicts hearing loss, eye problems, and heart disease on newborns? Measles, mumps and rubella are all exclusive to humans; unlike, say, influenza, which infects birds and mammals, they don't have any reservoirs in the natural world. It's well within our power to be rid of them forever. [deleted] If you get the inactivated shot and then, after some time, take the live oral vaccine, would you get the best of both worlds? [Here's a nice simple explanation](http://missinglink.ucsf.edu/lm/immunology_module/prologue/objectives/obj08.html) of how it takes time for the body to develop an immunity after receiving a vaccination. It's an unfortunate consequence of the mechanism that it does take some time. If your girlfriend's uncle was exposed to polio before the immune response had completed, he'd have been just as likely to contract polio as he was before receiving the inoculation.

And as mentioned by /u/Wisery, there is an incubation period before symptoms show up. It could have been that the vaccine was received too late and the disease was already present. [That's actually possible](http://en.wikipedia.org/wiki/Polio_vaccine#Vaccine-induced_polio), assuming it was the oral polio vaccine. It's no longer used in the US, for just that reason. It is still used in the field in developing nations due to its stability and ease of transportation.

Edit: fix link to use some reliable information. In addition to possibly acquiring it from the oral vaccine, there was a very high profile case where one of the manufacturers of the vaccine, Cutter Labs, accidentally contaminated some the inactivated (injected) version with live virus. But that was soon after the vaccine was first released (1955?) and it lead to a lot more oversight and regulations of how vaccines are manufactured. How and when is the decision made as to which strains to select for the coming seasons flu vaccination campaign? Here's the response on the [CDC vaccination website](http://www.cdc.gov/flu/professionals/vaccination/virusqa.htm).

There's more info in the link, but generally, the strains are selected each year "based on which influenza vurs strains are circulating, how they are spreading, and how well current vaccine strains protect against newly identified strains". They list all the organizations that contribute to the monitoring and disseminating of information relation to influenza globally and locally. WHO makes recommendations, and in the US, the FDA then chooses which vaccine will be used. Why not make a single mega-vaccination of all known flu strains? Because the flu mutates so rapidly that there is no such thing
 as "all known flu strains" also a mega vaccine (like one with hundreds of strains) would be prohibitively expensive.  My antivirus works by identifying minor parts of a whole program. Is it theoretically possible to train my B cells to work on the same principle? If you can get it to trigger on the vast majority because it recognizes similarities between them?  That's actually what the immune system does already! There are some common markers on the surface of bacteria/viruses/parasites (and not on the surface of our own cells!) which the immune system is trained to recognize - this is called the innate or non-specific response. For example, lipopolysaccharides or LPS are found on the surface of most bacteria, and will trigger an immune response. This is how we clear most pathogens, but faced with a large number of these organisms the body may need a stronger response which will stay in our immune memory - which is where the adaptive or specific immune response comes in. While it's not exactly a "mega-vaccine", this is actually what currently happens. The flu vaccine comes in two forms, the mist and the injection. The mist and injection also consist of several varieties, with the most common being tri- and quadrivalent. This means that each vaccine actually covers three (tri-) or four (quadri-) strains of flu, in order to provide the broadest protection. On a related note, how are new flu vaccines developed and distributed every year, when it seems that all other medications take years and years for testing and approval? I am full-on pro-vac, but I've always been a bit leery of flu vaccines for this reason.  If a vaccinated person becomes infected with the live virus, can s/he still spread the disease while their immune system produces antibodies against it? In other words, if I got vaccinated for measles as a kid, and came in contact with my roommate who is sick with measles, while my body is killing off the live measles virus with antibodies, am I still spreading it around even though I show no symptoms?
EDIT: I don't know if my question is clear enough.... Are vaccinated people contagious if they encounter the real virus out in the world?  Excellent question.  It depends a lot on the disease, the type of vaccine, and how much time has passed since you were vaccinated.  

For measles, there is evidence that transmission without symptoms is possible in vaccinated populations (one example: http://www.sciencedirect.com/science/article/pii/0264410X89901990), but there's no evidence that it's a big deal for keeping a measles epidemic going.  

For polio, it depends on which vaccine you got. The oral (live attenuated) vaccine protects from infection by reducing the odds of infection on exposure ("shedding" poliovirus in stool)  to 13% compared to no vaccination, while the injected (inactivated) vaccine provides no protection from infection (http://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1002599).  Both vaccines protect you from paralysis.  The injected vaccine is safer in absolute terms for you as an individual (http://www.reddit.com/r/askscience/comments/2urird/raskscience_vaccines_megathread/cob6l6j), but the oral vaccine is better at stopping infection, and neither stops all infections.  This is why we use the injected vaccine in countries where poliovirus transmission is non-existent, but use the live vaccine in countries where poliovirus transmission is a concern.  If we use the injected vaccine in the wrong place, polio can transmit silently as happened recently in Israel (http://www.sciencemag.org/content/342/6159/679).

Last for now, even if you can get silently infected and can transmit after vaccination, infections in vaccinated people are usually smaller (less virus/bacteria produced) and last for less time. Because of this, silent infections in vaccinated people, if they occur, are usually less important to transmission.

tl;dr: Vaccinated people are usually individually-protected, but they might be able to host a silent infection, but that silent infection will probably be small and less important for transmission, but not always.  This is part of why it's important to vaccinate everyone. Thank you for such a thorough reply! A few questions. 
&gt;
1.Would you mind explaining in a little more depth why the oral polio vaccine is better in some circumstances than the injected polio vaccine, and vice-versa? 
&gt;
2.Ultimately, if I understand this correctly, it is possible to be vaccinated, temporarily infected, asymptomatic, and contagious. So, if a freshly vaccinated kid goes through a "shedding" phase, then could his nonvaccinated classmate catch the disease from him? If nonvaccinated kid caught the disease would it be really bad and cause an outbreak all over town, or would it be a lessened version of the disease since he caught it from someone else's vaccine? I'm glad you liked it!

1. We talk about immunity like it's one thing, but it's very complicated.  Vaccines train the adaptive immune system to respond, but there are lots of components to the adaptive immune system (http://en.wikipedia.org/wiki/Adaptive_immune_system), and most vaccines do not train all the parts of the system that are important to fighting off a disease.  

Poliovirus infection mostly takes place in the intestine, but it can cause paralysis when the virus travels from the intestine through the blood to the nervous system.  So, poliovirus immunity can act in 2 ways: there's local "cellular" immunity in the intestinal tissues where the infection takes root, and there's also blood-born "humoral" (like the four humours) immunity that can block the trip to the nervous system.  

The oral vaccine is a live poliovirus that's been modified so that it is very unlikely to cause paralysis (like 1 per million rare, vs 1 per hundred paralysis for wild polio infections).  Because it's a real polio infection, it replicates in your intestine, triggering the development of intestinal immunity, and it also travels into your blood and triggers blood-born immunity. The live vaccine gives you essentially the same immunity a natural infection would provide, but with much more safety.

The injected vaccine is made out of "dead" (inert, can't replicate) poliovirus protein and is given in your arm.  That treatment is really good at generating blood-born immunity, but it does very little if anything at the intestinal cells where poliovirus can get a foothold because it doesn't travel there.  So, someone with the injected vaccine has good protection from paralysis, but they are almost unvaccinated to stop infection (there are some more complicated effects I'm leaving out).

The reason different places use different vaccines comes down to "is 1 paralysis per million vaccines a big number or a small number?"  It's a small number if wild polio is still circulating in your country (Pakistan, Afghanistan, maybe still Nigeria) or in a neighboring country that can re-infect you, and so it's better to risk a few vaccine-associated paralytic cases to better prevent transmission of the much more dangerous wild polio. But, 1 per million is a big number if the risk of ever getting exposed to wild polio is much lower (like in the US or most of Europe or South America), where it's judged to not be worth the few vaccine-associated cases per year.  

It's worth pointing out that until about 20 years ago, almost every country used the oral vaccine because polio transmission risk was a serious concern everywhere. It's the success of polio vaccination that has gotten us so close to eradicating the disease that we are asking these complicated questions now.

2. It's possible *sometimes* in a couple different ways, and sometime impossible.  

First, all vaccines that are based on proteins or inactivated "dead" bugs can't transmit and so there's no worry (http://en.wikipedia.org/wiki/Inactivated_vaccine). 

Live "attenuated" vaccines (http://en.wikipedia.org/wiki/Attenuated_vaccine) can *in principle* transmit and give the neighbor kid a vaccination for free, but transmission is only common for oral polio vaccine and is unusual for all the others.  So, with the exception of oral polio vaccine, there's no worry about transmitting anything from a freshly vaccinated person to a non-vaccinated person. And, except in very rare cases (that 1 per million from earlier), transmitting the polio vaccine helps because it's like getting more people vaccinated for free.  Nobody gets sick, everyone is happy. 

Now, if someone was vaccinated a long time ago, but picks up a wild infection like we were talking about a comment ago, then they can pass it on but are usually much less likely to pass it on than if that person was never vaccinated. It's less likely because the vaccinated person is often less likely to get infected in the first place and the infection is often smaller than it would be if they weren't vaccinated.  So again, the vaccination makes it safer for everybody.

The main point of my posts here is that immunity isn't "yes or no". It's a continuum.  

On one end are things like measles vaccination (and mumps, rubella), where the protection after you get vaccinated with all required doses is excellent for decades.  These are up there with closed sewers and garbage collection as the most important public health inventions of all time.

On the other end is flu vaccine where the protection halves your odds of getting badly sick if you get the flu, and you need an update every year.  

Edit: this is why I never write on reddit. Too long! I'm not sure if this question is acceptable for this thread, but:

Are there any studies about changing people's minds about vaccines? Are there any methods known to be more effective for convincing someone to vaccinate? Does this change for fence-sitters vs adamantly anti-vaccine people? The AAP published a study on how to effectively promote vaccinations.

http://pediatrics.aappublications.org/content/early/2014/02/25/peds.2013-2365


&gt; RESULTS: None of the interventions increased parental intent to vaccinate a future child. Refuting claims of an MMR/autism link successfully reduced misperceptions that vaccines cause autism but nonetheless decreased intent to vaccinate among parents who had the least favorable vaccine attitudes. In addition, images of sick children increased expressed belief in a vaccine/autism link and a dramatic narrative about an infant in danger increased self-reported belief in serious vaccine side effects.

&gt; CONCLUSIONS: Current public health communications about vaccines may not be effective. For some parents, they may actually increase misperceptions or reduce vaccination intention. Attempts to increase concerns about communicable diseases or correct false claims about vaccines may be especially likely to be counterproductive. More study of pro-vaccine messaging is needed.

 You mean they published a study on how we don't know how to effectively promote vaccinations and more research is needed...
 Well, the study wasn't as useless as you make it out to be - they identified several flaws in the current system, and the first step in fixing that is making people aware of the problem. Which is great that the study pointed those flaws out. But wdr1 didn't make that clear with the selected quotation. Generally, when one makes a statement and cites a specific portion of the source, that cited portion should support the statement. Here, the cited portion doesn't -- instead, it supports the statement that jamdaman made. Interesting question. A great NPR article covers the psychology. 

http://www.npr.org/2011/01/09/132735944/as-the-facts-win-out-vaccinations-may-too

Basically, the anti-vaxxers are alienated and the evidence that shows that they are wrong causes them to be more and more skeptical. Similar to conspiracy theorists, they use the fear and paranoia to find issues with the facts and use that to their favor. They are convinced that the "pro-vaxxers" are propagating the fear that the money-grabbing pharma companies are using to line their pockets. Each piece of fact that comes out reinforces their theory that everyone is a sheep to big pharma. 

 Okay, how about the fence-sitters, who aren't quite "anti-vax" but they're hesitant about vaccines? [deleted] Are you referring to people who question the safety of vaccines or the people who question whether it should be mandated that everyone gets a vaccine? The former. People who are just not sure about whether vaccines are safe and worry that the anti-vax movement might have some basis in truth. [deleted] [deleted] What sorts of questions should we ask them? Does that study apply to fence-sitters too or is there a chance that scientific evidence will get through to them? All teaching is like this; people trust and remember what they figured out for themself and distrust what they were told (especially by people who take the Parent-&gt;Child transactional tone, which they almost always do). Your goal is to subtly provide 2 and 2 and wait for them to put it together.
 It is very hard for a logical person who listens to logic and reason and draws conclusions based on scientific evidence to change the mind of someone who ignores all of the above.  Yeah, so is there anything that *does* convince some of them? Appeal to emotions? Showing them videos of sick kids? As to appealing to emotions, Roald Dahl's [letter](http://www.roalddahlfans.com/articles/meas.php) to the anti-vax crowd in the 1980's recounting the tragic death of his daughter to measles in 1962 may help. Showing them videos of sick kids strengthens their anti-vaccine conviction, oddly enough ([source](http://pediatrics.aappublications.org/content/early/2014/02/25/peds.2013-2365)). 
This is a consequence of "motivated reasoning", in which challenging their beliefs is effectively attacking their being, and so they defend themselves and in doing so reinforce their beliefs. 

You cannot argue someone out of such beliefs. Reciting facts will not convince them. It must come from within; they must question their own beliefs and instilling that in someone is not easy. Peer pressure is probably the most effective - if one observes that others in their peer group share a belief contrary to their own, they are much more likely to examine that belief. The Socratic Method may be successful as well. Do you have a source for the peer thing and the Socratic method? I want to do more reading [This article](http://www.motherjones.com/politics/2011/03/denial-science-chris-mooney?page=1) has some good descriptions of motivated reasoning. I'm afraid I don't know of any better sources for how to overcome it, though. Hope this doesn't come off as annoying, but [here's something I wrote a while ago on an alt account about using the Socratic method to help convince anti-vaxxers](https://www.reddit.com/r/IWantToLearn/comments/27r44b/iwtl_how_to_make_my_mom_friend_understand_antivac/ci3lxqb). It seemed to be received well. I linked to lots of other sources that may interest you! Hope this helps. [deleted] Have there been studies that talk not just about potential side effects, but actually give odds for experiencing the possible severe side effects of childhood vaccination? 

How do we effectively judge the risks of non-vaccination compared to the risks of vaccination? Yes, this is the entire purpose for having the Vaccine Adverse Event Reporting System (VAERS).  The difficulty in studying the most severe reactions is that they are so rare, it's often hard to prove that they happened because of vaccination, or just happened around the same time by coincidence.

In order to conclusively show that a vaccine causes a serious adverse event, you would need to do a randomized controlled trial, with one group of children getting vaccines and the other group getting a placebo.  The 2 major barriers to this sort of study are that it would probably take hundreds of thousands of participants, and it's unethical to put anybody in the placebo group, because of all the risks associated with being unvaccinated. I was actually hoping for an answer that linked to some studies presenting odds. I am familiar with the [VAERS](https://vaers.hhs.gov/index), but I'm not sure we do a good job of communicating risk to the public. Where are the sources that make that easier? 

[The CDC does have information on many vaccines](http://www.cdc.gov/vaccines/vac-gen/side-effects.htm), some of which includes serious side-effects odds. For example, vaccination against Anthrax (not exactly commonly given) has less than 1 in 100,000 chance of causing serious respiratory distress. Given the general public's increasing distrust of the US federal government, are there other authoritative sources on vaccination risks, especially when compared to the risks of not being vaccinated against a certain disease? To add to the other guy's comment,  a general rule of thumb is that it takes 3000 patients in a randomized clinical trial to detect a side effect that affects 0.1% of patients and 30 000 patients for 0.01%, and so on. So it is obvious that prospective studies are not possible for rare side effects (with a minimum patient cost of about 12 000$ per patient). This means that data for rare side effects come from retroactive studies (from databases, rather than direct patient observation). This also means that there is no way of knowing before its been mass administered. In all cases, it's been judged that the risk of adverse effect is outweighed by the benefit the vaccine provides. This is in part why people don't get every vaccine unless needed (rabies for example, which is rather a higher risk vaccine, and most likely anthrax too, as a matter of fact). And as for not trusting the governments... I don't know what to say... their job is to analyse data given by industry to make their own decisions regarding public safety. Besides countless scientific data supporting the effectiveness and safety of vaccines in general, my best advice is to look at other governments recommendations since they are the ones who are in charge of public health in all countries. A great start is NICE for UK and CADTH for Canada. How are the vaccination schedules drawn up and what factors are taken into account?

Many of the parents of unvaccinated kids I have come across are not afraid of their kids getting autism so much as a "too much too soon" mentality. As a result they adopt a go-slow method and invent their own schedules out of thin air and delay some vaccines by years on the basis of research they have claimed to have read that the schedules are profit-driven. The CDC [schedules](http://www.cdc.gov/vaccines/schedules/hcp/child-adolescent.html ) are built by committees of experts.  "The recommended immunization schedules for persons age birth through 18 years and the catch-up immunization schedule have been approved by the Advisory Committee on Immunization Practices (ACIP), the American Academy of Pediatrics (AAP), the American Academy of Family Physicians (AAFP), and the American College of Obstetricians and Gynecologists (ACOG)." Ok, but what do the experts base their decisions on? What are the trade-offs? Why not deliver all the vaccines at birth? The immune system of newborns is not fully developed until around 6 months old. 

At least the part of the immune system that could develop antibodies which are the major source of protection in immunizations. Aren't these vaccination schedules primarily designed for administrative efficiency? Certainly possible that the scheduling is influenced by efficiency, but not at the expense of vaccine safety. 

FDA validation for vaccines is extensive, and it would not be scheduled as it is if there was statistically significant evidence of danger. Of course there *may* be unknown danger in an accelerated schedule, but the fact that they aren't seen in studies means that it is impossible to pick them out above random chance fluctuations (known as "background"), meaning that it is essentially an unmeasurable effect using current techniques. A related example, many people would consider radiation to be dangerous, but we do not observe any increase in background cancer rates in Denver vs say Portland, even though Denver has higher naturally occuring concentrations of radioactive isotopes in the soil  and has [more than double the ground-based background radiation of Portland](http://energy.cr.usgs.gov/radon/usagamma.gif). This doesn't mean that radiation is *safe* but at those levels the effects from increased natural soil deposits are negligible and indistinguishable from the background in other words, nobody is going to tell denvorites to move to portland for their safety. To demonstrate the opposite, there *is* a statistically significant effect (meaning we can see it above noise) on cancer rates due to radioactive fallout blanketing everything east of the Rockies from nuclear testing.

With regards to vaccines, administrative efficiency is its own form of positive. The more likely you are to have everybody do the full course, the more likely the vaccination effort will have a positive outcome  on the population. If you can safely combine multiple vaccinations in order to avoid repeat visits, this would mean fewer missed doses and therefore more efficient vaccine drives. If it reduces costs its win-win Why do European schedules digress from USA schedules in some circumstances. Do they have different information than us? 

For a quick comparison of the differences among European nations here is a [European Centre for Disease Prevention and Control website](http://ecdc.europa.eu/en/Pages/home.aspx). [deleted] [deleted] These are questions that should be directed at your doctor.  What are the facts regarding the [CDC whistleblower](http://time.com/3208886/whistleblower-claims-cdc-covered-up-data-showing-vaccine-autism-link/) incident? What did the omitted data, which some claim demonstrated increased risks of autism on African American boys, actually suggest? Some things to consider about the so-called incident:

* First, snopes.com [unambiguously judges as false](http://www.snopes.com/medical/disease/cdcwhistleblower.asp) the claim that "data suppressed by the CDC proved that the MMR vaccine produces a 340% increased risk of autism in African-American boys." The article there goes to great lengths to document how the 'whistleblower' incident is a *case of fraud being perpetrated on the public by anti-vaccine activists*, rather than a case of fraud perpetrated on the public by the government.

* The 're-analysis' study published by Brian S. Hooker claiming the increased risk of autism in African American boys *[was retracted by the journal that published it with an apology.](http://www.translationalneurodegeneration.com/content/3/1/22)* The reasoning was 'undisclosed conflicts of interest' not disclosed during the peer-review process. This puts the study in question into the incredibly tiny proportion of papers retracted for scientific misconduct (in order to contextualize this, [a recent study found that only 0.0082% of papers, less than 1 in 10,000, are retracted](http://www.pnas.org/content/109/42/17028.full), 67.4% of which are because of misconduct). 

* Taken as a whole, the evidence seems to indicate that the "CDC Whistleblower" case was one of activists intentionally misleading the public about the nature of government work on vaccine safety. A researcher's comments were taken out of context, an activist with financial conflict of interest published and was forced to retract an invalid study, and the CDC took a hit in public trust. 

edits: grammar; also, please note that the snopes.com article is analyzing the *media coverage* of the so-called whistleblower incident, while the *Proceedings of the National Academy of Sciences* and *Translational Neurodegeneration* papers and editorial statements discuss or provide context for the scientific validity of Hooker's claims. /u/dearsomething (and others) provide additional links to sources discussing the scientific and statistical errors made in Dr. Hooker's 're-analysis' of CDC data on autism and vaccination.
 There are a couple of other things to point out:

1) Autism is not quite considered a neurodegenerative disease. It is more often associated with stages of macroencephaly during early development, followed bywhat appears to bestunted neural development or excessive pruning at the tail end of the critical period. Exact neural mechanisms are still a bit unclear. However, the fact that the journal considered this paper as appropriate for review is a bit odd.


2) The statistical analysis in the Hooker article are nothing short of complete nonsense. See [here](http://blog.minitab.com/blog/adventures-in-statistics/analysis-and-reanalysis3a-the-controversy-behind-mmr-vaccinations-and-autism2c-part-1) and [especially here](http://blog.minitab.com/blog/adventures-in-statistics/analysis-and-reanalysis3a-the-controversy-behind-mmr-vaccinations-and-autism2c-part-2). The researcher's statistical method was extremely flawed.  The CDC study was looking at the overall risk of autism from vaccines and found no link.  The researcher narrowed down the overall sample into various ethnic groups and ages.  The thing is that if you do this enough times, you will eventually get a statistically significant link by mere chance.

Basically what he did is [this](http://xkcd.com/882/) with African American boys being the green jellybeans. While I find the multiple comparisons thing an important topic, that's not really what he did.


What Hooker did, statistically, was the following:


1) Select and partition the data into sub-samples wherein one sub-sample is of African American males -- which means already the findings _must_ be limited to just this slice of the demographics per analysis.

2) Did not control for birth weight where low birth weight is (i) known to associated with autism and (ii) low SES participants.


3) Used Chi-square which is an inappropriate technique for this case. All it will tell you is that _something_ in your contingency table is likely to be dependent on something else in the table. 


Which is _precisely_ what he did: sliced the data without correcting for known confounds and ran an inappropriate analysis. His chi-squares showed him that there is some dependency. In this case: it was almost certainly the confounds he did not account for.
 I hope you teach statistics somewhere because this breakdown was beautifully comprehensible. &gt;The thing is that if you do this enough times, you will eventually get a statistically significant link by mere chance.

A similar pitfall is the [look-elsewhere effect](http://en.wikipedia.org/wiki/Look-elsewhere_effect). I'm absolutely with you. This is a low-impact factor journal (the paper from Proceedings I linked to inversely correlates impact-factor with likelihood to have to retract based on misconduct), and I'm guessing that it is occasionally hard to resist publishing sensational results. 

The so-called 're-analysis' that Hooker conducted is almost completely indefensible, from what I can see. It is, more or less, the exact opposite of the Law of Large Numbers: if you re-slice and re-sample data enough, you can find a 'significant' result for almost any hypothesis if you choose your sampling size carefully enough. It reminds me of the cherry picked climate data used to dispute the accuracy of climate models.

For those unfamiliar with statistical power and sampling size, [you can read more at this page](http://www.math.uah.edu/stat/sample/LLN.html), or in any statistics textbook.

*edit: poor word choice The long and short of it is that it suggested nothing.

The anti-vaccination folks decided to interpret (and even deliberately misquoted in their complaint to the CDC) a sentence in the research proposal as saying that the researchers would analyze the data in the context of race. The research proposal merely suggested that it was one possible variable that could be studied.  To the anti-vaxxers, this was apparently scientific fraud of the worst sort.

To make matters more embarrassing for the them, the anti-vaxxers were given the raw data set and did their own analysis, coming to the conclusion that (surprise!) there *is* a link between African American boys and vaccine/autism risk. That paper was later retracted for applying incorrect statistical tests, cherry picking data subsets, and, most egregiously, analyzing the study as though it were a completely different type of study. [deleted] Is this raw data set available to the general public? I am teaching a statistics class and some students have expressed interest in looking into the statistics of vaccines. This would be great to have so I can show them how to do it properly and what the results actually show.  There are public use data available from the CDC [at this link](http://www.cdc.gov/vaccinesafety/Activities/vsd/accessing-data.html#1). You just have to email their public safety coordinator and they'll send you the raw data, analyses, and reports associated with both studies. One is of thimerosal and autism, the other is on thimerosal and neuropsychological outcomes after 7-10 years.

I believe the first data set listed is the one that Hooker sliced and diced to get his results. So I haven't read the study referenced by the supposed CDC whistleblower, but in terms of potential findings linked to autism- if such a finding did occur, it was most likely due to poor sampling than anything related to vaccine exposure. My reasons for this is that there's no plausible mechanism for the vaccine to cause autism at the biological level. Albeit we haven't completely figured out the cause of autism, given the large number of people receiving vaccinations- if a real causal link existed- it would have been found by now. The fact that autism diagnoses occur right around the age of recommended vaccinations and that we aren't that great at diagnosing it on the first place only complicates things. Additionally, many of these studies aren't carried out exclusively by the government, but by research organizations or universities. Worst case scenario is that the study does exist and that the finding was found, however- these epidemiological studies are based on the scientific method and statistics. Testing and retesting allows us to say vaccines don't cause autism because for every 1000 studies you're likely to find one or two that happen to (completely by random chance) significantly show the opposite result. 
Edit: http://www.snopes.com/medical/disease/cdcwhistleblower.asp The incident involved the re-analysis of publicly released data from a paper published in 2004 that previously found no correlation between vaccination and autism. The re-analysis suggests that the initial study was flawed because it didn't take into account that the effect of vaccines on autism might be isolated to a particular subset of the sample. After re-analysing the data they came to the conclusion that there was a link between vaccines and autism in African-American boys, particularly those vaccinated after the recommended MMR vaccination period of 17 weeks.  

The problem with this reanalysis wasn't that the sample itself was flawed, it was that the statistical analysis of said sample was inappropriate. The re-analysis didn't take into account confounding variables and divided the data into subsets so small that valid statistical conclusions would have been impossible to make.

They essentially took the data, divided it so it was African-American children vaccinated 17 months + vs the rest of the sample, and found a correlation with autism then claimed a causal link. Any scientist can see the problem with this test, as given the initial sample size the data is subdivided to a level where you're comparing a group with about 10 samples and no control for confounding variables to the rest of your sample. 

Not only was the confidence interval in there sample enormous, if you use appropriate statistical analysis you see that the real causal link is between birth weight and autism, as low birthweight was overepresented in African-American children vaccinated 17 weeks+ in this sample. This isn't exactly a revelation of a conclusion as there are already much better samples with birth weight as their primary measured variable that suggest low birthweight has a strong correlation with autism.
 In what cases has vaccinations caused harm to somebody? 

Note: I'm up to date on vaccinations and am **not** against them  There are undoubtedly some side effects from vaccination. I suggest taking a look [at the comment](http://www.reddit.com/r/askscience/comments/2urird/raskscience_vaccines_megathread/cob09xo) from /u/terpichor above. Many vaccines, such as the quadrivalent influenza vaccine (the shot) contain inactivated virus, while others, for example flumist (they spray it in your nose), contains a live attenuated version of the virus.

Back when smallpox was a thing, vaccinia virus was (and still is) used as the vaccine. It is a bit different than most vaccines in that it is well known to cause fever, swollen glands, and possibly flu-like symptoms. In about 1 in 1000 people vaccinated, a rash could occur from the virus. People have even died from smallpox vaccination in the case of [progressive vaccinia](http://cid.oxfordjournals.org/content/36/6/766.full), [eczema vaccinatum](http://en.wikipedia.org/wiki/Eczema_vaccinatum), or encephalitis (inflammation of the brain) caused by the virus. These occurrences were rare however, happening in 14-52 out of 1,000,000 people vaccinated. You can visit the [CDC's page](http://www.bt.cdc.gov/agent/smallpox/vaccination/reactions-vacc-public.asp) about the side effects of smallpox vaccination if you're interested.

In other vaccines, [allergic reactions](http://www.cdc.gov/vaccines/parents/vaccine-decision/side-effects.html) to one or more of the components may occur, albeit rarely. If you know you're allergic to a component of a vaccine, or if you have a genetic or acquired immunodeficiency, you can certainly get an exemption for medical reasons.

The truth is that vaccinations can have adverse effects, and these are generally due allergic reactions to one or more components of the vaccine. In terms of causing diseases like autism or autoimmune diseases however, there has been a significant amount of research showing that there is no correlation. The smallpox vaccination is a great example to bring up, and it's really interesting (obligatory [CDC smallpox vaccination link](http://www.bt.cdc.gov/agent/smallpox/vaccination/reactions-vacc-clinic.asp)). It's kind of... poked? onto your skin using an apparatus (TIL, called a "bifrucated needle, thanks [wikipedia](http://en.wikipedia.org/wiki/Smallpox_vaccine)). People who get the vaccine tend to get this lovely [lesions](http://www.nejm.org/na101/home/literatum/publisher/mms/journals/content/nejm/2003/nejm_2003.348.issue-5/nejmicm020924/production/images/medium/nejmicm020924_f1.gif). 

A decent number of vaccines, including the flu vaccine, include some egg. Because it's a not-unheard-of food allergy, they do have some alternatives that don't (I believe the nasal spray doesn't, but I might be wrong).

Allergic reactions can usually be treated immediately if you're at the doctor's office, or if the pharmacy has an epi-pen. 

It's important to remember that for the vast, vast majority of people, any side effects are going to be much better than contracting the disease, and vaccination is always encouraged.  Just to add on, the pharmacy will be able to treat the allergic reaction initially.  It is required that all vaccine-administering pharmacists be CPR trained and have epinephrine pens readily available in the event of a reaction. The smallpox vaccine is also interesting in that I feel the public has a generally positive opinion of it, since it "worked" and eradicated the disease. So I think a lot of people think of it as the best vaccine, whereas it actually had a lot more side effects than most (if not all) of the vaccines we still use. Concerning Herd Immunity, how does herd immunity stay established if adults do not get the booster vaccines and the duration for the aforementioned immunity has expired? Is there a study that compares the mental development of a child who is vaccinated completely vs a child whom is not vaccinated? I tried to find a study and cant seem to find anything other than "austism is not linked to vaccines", which is obviously everyone should know by now.  I don't know if such a study exists (I've never looked), but if it does not exist, I'd guess that it is due to ethical issues. To perform this kind of study, you need grant money which is basically always tied to ethics committees (makes sense). I would be surprised if any committee would let you split populations into two groups where one is not given the life saving, proven safe prophylaxes that the rest of the population is offered. In addition, even if you got it through by doing a retrospective study, it's going to be very difficult to find and statistically match the number of children you'd need to get the appropriate study size. I'm also interested in this. And to add to it if I may...in addition to mental development are there any studies that compare the long term physical development of vaccinated vs not, especially in terms of autoimmune diseases? My son hasn't been fully vaccinated (specifically MMR) due to a severe egg allergy. We've also been instructed by his doctor to not give him the flu shot, which really sucks as he also has viral asthma that requires 24/7 albuterol treatments (every 4 hours) when he does get sick. My wife and I were told by one of his doctors at Mayo Clinic that there was research being done on incubating vaccines in insects; another doctor told us that there were some vaccines on the market that were incubated in something other than egg albumen but despite numerous requests, she would/could not help us locate and administer this or provide further information.

My questions are: 

* Are there vaccines that are incubated in something other than eggs? If so, is it just research at this point or are they commercially available?
* Any suggested reading on the topic of egg allergies and vaccines? 

**edit** regarding my second question: I don't want to violate the rules of this thread and am not looking for personal medical advice, I am just wondering if there is consensus on this approach.

**edit 2** removed my second question, as it was too close to asking for personal medical advice Hello!  I also suffer from egg allergies that I have had my whole life.  I receive a flu vaccine every year and have had no adverse effects.  I have also received all other vaccines.  **NOTE:** This is not to say go get your child immunized.  Everyone with allergies can react differently.

1.  There is a flu vaccine without egg called *Flubok*.  [CDC information here.](http://www.cdc.gov/flu/protect/vaccine/qa_flublok-vaccine.htm)  

2.  The second portion of your question is more medical advice.  I suggest consulting with an Allergy and Asthma specialist physician who will be able to answer your questions.

3.  For the last part, I suggest reading over the [American Academy of Allergy Asthma and Immunology](http://www.aaaai.org/conditions-and-treatments/library/allergy-library/egg-allergy-and-the-flu-vaccine.aspx) that has some resources on allergies.  If you'd like to speak with someone about it, you can contact the [Food Allergy and Anaphylaxis Network](http://www.foodallergy.org) or FAAN.  They have been providing advice and resources for people with food allergies for many years.

Edit:  I know how hard it is to raise a child with food allergies as I was the child.  If you would like any other sources on food allergies, feel free to PM me. Thank you so much for your response! I was not aware of Flubok and we will absolutely be researching that this evening, this is an exciting prospect for us.

It's reassuring that you were able to immunize without complications, we will follow up with an Allergy and Asthma specialist for further recommendations but I understand that everyone is different and we may end up staying un-immunized. I realized after I posted my questions that the second one was falling on the side of medical advice, I suppose we are just dismayed by the inconsistent advice we have received over the years regarding his allergies (pertaining to immunizations and also more generally), so apologies there.

We are definitely familiar with FAAN, but I haven't read anything from the American Academy of Allergy Asthma and Immunology; looking forward to reading through their materials and appreciate you sharing these resources.

Again, thank you very much. :) This is a question for the social sciences / demographic perspective.

I've never seen an article or met a person who was anti-vaccine. Only seen them referred to in articles / internet things like this. How large is this movement? Where is it popular and who is it popular with? Is it growing or shrinking?  Just some anecdotal evidence but it does seem popular in some of the "[crunchy](http://www.urbandictionary.com/define.php?term=crunchy+mama)" demographics. I know Portland has some pretty high rates of unvaccinated children in their schools. 

http://www.kgw.com/story/news/health/2015/02/03/some-oregon-schools-have-high-rate-of-unvaccinated-kids/22819593/ There are lots of blogs, facebook groups and websites where they congregate. I don't really want to bring them traffic but they are quite easy to find and if you really want to read the kinds of things they say, I can provide some links. Or google things like 'vaccine truth', 'anti-vaccine groups', 'vaccines evil', etc etc.

It is hard to get real numbers here, but mostly this is tracked by counting non medical exemptions from vaccines in public schools. This isn't a true count of the number of unvaccinated out there as it excludes home schoolers, and there are some reasons to get a non medical exemption even if you vaccinated or planned to vaccinate, however it's a pretty good proxy for the relative trend. 

http://www.cnn.com/2015/02/03/health/the-unvaccinated/ How exactly does a vaccine immunize a patient against a given disease? Is this safe? The vaccine exposes the patient to a small, controlled dose of the pathogen. Sometimes the pathogen is in its natural, live, infective form, sometimes it's a dead, uninfective pathogen, and sometimes it's a digested or modified mix of pathogen parts that are uninfective. Regardless of the exact form of pathogen, the purpose of the vaccine is to expose the immune system to the pathogen in a controlled way. The patient's immune system develops an immune response to the pathogen on a small scale, ending up with antibody-producing plasma cells specific to that pathogen. With time, the antibodies fade, but the body has the opportunity to make "memory cells" that can be activated immediately the next time that pathogen is encountered. So the end result is a rapid, specific immune response to the pathogen that can usually nip a brewing infection in the bud. 

There are some potential [side effects](http://www.cdc.gov/vaccines/vac-gen/side-effects.htm) of vaccination, but overall the process is very safe. The immune system does the same thing when it encounters any pathogen; the vaccine just allows us to control the dose so you don't have to get sick to get an immune response. 

Source: Parham's The Immune System Some anti-vaccinationists talk about the mercury in many shots... While it may be a negligible amount, what is its purpose in the vaccine? The mercury was present in a compound called Thiomersal. It has the simplified chemical formula of C9H9HgNaO2S. It was used as a preservative for multi-dose vials. That meant that a single container could be used for multiple patients. Many different syringes could draw from the same vial. It kept the cost of vaccination low. The vials did not need to be refrigerated.

It's been removed from most vaccinations because of the associated (yet unfounded) fear. It is toxic, but requires a much larger dose than was found in vaccines to be of any danger. It is quickly metabolized by the body.

It is much less toxic than metallic or inorganic mercury. Just as something like Chlorine is very toxic in its molecular gaseous state but not when it is when in an ionic state as a part of NaCl, or better known as table salt. Something important to remember regarding toxic substances: Everything is toxic, the important part is the dose. &gt; The mercury was present in a compound called Thiomersal. 

Which also used to be in contact lens solution (and maybe still is). The only adverse effect I ever heard of is that some people are sensitive to it and it made their eyes red and itchy. There is a substance called thimerosal that has traditionally been used as an anti-microbial (particularly antifungal) agent in order to keep multi-dose vaccine lots safe from contamination. This substance contains mercury, as do many other compounds. [The CDC has a faq sheet about thimerosal safety and it's use in vaccines.](http://www.cdc.gov/vaccinesafety/Concerns/thimerosal/thimerosal_faqs.html)

There are really a lack of alternatives to thimerosal, so the removal from many vaccines (to appease public distrust) has resulted in far more expensive vaccine formulated for single-dose only. There are three vaccines (one flu, two childhood-delivered) that still use thimerosal due to either borderline undetectable trace quantities or the inability to manufacture flu vaccines in sufficient quantities without it. [Explained at length and quite well in the same faq sheet farther down](http://www.cdc.gov/vaccinesafety/Concerns/thimerosal/thimerosal_faqs.html#f).

The short answer as to why thimerosal is generally safe is that the mercury in the compound is not in a form shown to be harmful to humans. Repeated studies *since the 1930s* have shown thimerosol to be safe to use in human and animal vaccines as a preservative (interestingly, the reason it is included at all is because the first efforts to vaccinate children in the UK (1920s) resulted in ~1/2 of patients dying due to direct injection of staphylococcus bacteria). [The FDA has a good page with information on thimerosal](http://www.fda.gov/BiologicsBloodVaccines/SafetyAvailability/VaccineSafety/UCM096228), why it has mostly been removed (public paranoia), and why it is still included in some vaccines. It is part of the stabilising agent Thiomersal that allows vaccines to be stored for long periods of times making them cheaper and more available. Since vaccines are made of organic material they need to be preserved if not used right away.  All vaccines typically have a small amount of preservative in them.  
 They're talking about thimerosol, which has actually been discontinued in childhood vaccines.  Thimerosol is present mainly in the influenza vaccine where it acts as a preservative, but there are two important things to note about it: A) they are present in extremely low concentrations, as in much much less than you would find in many foods and B) Thimerosol isn't mercury, it's a mercury containing compound.  The form of mercury in thimerosol (ethyl-mercury) is one which can be rapidly broken down and excreted in the body. [Thiomersal (or thimerosal)](http://en.wikipedia.org/wiki/Thiomersal) is the mercury based compound that people are referring to. This was added as a preservative, as it stops bacterial and fungal growth (something you obviously don't want in something you're injecting into people).

However a small number of researchers claimed that this mercury could be causing neurodevelopmental conditions, such as autism. This has been shown to [not](http://jama.jamanetwork.com/article.aspx?articleid=197365) [be](http://ebmh.bmj.com/content/8/1/23.full) the [case](http://www.fda.gov/BiologicsBloodVaccines/SafetyAvailability/VaccineSafety/UCM096228#saf), that is thiomersal exposure through vaccination does not associate with autism.

However due to public pressure the use of this chemical is being phased out anyway. Is there any direct evidence that the Measles outbreak is due to the lack of vaccination? In other words, has the possibility of a mutation conferring resistance to vaccination been ruled out? 

I know a lot of people are quick to say "I told you so" to the anti-vaxxers, and while I support proper vaccination, I worry we are not being objective in these conclusions.  [CDC surveillance](http://www.cdc.gov/measles/cases-outbreaks.html) has confirmed that the majority of people sickened in the current outbreak were unvaccinated, which would suggest that this outbreak is a result of lowered vaccination rates as opposed to any mutation. 

Some vaccinated people may also have been sickened, though, because MMR confers immunity in [only 95-97%](http://www.cdc.gov/vaccines/vpd-vac/measles/faqs-dis-vac-risks.htm) of people, and because MMR immunity can occasionally wear off as people get older. That's why herd immunity is so important!
 I find a lot of conversations about vaccines boils down to relative risk. That is, if I give my child a vaccine, what are the chances that something life-altering will happen?

* What sources are out there that accurately calculates the relative risk of getting a vaccine vs. not getting a vaccine? 

* How do these odds stack up to other activities and choices we make in life? For example, what are the odds your child will die in a car accident or will be crippled for life because you let them play sports? 

* I've heard (but cannot source) that one child chokes to death on a hot dog every week in the USA. That's some 50 children dying each year because of hot dogs. I imagine that the number of vaccine-related deaths is much lower than 50 a year. Given this, why is there not a larger push to make hot dogs safer? 

 [deleted] In terms of serious complications, the CDC's [Recommendations of the Advisory Committee on Immunization Practices](http://www.cdc.gov/MMWR/preview/mmwrhtml/00053391.htm) has this to say:

&gt; The incubation period of measles (rubeola) averages 10-12 days from exposure to prodrome and 14 days from exposure to rash (range: 7-18 days). The disease can be severe and is most frequently complicated by diarrhea, middle ear infection, or bronchopneumonia. Encephalitis occurs in approximately one of every 1,000 reported cases; survivors of this complication often have permanent brain damage and mental retardation. Death occurs in 1-2 of every 1,000 reported measles cases in the United States. The risk for death from measles or its complications is greater for infants, young children, and adults than for older children and adolescents. The most common causes of death are pneumonia and acute encephalitis. In developing countries, measles is often more severe and the case-fatality rate can be as high as 25%.

In approximately 1 in 10,000 infected people, [subacute sclerosing panencephalitis](http://en.wikipedia.org/wiki/Subacute_sclerosing_panencephalitis) can occur, with rather high mortality.

Honestly though, if you're not spending a lot of time in areas with frequent visitors from countries in which measles remains endemic (eg. Disneyland), the risk of measles infection is rather low, for the moment at least. There is often a ["clustering of exemptions"](http://www.sciencedirect.com/science/article/pii/S0264410X02006278) in localized communities where vaccination is concerned, and this can indeed undermine [herd immunity](http://en.wikipedia.org/wiki/Herd_immunity) in those areas. This was [shown to be the case](http://pediatrics.aappublications.org/content/125/4/747.full) for a rather large outbreak in San Diego in 2008. So if you know measles has been circulating in your area, or if you happen to know the local rate of MMR exemptions is high, it may be best to avoid public areas. Overall though, it's highly unlikely your child will be exposed thanks to sufficient vaccination coverage in most areas. You often hear about the number of shots administered over the last few decades has increased. 

However, are the shots received the same as there counterparts in the past? Are we receiving a more doses now, or are they just better spread out? We're both vaccinating against more diseases than we used to and we've learned that boosters are needed periodically to keep immunity strong. The increased number of shots basically means stronger immunity to more diseases. How many companies make each vaccine?  Like, is there only one producer of each and so only one type, rather than a variety of different "brands" if you will?   What are the other ingredients in each injection, as in, the medium the pathogen is contained or preserved in?   A lot of the anti-vax hype I have heard centers on things like the mercury content of the injections (the same amount of mercury in 6 months of breast feeding injected into an 8 pound baby all at once...etc.)   As someone who won't use commercial toothpaste because of additives and sketchy fluoride sources, this is by far the scariest part of vaccinating for me.  So could they produce "green" vaccines that would pander to those of us who fear big pharmas corner cutting with cheap or poorly researched fillers?  Or are they really the best possible mediums to hold the pathogens safely while they wait to mingle with our bodies? 5 companies control about 90% of all vaccine profits. They are Sanofi, Merck, GlaxoSmithKline, Pfizer, and Novartis. For each type of vaccine there can be one maker or a few. The flu vaccine for instance will have a few different companies and the difference is usually the number of valances (quad or tri). But for much less common vaccines, like the anthrax vaccine, there is usually one company that makes it.

As for the Mercury situation, you can check out [this](http://www.cdc.gov/vaccinesafety/concerns/thimerosal/thimerosal_timeline.html) page where they talk about the thimerosal which is source of mercury. I wouldn't say this is poorly researched at all. But the mercury is a part of a molecule in thimerosal it is not the same as pure mercury. Just like how table salt isn't poisonous like chlorine and highly reactive like pure sodium. 

Things like Formaldehyde will be found in trace amounts in vaccines and people often equate this "cutting corners" however this is used to kill the virus. It is also one of the only substances that can do this while being easily filtered and centrifuged out of the serum that is eventually used as the vaccine. 

As for "green" vaccines, they are making vaccines that will cater to people who are afraid of this type of thing. The issue here is that no matter what is in there people will have a problem with something. Whether it is one of the ingredients or the fact that the viruses are genetically modified. Something will always be wrong for someone. But if you would like the list of ingredients [here](http://www.cdc.gov/vaccines/vac-gen/additives.htm) is a link to the page where it is on. 

Honestly the CDC does have most if not all of the information you are looking for.  "Thimerosal has been removed from or reduced to trace amounts in all vaccines routinely recommended for children 6 years of age and younger, with the exception of inactivated influenza vaccine."

*http://www.fda.gov/BiologicsBloodVaccines/SafetyAvailability/VaccineSafety/UCM096228*

[Here](http://www.fda.gov/BiologicsBloodVaccines/SafetyAvailability/VaccineSafety/ucm187810.htm) is information on the other ingredients in the vaccines, along with explanations for why they are there.

Aluminum isn't "corner cutting" - it's designed to increase the immune response so the vaccine will be more effective. Formaldehyde isn't "cheap", it's one of the most effective ways of damaging the bacterial/viral toxins in vaccines while still rendering them effective at inducing immunity. (And it's also present at far higher concentrations in your body naturally.)  The mercury-vaccine link that I'm aware of is through the mercury-containing preservative thimerosal / thiomersal:  http://en.wikipedia.org/wiki/Thiomersal_controversy.  Thiomersal is broken down by the body into ethylmercury, which the body can remove, and not methylmercury, which builds up over time.  The use of thiomersal in vaccines is considered safe by the CDC and FDA, and they've found no links to autism.

Regardless of that, anti-vaxers basically jumped on the "vaccines have mercury and that causes autism" as a way to rile people up.

***Here's the important part, though:***  MMR (Measles, Mumps, and Rubella), IPV (polio), and Varicella (Chickenpox) vaccines do not, and have NEVER contained thimerosal.

Source:  http://www.cdc.gov/vaccinesafety/Concerns/thimerosal/thimerosal_faqs.html#j

Anyone who's anti-vax across the board because of mercury concerns hasn't done much reading on the subject...  They're throwing baseless accusations around and generalizing it to include vaccines that don't even contain the compound they're worried about. &gt; So could they produce "green" vaccines that would pander to those of us who fear big pharmas corner cutting with cheap or poorly researched fillers?

They already do. The antivaxxers *already won* on this front; modern vaccines by and large do not use thimerosal (which is not even mercury; it contains mercury in its chemical composition but that's not the same as pure mercury).  [deleted] I've recently seen a mathematical model applet that shows infection rates with variable percentages of a population having been immunized.  The applet showed no appreciable difference in infection rates between a 75% immunized population and a 100% immunized population.  Do these seem like accurate numbers, or am I misinterpreting the data?  Second, if our voluntary immunization rates exceed the 75% mark (which they do in most cases), why is there such a large media push for mandatory vaccinations?

[edit] thanks for all the replies.  I'm at my day job at the moment.  When I get home later, I'll try to find the applet in question.  I'm familiar with herd immunity but was mostly curious about the numbers.  One person who commented on my question stated an 85% threshold, but I remember the applet showing almost no increased risk with even only a 75% rate.  My memory might be faulty, though.

[second edit] My apologies that I've been unable to find the applet in question.  You may kindly disregard my "contributions" to this topic. I can't comment on the accuracy of that model, but remember that vaccination rates are far from equally distributed across the nation with many clusters of unvaccinated children [with vaccination rates much lower than the national average.](http://pediatrics.aappublications.org/content/early/2015/01/13/peds.2014-2715) I'd be interested in seeing this applet. If it's using a random distribution of the unvaccinated population, I would say this is where the disconnect from reality is. In reality, it's clusters of non vaccinated individuals that occur, and thus that local group is at a much higher risk of both contracting the virus, and passing it.  I can weigh in on this.

When vaccine coverage is high enough, then an index case of the disease has a hard time finding someone to infect.  Its like finding a needle (a susceptible person) in a haystack of vaccinated people.  This is usually called *herd immunity*.

 Do you have a link to this mathematical model applet? Genuinely think that sounds interesting and want to see it myself, not trying to attack you. [deleted] The concept is accurate, but the numbers are going to be far more variable than the applet suggests.

There are a few factors that dictate where the top of that curve levels off, but two of the most important are:

**How quickly/easily the disease spreads.** 

This is based on infection rates and vectors and what methods are available for transmission. For example, a very infectious disease might require 90% immunization as each infected individual will present far more opportunities to find other susceptible individuals. At the same time, a disease with poor vectors (eg: Ebola) might only require 60% as its easier to suppress spreading by simple quarantine.

**The effectiveness of the vaccine.** 

While 75% of the people might be vaccinated, all vaccines have a failure rate. If that failure rate is 10%, then the 75% of vaccinations only produce 67.5% (sloppy math?) immunity. If you combine this with the percentage of the population that cannot be vaccinated (infants, immunosuppressed) then the percentage of people who need to be vaccinated to reach a certain immunity level is going to be significantly higher than just that target level. 

Doing some quick math: Assume that 85% immunity is required to stop the spread of some disease. The current vaccine in question has a 10% failure rate. 3% of the population cannot be vaccinated. I believe that works out to require about 97% of the remaining population to be vaccinated in order to reach the 85% immunity mark. For 75% that target would be better (86% vaccination) but as others note, 75% is a lot lower than the estimates I've seen for the diseases we're more concerned with now. Did the applet take into account the R0 values for various pathogens? The necessary rates of immunity for herd immunity would be vastly different between measles and influenza for example. How successful was the swine flu vaccine a few years back when it was all over the news? I feel my impression of the whole thing is very skewed. After receiving the flu and DTP vaccines this year I developed an auto immune reaction to the vaccine that is quite serious. My neurologist diagnosed it as post vaccination neuritis. 

My question is, how common are reactions like this, and am I at increased risk of this happening if I get vaccinated again next year? It would be nice to have my feet, hands, and face stop going numb and burning, so I'm quite hesitant to get vaccinated again.  I've been told that when we are exposed to an illness in nature that we weren't vaccinated to and survive it, we will gain an immunity that has a chance of being passed on to our children.  However, a vaccinated immunity doesn't share this characteristic and can't be passed on.  How accurate was this information? Acquired immunity is not heritable, unfortunately. A vaccination is essentially an artificial method of acquiring immunity, and thus it is also not heritable. The parts of immunity that are heritable (without going into extreme detail) are the genes that allow for recognition and response to a wide variety of pathogens. 

Edit: my source here is Kuby's *Immunology*, sixth edition  [deleted] Neither of the types of immunity you described can be passed on. I'm interested in the epidemiological consequences of providing vaccines for epidemics vs endemics - in particular, say that a vaccine for Ebola is rolled out soon, is it really expected that it will bring the outbreak to an end (especially as recent data shows it may be already declining), or is there more interest in preventing endemicity? Providing vaccines only during outbreak situations is called "ring vaccination." It was used for [small pox eradication](http://wwwnc.cdc.gov/eid/article/10/5/pdfs/03-0419.pdf) and [foot and mouth outbreaks](http://www.ncbi.nlm.nih.gov/pubmed/11039695). It's most effective when the pathogen is rare in the environment, and there is a small, identifiable number of people/animals who have been exposed. Logistically, it's cheaper and faster to vaccinate only the people who have been exposed than to vaccinate every individual in a population. 

In an endemic situation the disease is present in the environment/population on a permanent basis, it's much harder to keep track of who has been exposed to a disease (especially when you consider that there might be asymptomatic carriers), and there are more environmental sources of disease, so ring vaccination would be impossible. In those cases, you really have to vaccinate the entire at-risk population to control the disease. 

[This article](http://www.nature.com/drugdisc/news/articles/424602a.html) suggests that the newest version of the Ebola vaccine would be used primarily for outbreak control.  I'm not sure if this is really the right place to ask this, so forgive me if it isn't.  

When people say that vaccines will give your children autism, are they implying that a (for example) 5 year old child will develop autism as they mature because of it, opposed to saying that if you are vaccinated your future children will have autism, or is there an implication I'm missing?  People who make that claim believe that vaccines cause autism because (invariably) their child 'developed' autism shortly after getting vaccinated.

This is not in fact true: autistic children actually display typical behaviours prior to diagnosis (and even have been shown to have [different compositions of neurones in the brain before birth](http://www.nejm.org/doi/full/10.1056/NEJMoa1307491?query=featured_home&amp;)), but the schedules of vaccines tend to coincide with developments of behaviours and symptoms that are more identifiable. Thanks for doing this!

How are vaccines tested for long-term consequences? I'm specifically thinking of a time frame beyond the ten year mark.

Related to that:

Years ago at university I distinctively remember sitting down while waiting for an event to start. Over in the corner, a video was playing that documented a group of women that contracted cervical cancer from some form of medication. I believe it was a vaccinebut I could be very wrong. We're looking at the 1950s here. If this rings a bell in anyone's mind, I'd be really interested to hear the case in question. Again: I may be getting this very, *very* wrong here, but I just wanted to put the question out. 

EDIT: The drug in question is [Diethylstilbestrol (DES)](http://www.cancer.gov/cancertopics/factsheet/Risk/DES) and the name of the movie is [A Healthy Baby Girl.](https://www.youtube.com/watch?v=GkEpHRO2Fww) DES was a synthetic hormone thought to have helped prevent miscarriage and other complications of pregnancy. It is *not* a vaccine. Is it possible to make a mathematical estimation of how likely an unvaccinated individual is to get a disease given a variety of known inputs, such as its R0 / basic reproduction number, prevalence in the region, etc.,  or is it a guessing game?  If it were possible, I would find this immensely helpful in a variety of contexts.  For example, when it comes to deciding whether to vaccinate my indoor-only, elderly pets who have shown rather unpleasant reactions to certain vaccines, or when it comes to discussing the merits of measles (ludicrously contagious) vs other vaccines in humans. I do this for a living. It's possible and it's a guessing game.  

Since you know "R0", you probably know a little about the basic mathematical principles of disease modeling (http://en.wikipedia.org/wiki/Mathematical_modelling_of_infectious_disease).  The simplest formula to answer your question is

(the probability per day of getting infected if not immune) = (probability per day of infected contact transmitting to non-immune individual)*(number of infected contacts per day)

The guesswork is in both the terms on the right.  

For your pets, true guesswork if they are indoor pets is that the number of infected contacts per day is zero, and so the probability is zero, no matter what the transmission probability. I wouldn't immunize your elderly pet based on what you said unless *you* hang out with a lot of other pets even if your pets don't.

For measles, the guesswork is statistical estimation from data, and Bryan Grenfell is the best source (http://mysite.science.uottawa.ca/flutsche/PUBLICATIONS/Grenfell.pdf).  But, to be quick-and-dirty about it, the first parameter in the equation is roughly 0.9 for measles. That means there's a 90% chance per day that if you are not immune and you are in close contact with someone with measles (like a sibling), you'll get measles.  

So, maybe you're not immune and you were recently at Disneyland and waited on line for an hour with someone who had measles. Then the probability you get infected might be something like 0.9/24*1 = 0.037, so you've got a 4% chance of being infected that hour. If you're in line with 10 people over the day, that's 40%. 

But, if you're immunized, that 0.9 per infected contact per day drops to something small enough that it's not been reliably measured, and even if you do somehow catch some measles, you'll probably be asymptomatic unless it's been decades since your last booster.  So the vaccine is a really good idea.

But your vaccination-skeptic friend asks, what if I don't plan on taking my kid to Disneyland? Then, sure, as long as you never take your kid anywhere where people might have measles, then the probability of getting measles is zero and so the vaccine won't help.  However, how is your friend gonna hide the kid from all sources of measles for all time?  There are a few million measles infections globally per year, and Disneyland, the UK, China, Russia, Nigeria [etc]( http://www.who.int/immunization/monitoring_surveillance/burden/vpd/surveillance_type/active/measles_monthlydata/en/), show that measles is transmissible enough to find non-immune people wherever they are. So even if the odds of meeting someone with measles are low every day, the lifetime odds accumulate.  And anti-vaxxers hang-out together, so it only takes 1 to bump into that random stranger for the whole community to get sick. Like in Disneyland.

Edit:  the "for a living" part means the guesswork is a lot more statistically sound and the math a lot more detailed, but this is really the gist of it! If humans just stopped vaccinating cold turkey, would evolution eventually help humans get over the disease and not be susceptible after a few generations?  There has been diseases in the past that have come and gone.  Just wondering.  If this is the case, is it still possible for humans to evolve the same way with vaccines?  If not, what am I not understanding about evolution (might be wrong thread, lol)? An important thing to remember is that the infectious organisms (whether they're viruses, bacteria, fungi, or something larger) are all evolving as well. Not only that, but due to faster replication times (and certain genetic considerations) they could be considered to be evolving faster than we are. Remember that some pathogens have been infecting humans for thousands of years, and yet we've still been evolving together all of that time.

Scientists talk about the [Red Queen hypothesis](http://en.wikipedia.org/wiki/Red_Queen_hypothesis). Basically imagine a bacteria that lives in a certain animal. It might be under evolutionary pressure to get in the cells of that animal, so it evolves a protein to grab on to a certain receptor on those cells. Well, that animal is now under pressure to change that receptor so that the bug can't get in. But now the bug is under pressure to change again so that it can still get in.... and so there's this evolutionary arms race where both players are always changing, but end up in the same place.

Something that can happen is a loss of virulence throughout evolution, i.e. an infection does less damage as time goes on. One might argue that this contributes to why 'new' infections (for humans at least) like Ebola cause so much damage, because neither of us are evolved to exist cooperatively with the other - remember it doesn't help a virus if it kills off everyone it infects very quickly, as eventually everyone will be dead and there'd be no hosts left! Humans didn't vaccinate for thousands of years, and infectious disease was one of the main causes of death until the last century. That's thousands of years of evidence that humans don't "get over" diseases naturally. In fact, I'm not sure I know of any human pathogen that naturally eradicted - someone let me know if there are any. If you're thinking about something like the black plague, that's definitely still around, but it's now treatable. 

And just to totally precise, humans HAVE been crudely vaccinating against smallpox for longer than modern vaccines have been around. Jenner was testing his worker's kid with an early cowpox vaccine in the 1700s, and India might have had some variolation going on more in the B.C.s. I've not heard of other pre-Pasteur-era innoculations, though. [deleted] Let's say I am a healthy average person and I get the whooping cough vaccine every year. I don't "need" to get it. What will happen to me? 

My angle on this particular question comes from the concept of "over vaccination"; that we vaccinate for diseases that we are already immune to. My follow up question is: so what? Is getting an extra vaccine, or an extra 100 vaccines, really going to cause damage?  This is a topic of [ongoing research](http://www.ncbi.nlm.nih.gov/pubmed/10648110) that is especially pertinent to veterinary medicine because most of our pets are vaccinated every single year (or every 3 years). In the vast majority of animals, there is absolutely no negative consequence of vaccinating when the animal already has high titers against a pathogen. However, there is a possibility that the repeated irritation caused by the adjuvant the vaccine is mixed with can increase the likelihood of cancer. To my knowledge, this has only ever been proven in [cats](https://www.avma.org/KB/Resources/Reference/Pages/rbbroch.aspx). 

In response, vaccine makers have started making vaccines that don't contain adjuvant to prevent any sort of repeated irritation. Furthermore, there are ongoing studies to nail down the true efficacy of various vaccines so we can only vaccinate when our titers drop below a threshhold, which is closer to how vaccination happens normally in humans.

TLDR: You'd probably be fine, but why would you ever do that?  If you get the TDaP vaccine (Tetanus, Diphtheria, acellular Pertussis) vaccine every year, there is a chance you will develop a hypersensitivity reaction, especially if you keep getting it in the same arm.  The reason for this is that vaccination allows your body to mount a rapid, strong response to a particular antigen.  Booster shots basically work by poking the bear to keep it active.  Once you're vaccinated, repeatedly injecting more of that antigen can provoke an overreaction at the site of injection.

However... This is not a problem for somebody getting lots of different vaccines, because the immune system is being exposed to a variety of antigens, and not the same ones over and over.  Also, immunity from some vaccines (including TDaP) fades over time, so it's important to get regular boosters to keep up your immunity. Why do we have to give vaccines to babies?  could we just give them to 4-year olds?  

I get that having babies exposed for a longer period of time is dangerous, but for those that are scared of autism or other "weakening immune system" things and wouldn't get it at all.  Why not encourage them to get it once they are out of that 'critical' stage.

 Because infants and young children are most vulnerable to a lot of the diseases we vaccinate against.  For example, pertussis (whooping cough) is unpleasant to have as an adult, but it [regularly kills babies](http://www.cdc.gov/pertussis/outbreaks/trends.html).  Haemophilus influenzae B used to be a major cause of (potentially fatal) [epiglottitis](http://emedicine.medscape.com/article/763612-overview#a0156) in young children, but now it's quite rare thanks to widespread vaccination.  Rotavirus, which causes severe diarrhea, isn't a big problem in wealthy countries, but kills ~~millions~~ [hundreds of thousands](http://www.who.int/immunization/monitoring_surveillance/burden/estimates/rotavirus/en/) of children every year in areas without access to healthcare and clean water.

The other benefit to vaccinating very young children is that their immune systems are better at mounting the type of response that generates long-lasting immunity.  If you give the same vaccine to a 1 year old and a 10 year old, the 1 year old will have a much better chance of long-term immunity.

EDIT: Added some sources Thanks for a very insightful answer.

Quick followup - Shouldn't we then be pushing anti-vaxxers to get vaccinated a bit later in life.  I know as some other redditors commented, they may still resist (e.g. I'm not poisoning my child) or it may be seen as 'giving in' but if their worry really is just autism / giving it to a baby, we may be able to reach a good chunk of individuals, no? Ultimately, it's better to be vaccinated late than never.  For this reason, some pediatricians are willing to negotiate with parents if the vaccinations schedule is a big problem.  The major problem is that when the pediatrician gives in on that front, it may be seen as an admission that there is actually a risk of autism.  

Also, some vaccines are completely useless if given too late, either because the patient will not have an adequate immune response, or because these diseases are so prevalent that they will have already been exposed.  The HPV vaccine is a great example of this, and it is not given to anybody over 25 because most people at that age have already been exposed to HPV. if most vaccines remain voluntary as they currently are, then this should already be able to happen, right? I've been exposed to a ton of the conspiracy theory "facts" and unfortunately some of it has me not knowing who to trust and what information is actually factual.

Why isn't it enough for our immune systems to be able to defend against these bacterias/viruses? Can we not do something naturally to boost our immune systems to protect us?

Does getting vaccines actually create stronger viruses/bacteria because they can evolve and figure out how to get passed our defenses?

Do vaccines really come from aborted fetal/monkeys/pig cells? Also, has there been any studies to show/prove that (if they do come from aforementioned cells) it's safe for humans? Isn't there some problems with mixing DNA?

I'm sure there are many more things that I was unsure of but I can't think of anymore right now. [deleted] Thank you very much for the very informative post.  I guess I can understand the need to get vaccinations for serious/debilitating viruses but is it really important to get the flu shot? I mean, I'm not really worried about getting the flu and I haven't had the flu shot since I can remember and I think I've only gotten the flu once or twice in the last 10-15 years. [deleted] When you're a young, healthy person, you don't get the flu shot to protect yourself because it's VERY unlikely that a flu will kill you. It's an altruistic act to protect those around you for whom an influenza infection could mean a very bad death. Even if you don't have any infants, elderly or immunocompromised people in your life, think of all the door handles you touch and buses you go on. Your health IS public health. This morning on NPR, they were discussing how anti-vaxxers would be less likely to vaccinate their children if there were PSAs by scientists and doctors explaining that vaccines are not harmful and what they've heard is complete bs. 

Their reasoning was because those people would feel like the doctors and suck were apart of the conspiracy that hurts their children.

They also explained that there is a mentality of "every other child is vaccinated so why would I put my kid through the pain when they're already safe?" but because so many people think this way, a lot of kids aren't vaccinated.

What else did they talk about..... I cannot remember if they were saying that social pressure works or it's just being done. Social pressure being that parents with vaccinated kids don't invite kids that are not vaccinated to birthday parties and those parents don't hang out with parents that refuse to vaccinate their kids. 

Along with the above (social pressure) they also discussed about coerced vaccines (mandatory vaccinations for each child) helps, well i mean obviously.  It is widely argued that Vaccines are a public good, and indeed the medical research would prove that the case. 

But why should such a medical necessity be privately owned by a company, and the public be charged much more than need be, for that company's profit, rather than vaccines being a public service?
 I actually just have a question about what governs the effectiveness of the flu vaccine from year to year. I can't remember where I heard it so it is probably apocryphal, but someone said it was only about 25% effective this year. I always get mine anyways, but I still would like to know how that is determined. I'm guessing the number is calculated by the number of flu visits, but what it is really based on is the percent of flu virus variations that the vaccine protects against. If you have the actual number or where I could find that and what it means, that would be great. There are a huge number of strains of flu, and they are mutating every year. doctors predict which is most likely to be "in" this season and a vaccine is developed to combat those strains (it takes several months to make the vaccines, hence the prediction). In that period of time the virus can mutate and change, or another strain that wasn't predicted could be dominant, making the vaccine less effective. How did the idea that vaccinations can cause autism come about? Is that accurate? I thought autism is a disorder that people are born with. It's 100% inaccurate. The first person to suggest that vaccines and autism have a connection was a man named Dr. Andrew Wakefield. He was unequivocally found to have been forging his data for financial reasons, and was stripped of his license to practice medicine (so he is no longer even a doctor). He was attempting to allege that MMR vaccine had negative effects so he could market his own alternative vaccine and profit from it. Hundreds - *hundreds* - of subsequent studies and meta-analyses have found absolutely no connection between vaccines and autism. 

You might enjoy learning Wakefield's story in comic form, [here: "The Facts in the Case of Dr. Andrew Wakefield.](http://darryl-cunningham.blogspot.com/2010/05/facts-in-case-of-dr-andrew-wakefield.html)"

The majority of our current research is leading strongly toward evidence that the development of autism begins in the womb, long before any vaccinations take place. I have no doubt that the efficacy of the seasonal flu vaccine is tracked and eventually reported... does anyone have a link?  IN addition, it would be great to see a "plain language" breakdown of what the various statistics actually mean.  (e.g. what exactly does percent effective mean?  is it a comparison of flu rates among vaccinated and unvaccinated populations?  is it referring to some measure of strain specificity?) 
 I was discussing vaccination with someone and they mentioned that because vaccines contain trace peanut or egg proteins that it's possible a child develop an allergy to peanuts or egg down the line. Is this possible? I couldn't find any studies on the matter. Is it possible to get sick from a vaccine/be contagious with the disease you received the vaccine of? I heard someone who was against vaccines refer to this as "shedding" and that this warning is included in an insert with the vaccine. I don't have a medical background but I follow outbreaks for my job and am really interested in epidemiology even though a lot of it goes over my head. I was recently reading about flu epidemics. The article discussed why the Spanish flu seemed to affect young, healthy adults more than any other demographic - because it was the first time they had been exposed to an H1 flu (same thing with why Swine flu had a bad affect on young adults about 90 years later). There had been flu seasons that the elderly had been exposed to that was an H1 flu so they weren't as hard hit as the young adults who had zero immunity to it.

If I'm remembering correctly, the article explained that the H# part of a flu strain is what we are most concerned with when it comes to our immune system fighting the virus.

I know bird flu is a big concern to the CDC and WHO and they are constantly monitoring it. I believe one of the strains is an H7, which I am assuming is something we have never been exposed to, at least in the US. If this is the case, why not create vaccines around different H#s instead of focusing on trying to guess exact strains? Or, offer them in addition to the seasonal one? Get everyone in the US exposed to some form of ever H# that could possible exist over many years, even if it has very minimal protection - very minimal is better than absolutely none and millions of people being wiped out. I'm sure I'm over simplifying or not understanding something about this.

Question two - let's say an H7 strain was created into a vaccine and I got it today. How long would it offer some form of protection, for the rest of my life? (I know maximum effectiveness would be against an exact strain) As far as measles (chicken pox?): is it common to cause death? If it does not cause many deaths why is there a panic over having it as a child? 
I understand that it can be dangerous for infants. If that's the case why not vaccinate when an infant and let that be it?
I know that shingles is dangerous but how so more than measles as a child? 

Finally please help me understand: There is a large number of adults who have been vaccinated for measles but they have to get re-vaccinated on time to resist getting it? They must keep up on shots because they could contract from infected individuals? Is this why many people are angry about unvaccinated people? Simply because they must keep getting vaccines or is it truly fatal? 
Sorry I'm uneducated about this. From Oregon (not sorry about that) Anyways, everyone I talk to here just have speculations because most of us are not scared of chicken pox and most have had it.
Thank you. Thank you. Thank you for clearing this up for me. Why is MMR vaccine given after the first birthday?
Most infants born in the United States will receive passive protection against measles, mumps, and rubella in the form of antibodies from their mothers. These antibodies can destroy the vaccine virus if they are present when the vaccine is given and, thus, can cause the vaccine to be ineffective. By 12 months of age, almost all infants have lost this passive protection.

How effective is MMR vaccine?
More than 95% of the people who receive a single dose of MMR will develop immunity to all 3 viruses. A second vaccine dose gives immunity to almost all of those who did not respond to the first dose.

How serious is the disease?
Measles itself is unpleasant, but the complications are dangerous. Six to 20 percent of the people who get the disease will get an ear infection, diarrhea, or even pneumonia. One out of 1000 people with measles will develop inflammation of the brain, and about one out of 1000 will die.

[http://www.cdc.gov/vaccines/vpd-vac/measles/faqs-dis-vac-risks.htm] Why are people who vaccinate their kids worried about others not vaccinating their kids, if vaccinating their kids means they won't get the disease. Won't it just kill off all the people who chose not to vaccinate?  First, not every single person who gets vaccinated gets complete protection by the vaccine. Vaccines don't make you invincible. You can still be infected by the disease, but because your immune system is able to immediately begin fighting the disease with vaccine-induced antibodies, you usually won't have symptoms. However, there is still a chance that you won't produce enough of an immune response to protect yourself or that you'll be really unlucky and get some super pathogenic form of the disease.

Secondly, some people cannot be vaccinated for medical reasons: Babies, cancer patients, those with severe allergies, etc. These people rely on "[herd immunity](http://www.vaccines.gov/basics/protection/)" to protect themselves. 

When people who are able to be vaccinated are not vaccinated, they increase the risk of disease for everyone.   Isn't it also true that the more a disease is transmitted, the more chance it has of mutating into a strain (and potentially more dangerous) that we are not protected from by vaccinations?   Sure. Viruses mutate every time they replicate. Most of our immune responses are targeted to very specific, conserved attributes of the pathogen ([PAMPs](http://www.jleukbio.org/content/81/1/1.full)). But it's certainly possible that even those conserved areas can mutate over time. This happened recently with [polio](http://www3.uni-bonn.de/Press-releases/polio-mutated-virus-breaches-vaccine-protection) (scary!).  If an immune vaccinated host with an optimal immune response was exposed to the measles virus, would they be able to spread the virus to others in the "herd" for a period prior to fighting off the infection?  Highly unlikely. Viruses have to incubate for a variable amount of time in the host before they can be spread. For example, measles incubates about [2 weeks](http://www.cdc.gov/vaccines/pubs/pinkbook/downloads/meas.pdf) before the host becomes infective. Because a vaccinated individual is able to produce specific antibodies right away, they should clear the virus long before they become infective.

It's worth noting that that statement only applies to vaccines that prevent illness (the most common type). For some pathogens, the vaccine only makes the disease milder, less infectious, or shorter.  That is what I was wondering, how long after exposure could an immune host carry around the virus. A host could presumably carry it on their clothes etc. But you wouldn't be actively spreading it.  I ask because a common counter argument is that immune hosts diminish herd immunity simply by carrying the virus around as immune hosts. Can you help me disprove that? 
 Vaccines [aren't 100% effective](http://www.cdc.gov/measles/hcp/), plus it reduces herd immunity (furthering the disease spread), and some people cannot safely get the vaccine. [deleted] The test is not routinely done as far as I know.

I would expect the parents you reference to either not know, or to assume the efficacy is so high so as not to matter much.

Moreover, I think there's little you can do: IIRC you can give booster shots later on, but giving them shortly after the last identical vaccination they've been given does not strongly raise protection levels. In other words, if the vaccination failed to take hold, it's better to wait a bit before trying again. But again, the whole failing to take hold thing is relatively uncommon. Not everyone who receives a vaccine develops immunity against the disease.  The percentage of people who are still susceptible after vaccination varies with the vaccine.  For example, the [WHO Measles fact sheet](http://www.who.int/mediacentre/factsheets/fs286/en/) states that 15% of children who receive the vaccine fail to develop immunity with the first dose.  (This is why two doses are recommended.)

Plus not every child can receive vaccines, even if the parents wish for it.  As stated elsewhere in this thread, some people have allergic reactions to vaccines (often from egg components in them). [deleted] From: http://www.cdc.gov/vaccines/vac-gen/side-effects.htm

Anthrax section:

Mild Problems
Reactions on the arm where the shot was given:
Tenderness (about 1 person out of 2)

Redness (about 1 out of 7 men and 1 out of 3 women)

Itching (about 1 out of 50 men and 1 out of 20 women)

Lump (about 1 out of 60 men and 1 out of 16 women)

Bruise (about 1 out of 25 men and 1 out of 22 women)

Muscle aches or temporary limitation of arm movement (about 1 out of 14 men and 1 out of 10 women)

Headaches (about 1 out of 25 men and 1 out of 12 women)

Fatigue (about 1 out of 15 men, about 1 out of 8 women)

My question is, why do women get symptoms more often than men? Put simply, there are [differences in the immune system of men and women](http://www.sciencedirect.com/science/article/pii/S0896841111001260), just as there are more obvious physiological differences.

In a very general summary, women's bodies tend to have 'stronger' immune responses, hence why they have a lower incidence of many infectious diseases and a higher incidence of autoimmune conditions. 

A lot of the symptoms of vaccine-associated side-effects are immune-system mediated, so a more active anti-vaccine immune response can lead to the conditions listed above. 

This is actually how we test for if people have been infected with TB, with a [Mantoux test](http://en.wikipedia.org/wiki/Mantoux_test): you inject some of the proteins from the bacteria into the skin, and then measure how big and red the swelling gets (caused by immune cells migrating in) to infer immune activity against the bacteria. That makes perfect sense, thank you! You're welcome, it was a good question! jamimmunology has the most likely explanation for this phenomenon, but I'll add one more - sociology.

Anthrax vaccination is notoriously painful. It's considered a bad vaccine by many not because it doesn't protect (it does!), but it takes 4-5 shots over a long period of time, and each shot gets increasingly painful and causes more intense inflammation and aching.

While I think a physiological explanation is important, I do wonder if women are just more likely to tell someone about the negative effects or perhaps be more likely to notice a cosmetic outcome like a bruise, redness or a lump. Many of these responses will be self-surveys that the volunteer turns in, and are thus more subjective than an observer might be. This is just a thought, I have absolutely no data on it, but it's something I'm sure public health-minded folk have thought about.  There is one or more vaccines that have a warning label or flyer that comes with the vaccine(s) that states, as a side effect, that it may cause SIDS and/or autism. 

What's the story or reason for this? I have to assume it's a liability issue or something...but...I still find it interesting. 

Anything? i don't know of the label you mention if you could post a picture of one and link it i would be interested to see that. one medical study back in the mid-90's suggested a possible link between a preservative in vaccines which contained mercury (thimerosal) and autism but the results proved to be unreproducible, and the head doctor in question was discredited when he refused to stop proprting that to patients to stop them from immunizing. the mercury compound (thimerosal) is now considered safe although most vaccines have stopped using it anyway:

In 2004, the IOM's Immunization Safety Review Committee issued its final report, examining the hypothesis that vaccines, specifically the MMR vaccines and thimerosal containing vaccines, are causally associated with autism. In this report, the committee incorporated new epidemiological evidence from the U.S., Denmark, Sweden, and the United Kingdom, and studies of biologic mechanisms related to vaccines and autism since its report in 2001. **The committee concluded that this body of evidence favors rejection of a causal relationship between thimerosal-containing vaccines and autism, and that hypotheses generated to date concerning a biological mechanism for such causality are theoretical only.** Further, the committee stated that the benefits of vaccination are proven and the hypothesis of susceptible populations is presently speculative, and that widespread rejection of vaccines would lead to increases in incidences of serious infectious diseases like measles, whooping cough and Hib bacterial meningitis.

taken from [http://www.fda.gov/BiologicsBloodVaccines/SafetyAvailability/VaccineSafety/UCM096228]

also there is a list of vaccines at the end of that article that shows how few still use it. Ya...I know...and thanks for the detailed reply. 

I've been looking at this for a long time and still can't precisely nail down if this thimerosal matter has merit or not. 

But it's not the only thing in this vaccine debate and I can't imagine that any amount of "stuff" put directly in the bloodstream of a small child, over and over again, is going to be perfectly healthy. 

I'm learning that there are just risks and compromises on both sides of the equation. Vaccines are not perfect, but then getting the measles (etc) is not a good thing either. 

Again...thanks! &gt;I've been looking at this for a long time and still can't precisely nail down if this thimerosal matter has merit or not.

It's worth reiterating that thimerosal **is not used anymore** in vaccines except for one type of the flu vaccine. Even if thimerosal were problematic (and no study has shown that it is), it's no longer a concern.

&gt;Since 2001, with the exception of some influenza (flu) vaccines, thimerosal is not used as a preservative in routinely recommended childhood vaccines.

[Source: CDC](http://www.cdc.gov/vaccinesafety/Concerns/thimerosal/)

&gt;But it's not the only thing in this vaccine debate and I can't imagine that any amount of "stuff" put directly in the bloodstream of a small child, over and over again, is going to be perfectly healthy.

For the vast majority of people, vaccination is perfectly healthy (and much preferable to the alternative). There are several excellent comments in this thread about the side-effects of vaccines, how they're tested, how the schedules are determined, what's in vaccines, etc. Side-effects, testing and ingredients are all (for the most part) well-known and publicly available. Vaccinations are not "perfect", but no medicine or procedure is. That doesn't mean modern medicine is something to forego; it's just reality. For the vast majority of people, getting the disease will be significantly worse than getting vaccinated against the disease. Not used in the U.S. but used outside of the U.S. 

By the way, are you aware that some vaccines have a warning on them, put there by the manufacture, that states that they have side effects including SIDS and autism? If anyone is still answering questions, I have one I'm curious about. One thing spreading around lately is an image showing that there have been 0 deaths due to measles in the past 10 years in the US, but 108 deaths due to the MMR vaccine. Now obviously this is misleading as there have been 0 deaths mostly due to the vaccine, and the 108 deaths are things reported to VAERS which could all be completely coincidental. 

However what I'm curious about is, do we have a good estimate of how many deaths per year we might be experiencing currently from measles if no one vaccinated? It seems to me that even if you take the 108 number seriously, it would only be valid to compare that number to the number of deaths from measles if there was no vaccine. However I have no idea what that number would be. We know what it was before vaccination, but populations have changed and medical care has advanced since then. We also know what the death rate is currently in the US from measles, but I don't know what an estimate for yearly cases of measles would be in a completely unvaccinated population. 

Just curious, my gut feeling is that without vaccination the number of measles deaths would be MUCH higher than 10.8 per year but I don't really have any data to back that up... [Here's a relatively recent study](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1761051/) of villages in West African countries where they estimated the  a) the attack rate (% of kids who got measles) and the b) case fatality ratios (% of kids who died, among those who contracted measles). 

There are some limitations to this study (as with all studies); for example not all of the children who contracted measles had access to medical care. So maybe the death rate would have been lower. But the data clearly demonstrate that this is not a benign disease. [deleted] [deleted] [deleted] [deleted] (Reposting from the other thread)

Hi! me and some other grad students have been discussing this for the last half hour. It's likely due to some kind of colour constancy illusion, where some people are perceiving the context to be something like "lit by blueish daylight" and others are perceiving it to be something like "under yellow department store lights." In the former case, your brain will try and get the objective (if such a thing can be said) colour by subtracting out the blue as a shadow, and in the latter case it will do the same thing for the filigree by subtracting out the yellow as a reflection. This is a common illusion in psych : [See here](http://www.echalk.co.uk/amusements/OpticalIllusions/colourPerception/colourPerception.html). but it's not seen that often 'in the wild,' even though your brain does this constantly.  That makes sense,  but why do I see it as blue and golden brown?  My brain can compensate for the shadows for one color,  but not the other? It's disconcerting that brown isn't even an option.  [The actual colors in the picture itself are blue and golden brown.](http://i.imgur.com/RsvSM5N.jpg) The picture itself is quite distorted. Although swatching the color of one of the dark lace segments may give you that, the picture also isn't exactly one of very good quality - it's pretty overexposed, and I would suspect that that's what makes what might in real life be black appear as brown in the picture. Why does anyone NOT see it as blue and brown?  We're all used to colour-casts in photos, so it could just possibly be white although the shadows would be different.  But plenty of girls' stuff has 'nude' net (misnomer) around the yoke, so frills matching that would surely be the natural presumption.  Where is the evidence for any version of 'gold'. [deleted] This is a perfectly acceptable option, depending on what kind of lighting your brain interprets as being present, it's just that most people seem to side with blue/black or white/gold.  For the people that only see a white dress.  [This is close to what other people are seeing as a blue/black dress.](http://i.imgur.com/fCrrgpo.png)  I got this image by just editing the brightness and contrast of the image.  Maybe getting this view of the image will help you flip the colors.  I see a white dress most of the time.  After I stare at the altered image for a while, if I go back to the original, it looks black and blue.   I guess seeing the dress one way helps your brain correct the image in that direction. Do you have a reverse of this. I only see blue black and want to try to get it to flip. Think of the dress and everything in the foreground as under a tent (and you, the viewer of the scene, are under the tent as well). While everything else (the background--aka what's lighter/brighter--aka what's out of focus) is outside of the tent. Think about the sun at high noon, directly over the tent and bright as can be at midday (so bright that when you exit the tent, you're blinded). Now, the dress's "darkness" is really just the shadow of the tent, because shadows have a slightly bluish hue compared to direct sunlight. If you can see the dress in the bluish-hued shade of a tent, then you can see the dress as being gold and white (where the gold is what you previously saw as black, and the white is what you thought was blue).

Alternatively, bring the picture up on a screen with actual gray or black pixels around the edges. Compare the top color on the dress to the dark gray frame, and it should look gold in comparison. Then try to see the color below that (what you think is blue) as white. If you can do that, you may also see it. [Here!](http://i.imgur.com/o1rwjid.jpg) I just looked at your link for two minutes, closed it, looked at the original image and can now only see blue and black. I may or may not be having a mental break down right now... This is the only thing that has helped me see the original as anything close to blue and black. Thank you. This still looks like really dark gold and white under blue light.  [deleted] [deleted] I think that's exactly it. The question is why people land so hard on one illuminant or the other. Very different priors going around... It's not that surprising given the ambiguity of the lighting in the photograph. The photograph is back lit and people seeing gold and white are interpreting a shadow across the front of the dress due to that. However, you can also see other shadows playing off the front of the dress, which indicates it is also being lit from the front.

I think this very much gets into a question of whether it's two faces or a vase, but in this case it's harder to switch your perception once you've seen it one way because it's a complex image.

http://www.mpocares.com/wp-content/uploads/2012/05/document1.jpeg Can the lighting be made less ambiguous?  Can the picture be fixed?  I've seen many folks post versions where they crank up the blue, but that's not really fixing it.  Can the context be made clear to everyone? Not really, because the photo is pretty awful quality. But, you can take a photo of the actual dress and make it took like the ambiguous photo by adjusting the color temperature and adjusting the curves:

http://i.imgur.com/osEICeb.jpg

That was as close as I could get to matching the RGB values for the two colors. It's easy for people to notice that the color temperature is skewed yellow because you have the skin as a reference.  I actually managed to fix this for my brain by using photoshop to (somewhat poorly) counteract the problem of the original photo. It's VERY overexposed. [Here's the photo with the exposure massively reduced](http://imgur.com/feoDKum)

EDIT: For anyone who hasn't seen a "proper" photo of what the dress looks like normally, [here it is](http://www.amazon.co.uk/dp/B00SJEUCWU/ref=tsm_1_fb_lk)

EDIT2: I didn't realize just how dark my image was, and chriscosta77 did a much better job below: http://i.imgur.com/yPZiEin.jpg Try something a bit more middle ground! I edited to the correct white balance. 

http://i.imgur.com/yPZiEin.jpg Bingo. I was lazy. The issue is definitely a huge combination of exposure AND white balance. Good work. Sure.  

Now, assuming you can kind of forget what the picture looked like, this color swatch *should* look the same to everyone because taking out the lighting should remove the illusion. It should look blue. I promise I didn't manipulate the color in it in any way.

http://i.imgur.com/3oH4jw4.jpg Right, so, this is strange.  I see the original photograph as blue-black, but I see this swatch as white-yellow.  What gives? &gt; Right, so, this is strange. I see the original photograph as blue-black, but I see this swatch as white-yellow. What gives?

I saw all the images as white/gold *until* I looked at this swatch. Now every photo of the dress, or swatches containing it, appear blue and black. Still looks tan/off-white to me. Is this because I remember the photo?   It could be. It could also be monitor/display discrepancies, but my money is on you remembering the photo and it being difficult to see that pattern out of context now that you know the context. Visual illusions are difficult to break once we have them. I was stuck on Gold/White for 2 hours. I blinked my eyes quickly while moving my fingers closer and further from my eyes. This was in a dark room with only the monitor light. This allowed me to see it Black/Blue. However, I can't go back to Gold/White.

Is this just coincidence, or is this a legitimate method to break visual illusions? I think you just trained your brain to see the "right" colours. During my studies we had some lectures involving stereoscopic images (remote sensing), and for some people it is mere impossible to see the 3D. But, if you put down e.g. a pencil and focus on just the tip of the pencil and having that tip on a mark on the image (one of the two images) you can "force" your brain to suddenly visualize the 3D environment.  [deleted] Wow, that worked! But I have to concentrate on not letting the yellow "creep back" into the image, in order for the black color to stick. This is so strange.

ETA: Holy shit, when I look at the original photo now, it's blue/black!!! I stared at it for like an hour before and couldn't make it switch, but now I can't go back to seeing white/yellow. Wtf! I have a similar thing happening to me.. In the original I can only see blue/black, this swatch when I first open it appears gold/white but then fades to the blue.  It's weird cause with other things like this I've seen (like the spinning ballerina) I can switch between the two but not with this Thank you. Your description caused me to go back and focus on the shadows on the front of the dress. The colors slowly faded to black and blue. Now the picture is "fixed" in my brain, and I can't see it the other way. I try to focus on the backlighting, but it does not have an opposite effect [deleted] Could the lighting in the environment where the viewer is when she sees the image be affecting their perception? Like, if you're outside looking at the image on your phone, the outdoor blue sky sunlight makes your brain see white and gold, but when you get home and look at it again the yellow light inside makes your brain see blue and black?  Maybe depends on the illuminant of the place where they are

edit: other people have made the great point that it looks the same to many people in the same room who see it for the first time, so I'm likely incorrect on this one. I want to agree with this, but there are lots of reports of couples disagreeing with each other on the same screen. Your guess is as good as mine as to why there would be a divide in priors aside from the obvious fact that it's just the right level of ambiguity to encourage both sides. Many people have tried with multiple people in the same room from the same angle. Still come up with different colors.  I first saw it as distinctly gold and white. After viewing others' posts of the color corrected version, I went back to the original photo and saw it as black and blue. It was sincerely strange. Why would that happen? Did my brain compensate for the ambiguous visual data with the visual knowledge from the other photos? One thing I tried was slowly turning my head away from it while keeping it in my peripheral vision. As my head turned away from image, it started to turn blue and black in my side vision. Strange!  Given the observations, this reminds me of the spinning dancer. Where you see the dancer spinning clockwise, but when you try again later it's spinning counter clockwise. Your brain just likes to mess with you. Both are good examples of your brain trying to interpret ambiguous image data as if it were seeing it in real life- this may be better as viewed not as your brain messing with you though, but artificial images messing with your brain. You never notice colour constancy in normal life because your brain does it so well. Right, but like who is right in this case? Is that dress White or blue? It seems like that should be able to be demonstrated easily, yet it's left to like gawker comments to make the determination.

I'm more perplexed by this situation rather than the dress itself (which I see as White) The actual colours if you use a photo manipulation program are something in the light blue/purple range and a tan/brown colour ('gold' isn't exactly a colour, afterall). If nothing but that image existed, I would say it would be impossible to determine the 'real' colour, because: a) we don't know the actual context the photo was taken in, and b) there's no such thing as a real colour. 

To explain b) a little more, remember that your monitor is not showing the same colours as the original dress would give off, because monitors use only a couple colours to recreate all the rest (and, actually, there are some colours your monitor cannot recreate as a result). Even in real life, you don't know if something is really giving off a single wavelength actually associated with "blue" or if you're just perceiving some combination of other wavelengths that way. This is why different light sources can so easily change the colour of something, and why your brain can be tricked like this. 

This may be long and confusing.... feel free to ask for clarification!

Edit:I am aware there is an actual answer here! I did say "if only this image existed..." But arnt the pixels on a monitor the same colour as the cones in your eye? I'm not good at biology... Not really, and not quite! Your cones aren't really RGB, but the pixels do a pretty good (ish) job. You can read about this kind of stuff on [wikipedia articles about Gamuts](http://en.wikipedia.org/wiki/Gamut) The actual dress is black and blue. It is demonstrated by [inverting the photo](http://i.imgur.com/CvEixZ9.jpg) (Pixels can't lie)

Credit goes to /u/californicate-
 What does inverting it do? I still see white and bronze... Except reversed?  If you invert yellow, you get blue, not white (which you get from inverting black). Am I supposed to be seeing both dresses in your photo as tan and white? In OP's, I see it as black and blue every time, but yours as tan and white every time. [deleted] [deleted] [deleted] The actual dress is black and blue.  This is demonstrated by finding the dress for sale and seeing what color it is. [Buzzfeed found it](http://www.buzzfeed.com/briangalindo/we-may-have-found-the-which-color-is-this-dress-and-its-blue#.nbRzQv08k) [deleted] [deleted] [deleted] [deleted] [deleted] So how does it change for some people? It is an illusion and people disagree with it because the information is ambiguous. Your brain can sometimes switch back and forth on how it decides to interpret an image. If you've seen the illusion with the rotating ballerina, that's a good example of your brain switching your perception occasionally. After reading your comment and going through the linked illusions, my initial perception of black and blue flipped to white and gold. This is after reading the OP and staring at the picture for a good five minutes trying to see white and gold. Now I can no longer see black and blue however hard I try, and/or rest my eyes. How common is this phenomena?  Some illusions are really easy to flip back and forth on (like the necker cube) whereas others are harder. Tricking your brain into changing its opinion isn't really well studied, I think (though I welcome someone to prove me wrong!)

Sometimes you see something once and it's with you forever, like those "can't be unseen" images (e.g., the colonel on KFCs bowtie being legs and arms of a stick figure; or, in the psych literature [this dalmation, that once you see once you will see forever when you encounter the image](http://www.moillusions.com/wp-content/uploads/2009/12/Mysterious-Dalmatian-Optical-Illusion.jpg) 