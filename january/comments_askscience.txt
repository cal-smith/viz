A type I supernova begins when the star undergoes electron degeneracy collapse - meaning that all the electrons and protons in the star undergo reverse decay and merge into neutrons.  The process takes about 20 seconds, which is a pretty amazing speed for anything to happen on the scale of a red giant.

But other posters are right, the actual explosion (which happens when the outer layers of the star rebound against the newly-formed neutron core) would take several minutes to become apparent.  Though still, that's incredibly fast for an enormous, billions-year-old star.

edit: gilded!  Thanks guys!  (Not really, but I just always wanted to say that.)

edit: gilded *for real!*  Thanks!  It's like my very own supernova. A tangential question:  when I've read about red giants, I usually see references to a diameter on the order of light-minutes.  How does the collapse happen an order of magnitude faster than the diameter / c?  Or is only the very core of the star collapsing? Only the core collapses.  The core of a giant star is about the size of the earth but much more massive.   That's where the massive explosive energy comes from as well, things colliding at .9 c. Massive here doesn't refer to size but density, correct? "Massive" refers to mass. If something has the same size but more mass, then yes, its density will be proportionately higher as well.  Ok, so this is a concept I've never understood- I've often heard that neutron stars are a quadrillion times denser than water- but how is this possible? Isnt the densest element osmium, which is only  22 times as dense as water?

 Simple answer, neutrons are not an element and even hydrogen, the lightest element can be compressed to be denser than osmium is when it is sitting in the air at room temperature at sea level. Things can compress beyond their resting densities although when a material is solid or liquid they generally can't, however at very high pressures and superheated (which happens on its own if you compress something enough) materials change state and the atomic weight and structure becomes a lot less important due to the electromagnetic interaction between the atoms breaking down under pressure. You know how the mass of an atom is in the nucleus, and the electrons  are amazingly far away from it and the atom is mostly nothing?

Well, neutron stars are like one earth-sized nucleus.  All neutrons, all the time. That's not exactly true. A thick layer, maybe the majority of the neutron star consists of a Fermi gas of very neutron rich nuclei.  They are not stable but are dripping free neutrons on to each other.    Think of it like this: you've probably heard that atoms are mostly empty space. I think some teachers at highschool make the analogy that the nucleus is the size of a golf ball if the atom is the size of a football field.

My understanding of neutron stars is that they are a "soup" of neutrons that are under so much pressure that they occupy this region that would usually be empty space. 

Also note that because there aren't any protons or electrons, there isn't any electrical charge to make things repel.

*Edit: To run with the analogy, Osmium would be like if you had slightly smaller football fields, where as a neutron star would be like filling the football field with golf balls. I'd also tweak the analogy to have each proton/neutron be a golfball.  The density of osmium is because there are a couple hundred golfballs (if memory serves, the volume would be much larger, but density still ends up being 22x that of water).

So, your neutron 'soup' isn't all the golf balls touching each other, but is still a quadrillion times as many golf balls as osmium.
 Protons and electrons have charge, so gravity can only compress them so far before the repulsive forces (like charges repel each other) dominate and stop the compression. Neutrons have no charge, so they can be compressed much more (until neutron-degeneracy forces begin to dominate) and so neutrons can be packed much denser than other kinds of mass.   If an atom were the size of a football field, the nucleus would be a marble in the center and the electrons would be gnats buzzing around. A similar volume of collapsed matter, which makes up a neutron star, would be like a stadium full of marbles. 

In a sense, the atoms in traditional matter never touches one another. Instead, the EM force repels all the (-) charges of the electrons involved like a bunch of magnets that are all on the same pole, maintaining our "football field" distance,

The neutrons in collapsed matter actually touch, so to speak. This is possible due to the lack of charge of the neutrons.

So if you have uranium or something you have maybe a bowling ball or something in the center of an empty field, which is still several orders of magnitude less dense than a stadium full of marbles. Things can be compressed way smaller than their "normal" density. That is just their density at standard pressure and temperature. 

Even solids and liquids compress, no matter what you've been told. For example, if seawater didnt compress under its own weight then we would have about 5% more seawater volume on earth. 

However, when you get to REALLY extreme compression you start to form what is called degenerate matter. http://en.wikipedia.org/wiki/Degenerate_matter There is a difference between an object moving at c and a process appearing to move faster. If I point a laser at a far away point, and sligthly move the laser on my end, the dot may appear to move faster than c. But since it's just the spot were the laser shines at, nothing is really moving faster than c. I never understood this example. Theoretically if i point a laser at a far away point, the light of the laser has to travel there. Then i move the laser to another point and light has to travel there in c again. There is just light arriving at a former point while i adjust the laser to  another point. Do i totally get this wrong? Why would it seem faster to me?

Edit: Thanks for all your answers people. :) I think i somehow understand it now. I believe the idea is that the dot of laser light would seem to move faster than c *sideways*. You shine a laser at some point 1 light second away, then turn the laser so that it shines on a point that is still 1 light second away from you, but is 4 light seconds away from the original point. The dot will have "moved" faster than c, but that's really just an illusion caused by how humans perceive events.

EDIT: ~~Geometry.~~  As was pointed out, the scenario I made is geometrically (at least with cartesian space) impossible; the farthest away the points could be is 2 light seconds if they were both 1 light second away from the observer. I don't know what distances to use that wouldn't get in the way of comprehension, though. Oh ok.. that makes somehow sense to me. Lets say there is something between this 2 points. The laser would move really move from one point to the other or would it somehow trip on the way because i do not send "enough" light for the distance of 4light seconds. Sorry if this question is stupid. Maybe i just think wrong. Think of the laser as a machine gun.  It's constantly shooting photons.  Your brain is thinking of the laser's target as a 'thing' that is moving.  When in reality, it's just a point in space where photons are travelling to from the laser.  Since the laser is constantly shooting photons, it seems like these are connected events, when in fact each photon moving from the laser to the target is an individual event.  So, you can move the target faster than c because it is a constantly changing, independent event.  It's not a 'thing' that is moving continuously.

So as for your question, the laser could skip and not hit every continuous space between the two points you shine. Remember that no matter what, the concept of a light source illuminating the "entire" surface is just an illusion. Light sources shoot fotons - discrete things. No matter how much light you would use, it's still as if you were shooting quantum bullets at a wall. Each of those photons individually hits and interacts with one electron of one atom in the wall. No matter how slow or how fast you move the light beam across the surface, you have the same situation: individual photons interacting with individual electrons.

The only thing you might talk about, then, is what is the probability that a certain fraction of the atoms will have one of their electrons interact with a photon from your beam.

To give you some idea of scale, a green photon (510nm wavelength) has an energy of roughly 4E-19 Joules. A green laser with 10mW optical output power shoots out about 2.6E16 green photons per second. A table salt crystal has a lattice constant of 0.56nm. So let's say we sweep a 3mm laser spot across one metre of distance - how many atoms on the surface do we sweep over? About 1E16. Each of those atoms has, on average, 14 electrons, so we sweep over 1.3E17 electrons just in the surface layer of salt. But we only have 2.6E16 photons *per second*. So you already see that you illuminated most of the surface atoms, but not most of the electrons in those atoms - and only if we move it rather slowly, with an apparent speed of 1m/s.

If we move the spot with the apparent speed of light, 3E9 times faster, we'll only illuminate about every billionth atom in the surface. Now imagine that we move it at a speed a million times the speed of light - we'll illuminate about every 1E15th atom in the surface swept over by the beam. But there's only about 1E16 atoms there. So we'll, effectively, illuminate just a few atoms between the starting and stopping point. All humans think wrong. The brain takes a lot of shortcuts in order to work as well as it does, and it takes a lot of effort to overcome that.

And... I can't answer your next question. I'm not nearly qualified enough, and after thinking about it for a few minutes my intuition can't even agree on an answer. I will say that since light is composed of photons, even a strong, stationary beam of light would appear to be a bunch of discrete dots if you had impossibly good [resolving power](http://en.wikipedia.org/wiki/Angular_resolution). Ok, how about this example: Let's forget the laser altogether.  

You are looking into the sky at Polaris.  Then you move your eyes to look at Rigel.  The distance between the two objects you are looking is several light years.  This distance, divided by the time it would take to move your eyes is far greater than the speed of light.  But your eyes only moved millimeters, so you should have divided this short distance by time, not the distance between the stars.   This type of mistake is easier to make when things get subtle.

edit: grammar Because you are seeing the point at which the laser shines move faster than c, not any particle itself doing so. [I tried to make a gif to explain it](http://imgur.com/Y4xZjHR). This is an excellent visualization of what's going on (might be slightly improved by showing the photons as they hit the surface between the two points but works well as-is too) A water hose is the best explanation for this.  If you point a water hose at a spot on the wall and move it to point at another spot on the wall, all of the water you directed at the first spot will have hit the wall before the first drop of water hits the second spot. Now instead of miles per hour, scale the concept up to c and there you go. as you move the laser the end dot, can traverse a great distance in a time that appears faster than light.. you can imagine with a strong enough laser.. it doesnt take you changing your angle much to move the end point a great distance.

but your right, it doesnt allow for faster than c communications because what is really happening isnt that the dot is actually moving across a surface light years away.. but that light is coming from us at c at various angles.

I guess an easier example to see, would be make a giant scissor finger puppet with your hand, in front of a way too bright light, shining on a wall suitably far away that your fingers shadows appear to be one light year apart. Now close your finger scissors.. what happens to the scissor shadow? Does ti take 1 year to close? or seconds.
  It would close in seconds on both ends, but it would happen 1 year after on the shadow end. yeah, but i'm not sure how far the wall is.. so when it happens on the shadow end depends on that.

but yeah darkness isnt traveling faster than light either, whats happening is we are ceasing to block light at various angles which then travel at c to fill in the spaces tht were originally in shadow. Even if we beam information from star a to star b through a laser beam placed on the earth, we could never achieve faster than light communications because any information from star a would first have to travel from star a to the earth and then be beamed to star b. So the total time would be greater than information beamed from star a to star b practically.  Imagine it's a machine gun instead of a laser pointer (bullets instead of photons). Imagine how the bullets would spread out as you turned the gun, and realize that you would be hitting the second target with a different bullet than the one that hit the first. It's not like you moved the first bullet you shot. You just shot more bullets.

That made it click for me. The main thing to note is that *a visible dot of laser light is not an actual physical object*. If you move a laser, new photons will create a new dot at the new location.

It's just an illusion in the human mind that the two dots are "the same" or that a single dot "moved". In reality, the old dot stopped existing and a new one appeared in a new location. The apparent distance over time might be greater than the speed of light, because nothing actually physical moved.

 It doesn't really answer his question though. The collapse of a star isn't an 'apparent' thing, it's a physical process happening to the star, and it can't happen faster than the diameter of the star divided by c. So the answer of 20 seconds is still puzzling.

However, since it's only core collapse, and the core is pretty small, it does indeed take seconds, not minutes, but it'd all be hidden behind the outer layers of the star.
Most of the hot gas surrounding the core gets blasted off by the core going supernova, but again, that can't happen faster than a couple of minutes because of its sheer size.

Tl;dr looking at it from afar, it'd take minutes. I believe the 20 seconds isn't describing one big event across the full diameter, but instead billions of small events dispersed throughout the star.  An electron merging with its proton doesnt take very long at all, and is happening simultaneously scross the star.

I'm new to this, but that's how I understood the description. 20sec seems oddly specific and short. How do we know this? There are a lot of stellar phenomena that can be very accurately predicted using fairly simple models.  Also, I'm not saying it's exactly 20 seconds, but just in that range.
 I love how your answer is essentially,  "we know this because there are ways."  I think the point he is trying to make is that even though stars are astronomically large (literally) they are still fairly simple and homogeneous. So the ability to predict what would happen to a star under certain conditions is well within the realm of our current physical models. Thanks - you expressed it better than I did or could have.  Have we ever seen this happen? Can we observe far away stars with enough granularity to allow this yet? http://en.wikipedia.org/wiki/Betelgeuse  
This star is ready to go supernova anytime soon. We may see it in our life time. When it does go, we will be able to see it with the naked eye, which would be a spectacular sight. Also the star could have already went supernova and the light has not reached us yet. &gt;"**As of 2014, the most recent theoretical calculations suggest Betelgeuse has recently started core helium burning and that it will explode as a supernova after going through carbon burning, oxygen burning, neon burning, and silicon burning on its center within 100,000 years.** The estimated age for the red supergiant, that is still ascending the red giant branch, would be between 8 and 8.5 million years"

&gt;"Betelgeuse is already old for its size class and is expected to explode relatively soon compared to its age. Solving the riddle of mass-loss will be the key to knowing when a supernova may occur, an **event expected in the next million years.**"

&gt;"Due to misunderstandings caused by the 2009 publication of the star's 15% contraction, Betelgeuse has frequently been the subject of scare stories and rumors suggesting that it will explode within a year, leading to exaggerated claims about the consequences of such an event. The timing and prevalence of these rumors have been linked to broader misconceptions of astronomy, particularly to doomsday predictions relating to the Mayan calendar. In their 2012 study, physicists at the Space Sciences Laboratory point out that the apparent contraction in the star's diameter may be due to the complex dynamics in the star's surrounding nebula and not the star itself, reconfirming that until we better understand the nature of mass loss, predicting the timing of a supernova will remain a challenge. **The latest studies project a supernova in 100,000 years.**"

100,000 years. We are just as likely to see a magnetic pole reversal as we are to see this in that time frame.

http://en.wikipedia.org/wiki/Betelgeuse#mediaviewer/File:Betelgeuse_supernova.png This should be getting more attention. Lol. It sucks when Science is used in the media to scare people by exaggerating the facts. But it also sucks when those exaggerations out grow their truthful sources. I am sad to hear that it's unlikely to go during my small stretch of lifetime, it would of been rather amazing to see. We can already see it with the naked eye! It's one of the stars of the constellation Orion. But when it goes supernova, it'll be something quite spectacular. It'll cast faint shadows during the day, and it'll far outshine the full Moon. [deleted] That sounds crazy awesome. How do we know this? Would it rise and set like other celestial bodies in the sky? Would it be like an eclipse where it's only visible to certain areas? Well the article says it's 643 light years away +/-146. So it could have gone supernova in the last 643 years and we wouldn't know it yet.  Wow!  The best we can do for a distance measurement on something as close as Betelgeuse is +/- 25%? [deleted] we've just got to be careful not to say its name three times after it happens or we'll bring it back Maybe but often people get stuck-up on empirical truths (as most of our science and systems are based on them). When we are talking things in the realm of cosmology and galactic evolution, while there is a lot to see just simply to how long it takes light to travel (and thus having a pseudo time machine to look into the past), the truth is often what we conclude is happening in these cosmological entities is what's most consistent with the full set of physical theories. We do this because we do have many empirical examples for these theories in our neighborhood, so we either have to accept these as predictors of these cosmological entities or we have to re-work science.

In other words what I am outlining relates to Godel's Incompleteness Therom which says an axiomatic system can never be both complete and consistent. In physical sciences, we seek consistency, knowing there is always more to complete our models.

This can all be simplified by one famous quote, "all models are wrong, but some are useful".

I hope this answers your question. Yes, it does, thank you :) But I would assume the model only works for a spherical star in a vacuum. Typical. Astrophysicist here with specialization in stellar computational models. Can confirm. Warm Stars are pretty easy to model. Cool stars are a bit harder.  That's the way all maths are for me. I'm like a dog watching a magician.  **Read all of these and then you can explain it for them:**

 Endeve, E., Cardall, C.Y., Budiardja, R.D., Beck, S.W., Bejnood, A., Toedte, R.J., and Mezzacappa, A. 2012, Turbulent Magnetic Field Amplification from Spiral SASI Modes: Implications for Core-Collapse Supernovae and Proto-Neutron Star Magnetization. Ap.J. 751, 26.

 Lentz, E.J., Mezzacappa, A., Messer, O.E.B., Liebendorfer, M., Hix, W.R., Bruenn, S.W. 2012. On the Requirements for Realistic Modeling of Neutrino Transport in Simulations of Core-collapse Supernovae. Ap. J. 747, 73.

 Yakunin, K.N., Marronetti, P., Mezzacappa, A., Bruenn, S.W., Lee, C.-T., Chertkow, M.A., Hix, W.R., Blondin, J.M., Lentz, E.J., Messer, O.E.B., and Yoshida, S. 2010. Gravitational Waves from Core Collapse Supernovae. Class. Quant. Grav. 27, 194005.

 Endeve, E., Cardall, C. Y., Budiardja, R. D., and Mezzacappa, A. 2010. Generation of Magnetic Fields by the Stationary Accretion Shock Instability. Ap.J. 713, 1219.

 Bruenn, S. W., Mezzacappa, A., Hix, W. R., Blondin, J. M., Marronetti, P., Messer, O.E.B., Dirk, C. J., and Yoshida, S. 2009. 2D and 3D Core-Collapse Supernovae Simulation Results Obtained with the CHIMERA Code, Journ. Phys. Conf. Ser. 180, 012018.

 Blondin, J. M. and Mezzacappa, A. 2007. Pulsar Spins from an Instability in the Accretion Shock of Supernovae, Nature 445, 58.

 Liebendorfer, M., Rampp, M., Janka, H.-Th., and Mezzacappa, A. 2005. Supernova Simulations with Boltzmann Neutrino Transport: A Comparison of Methods, Ap. J. 620, 840.

 Liebendorfer, M., Messer, O.E.B., Mezzacappa, A., Bruenn, S. W., Cardall, C. Y., and Thielemann, F.-K. 2004. A Finite Difference Representation of Neutrino Radiation Hydrodynamics for Spherically Symmetric General Relativistic Supernova Simulations, Ap. J. Suppl. 150, 263.

 Hix, W. R., Messer, O.E.B., Mezzacappa, A., Sampaio, J., Langanke, K., Dean, D. J., and Martinez-Pinedo, G. 2003. The Consequences of Nuclear Electron Capture in Core-Collapse Supernovae, Phys. Rev. Lett. 91, 201102.

 Langanke, K., Martinez-Pinedo, G., Sampaio, J. M., Dean, D. J., Hix, W. R., Messer, O.E.B., Mezzacappa, A., Liebendorfer, M., Janka, H.-T., and Rampp, M. 2003. Electron Capture Rates on Nuclei and Implications for Stellar Core Collapse, Phys. Rev. Lett. 90, 241102.

 Cardall, C. Y. and Mezzacappa, A. 2003. Conservative Formulations of Relativistic Kinetic Theory, Phys. Rev. D68, 023006.

 Blondin, J. M., Mezzacappa, A., and DeMarino, C. 2003. Stability of Standing Accretion Shocks, With an Eye Toward Core-Collapse Supernovae, Ap. J. 584, 971.

 Bruenn, S. W., DeNisco, K. R., and Mezzacappa, A. 2001. General Relativistic Effects in the Core-Collapse Supernova Mechanism, Ap. J. 560, 326.

 Liebendorfer, M., Mezzacappa, A., Thielemann, F.-K., Messer, O.E.B., Hix, W. R., and Bruenn, S. W. 2001. Probing the Gravitational Well: An Energetic Supernova Explosion with Boltzmann Neutrino Transport in General Relativity, Phys. Rev. D63, 103004.

 Mezzacappa, A., Liebendorfer, M., Messer, O.E.B., Hix, W. R., Thielemann, F.-K., and Bruenn, S. W. 2001. Simulation of the Spherically Symmetric Stellar Core Collapse, Bounce, and Postbounce Evolution of a Star of 13 Solar Masses with Boltzmann Neutrino Transport, and Its Implications for the Supernova Mechanism, Phys. Rev. Lett. 86, 1935.

 Mezzacappa, A., Calder, A. C., Bruenn, S. W., Blondin, J. M., Guidry, M. W., Strayer, M. R., and Umar, A. S. 1998. An Investigation of Neutrino-driven Convection and the Core-Collapse Supernova Mechanism Using Multigroup Neutrino Transport, Ap. J. 495, 911.

 Mezzacappa, A., Calder, A. C., Bruenn, S. W., Blondin, J. M., Guidry, M. W., Strayer, M. R., and Umar, A. S. 1998. The Interplay Between Proto-neutron Star Convection and Neutrino Transport in Core-Collapse Supernovae, Ap. J. 493, 848.

 Mezzacappa, A. and Bruenn, S. W. 1993. Stellar Core Collapse: A Boltzmann Treatment of Neutrino-Electron Scattering, Ap. J. 410, 740.

 Mezzacappa, A. and Bruenn, S. W. 1993. A Numerical Method for Solving the Neutrino Boltzmann Equation Coupled to Spherically Symmetric Stellar Core Collapse, Ap. J. 405, 669.

 Mezzacappa, A. and Bruenn, S. W. 1993. Type II Supernovae and Boltzmann Neutrino Transport: The Infall Phase, Ap. J. 405, 637.

 Mezzacappa, A. and Matzner, R. A. 1989. Computer Simulation of Time-Dependent, Spherically Symmetric Space Times Containing Radiating Fluids - Formalism and Code Tests, Ap. J. 343, 853.

**What, you mean you have better shit to do than try to sum up decades of complicated research into a few short paragraphs on reddit? You lazy SOB.**

**E: gold, now I can build my own hohlraum and study the process up close!  Thank you!* [deleted] [deleted] Just spent weeks writing a paper summarizing decades of research on the stellar luminosity function and let me tell you.... It isn't easy. So many different units and conversions blargs. Convert from cgblarg to mkblurgh, and then back to something like cgblargh. 

Currently reading a stellar structure book written by a physicist, who makes the cgswhyyy dig in the intro I don't know if you were trying to sound like a dick or I just read it that way. He could probably show us the "fairly simple" models, simulations and calculations, but we wouldn't understand any of them anyway.  I find this interesting. According to a couple sources a red giant can be up to 621,000,000,000 miles in diameter. At this distance, it would take light 3338.7 seconds to get from one side to the other. And that's light in a vacuum. It would take *significantly* longer for a photon to traverse through a red giant.  
  
[It takes a photon more than 10,000 years to travel from the core of our sun to the surface](http://www.badastronomy.com/bitesize/solar_system/). A red giant is much bigger than our sun, obviously! A quick google tells me when the sun becomes a red giant its radius will be about equal to its distance from the earth now. That means its diameter will be about 16 light minutes. How can something happen across an object that large that fast when something that happens on one end takes at least 16 minutes to affect the other. If I'm reading this correctly, it [sloughs off its outermost layers](http://en.wikipedia.org/wiki/Type_Ia_supernova#mediaviewer/File:Progenitor_IA_supernova.svg) before that particular reaction occurs. Wasn't there a supernova around 1089 that people could see during daytime for weeks? SN 1054 which was visible on Earth in 1054. It could be seen during daytime for 23 days. Crab Nebula is the remnant of this supernova.

[https://en.wikipedia.org/wiki/SN_1054](https://en.wikipedia.org/wiki/SN_1054) Thank you! It's an order or magnitude estimate. It tells you it's not 1 second, and not 1000 seconds, but it could be 18, or maybe 23, etc.  It's probably 22.0609 seconds that it takes in whatever computer models that they use to approximate this, and 20 seconds conveys the same amount of useful information as whatever their model exactly predicts, which would probably vary a little based on what the assumptions about the star were, so that's the explanation on why it's specific. 

I never touched astronomy while I was getting my BS in physics, so I can't speak for the more interesting part of the question. You might have a point in physics generally, but actually anything prefixed with astro- can be assumed to be very approximate.  Quite often you'll only be working to an order of magnitude level of precision.  The model might spit out 22.0609 seconds, but nobody would consider this meaningful, and would be absolutely ecstatic if it were within a factor of 2 of the reality.  The difference is that in something like quantum mechanics, say, we might get something like 22.0609 seconds and then complain that it isn't accurate *enough*! I would have to disagree. Yes in astro- it could be a bit iffy with distances and so on and so forth, but in terms of certainty this problem is more quantum physics / statistical physics and the ridiculous ammounts of particles involved will only *add* to the certainty (macro vs micro states etc) and not the other way around.  But the complex structure and rapid changes in structure that occur during a supernova will put all that uncertainty right back in.  If a star were a completely homogeneous sea with identical properties throughout, then the random nature of the interactions would allow for extremely precise calculations, but it isn't.  It's lumpy and has very complex structure, especially when approaching or during a supernova. That number seems quite incredible to me for anything to happen to an entire star. The sun (which is smaller than stars going supernova) is already [5 light seconds across](https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=diameter+of+the+sun+in+light+seconds). Are you saying that the degeneracy collapse is entirely propagated by photons/EM/gravity waves/fields, and has nothing to do with the internal pressure supporting the star? Because pressure waves would be bound by the speed of sound, or at least relativity, and should be substantially slower.  The collapse happens in the core of the star, and it's caused by gravity, which is in an unstable equilibrium with internal pressure.  The core itself reaches a large fraction of the speed of light as it falls inward, and the rebound happens when it reaches neutron star densities.  The rebound is what causes the actual explosion throughout the rest of the star. The [wiki for Type II supernova](http://en.wikipedia.org/wiki/Type_II_supernova) references [this paper](http://relativity.livingreviews.org/Articles/lrr-2003-2/download/lrr-2003-2Color.pdf) which says:

&gt;Approximately 70% of the inner portion of the core collapses homologously and subsonically. The outer core collapses at supersonic speeds [71, 170]. The maximum velocity of the outer regions of the core reaches  710^4 km s1. It takes just 1 s for an earth-sized core to collapse to a radius of 50 km [8].

Then the main event: "The core overshoots its equilibrium position and bounces. A shock wave is formed when the supersonically infalling outer layers hit the rebounding inner core" Actually, if I remember correctly, a star big enough to end in a supernova, would hardly live a billion years. For a supernova (of type II) a star has to have an intial mass at least 8 times larger than the mass of the sun. The higher mass leads to more pressure on the core and thus an overproportinal speed in the "burning" of hydrogen. Thus these huge stars only life millions, not billions, of years.

http://en.wikipedia.org/wiki/Star#Age
  Depends on the type of supernova. Type 1a supernovae involve white dwarves, which are pretty old stars. Although this is not a core collapse supernova. &gt;Type 1a supernovae involve white dwarves, which are pretty old stars.

~~Are you saying that white dwarves can go supernova? A star can end up as a white dwarf after a supernova, but that says nothing about its lifetime. And while white dwarves have incredibly long lifetimes, they aren't necessarily old.~~

EDIT: I suck. They can if they're actively accreting matter from a stellar companion, and they all go boom at more or less the same point (that is to say, there is a finite and well understood amount of mass that can be accreated by any white dwarf, beyond which it goes supernova). 

The predictability of the energy output from this process is what makes type 1as perfect "standard candles" for determining the distance to their host galaxy.  Apparently this can only happen in a binary star system where the white dwarf leeches mass from the other star. That is true, there are some processes that can form white dwarves from relatively young stars, but most form only after billions of years.

The mechanism of a type 1a supernova is accretion of material from the other star in a binary system. Once the mass of the dwarf is over 1.44 solar masses, the Chandrasekhar limit, electron degeneracy can not longer support the star and it undergoes a 1a supernova. &gt; A star can end up as a white dwarf after a supernova

A supernova can result in a neutron star or black hole, but not a white dwarf. White dwarfs are the cores of dead stars that were not massive enough to go supernova. What triggers reverse decay, and how is it coordinated across the entire star so uniformly that the entire, massive object converts in such a short time? I'm not going to explain this well, but: the star reaches its maximum density per the Pauli exclusion principle; you literally cannot add another electron or proton to its mass without having overlapping quantum states (two particles occupying the same state at the same time), which is impossible for that type of matter. So the only option the star has is for protons and electrons to undergo "reverse decay," or fuse together to form neutrons. 

Thus the core of the star collapses into a neutron star while going supernova. At that point, what's keeping the star from collapsing further is neutron degeneracy pressure - but if that gives way, the core collapses completely into a black hole.  So this relies on some (perhaps reasonable) assumptions of uniform density build up throughout the core of the star?

Also, somewhat unrelated but I've always wondered, is there an independent basis for the Pauli exclusion principle, or is it simply an axiom that must be accepted to make sense of experiment? The PEP is a result of treating quantum systems through the use of wavefunctions. Physical systems all have certain symmetries which must be preserved and the relevant one for this is that fermionic wavefunctions must be antisymmetric with respect to the exchange of particle labels. &gt; Physical systems all have certain symmetries which must be preserved

Can you unpack this a bit for me, or explain the symmetry in a (...I dunno...) wave in a water tank? Is there an "exclusion principle" for standing water waves? Basically, in Quantum Mechanics the fundamental particles are assumed to be indistinguishable. From this axiom, when you construct a wave-function for a system of, say, two electrons, you must construct it in such a way that you could exchange the two particles in the wave function without changing the wave function. There are two natural ways to do this by combining wave-functions that would describe each individual particle. 

Say A(x_1) is the (time-independent) wave-function that describes 'electron 1'. And B(x_2) is the wave-function that describes 'electron 2', and x_1, x_2 are the variables that used to reference electron 1 and 2. I put those terms in quotes, because as you'll see there really isn't any 'electron 1' or 'electron 2', there are just two electrons.

You can take the total wave-function to be = A(x_1)B(x_2) - A(x_2)B(x_1). This is (anti)symmetric under switching variables x_1 and x_2.(This is equivalent to swapping 'electron 1' with 'electron 2'), and a solution to the multi-particle Schrodinger equation. By anti-symmetric, I just mean that swapping x_1 and x_2 creates the same wave-function with a minus sign. The minus sign leads to some interesting properties, but for the purposes of distinguishing 'electron 1' and electron 2', the minus sign is useless. So the indistinguishability of electrons is preserved by this wave-function. i.e. if you measure the location or momentum or any property of an electron in this system, it is impossible to say whether you measured 'electron 1' or 'electron 2'.

   Now you might notice that if A(x) = B(x), we have a major problem: The total wave-function is zero, which in QM means that the state doesn't exist. Therefore you can't have two electrons existing in the same state in any system. This is the 'source' of the Pauli exclusion principle, or at least the mathematical framework that predicts it.

I'm not completely sure why, but particles with half-integer spin(they have intrinsic angular momentum of 1/2, 3/2, etc. h-bar) are subject to the Pauli exclusion principle. These particles are called fermions and include most of the things that we ordinarily think of as matter, like electrons, protons, etc. 

Bosons, particles with integer spin, use a different formula to form composite wave-functions, a plus sign instead of a minus sign. Phi(x_1, x_2) = A(x_1)B(x_2) + A(x_2)B(x_1), and there is no problem if A(x) = B(x). Bosons are mostly force carrying particles like photons. 

As to why bosons add, and fermions subtract, I can't answer, but it obviously appears to be related to the spin of the particles, or may be an axiom itself.  Your answer conflates Type Ia and Type II supernovae a bit. Just to be clear, Type Ia's are white dwarfs gaining enough material from somewhere (accretion from a donor star or mergers with another white dwarf) that the pressure exceeds what electron degeneracy can support. Type Ias don't happen in red giant stars, though, as you suggest. Red giants have thick hydrogen atmospheres above the core, resulting in a Type II supernova that shows strong hydrogen lines in its spectrum (unlike a Type Ia). These Type IIs are from the death of an old, massive star (&gt;8 solar masses) and are often called "core collapse" supernovae as well. The collapse is so fast because it's related to the free fall time of the core. The rest of the star is huge, though, and the eruption takes much longer to come out through the outer layers, typically hours. A supernova can last weeks or months.  Suppose our star went supernova as a type I. We would notice within 8 minutes that something went horribly wrong, but how long until the shockwave hit and consumed earth? We would realize something is going horribly wrong at about the same time that a blinding wave of light destroys the Earth's surface. We would know a couple hours before we see the explosion. The explosion has to propagate out through the star at much less than c while the neutrinos generated by the electron-proton fusion will come out at c. We are watching for this, right? ... Why would we.  If it happens we're all dead anyway, who cares? What's your survival plan? How does time dilation affect this estimate? Were we able to stand on the surface of the developing supernova, would we see it taking much longer? &gt; all the electrons and protons in the star undergo reverse decay and merge into neutrons. 

What causes this to happen? Huge pressures. While the star is active it creates a lot of energy that pushes the outer layers of the star away from the core. Once the star "runs out of fuel"/uses it all up there's nothing to push the outer layers away and then due to gravity it all collapses on the core that gets crushed and electrons and protons "fuse"/merge into neutrons. A massive star is being compressed by its own gravity, which is what causes the stellar core (where this pressure is largest) to undergo fusion in the first place. But if you heat something, it'll expand - like the gas in a hot-air-balloon. This expansion of hot gas is what keeps gravity from compressing the star further. At a certain point in a star's life the fusion in its core dies out because it takes a lot more energy to fuse larger atoms together while at the same time the energy released becomes lower. Therefore, the stellar core cools down and there's less internal force that counteracts gravity. 

In a "normal" star - one that's not undergoing supernova - the balance between the internal pressure of the hot gas and the pressure of gravity acts like a thermostat, keeping the fusion rate roughly constant: 

- for some reason fusion rate decreases, the core cools and compacts - but if it's more compact, fusion rate increases again

- if the fusion rate increases too much, the core heats and expands, thus reducing the chance of two particles colliding and undergoing fusion, rate decreases again From what I understand, it has to do with gravity trying to pack a bunch of material into as small a space as it can. At a certain density, it all smushes into neutrons.  What if it were possible to stop the rebound?

The star overshoots its equilibrium when the core collapses. Sounds like something out of Star Trek to try and slow the collapse to ease the star into a new unnatural equilibrium. What effects would be visible from the outside? Would the star "live longer" and produce different fusion products?  dude that is so awesome.  as soon as i saw this question i thought 'hey that IS a good question, i hope someone knows the answer' AND HERE YOU ARE

thank you! If you look at the light curve of a supernova, it takes on the order of days to reach its luminosity peak. The actual process that releases the energy only takes seconds to maybe a few minutes, but it takes a long time for the emission of electromagnetic radiation (light etc) to peak. The electromagnetic radiation is just a minor byproduct of the supernova.

SN 1987A was first discovered in February 1987, but it only reached peak luminosity in May. Well of course the peak neutrino flux occurs well before the peak flux of electromagnetic radiation, which was one of the most important discoveries after SN1987A.  Neutrinos make up the majority of the energy released in a supernova event, and there is still a delay as the rebounding supersonic shockwave is actually opaque to neutrinos for a period of time Very interested in something opaque to neutrinos, can you explain more please ? In the collapsing core of a giant star that is producing a supernova, a proto-neutron star is formed. That is, the density of the core reaches such great magnitudes that protons and electrons combine into neutrons; neutrinos are a byproduct of this reaction. However, as stated, the region in which these neutrinos are produced is dense. It's so dense that even neutrinos can't travel far without colliding with other particles and scattering. The region is "opaque", rather than "transparent", to neutrinos because their flight paths are continually disrupted, and the vast majority of them are therefore trapped within the overdense region. How is the shockwave opaque if the star as a whole is effective transparent to neutrinos? &gt;the rebounding supersonic shockwave is actually opaque to neutrinos for a period of time

Chiming in with the other posters, I'd appreciate further explanation. 

Theorists surmise that neutrinos must impart some energy to the outer shell to explain their models, but I don't think anyone yet has a good explanation for how this occurs. 

Is that the phenomenon you're alluding to in regards to opacity?   Isn't that because luminosity is a function of size? That is, the individual atoms aren't getting any more energetic, they are just expanding into a much larger sphere and therefore appearing to us, very far away, as much brighter? &gt;Isn't that because luminosity is a function of size?

It would be a function of size and luminosity per area (or volume). But there are complicating factors such as opacity and radioactive decay. It would also be very bright.  I can't link right to it as I have done frequent before, but XKCD is again relevant.  In his book the author quotes a well known astrophysicist in saying "However large you think a supernova is, it's bigger than that."  To get an idea of how bright a supernova is, he compares viewing one from one AU away (from here to the sun) to watching the detonation of a hydrogen bomb while the device is pressed against your eyeball.  The supernova would still be brighter.  *By nine orders of magnitude.* When betelgeuse goes kaboom it will be as bright as a full moon for a month, while being 600 light years away.   Everything within 600 light years of betelgeuse with a good view of it would have a good show.
 So we're just far enough away to see a good show and not(?) be in danger? If you were alive in the Southern Hemisphere in 1987 you would have been able to witness a supernova with the naked eye: 

 http://en.m.wikipedia.org/wiki/SN_1987A

Although that's 168,000 light years away, it lasted for a period if months as the "explosion" died down.

I did read that when Betelguex goes it will be as bright as the moon... Question: When Betelgeuse goes supernova, will potentially dangerous particles stream through our solar system? No, unless you count high-energy photons.

edit: I assumed /u/Goldin was referring to particles in the sense of *massive* particles, as opposed to massless photons.  Aren't high-energy photons pretty dangerous, though?  If Betelgeuse goes supernova, will there be a high enough density of the photons to cause harm? No, our upper atmosphere is excellent at absorbing them.

So good actually that it makes gamma-ray telescopes a tricky affair. They have to be built on high mountains, and only then are able to observe the secondary particles that the high-energy gamma rays create when they smash into the atmosphere. What about spacecraft, manned or unmanned? [deleted] Oh you..  
  
To answer the original question: this is one reason why space telescopes are so useful and important.  well the heat shields are because anything in orbit around the earth is falling at the earth (and missing) at tens of thousands miles per hour. you hit atmospheric gasses at those speeds, this lovely thing called friction starts to come into play and begins heating up your orbital vehicle or satellite. Say if you were in a synchronous orbit, or just managed to levitate yourself above the earth, unless you're falling at mach 3, you'll just hit a lot of wind resistance and not burn up. Maybe get torn apart though..

The better answer would be that our magnetic field will bounce those particles off pretty efficiently. It does a pretty damn good job at bouncing off the sun's particles on a daily basis. A star that is light years away poses no real threat to the earth unless it has a pole facing us and is a red hypergiant in our galactic neighborhood.

Our ozone layer in the upper atmosphere does do a wonderful job of stopping UV-B radiation though. (think of it as using a torch on creme brulee to create a hard sugary shell, the ozone layer is replenished as UV-B radiation rips oxygen apart and creates ozone) My layman's understanding is that [it isn't (mainly) friction which causes the need for heat shields, but that the majority of the heat comes from the compression of the atmosphere in front of it](http://www.uu.edu/dept/physics/scienceguys/2003Mar.cfm). A supernova has to be relatively close AND be pointing a pole directly at us for it to endanger Earth. Will the supernova be anywhere in our lifetimes? I've heard it was going to be true but I'm skeptical  As I understand it, it *could* happen in our lifetimes, but it's not very likely to. It's one of those things where we could all wake up next Tuesday and see it, or it may not happen for another 95,000 years. Phil Plait said in his blog that the current best guess estimate put it in the 100,000 year range^(1).  So, soon astronomically speaking, but a very long way off by human reckoning.  

^(1)http://www.slate.com/blogs/bad_astronomy/2014/09/08/betelgeuse_astronomers_give_it_100_000_years_before_it_explodes.html The size of a SN explosion is so large that it takes a considerable amount of time to cover those distances even if stuff would move at the speed of light - and it usually moves quite a bit slower than that. 

Time lapse of Eta Carinae, spanning 13 years: http://apod.nasa.gov/apod/image/1412/CarinaExpanding_Hubble_750d.gif  
http://en.wikipedia.org/wiki/Eta_Carinae   
edit: (not actually a supernova, but still somewhat supernova-ish - thanks several commenters)

2nd edit:  
I should include a link to the full page of NASA's "Astronomy Picture of the Day" archive where that image is from:   
http://apod.nasa.gov/apod/ap141202.html  
  
about the lobes/bubbles:  
http://apod.nasa.gov/apod/ap140717.html
 For some context, the above is a picture of [the Homunculus Nebeula](http://apod.nasa.gov/apod/ap141202.html), not a supernova.

&gt; How did the Eta Carinae star system create this unusual expanding nebula? No one knows for sure. About 170 years ago, the southern star system Eta Carinae (Eta Car) mysteriously became the second brightest star system in the night sky. Twenty years later, after ejecting more mass than our Sun, Eta Car unexpectedly faded. Somehow, this outburst appears to have created the Homunculus Nebula. The three-frame video features images of the nebula taken by the Hubble Space Telescope in 1995, 2001, and 2008. The Homunculus nebula's center is lit by light from a bright central star, while the surrounding regions are expanding lobes of gas laced with filaments of dark dust. Jets bisect the lobes emanating from the central stars. Expanding debris includes streaming whiskers and bow shocks caused by collisions with previously existing material. Eta Car still undergoes unexpected outbursts, and its high mass and volatility make it a candidate to explode in a spectacular supernova sometime in the next few million years. I always wondered. If I were actually inside said nebula, would I be able to tell? Just how dense are Nebula? &gt; sometime in the next few million years.

Can't you be a little more specific?  I would like to pencil this in on my calendar. That reminds me of a great Chemistry teacher I had back in college. When talking about significant figures, he said the sun at it's core is 27 million degrees.

A student asked "Fahrenheit or Celsius?"

And he yelled back, "IT DOESN'T MATTER." 27 million degrees celcius is about 48 million in fahrenheit. I would call that a significant difference. Actually, sooner than that, Betelgeuse (pronounced "beetle juice") is due to explode within the next 1,000,000-100,000 years. It's so close to Earth that the explosion will be the second brightest thing in the sky next to our sun.  Betelgeuse is 642 lightyears away &amp; is as large as the orbit of Jupiter. It is the 9th brightest star in the sky. It has also been showing increasing instability, some reports are saying that it is shrinking at an alarming rate.
 
The brightest star in the sky is Sirius, which is about twice as massive as the sun but only 8 and a half lightyears away- as a comparison. 
 
The universe is scary big. Wouldn't the brightest star in the sky be the Sun?

;) Only relatively. It's weird that you said "1,000,000-100,000 years" instead of "100,000-1,000,000 years". Would something that far away affect us in any relevant way heat-wise? Or would it just be bright in the sky?  Not heat wise. In most respects (i.e. not a Gamma Ray Burst), we're safe as long as it's more than 20 light years away. Do we have anything to fear from radiation from it when it goes?   I understand the Heliosphere helps protect against such things but if the explosion would be greater than the light from the moon, I could imagine how it could give the magnetic protection from the sun a run for its money. Here's a little bit of comfort from EarthSky: " When Betelgeuse does blow up, our planet Earth is too far away for this explosion to harm, much less destroy, life on Earth. " http://earthsky.org/brightest-stars/betelgeuse-will-explode-someday When the light from the supernova arrives, so will the radiation. I honestly don't know how much of a dose Earth will receive, but if our magnetic field is enough to protect us from the Sun, it probably stands a good chance against an explosion 640ly away. (In addition, our Sun has it's own magnetic shield) Another fact: The Ozone layer plays a significant role in protecting us from cosmic particles (rays), however, we've been punching holes in it for the past two centuries. I work at [First Light](http://www.firstlight-magazine.com/), where the little gif was made (it was also [astro picture of the day](http://apod.nasa.gov/apod/ap141202.html)

I wrote an issue about Eta Carinae. 

In truth, this is not a supernova but Eta Car is the best candidate we have to become one some day. It is really massive, and really close (but not too close to outburst us).

TL;DR : This is not a supernova, it's a complex explosion due to a likely two-star system (and there have been likely at least 3 explosions here).
But a supernova might happen in the really really near future (can be any moment or in 10 years). Are the lobes and jets caused by the fact of there being two stars involved, or is something else going on?  Is it possible for a single star to explode and create multiple lobes of gas? Here is a short video explaining what is going on, with amazing 3d modeling used by the science teams studying it. 

https://www.youtube.com/watch?v=0rJQi6oaZf0 What created the lobes and jets is still "unknown", as we can't directly access the inner stars because of the huge cloud of gas.
But the theory is that when both stars are at their periastron (their closest approch), the interaction between their winds and masses disturb the larger star. This stars then seems to "eject" its superior layer. That would explain the shape of the lobes.
The jets are explained mainly because of the other star interaction (but remember we don't see it, in fact its the jets that showed the existence of the other star).

As for the homunculus, there are in fact 3. The biggest is caused by the 1842 explosion, there is also a smaller one due to a smaller explosion in 1870. And another that could have happenned thousand of years ago, there are some remains still visible.

I don't know any example of a star that would "explode" and survive alone, but who knows ?

[The NASA Goddard team just published a new video that explain the stellar winds](http://www.dailymail.co.uk/sciencetech/article-2901920/Delving-deep-stellar-neighbour-Nasa-reveals-massive-star-amazing-3D-models.html), it is really beautiful ! 


http://www.dailymail.co.uk/sciencetech/article-2901920/Delving-deep-stellar-neighbour-Nasa-reveals-massive-star-amazing-3D-models.html
 So when astronomers talk about stuff like this, are they saying "10 years" as in "10 years from our perspective", or "10 years, ***plus*** the amount of time it would take for the light to reach our eyes"? They talk about "10 years from our perspective". 
But you're right, it's always a problem as an astro journalist to talk about years, as these events might have already happened but we can't know it yet because light is still on its way.
 In this case he meant we could see the supernova in as little as ten years. Or tomorrow.

But you are correct in realizing that if we were to see a supernova in ten years, it would have happened many years before from the reference frame of the star system.  So the planets of that star would have gone kaputt almost instantly, but he explosion is so huge that it'll keep exploding at that velocity for decades? Sorry for off-topic, but is "to go kaputt" a thing in english language? As a german, it amuses me.  The US has a large population with German ancestry but a lot of the words are also cognates that entered English by way of Yiddish speakers. 

Kaput, Schlep, Klotz, Lox, "Oy Vey", Schmaltz, Schmutz, Schnoz, Shtick, Shpiel, Spritz, and the word Yiddish itself.  What meaning does it have in German? Kaput in English is an informal way of saying it's broken or became useless.  [deleted] the movie 'saving private Ryan' suggests that the phrase was maybe borrowed during exposure to German radio and loudspeaker propaganda during WWII. I'm sure it was used by many an immigrant before that but it seems like the military likes to come up with lots of ways of saying things are messed up. could be the origin for general use in english.. German was the 2nd most spoken language in in the US until after WWI.

http://en.wikipedia.org/wiki/German_language_in_the_United_States
 OED has citations of it's use in English dating from 1895. I was amused to hear this from the guy at the Germany pavilion in Disney World, after returning a broken mug. Actually some people do use the word kaputt in English as a substitute for broken, I had this conversation with my German girlfriend. It's an older word but some people would still say "My car is kaputt' or something like that. Old comics used to have it too. Though even in that phrase there is a sense of complete brokenness or finality.  Don't know if kaput in German is a fixable broken, but I don't think the American borrowing is fixable. Kaputt is a german word and means "broken" as well.  
I'm so looking forward to use it while speaking english. Most native english speakers dont even realize its a foreign word. I thought it was early 20th century slang until right now. Most native English speakers probably have no idea just how much of our language is just bastardized versions of other language's words.

English is basically the language equivalent of the Borg. To be fair, I suspect a lot of languages are like that to some extent (studied Japanese for a while, and they have a lot of loan words), but America's origin as a nation of immigrants probably makes it a little more common here. That's not true.  The vast majority of native English speakers know we stole it from somewhere.  Most people assume it's Yiddish. Yes, we say it all the time, what does it mean? We use it to mean something got broken, destroyed, ended, demolished. I have a 3 year old so I use it a lot...

I looked it up: 
kaput
/kpt/
adjective 
1.
(postpositive) ( informal) ruined, broken, or not functioning
Word Origin
C20: from German kaputt done for, from French tre capot to have made no tricks (literally: to be hoodwinked), from capot hooded cloak In areas with a historically high German Immigrant population, yes. I come from Wisconsin, and I heard it there all the time.
 Yeah, it's a thing. To break and no longer work with no chance of repair. Yep.  Not used very often, but it is a thing.  Usually used for when an item "dies" 

"My TV went kaput last night and stopped working." "instantly" would be in the order of weeks or months, but generally you are correct. 
 Why does it only loop 5 times? When exporting a .gif in Photoshop via Save For Web you have the option to choose whether it should loop once, forever, or a custom number of loops. I don't know if this particular gif was made in Photoshop but other software with gif creating abilities will have a similar option. this bothers me. i'm looking for differences between the frames and trying to wrap my head around what i'm looking at, but every 10 seconds i have to refresh the page so in my mind i'm making myself look faster for differences because i feel like i'm running out of time even though i can just click refresh. 

tanks for listening.  Recall that a supernova follows when a star "falls into itself" (gravitational collapse). This implosion can be modelled by the same physical laws that tell us how planets go around the sun [^^see: ^^Free-fall ^^time](http://www.wikiwand.com/en/Free-fall_time), and the result is less a second, depending on the density of the collapsing core (~10^9 grams/centimeter cubed). 

[Here's a simulation of a supernova by Caltech's Jet Propulsion Lab](http://www.jpl.nasa.gov/video/details.php?id=1279). Note the timescale in milliseconds (and remember that 1000 milliseconds make a second).  It depends on what part of the explosion you're thinking about!

https://en.wikipedia.org/wiki/Supernova

Visible light output, weeks or months.  A very slow "explosion", except that's because it's so huge.  It may be expanding at 10% of the speed of light.  That is, if you had a planet-sized block of C4 and blew it up, it would blow outwards at a snail's pace compared to this.  

But the "explosion" proper- as if visuals of dynamite has any relevance- is in the initial internal reaction:

&gt;About 10^46 joules, approximately 10% of the star's rest mass, is converted into a ten-second burst of neutrinos which is the main output of the event.

Dat's a BIG BOOM!  The star spends those weeks or months shining and coming apart because of that 10-second event.  This part is theoretical, we cannot measure it. The explosion in 1054 a.d. of the crab nebula was observable by the naked eye during the day for weeks after it was first observed. So if you are simply asking how long you could see the explosion, depending on the distance, a fairly long time. http://www.astronomy.com/news/2007/06/crab-nebula-exploded-in-1054 It's my understanding that a supernova takes a few minutes from beginning to end.  If this is the case then, while not instantaneous like a Michael Bay-esque fireball, it would be incredibly fast considering the star in question would be significantly more massive than our sun. Is it possible we have missed supernovas simply because we were not pointing our telescopes at the right part of the sky? http://en.m.wikipedia.org/wiki/List_of_supernova_candidates

We have a few stars that we expect to go supernova. Scientists think ~~Betelgeuse (one of Orion's shoulders)~~ will go supernova any day within the next few hundred-thousand years. We might be able to see it in our lifetime!

EDIT: I stand corrected, it was Eta Carinae that we may get to see go supernova. My understanding:

The explosion itself might be fairly rapid, but when observed from distance it appears slow because the ejecting mass is still subject to relativity and can't exceed the speed of light. Not true.  If something takes 5 minutes to happen, one million light years away, then it will still appear to have a duration of 5 minutes; it'll just take 1 million years for the event to reach us.   That's not what I'm saying.

When the mass spreads after the explosion, it travels outward for centuries at speeds that appear slow from a distance. That cloud can only move out at sub-light speeds.

Think about watching a commercial jet at cruising altitude from the ground. It appears to move slowly across the sky even though it's one of the fastest-moving objects you'll ever see on earth. Now multiply that distance a couple trillion times and crank up the speed by about 100,000 (speed of light vs an airliner), and the expanding cloud appears to move very slowly. I get what you mean, but that has nothing to do with relativity or the amount of time between events. That still has nothing to do with relativity.

Objects further away seem to travel slower because they need to move faster to cover X ammount of 'distance' in your field of view than it takes for objects that are (much) closer. The light of the supernova explosion may reflect off interstellar gas for many years after the event due to the slow speed of light. [This star is not a supernova](http://38.media.tumblr.com/6e2aa17802d7c29424bc1d1b13011d2c/tumblr_n72dbmvTdF1t5fphqo1_500.gif) but shows a brief spike in brightness slowly traveling outwards over four years and illuminating interstellar gas as it goes. This reflected light is useful for indirectly studying the original event.
 this post got me onto a wikipedia article about all the supernovas we've witnessed before the modern day:

http://en.wikipedia.org/wiki/History_of_supernova_observation

It's very cool. I feel like I'm reading the background for a *Stargate* episode. I've actually seen two supernova's in my life so far: the one in M101 (SN2011fe) and the one in M82 (SN2014j) more recently. Both got bright enough that they could be observed with modest amateur equipment. It is such an amazing feeling to see with your own eyes that a star at about 11.5 million lightyears (and hence that far back in time) is giving out so much light that you can see it from your backyard with a small telescope. I'm seriously impressed and it's stuff like this which makes me want to go and get a backyard telescope. I once had access to an old telescope with a tracking motor but I couldn't figure out how to set it up by myself, it had basic directions and I didn't understand all the stuff in there about azimuths and whatnot, I'm too uneducated.

Maybe soon I can afford one. Another interesting and similar scenario of a major change would be if one had something not quite a star, say a gas giant planet, and decided to drop a nice neutron star into the middle of it, to light up the candle so to speak. It'd be a slow process. The luminosity would ramp up over hours, days and weeks, with a lenghtening time constant IIRC. I think a SF writer or two used this very scenario. It depends what exactly you're referring to.

The buildup takes a long time, longer than human history. As heavier elements build up in the star's core, the equilibrium between fusion and gravity tilts farther in gravity's favor. The core becomes denser, and heats up, and the accelerated fusion reaction releases extra heat, causing the star's outer layers to expand. The Sun is doing this right now, but as a small star it takes billions of years to undergo the process. However, even the largest stars still take hundreds of thousands of years.

However, the actual supernova event is much, *much* quicker. Once iron starts fusing in substantial quantities, the star's core collapses into a neutron star or black hole (or explodes entirely, in some cases) in less than a minute. The effects on the exterior of the star might be slowed somewhat, but you'd still get to see it all happen within a few minutes. You'd be wise to watch from quite a distance, though, delaying the image of the event by days or more (depending on what kind of eye protection you're wearing).

After the supernova, the expelled gas and dust expands outwards, forming a nebula. This, again, is a fairly slow process, with the nebula expanding and dissipating across light years of space over the course of several thousand years.

Note that the Sun is too small to undergo a supernova. At the end of its lifetime, it will have a helium flash, a somewhat similar but less energetic event that doesn't involve iron fusion. The smallest red dwarf stars may be too small for even that to happen, instead just shrinking and gradually burning out over many billions of years. You talk about 'real time" 
 At some point in the next million years Betelgeuse WILL go Super Nova!
 Not a question of if, but when. 

 When it DOES happen, it will take us somewhere around 400 years to find out, because it's around 400 light years away. we have no means of finding out about it that is faster than light speed. That means that whenever it happens, there will be that approx 400 year delay before we find out. No two ways about it. 

That means it might have already happened something less than 400 years ago, and it's just a question of the light traveling across that much space. Remember, that's not very far in deep space. 

When the light does reach us, at it's peak, it will be visible in the daytime, and at night will be brighter than the Moon. It will fade over several night, and I have always wondered myself how long we will be able to see it, both with the unaided eye, and with a pair of fairly cheap, sporting goods store binoculars.

 It WILL eventually fade to a nebula that is only visible with a telescope, and not very bright even then. 

 Sadly, no. Unvaccinated people are indeed at the highest risk, however, while vaccines are very effective, no vaccine is 100% effective. Most childhood vaccines protect between 85 and 99 percent of the population. For some reason, [a small percentage of folks who are vaccinated do not develop immunity](http://www.cdc.gov/vaccines/vac-gen/6mishome.htm).  This hasn't traditionally been much of an issue because with the vast majority of the population vaccinated for a particular disease, we develop "[herd immunity](http://en.wikipedia.org/wiki/Herd_immunity)." The more folks are vaccinated, the harder it is for a disease to spread, and so epidemics become less likely. 

Another issue (though not strictly what you asked) is that some children cannot receive the vaccine. Often this is because they have a compromised immune system thanks to a genetic disorder, or active cancer treatment. While these children cannot receive the protection of the vaccine, they *can* indeed receive the protection afforded by herd immunity. Unfortunately, as more people choose not to vaccinate their children, immunocompromised are put in particularly bad risk. In the case of measles, these children[ have up to a 50% mortality rate](http://www.health.govt.nz/your-health/conditions-and-treatments/diseases-and-illnesses/measles/protecting-children-who-cant-be-immunised-against-measles). 

**EDIT: Thank you everyone for the extensive and productive discussion, but please remember that personal medical anecdotes are not allowed in /r/askscience.** Also, even healthy babies don't usualy get their MMR until 12-15 months of age, so they're vulnerable.  After the late 1980s outbreak, an MMR booster was added to the regimen when it became clear that one MMR vaccine was not sufficient. While most younger people have probably had two shots, older people who have not had two shots may also be vulnerable.  A good example of this vulnerability can be seen in the recent mumps outbreak in the NHL.  Well there were a number of NHL players who caught the mumps after receiving a booster shot before the Sochi olympics last winter. Crosby, Perry and Suter all played in the olympics (and presumably got the required booster shot) but still ended up contracting the virus. I know right now we just do boosters based on a schedule but it seems like we don't necessarily know how long a vaccine is good for before the immunity tapers off.  Would getting titer tests done during checkups before administering booster shots allow us to gather more data to see when the immunity rates are falling off and adjust schedules accordingly? This is what is done during phase III and "phase IV" trials. Vaccine schedules are established based on III's data, and optimized when we get more information about how they work on the general population over long periods of time. I am not sure how this applies in America but in the Canadian health care system we have decided that the data is not worth the additional risk. MMR is simply offered/pushed without testing to adults that present with any other issue.

It makes sense given the stats. Titers can be pretty expensive, even with insurance. Unless you have cash to burn, its probably not a solution everyone can go for. That was actually an atypical strain of the mumps and was not something the MMR vaccine prevented. The truly scary side effect of antivaxers, not only do we lose herd immunity but a greater number of infections also represents a greater chance for mutation since each new patient is in essence a brand new population of the virus. Not to mention the measles vaccine was discovered in the 50's and combined into the MMR vaccine in the 70's.  It took a massive government push to get several generations vaccinated over decades to declare measles eradicated in 2000. With the antivax movement somehow growing, it could take years or decades to correct this. 

Source:
http://m.historyofvaccines.org/content/timelines/measles It's amazing to read this thread of responses from educated, rational people.  I love how the anti-vaxxers spew plain BS and cannot read something objective and internalize it.  Like have you read that pediatricians letter that debunks every single anti-vaxxer myth and actually cites each point with evidence/papers.  Yet they still choose not to believe.  The biggest selling point you would think to them would be how all pediatricians vaccinate their own children... Anti Vaccers are to liberals what Climate deniers and Young Earth Creationists are to Conservatives. 

Idiots who have decided that their "belief" is a better answer than true science. 

It doesn't help that there is an entire industry out there of very bad "science" (in heavy quotes) that skews their results to help these people keep their rediculious beliefs.  There is a growing segment of Conservatives that are also rejecting the "forced" immunization. They reject any mandate from the government as impugning on their liberty. It seems to be tied to devout Christianity. 

So we're now dealing with two fringe groups on opposing ends of the spectrum that are rejecting science and putting Americans at risk. 

I don't want to sound melodramatic but I am markedly more concerned about anti-Science folks than I am of Terrorists. Have we seen an increase of cases in adults, as well?  After all, many don't get their regular boosters.    Vaccinations of adults is indeed a big problem because there isn't really a program designed to keep them current.  The kids have their schools and daycares breathing down the parents necks to get vacinations...nobody does that to adults, but they should.  Yes, we're seeing increases of some of these diseases in adults.  Whooping cough is a big one that's been coming back.  Measles too.  How often is it recommended for adults to get vaccines?   If you're current on all the childhood vaccines, then the only ones recommended for adults would be a tetanus shot every 10 years and an influenza shot annually.  Thanks for the response.  And if you are around babies and such, pertussis boosters are appreciated.  If you have a tetanus shot, you have received the pertussis shot. 
They are now administered together to increase the usage of the pertussis vaccination. There's a new recommendation for adults over 65 to get a pneumococcal booster. http://www.cdc.gov/vaccines/schedules/hcp/imz/adult.html Actually, Britain has [scrapped the pneumonia vaccine](http://www.dailymail.co.uk/health/article-1392594/Pneumonia-jabs-pensioners-scrapped-dont-work.html) for older adults because it doesn't work. That's really interesting. I didn't know this. Thanks for the link.  The polysaccharide vaccine is not as effective for the post 65 crowd, as a booster, because it doesn't involve T cell immunity. The conjugated vaccine, prevanar, does involve T cells, and is effective. Not currently covered in Canada, though. 

http://microbiology.mtsinai.on.ca/faq/prevnar.shtml That tetatus shot should however be combined with pertussis (whopping cough) or you could lose your immunity to that and risk being the carrier that infects a baby. [deleted] In the U.S. military, all members vaccinations are tracked with a universal program depending on your branch. Late last year the program started routinely tracking MMR, Varicella, and Polio and set new bounds for all three. I assume in light of this issue. Good for them.   It makes sense they would do so.  Vaccines are cheaper than treatment.  They also have comprehensive centralized medical records on everyone.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Are you supposed to get boosters?

I never heard of that before, tried looking it up but can't see much, you got a link?

E.g. this FAQ site makes no mention of boosters http://www.immunize.org/askexperts/experts_mmr.asp Every time your body is exposed to the thing that triggers the immune response (your immune response to that particular organism is not to the organism itself, but to a specific protein or other complex molecule produced by the organism), the response is faster and stronger. For some diseases, one is enough. However, for some diseases, your body may develop only a weak immunity to the virus (or bacteria). This means that you can actually develop some symptoms of the disease before the immune system can control it, which means you are also at risk for spreading the disease. Boosters serve two purposes: to expose those who had the vaccine before so that their immune response is faster and stronger, and to give those who didn't develop immunity the first time a second chance. I believe six of the infected from the Disneyland incident are indeed infants and toddlers too young to have been vaccinated yet.  That's was really pisses me off.   I read that at least two of the employees who got sick were vaccinated  Vaccines don't always take. Like /u/sciencepodcaster said, there can be up to 15% of the population that don't develop a good immune response to the vaccine and are vulnerable to infection anyway. That's why herd immunity is so important. Also, some vaccines are only rated for so long(but usually like a decade), so someone who may have been vaccinated may have forgotten to get the booster shot later, as they're not really required for most things except maybe if you're involved with either a medical profession or school. [deleted] [deleted] [deleted] You're right! Good point.  This link from the CDC gives some info about immunity before a baby's first birthday. As long as mom has antibodies, she'll pass them to baby during the pregnancy and they'll provide some immunity through 12 months of age. Scroll down to "Recommendations", and it's the first question. http://www.cdc.gov/vaccines/vpd-vac/measles/faqs-dis-vac-risks.htm

I grew up in an anti-vaccine hotspot, and it's a concern of mine that when I have kiddos they'll be exposed from close family friends who have chosen to not fully vaccinate their kids. However, since I have been vaccinated I feel reassured that I'll likely pass some antibodies on to my babies. Hope this info helps! It isn't only that the babies are protected up until this age, but also that if they were to be vaccinated, mom's antibodies would destroy the vaccine and the child would not have the long term benefits provided by the vaccine. 

(not disagreeing with you, just adding information.) Can you cite some studies/sources on this? I'm curious, then, if mothers who practice extended breastfeeding (past 12 months) could be creating conflicts with other vaccinations. The antibodies in breastmilk don't pass into the baby's bloodstream, but only function in the respiratory and GI tracts, so they only vaccine breastmilk might potentially effect is the oral rotavirus vaccine. This is also why puppies get three rounds of shots.  No one is quite sure when the anti-bodies from the mother wear off so the shots can take effect.   The size of the dog seems to have something to do with it.  It's critically important to get all three rounds of shots as the risk for a puppy to contract Parvovirus is high, it's very sad how many die from it. Not too bright dog person here.  Would I be right to assume mother's antibodies tend to linger longer with big dogs than small? [deleted] [deleted] [deleted] It doesn't work like that.
When you have a vaccination, for about 3 months after exposure yoh will have antibodies in your system. What gives you the long term immunity is the memory T and memory B cells which are created during your immune response to the vaccination. When exposed again to the antigen, these cells rapidly multiple and get the immune system into action much quicker than if your body has never seen the pathogen before. 

Edit:
I am not sure, I never covered it in my immunology classes, but I would imagine the reason we vaccinate at 12 months is because the thymus may not be fully developed yet. 

I wouldn't advise listening to anyone on reddit about science/biology (including me,) you're better off going and reading the research papers yourself if you are interested. Currently studying the immune system in nursing school and our instructor said that the passive antibodies from the mother aren't permanent, so therefore the child has to start producing their own to continue their immunities. I haven't read into it in my textbook but that's what was said in lecture.  Indeed. However, Babies don't really produce sufficient antibody titers until they are around 1 year old (they actually start making some in utero, but production ramps up and diversity increases after 3-6 months of age).  Unfortunately not all mothers can breastfeed, which means those babies don't get any antibodies. The link above doesn't say that the antibodies are specifically from breastfeeding. It states that, "Most infants born in the US receive passive protection...from their mothers." I interpreted this to mean that these antibodies are passed during pregnancy. You are correct. There are also antibodies in breastmilk in response to a current illness, but it isn't only breastfed babies who have partial immunity passed on by their mothers. The question is: ARE the antibodies that are passed on from mother to child due to genetics or previous vaccinations the mother received during her lifetime.
 Babies receive some antibodies through the placental transfer of blood.

They receive some through breastfeeding. This is true. However, antibodies obtained through placental transfer only remain for a couple of months at most. Passive immunity through breastmilk provides protection for a longer period of time. Also, the type of antibody transferred through the placenta (IgG) is not the same as what is obtained through breast milk (primarily IgA).  This somehow needs to be higher. Vaccines are given on a schedule, it's not like a baby pops out, gets all his or her vaccines and is magically instantly vaccinated. New parents rely on the rest of us to get our vaccines to protect their babies until they're fully vaccinated. Which means that parents who choose not to vaccinate are literally gambling with the lives of the rest of our children. 

Edited because grammar. but if the rest of us adults were vaccinated the pool of candidates would be diminished until the virus would either have to evolve a new, stable reservoir or die off. This is part of the problem with Polio as it can remain stable in water supplies for quite some time so if we don't vaccinate 99.9% of the world it will exist forever.  I know you can't "kill" a virus with antibiotics, but are there ways to destroy otherwise stable specimens?   You're correct that antibiotics aren't used for viruses. There are antiviral drugs that can be used for some viruses, but certainly not all.  There are bunches ways to kill viruses, a variety of antiviral drugs for infections and chemical and physical means to treat surfaces.

The thing is though that viruses have a huge range of morphologies even different genetic setups (single or double stranded dna or RNA) and methods of reproduction.  This variety makes it difficult or impossible to deal with all the different viruses with any one treatment.  Some extreme methods like very intense heat and pressure will work in general if course. Outside of a body, they can be killed through chemical exposure, or other treatments, like intense light. There's also a small but significant number of children who receive the initial dose at 12-15 months but don't develop the proper antibodies. These children are not protected until they receive the booster at 4-5 years.  Even though I live in a small town, I didn't really take either of my kids out of the house except for Dr appts until they had 100% of their vaccinations. Right now I have a 1 year old and she just finished her first round. Now she can go places! Maybe I'm paranoid, but at least my babies are safer. Even though we wait to give the vaccines, passive immunity is given from the mother through the placenta or through breast feeding. It is however only short term immunity.  [deleted] And even _if_ it were "just" unvaccinated people.. Keep in mind that some folks are legitimately unvaccinated - i.e., the immuno-compromised, those allergic to some vaccine compounds, those who are particularly elderly, etc. etc. Some also just haven't got their vaccines _yet_. It isn't "just" other people who choose not to or unfortunate children who don't have a choice, it undermines the entire purpose of using a general immunity to protect those who cannot obtain said immunity. [deleted] [deleted] How do they figure out a baby is allergic to the compound of a vaccine? Often exposure - the same way they determine if a baby or child is allergic to other things - like penicillin, dogs, cockroaches, or peanuts.  An allergic reaction develops after your immune system encounters a foreign substance at least once. Although there are many checks and balances to ensure that your immune system functions properly (a proportional response directed at the correct intruder), it can, in rare cases, become sensitized to the new substance. When your immune system encounters that substance again, it launches an attack. This can be a minor reaction (seasonal allergies which are controlled by antihistamines, for example) or a full-blown allergic reaction (anaphylaxis.) 

The reason for the latency between the sensitizing exposure and the next exposure/reaction is that it takes time for your body to make antibodies against the foreign substance. Once those antibodies are present, your immune system is primed and ready for that particular allergen.

Allergic reactions to vaccines are very uncommon, but they can happen -- think in the neighborhood of roughly 1/10,000 chance (0.01%). Not my child, but my kitten had her normal kitten series of vaccines with no adverse effects. When we boosted the vaccines again at 1 year, she had an adverse reaction: within 10 minutes, she started vomiting, so I rushed her back to the vet's office. About 15 minutes after the vaccine, hives began appearing on her skin (visible just in front of her ears). The veterinarian quickly administered steroid and antihistamine injections to calm her immune system, but the end result is that she probably shouldn't have any more vaccines.

Anyway, if you've ever been asked to hang around the pharmacy for 15 minutes after a flu shot, this is why; they're waiting to see if you have an allergic reaction so you can be seen immediately by the pharmacist. [deleted] [deleted] [deleted] [deleted] [deleted] It doesn't have to be the first time, you can develop allergies to things you've been exposed to before, even things you've been exposed to your whole life. I'm not entirely sure if they do pinprick allergy tests on babies, but if the parents listed it as an allergy on their health records some doctors might not want to attempt using medicines containing the substance on the child without further testing. [deleted] Great answer!  Also, the vaccine loses efficacy over time.  A booster is required as a late teen / early adult which many people skip.  So even though you had the vaccine as a child, you may not be immune as adult! FYI - MMR is typically given at 12 to 15 months of age and a second booster at 4 to 6 years of age.  Most people will only ever receive these 2  vaccinations for MMR.  [immunization schedule](http://www.cdc.gov/vaccines/schedules/downloads/child/0-18yrs-schedule.pdf)  For anyone interested Immunize.org is an excellent resource for vaccine info and vaccine-preventable disease.  [pictures of patients with measles](http://www.immunize.org/photos/measles-photos.asp) They give you a booster if you recently had a baby/will be around a baby and are unsure of your immunization record.

At least in my area anyways. In the US most OBGYNs will take a history of MMR vaccinations.  However, they only routinely check Rubella status (German measles).  

[link](http://www.acog.org/~/media/For%20Patients/faq133.pdf)

You are most likely thinking of Tdap (tetanus, diphtheria, and pertussis).  This is given pregnant women and husbands and grandparents are advised to get a booster before being around the baby to prevent pertussis.     [deleted] To add something *vital* to this, and in fact a more important answer for the general population, is that due to having a population in which to propagate, it also allows the virus ample room to *mutate* - don't forget that mutations are random, it's *selection* that is a response to the environment.

**The measles virus can mutate due to unvaccinated individuals giving it the environment to do so, and re-infect "vaccinated" individuals because their vaccine didn't cause them to develop an immune to response to "all measles", just the specific type they were vaccinated against. Cue outbreak.**

... so no matter how many people are vaccinated, if there's an unvaccinated population that allows the virus to mutate, it can re-infect the vaccinated population, causing a horrific outbreak. 

There is, in fact, good ethical cause by which to justify considering not getting a vaccination to be harmful to the public, and worthy of punitive responses, as they risk the well-being of *everyone* solely to justify their own ego-istic need to always been right, continuing to use group-confirmation to believe something that has not only been debunked, but laughed at and tossed out the window - they'll listen to that guy who was lying, but not to *anyone else* showing them all sorts of evidence about how, in the end, [it's better for everyone to be vaccinated even if vaccines *do* cause autism](https://www.youtube.com/watch?v=RfdZTZQvuCo)... which, of course, they don't. Actually, measles is one of the least mutating, most stable viruses. Your reply does describe most other viruses though. Which is exactly why there's a flu vaccine every year(and sometimes even multiple times in a year), but  you only need a measles shot every decade or so(not an exact number of years) in your childhood for the one-dose vaccines(there are some that require multiple parts). Changing flu shots is about viral reassortment and rearrangement which aren't mutation. They're related concepts in that they add diversity to the viral pool, but that's all. 

 That's not true.  The change in the annual flu shot is indeed required because of mutations that arise (genetic drift).  Reassortment is what results in the spread of the new "H" and "N" types - something which thankfully doesn't occur as often as annually. [deleted] I always tell people it's like a seat belt. It will most likely save your life, but every once in a while, it just can't.  It's especially important for the driver to wear a seat belt for the safety of their passengers.  In the case for vaccines, everyone's a driver. Attention folks: **anecdotes and personal medical information are not allowed on /r/AskScience.** We are removing such comments, so please don't post them. Thank you for helping us keep the discussion on topic and scientific! [Here](http://op12no2.me/toys/herd/index.php?scenario=intro&amp;locale=) is a nice, simple model that illustrates herd immunity. It would be nice if one of their scenarios included vaccinated people having a small chance of becoming infected upon encountering an infected person (as is the case with some vaccines) to demonstrate that herd immunity is important for the general population as well as the immunocompromised population. &gt; herd immunity.

There are some people who want to vaccinate their children and agree with herd immunity -- but don't take certain vaccines for ethical reasons.

[This chart](http://www.cogforlife.org/vaccineListOrigFormat.pdf) is hosted by one [website](http://www.cogforlife.org/) that outlines some concern about an association between the development of certain lines of vaccines and willful abortion. I'm not going to argue one way on their logic here but I do think it is important to realize that people are not vaccinating against diseases and we could easily handle their objections.

The MMR, for example, was deemed by some as being immoral. Alternative lines of the vaccine exist but US pharmaceutical companies have ceased to manufacture or import them.

If we could push for the production or import of these vaccines for those with this specific ethical objection, we could increase herd immunity.

It'll be a lot easier to make these vaccines available than to convince someone that their sincerely held convictions on this topic are wrong. So basically, the people not vaccinating themselves or their children are the ones putting everybody at a greater risk. How do diseases "come back"? Since we had a wide coverage of vaccination (before the whole anti-vaccination thing) including all children for a long time, I thought things like measles and whooping cough were on the verge of extinction. How can they suddenly appear inside a mostly vaccinated population?  Reimportation is always a risk until a disease has been eradicated worldwide.  Measles is still very common in some parts of the world.  In 2012 it is estimated that the disease killed [~122,000](http://www.measlesrubellainitiative.org/learn/the-problem/) people in the world.  Most of those cases are in countries where poverty or war have made it difficult for many children but there have been a few cases in wealthier countries.  The [outbreaks](http://en.wikipedia.org/wiki/Measles_outbreaks_in_the_21st_century#Europe) within Western Europe in recent years have infected tens of thousands and killed a handful of people.

The Measles is a disease that spreads very easily.  People can be infectious before they get rashes on their skin and you don't need direct contact with an infected person to get it.  In the pre-vaccine era it was rare to find an adult that hadn't been infected with the disease at some point in their lives.  For those reasons the herd immunity threshold for Measles is relatively high([83-94%](http://sitn.hms.harvard.edu/wp-content/uploads/2010/09/Lecture_1.2.pdf).

Another thing to remember is that unvaccinated people tend to cluster together.  While the overall vaccination rate of your state might be high there may still be communities where a significant percentage of people aren't vaccinated.  If your patient zero arrives in a city like Laguna Beach or Newport Beach(both cities in Orange County, California where there are schools where 20+% of their students that didn't get the MMR shot) they are going to probably come into contact with a lot of people that aren't immune without much effort. Some diseases can infect other animals as well as people, so the animals act as a "reservoir" of active virus, from which people can get exposed and develop the disease. 

Even for diseases that can only exist in humans, there will always be some people within the population that are not vaccinated, or were vaccinated, but did not develop proper immunity. 

If there is any measles anywhere in the world, it has the possibility of traveling to any country, either when a visitor from another country arrives who has the disease, or if a citizen of that country who has no immunity travels abroad. 

This is why disease eradication has to be an international effort - smallpox was only eliminated after several decades of public health workers traveling to remote villages all over the world to administer vaccine whenever outbreaks occurred, and that was after industrialized countries had been vaccinating against smallpox for decades previously.

 Additionally, some people are allergic to certain vaccines, and they too need to rely on herd immunity.  I just want to let you know that I thought your post was very eloquently written, and easy to read, as well as understand. Thanks :) Heard Immunity should be term of the year or something. I've been explaining it a LOT lately, and it's good info for the public.  Just make sure you're explaining _herd_ immunity, and not immunity from being heard.  https://www.youtube.com/watch?v=ZRclbfK5q08

This video gives a good visual demonstration of herd immunity and the importance of high vaccinations rates among communities.

**Edit:** You can also try it out for yourself here:

http://www.software3d.com/Home/Vax/Immunity.php One additional point that a lot of people miss:

People who are immunocompromised (due to HIV, some cancers and cancer treatments, certain genetic conditions, anti-rejection drugs, and some other medications) are at elevated risk *even if they have already been vaccinated.* 

This group is usually brought up in the context of 'populations that can't be vaccinated'. Yes, it's true that people who are severely immunocompromised usually can't be vaccinated. But even people who had their shots as kids and developed effective immunity are at risk if they later go on to develop an immunocompromising condition.

All a vaccine does is teach your immune system how to respond to a pathogen. You still need your immune system to be in good working order when it comes time to actually mount that response. Well said. Sadly a lot of people forget about the immunocompromised whether it be due to a disorder, medications or even pregnancy. I'm on heavy immunosuppressants and work in healthcare so I fear one day I'll eventually catch something because of anti-vaccinators.  Yes, this is the reason I think it's so odd that anti-vaxxers have picked, well, vaccines as their target. They tend to not want to put chemicals in the body and are in favour of things being "natural." But vaccinations are actually the most natural way of dealing with pathogens that we have. 

Vaccines literally only work because they use your natural immune system to do all the work! We have two ways to deal with flu: the flu vaccination, and tamiflu. If you get the flu vaccine, your immune system is what fights off the flu virus. If you don't and you have to get tamiflu, it's a drug that fights off the flu virus.  It seems that if you want to survive the flu in the most natural manner, the vaccine is what you'd go for. 

Weird.  This is why antivaxers are so ridiculously selfish. They cause a gateway of risk to people whose choice was made for them by fate.  In addition to small children who can't be vaccinated yet &amp; have an underdeveloped immune system (newborns &amp; infants), you also have the elderly who often have not kept up on their boosters &amp; also have a compromised immune system. Those who cannot be immunized for health reasons rely on herd immunity.  Vaccination isn't a cure, it's about building a global community that's immune to a certain strain of the germ so that it has no more new hosts to infect and no chances of letting the germ mutate to a new strain. Even that's not possible because of a large number of people with compromised immune systems (*think cancer patients including babies and elderly folks*). 

By also not giving any new hosts, you're reducing the chance of the germ mutating to fight the immunity. By not vaccinating the kids, you're letting measles to mutate to a new strain that WILL infect the vaccinated kids because the vaccination is only for certain strains of measles. 

The closest thing you can do to reduce or eliminate a bug like this is to leave it no more new hosts to infect. That's why Eloba outbreak didn't get so widespread, we reacted in time to reduce any more new infections by not giving it any more hosts. 

Think about what will happen if measles mutates to a new strain that no kids on the planet will be protected from. I would actually steer your train of thought to the fact that if a microbe has no suitable hosts it can be completely eradicated (therefore no potential chance of mutation due to the fact that it no longer exists. ) 

We have successfully eradicated Smallpox in humans and Rinderpest in livestock and have a handful of other diseases that we as a race are attempting to eradicate. 

I also believe (but am not 100% sure) that there are plans to start the eradication of MMR in the foreseeable future.  Some vaccines just allow you to experience a fleeting, weak infection, like flu. You still get it, but it lasts days not weeks, and you get a fraction of the symptoms.   ^^ ++

There are also allergy shots, meant to reduce the severity of your allergic symptoms by exposing you all year long to the stuff you're allergic to.  There is an extra layer on top of the pure medical science. People that are against vaccination tend to flock together - e.g. villages full of people following specific faith. So the diseases have a good beachfront to establish and then spread because these people don't live in isolation.  This is very true, probably an over-looked factor. And if course it's not limited to something like an Amish village, merely the fact that "anti-vaxxers" tend to organise would increase the risks some. Firstly, vaccines aren't 100% effective so you need enough people to be vaccinated such that the chances of a susceptible person coming into contact with the pathogen is very small - if 95% of people are immune to the disease, they cannot carry it and so the people who aren't immune will not be exposed to it. This is called herd immunity and is also important in protecting immuno-compromised people who cannot receive vaccines.

Secondly, herd immunity is also important because it prevents a reservoir population forming in which the disease can mutate and evade the vaccination through adaptation. Even if the only people who catch the disease are the anti-vaxxers, the virus can survive within the population and evolve to beat the vaccine that everyone else received. Since vaccines take so much time and money to develop, this could quite easily devastate even the vaccinated population. In addition to what everyone else is saying I'd like to add to the fact that when you are born you are not given all of your vaccinations at once. You get some when you're born, then you get some in intermittent time intervals. You're not even completely vaccinated until around high school in most cases. Obviously measles is vaccinated against much earlier, but the point I'm trying to make is that the Anti-vaccine crowd puts other peoples kids at risk who would like to get vaccinated but it is too early. I have two daughters and I think about this every time the topic of anti-vacinators come up, I'd be furious if my child got sick or died before they go their vaccine because someone else "believes it causes autism".  Ugh People that think it causes autism drive me nuts. Even if vaccinations did cause autism (to be clear, I'm very well aware that they do not), I don't understand why having a child with autism is just *soooo* much worse than having them dying from diseases that could have easily been prevented. &gt;.&lt; It's a (faulty) risk-analysis. People think vaccines cause autism *often*, but see the diseases they protect against as vague, far-off threats. They know people with autism or autistic children, but they don't know anyone with the mumps or measles. Of course, the reason they don't know people with those diseases is *because* of the vaccines, but they don't stop to think of that. My thoughts exactly.  I find it quite insulting to people with autism, frankly Vaccines aren't completely effective. Sometimes people can't have them, they don't work on other people, and in some cases the disease can still be transmitted to vaccinated people.

The important concept behind the way vaccines keep society safe is herd immunity.  
Each individual may not be completely immune to the disease, but a group of (mostly) immunized people is not a viable environment for the disease.

Let's say we have a disease which is contagious enough that for every 20 people that catch it, 19 of them will expose one other person on average, and then every twentieth person will expose two people. (Ie. each infected person infects 1.05 more people).

We might have a group of 1000 people that have not had it yet.

We start with 1 person infected,  
Then it goes around 14 people or so (on average), now there are 2 infected,  
Then after 22 more cycles, there are 3 infected,  
After 28 more cycles, there are 4,  
After 38 cycles there are 10, 52 cycles is 20 and so on.  
As time goes on the disease spreads and flourishes

Eventually the disease starts to die off in the local population because it encounters more people who have had it than people who haven't. Some of these people will move around though, and the disease will spread from area to area, and it will eventually mutate to the point where a new strain can come back to the original population.


Now let's say 10 of these people move to a vaccinated area with 1000 more people (who are vaccinated but have never had the disease). And let's say the vaccine only prevents ~10% of cases (most vaccines are much more effective than this, but then most diseases are more contagious too). The disease now infects 0.95 people for every one infected.

We start with 10,
After two cycles there are only 9 people with it.
After 5 cycles, only 8
After 15, only 5,
After 30 cycles, only 2 people, and so on

Eventually the disease dies out in the population, before everyone has even caught it once. If the next population is also vaccinated, even fewer people there get it, and so on and so on until the disease goes extinct.

In this (rather contrived) example, a 10% effective vaccine can stop the disease entirely. Most real diseases are much more contagious, but a vaccine which is 80-95% effective (I think most vaccines lie somewhere in this range) can be enough to stop the spread.
 summarising everything I know;

Let's say a person who is vaccinated comes into contact with that pathogen.
Vaccines aren't 100% effective but if a vaccine is 95% effective then it means that only 1 in 20 people coming into contact with the disease are likely to catch it which is much better than everyone catching it.

People who are immunocompromised for some reason I.E Chemo or a genetic disorder cannot be vaccinated so they rely on the fact that everyone else is vaccinated to be protected.
Children under 12 months of age have not had the MMR vaccine also rely on herd immunity to protect them

Let's say an unvaccinated person comes into contact with that pathogen.
they have only the basic primary immune response to the disease and will suffer all the negative consequences which may be life threatening and cause permanent damage before their body can fight off the infection.
in the meantime, the pathogen has replicated many many times and produced and some of those will have varied genetically.
some of these genetic variations may change the antigens on the surface of the pathogen (the proteins that your immune system uses to recognise them as pathogens)

This person then comes into contact with many other people during their miserable day
because the antigens on the surface of the pathogen have changed; vaccinated individuals do not have an immune system that can recognise the new strain of pathogen and so they are not protected and have just had their week ruined.

In an idea world, everyone would be vaccinated against everything harmful.
this would mean that diseases (like measles) have a hard time infecting humans

this also means that they have a hard time replicating

this means that they are less likely to develop a new strain that can overcome the vaccination You have a point about pathogens in unvaccinated individuals getting the opportunity to vary antigenically. However, remember that measles (although it does have a high mutation rate) very rarely changes it's antigens - look at the 60 year long immunity on the [Faroe Islands](http://www.historyofvaccines.org/content/timelines/diseases-and-vaccines#EVT_100506). The more people catch it, the higher the chance of it mutating into a new form that might be resistant against your vaccination precautions.

[Your body adapts to the vaccinated 'examples' given to you, your body forms a defense that only works against that type and form of attacker]

If a disease mutates it can eventually change its form and behavior and your own defense wont recognize it was a threat, letting it breed inside you. Also, some children are either too young for vaccinations, e.g below 12 months,
Or children have autoimmune diseases meaning they have to take immunosuppressants (They basically have a suppressed immune system) Therefore those children can contract measles. Which is why it's very dangerous for people who can get vaccinated but choose not to. Not just for them, but for people who CAN'T get vaccinated.

So, people, VACCINATE! So you have two kinds of immunity: innate and adaptive.
Innate immunity just goes around looking for something to fight, when it finds it, it kills it via various mechanisms.  It eats it as in the case of macrophages, or it shoots holes in it (literally) via the complement system.
Adaptive immunity is a really complex system that gets activated when an antigen (usually a protein) is presented to a lymphocyte.  This starts off a chain reaction where B-cells in your lymph system begin getting trained to hunt and kill anything with that antigen.  These cells hunt down and kill the invading bodies that have that antigen on them.  With the help of T-cells, they create a pretty amazing micro-battle with invaders.  This is usually a surface protein that exists on the invading virus or bacterium.

That is how vaccines work, they introduce that antigen to your body so it can build those B-cells which remain in your blood stream ready to attack.  You will still get the virus, but when you do, you're ready with primed B-cells that already know and recognize that antigen.

Primed B-cells remain in your system pretty much for life.  But as you get older, your thymus shrinks.  It gets harder to produce T-cells, and your immune system gets weaker.  You may have other complications to your immune system from getting older; as it's incredibly complex and reliant on a number of cellular interactions that could be interrupted from something like a hip surgery, a blood transfusion, a graft, etc.  So even though you're vaccinated, your body may not be able to mount the full on defensive needed to fight off certain invaders.

So vaccinations protect teens to middle aged people most effectively.  But young do not yet have developed immune systems, and older people have immunocompromised systems.  These people are most at risk despite being vaccinated.   By getting vaccinated, you're contributing to herd immunity. Herd immunity means that an infection can hardly spread from one person who isn't immunised to another person who isn't. You could argue that it's egocentric not to get vaccinated, since you're not contributing to herd immunity, but rather increasing the chance of an epidemic. And some people, for various reasons, can't get vaccinated. But if everyone else gets their vaccinations, these few people have little to fear.  1) The MMR vaccine is not usually administered until the age of 1, leaving 12 months where a human is only protected by herd immunity. "[A child should receive the first shot when he is between 12-15 months, and the second when he's between 4-6 years of age.](http://www.webmd.com/children/vaccines/measles-mumps-and-rubella-mmr-vaccine)"

2) Some people are [allergic](http://www.webmd.com/children/vaccines/measles-mumps-and-rubella-mmr-vaccine) to certain vaccinations so they cannot receive them.

3) Every single human that is NOT vaccinated is an environment that a disease could potentially infiltrate, [mutate](http://en.wikipedia.org/wiki/Virus#Genetic_mutation) ("evolve") inside of, then become hazardous to the rest of us that did receive a vaccination.

4) Read up on [herd immunity](http://en.wikipedia.org/wiki/Herd_immunity). The more unvaccinated people, the less effectively they're protected by herd immunity and the less effective our herd immunity becomes.

TL;DR: Everyone that CAN be vaccinated SHOULD be vaccinated. Anyone that is not vaccinated is a potential threat to our entire species. Some people have legitimate medical reasons for not being vaccinated, such as the very young and the immune-compromised.  These people rely on herd immunity to avoid catching these diseases, and herd immunity is exactly what the anti-vaxxers threaten. Aside from what has been said about vaccines not being 100% effective there is also the fact that with the virus resurging into the population it has note opportunity to mutate and thus thwart out vaccination and making us need to make a new one. (Like how the flu shot is a different recipe every year)

And that's just taking about the u.s. population. If one of those viruses starts to come back here in the u.s. and spreads to other parts of the world it would be more devastating than usual. Why? Because we have modern medicine. Our usem of disinfectants and antibiotics in our foods means that any virus that thrives here is almost completely impervious to any of our sanitation methods. [deleted] You can not get the MMR vaccine until you are a certain age. My - year old son had it recently. 

We live in so cal. If he has contracted measles before he got the vaccine it could have been very bad. 

It may be their choice but they are putting innocent infants at risk by not vaccinating. 

You know parts of Los Angeles have a vaccination level lower than parts of the Sudan? [deleted] Not only those who are un-vaccinated, some people have an immunity in their bodies which will fight off the disease and render the vaccine useless. You can check if your vaccine worked by getting a blood check done.  To explain, there are two factors that determine your susceptibility to infection. Immune response  (including vaccination) and proximity to the disease.

When unvaccinated children contract a disease, such as measles, they are able to bring it into contact with vaccinated children. Those children then have a chance of contracting the disease anyway, as the vaccine is not 100% effective.

By increasing the number of vaccinated children, you decrease the likelihood that any one will become sick in the first place, but as soon as one becomes sick, the likelihood of an outbreak grows. In addition, every time a person gets infected their is a chance the virus will mutate. Most of the times the mutation is small and does not produce any noticeable effect. However, it is entirely possible that one of these rolls of the dice will come up snake eyes and the resulting change will reduce the effectiveness of the vaccination in the rest of us. The chance of an individual mutation doing this is unlikely but every new infection is another chance to roll the dice. Something else to consider is that some people are legitimately unable to get vaccinated for certain stuff. I have a friend who has been put in the hospital by a flu shot twice, so obviously he can't stay up to date on that one.
So people who can't get a vaccine for a legitimate reason are put at additional risk by people who just choose not to. I was born in 1984. Properly vaccinated with everything that kids now a days are vaccinated for with the exception of the chicken pox, as a vaccine didn't exist back then. When I went into the medical field they checked my titers and I had no immunity to one of the three parts in the mmr and had to get a booster. 

In fact, most people that I check who are adults in my practice, about half them are lacking the immunity. This is not an official statistic, this is just my observation.  Herd-immunity is nothing more than statistical probability of an encounter with a person carrying a contagious disease. The problem is, everyone can be a carrier of an illness/disease without being effected by it themselves even if they are immunized. Immunization just makes it less likely that the inoculated person will become ill from said illness/disease. Outside of countries with good, full coverage healthcare for the entire population, you know places like the US, there are three reasons people go unvaccinated:

1: The very rich will ignore doctors and medicine in favor of their own cultural reasons not to vaccinate. The major case of this in the west is over the unfounded connection with autism. The fact that this has been thoroughly debunked has not stopped these people.

2: The very poor who cannot afford the medical care necessary to vaccinate their children. Thankfully with Obamacare and the mandate to support preventative care this will be changing in this country, but there will always be remnants of this problem as healthcare is formulated now. This also includes undocumented immigrants who for various reasons cannot afford or use healthcare in this country effectively. By making people 'illegal' it creates a false isolation of undocumented immigrants, its like putting people in quarantine for a preventable illness and leaving the door open.

3: They are unable to be vaccinated effectively. This can happen due to various allergies. Or the vaccination did not actually take and so they have had their shots, but they lack the immunity they are meant to confer. So think about how many vaccines you have had, and ask yourself what the chance is that one of those did not work.

Now this isn't too bad. Vaccination gives a group what is called 'herd immunity,' meaning that the chance of unvaccinated people coming in contact with a disease carrier is lowered to the point that the disease becomes rare or eradicated from the population like polio. But if too many people are unnecessarily unvaccinated then this herd immunity is lost, and diseases can circulate through these three populations of people in our society.

If 3 is the only group going unvaccinated, then we should be fine. But if 1 or 2 are big enough then it can disrupt the herd immunity of your community. I've read that anti-vaxers cite outbreaks - including their own children contracting whatever it is - as proof that vaccines aren't effective.

It's like when politicians cut taxes, gut spending on programs, and then point to the programs and say they are inefficient / don't work. These people have essentially created the problem themselves, and on some level intentionally.

"Herd immunity" was already referenced, but what I was surprised to learn is that due to people being allergic to the vaccines and some people simply not developing an immunity (vaccine doesn't work on some small percentage of people), it doesn't take that many anti-vax idiots to screw up the system.

Redditors who know more about this - what's the risk of mutation, or some other way in which new outbreaks could really screw over even those of us who are vaccinated? News strains not covered by current vaccines, etc. [deleted] Dr Gil Chavez made a quote saying people should not be concerned if they have been immunized.  Disney used this quote to say it is safe to come theo their park as long as you have been immunized.  Both of these statements would lead you to believe that you are 100 percent protected with the vax.   This is not the case.    It's especially dangerous for those who CANNOT get vaccines for whatever reason, those people have historically relied on the vaccinated populous to protect themselves from disease, but now that a bunch of people think that vaccines are bad and aren't vaccinating by their own choice, and now we are seeing an increase in disease. So yes it is dangerous particularly for those who aren't vaccinated, but not everyone who doesn't get vaccinated does it by choice.  [deleted] [deleted] [deleted] [deleted] [deleted] Unvaccinated families tend to mingle and live near fellow unvaccinated families.  Sometimes they will be carries for a certain strain of a disease, lets call it Toxic.  As they all live together, Toxic will actually grow and evolve into a stronger and deadlier strain.

Those who are immunized to Toxic are immune to Toxic strain's 1, 2, 3.  The Toxic growing in the unvaccinated community would at some point evolve into Toxic Strain 4.  Now Toxic Strain 4 will start killing everyone and medical research will be a bit late passing out the shots.  The reason for that couls be that:
A). Toxic was suppose to be erradicated and doctors now arent trained for a 100 year old virus.
B).  Did not expect it to evolve again so soon and it being immuned to our immunizations.  [deleted] **Short answer:** Yes, in fact, there are certain plant species on earth that thrive in this environment. 

**Longer answer:** The sequoias, or redwood trees, can reach heights of up to 300 feet. How do they pump water up their trunks that high? Where do they get the water from? It turns out that the wet air, coming off the ocean, will condensed out and form a fog over land. The height of the redwood trees gives them a large and spread-out surface area, providing ample room for this water to condense out of the air and drip down to the roots, [providing the massive amounts of water needed to fuel these behemoths.](http://sunnyfortuna.com/explore/redwoods_and_water.htm)

So yes, such environments exist that thrive on fog and mist, and it seems that as long as there is a steady source of freshwater then life will, uh, find a way. Unfortunately though, [the redwoods are in trouble. Global climate change is causing the misty belt on the Pacific coast to shrink, yielding less mist over the land. If this trend continues, we could lose the redwoods forever.](http://baynature.org/articles/fog-and-redwoods-demystifying-the-mist/) 

Sorry for the preachy bullshit, but I really like the redwoods. Fuck Bruges, Redwood Natl Forest is like a fairy tale world. No where else on earth do you get trees as tall as football fields that are wide enough you can [make a tunnel for a car.](http://www.toocooldude.com/wp-content/uploads/2007/08/redwood-tree-tunnel.jpg) 

 The coast of the Atacama desert in Chile has frequent dense fog but there are places with absolutely no actual rain on record since people started monitoring.

This supports a bizarre collection of weird spiky plants optimized to collect as much fogdrip as possible. [*Tillandsia landbeckii*](http://www.chileflora.com/Florachilena/FloraEnglish/HighResPages/EH1153.htm) is basically a solid mass of bristles to maximize surface area, and is in the same genus as Spanish moss seen hanging from trees in humid southern parts of the United States. [More on this plant](http://www.ann-geophys.net/27/3571/2009/angeo-27-3571-2009.pdf). It might not be as cool as a redwood but you have to give it credit. I remember a cool documentary on Chile's fog plants years ago but I can't find it.

~~Native Americans~~ Canadians figured out how to catch fog using [fog nets](http://ngm.nationalgeographic.com/ngm/0308/feature3/). Apparently I made something up. Another one would be the very odd [*Welwitschia mirabilis,*](http://en.wikipedia.org/wiki/Welwitschia) of the Namib Desert. The Namib is kind of odd in that while there is little precipitation, there is fog.

[Welwitschia has specific adaptations to gather the dew.](http://www.asknature.org/strategy/344a3cdd33c79bf66338033224a231a3) This comprises the majority of the moisture the plant collects. I also remember reading about some kind of insect, or spider that lives there, which stands in the mist every morning then collects the droplets of water that form on its legs and drinks it, which is the only water it gets all day.  Really cool stuff.. I saw a BBC thing about [this guy](http://en.wikipedia.org/wiki/Thorny_dragon#cite_note-4) not long ago, not the namib desert nor a crawley, but might interest you. http://en.wikipedia.org/wiki/Namib_Desert_beetle Possibly the Namib Desert Beetle (Stenocara gracilipes). Huh, interesting. I'm no botanist nor very well educated on flora in particular, but I must ask; does this mean that if you were stranded in a desert and found this plant, you'd have a good chance of getting water from the 'conical tap root?' Not without some sort of nasty extraction process. There's no free water in there, best as I know from (limited) experience in repotting smaller plants. I've never heard of it being used as a water source by indigenous people.

Plus, it's in the [Gnetophyta,](http://en.wikipedia.org/wiki/Gnetophyta) and I would suggest there could be some pretty unusual or outright toxic compounds in there. Afrikaner sure are impressed by its resilience : tweeblaarkanniedood translates into two-leaf-cannot-die So would "tweeblaarkandood" translate into "two-leaf-can-die"?  https://www.youtube.com/watch?v=6PhRzO8TAnc

The Living Planet: Baking Deserts. Narrated by David Attenborough.

Fog moisture collection bit starts at 31:25 &gt; Native Americans figured out how to catch fog using fog nets

The article that you linked actually said that Canada gave those nets to the people living there, native Americans didn't figure that out. It actually said some pre-Columbian natives took advantage of snow melt in that area. My cousin actually did his Phd on the plants (bromeliads etc.) that live up in the trees in the Peruvian Cloud Forests. It's a fascinating place :) I remember seeing something on either NatGeo or Discovery about those Cloud Forests. I found them fascinating. In Chile that fog is called "camanchaca". Small towns in the desert also use fog nets to get water. The Atacama Desert is entirely in Chile. Are you referring to it or to the Peruvian Sierra? In the Atacama Desert the inhabitants collect the "Camanchaca", the name they give to the mist that comes from the Pacific Ocean. I saw a tumbleweed in Chicago. Would Chicago have an environment to sustain these things?  &gt; Sorry for the preachy bullshit, but I really like the redwoods. Fuck Bruges, Redwood Natl Forest is like a fairy tale world. No where else on earth do you get trees as tall as football fields that are wide enough you can make a tunnel for a car.

The trees you could drive cars through are Giant Sequoias (*Sequoiadendron giganteum*), not Coastal Redwoods (*Sequoia sempervirens*).  Giant Sequoias are found in the Sierra Nevadas, quite far from the coast.  Giant sequoias are wider and more massive than coastal redwoods, though not as tall.  The particular tree in the picture you linked is the [Wawona Tree](http://en.wikipedia.org/wiki/Wawona_Tree), a giant sequoia in Yosemite National Park's Mariposa Grove.  It fell down after a heavy snowfall in 1969.  There still exist some giant sequoias you can walk through, and certain coastal redwoods (or clusters of them that have grown together) have been hollowed out by fire and healed over, allowing you to walk inside.

EDIT: Apparently there are a few coastal redwoods on private land that can be drive through, most notably the [Chandelier Tree](http://en.wikipedia.org/wiki/Chandelier_Tree).  The other ones are smaller and a much tighter fit. Oh sweet, thanks for the clarification. I knew that the coastal redwoods were a type of sequoia, but I thought they were also the big ones. I learned something today.  Oh trust me, coast redwoods can get huge. Besides the Chandelier Tree there's also the Shrine Tree, and there are various parks up here with beautiful examples. Unfortunately they say that something like 97% of all redwoods have been cut down, and it's more likely than not that the biggest ones went first, so we'll never get to see that kind of majesty in person again. Sad, really. There are almost no old growth redwoods around anymore.  If you haven't found the "grove of Titans" yet, I suggest you do. It's a very humbling experience. i dont know what kind of tree it was, but in British Columbia Canada there are a couple trees with roads going right through them. I remember them clearly traveling from northern Alberta to Nelson BC,  so these huge tree tunnels on public roads do exist.  I`m from BC, and there are no such trees like the one you speak of. Especially in eastern BC. Had to chime in and say I experienced this the other night. We have a large Norfolk Pine in our backyard (in Australia), and I thought it was raining... until I went out the front yard and realised it was just fog that had rolled in. The backyard was being soaked by the pine-  like a moderate to heavy shower. Very surreal moment.  I can't avoid correcting your "How do they pump water up their trunks that high?". Plants can only 'pump' water about 50 cm (2 ft) and in a tree as large as a redwood, it is the leaves which 'pull' the water up the trunk as water evaporates from them. [Source specifically about this in redwoods](http://www2.humboldt.edu/redwoods/sillett/publications/kochEtAl2004.pdf)

To quantify "massive amounts" [it was estimated](http://dendrome.ucdavis.edu/fbrc/docs/Dawson_et_al_1998_read_for_class.pdf) that the presence of redwoods doubled the capture of water from mist but still 2/3rds was provided by rainfall. You're totally right, and I was going to discuss the hydrology of the redwoods, with the mist thing basically being a footnote in my memory but was ultimately the only thing important to the question. I was going to point out that "they don't actually pump water at all, it's a totally passive process," but I ended up not going back and fixing it, partly because this isn't a physics thread. 

You're right though, and I'm glad someone pointed this out.  Let's just be explicit and say that plants use [capillary action](https://en.wikipedia.org/wiki/Capillary_action) (re: [tree physics](https://npand.wordpress.com/2008/08/05/tree-physics-1/)). Capillary is not capable to reach the heights required, but defiantly plays a part. Water potential and respiration/transpiration are mostly responsible.  Quite. The current best explanation is the cohesion-tension theory as discussed in the source I linked to. How did redwoods survive the last interglacial (which was even warmer)? Given a slow enough change in temp the redwoods can "move" by seeds being blown where conditions are better but if change is too rapid those saplings cannot themselves reach maturity to seed so movement of the species is stopped. Some species can survive periods like that by having long lasting seeds, known as the seedbank effect. The first sequoias are from the last interglacial. Afterwards, their numbers declined greatly and they adapted to foggy climates. 

https://en.wikipedia.org/wiki/Sequoia_(genus)#Paleontology luck! :D  Something that almost rivaled the redwoods were the Lebanon Cedars, and some 
of the big trees up in the Atlas Mountains coastal region. 

Thousands of years of people chopping them down for watercraft, and a slow but steady warming
eventually wiped out most of em in that region. But, they've been transplanted all over the world. 

http://www.etsu.edu/arboretum/images/C.libani.jpg

https://www.haikudeck.com/dans-cedar-show-education-presentation-4uN9jUlDhn#slide-5

http://www.planfor.co.uk/buy,cedar-lebanon,1469,EN

http://www.bibleplaces.com/cedar-of-lebanon.htm

And this, is about the most you'll see of em together, most of those are young trees. 
http://upload.wikimedia.org/wikipedia/commons/5/53/Forest_of_The_cedars_of_God.jpg

Nobody alive will likely see just epic half million acre forests of 300-500 year old trees
like that. Unless the people live for like an extra 275-500 years. :D  The answer is, barely. There times when their range was much wider than it is now and it's slowly shrunk to a small strip of land on the West Coast. Redwoods are awesome and there used to be even bigger trees on the east coast. Imagine!! This can be observed around Mt Tamalpais ~10 miles north of San Francisco.  I rode my bike through there one day and it's kind of sunny when I started from Fairfax, CA.  As I start to ascend it gets foggy and ground is all wet.  People called it rain because that's what it looked like, but it was water condensing on trees falling down.

Also in that general area, you'll notice that south facing slopes have much less large vegetation compared to north facing slopes.  South facings slops have lots of grass, often dry, and few trees in comparison to north facing slope.  The fog gets burned off by the sun on south facing slopes but no so on north facing slopes so the large trees thrive there. Don't be sorry for "preachy bullshit." When you are right, and no one is listening, it's all you can do. Preach on, brother. Don't ever apologize.  Thank you for saying this! In a time when our society needs to hear the truth the most, we've somehow fostered a culture where pointing out major issues (and/or their solutions) is seen as cringeworthy. Things would be a lot better around this joint if people would just slightly alter their definitions of what is "cool" I find that hanging out with different people solves a lot of those problems. Yosemite is one of my favorite places in my state. The redwoods are a critical part of that experience for me.

I've been pretty numb to all the talk of global climate change that people have been preaching, but that hit me pretty hard. Maybe it's time to do something about it :\ I hope there's another place that due to the climate changing, would result it in being a good place for those trees to grow so at least they can survive - just somewhere else. send me seeds! it's near 99%RH here nearly year-round, plus there's a lot of ground water movement. The challenge is not finding the place were it can grown now, but finding a place where the climate will be stable enough for them to grown for hundreds or thousands of years. While this is an encouraging thought, the sequoia redwoods that I'm referring to are gargantuan and ancient. IIRC there's one I've seen that is like 2 millennia old, and a new environment isn't going to pop up overnight.  I can say with confidence that the Redwood National Forest is the most amazing place I've ever been.  Yes, it really is amazingly lush. Check out Sequoia/King's Canyon NP too if you get the chance!! I have to agree with you on the redwoods. No matter how many times I've seen them they still wow me. I am usually speechless when I first see them, it's hard to believe they can be that big.  Bruges is not really your thing? What's wrong with Bruges? Why did they bring Bruges into this? In the film In Bruges, they keep referring to Bruges being "like a fairy tale." [deleted] if you ever get the chance, i would highly recommend hiking the stretch of old 101 just south of Crescent City.  

iirc, the paved part is 2-4 miles north of the Wilson Creek rest area.  the trailhead for [Damnation Creek](https://www.google.com/maps/@41.647831,-124.112794,15z/data=!5m1!1e4) will get you there, just take the trail north instead of down to the creek.

i worked for a lady who did historical work for Humboldt Co. and contributed to some books.  When the "new part" of 101 was done, that ~15 miles had something like 900 degrees fewer curves.

Walking along "old 101" is pretty cool.  Its all covered in moss and in a few places there's less than an 8' gap between trees.

 Is that tree with a tunnel through it still alive and growing? I (believe) that only the outer rings of a tree are still alive and the rest is just structural wood, right? The tree in the picture linked above is the [Wawona Tree](http://en.wikipedia.org/wiki/Wawona_Tree), a giant sequoia (related to coastal redwoods) in Yosemite National Park.  It fell down in 1969.  The tree was still living until then though.  Redwoods and sequoias have a strong ability to heal wounds, particularly those inflicted by fire, in order to prevent infections from diseases, insects, or other animals (though the hole in the picture was manmade, widening an existing fire scar). You can still walk through the California tree, also in Yosemite,  and it is alive and well.  For someone who lives the redwoods so much, I suggest not conflating them with the sequoias -- which, although related, and which have a similar taxonomical name, are distinct in common parlance.  Agreed, it looks like endor there. Also drove my rental car through that tree this past summer. Worth every minute driving there from LA.  [deleted] I am in love with the redwoods as well and was sad to read that last bit. Those gentle giants are my home.  I live very near the redwoods. I thought there has been less mist lately. &gt; How do they pump water up their trunks that high? Where do they get the water from? It turns out that the wet air, coming off the ocean, will condensed out and form a fog over land. The height of the redwood trees gives them a large and spread-out surface area, providing ample room for this water to condense out of the air and drip down to the roots, providing the massive amounts of water needed to fuel these behemoths.

Is it not true that the reason those trees are able to do so is that there is a gradient created by different air pressure at the roots vs. the top of the tree?

 To be honest, I've heard three or four different explanations for the hydrology of giant trees, most of which contradict each other, and I'm still not entirely certain who to believe. I'll probably spend some time digging through the literature to figure it out tomorrow.  Yes, an example of where this happens are the [fog deserts](http://en.wikipedia.org/wiki/Fog_desert) like the Namib desert in Africa and the Atacama desert in South America. Plants that specialize in acquiring water from fog are called nephelophytes. The [namib desert beetle](http://en.wikipedia.org/wiki/Namib_Desert_beetle) is also an insect that collects its water from fog, condensing it on its wings before collecting and drinking it. Here are some images of how it collects fog: [1](http://www.asknature.org/images/uploads/strategy/dc2127c6d0008a6c7748e4e4474e7aa1/biomechbglowres.jpg) [2](http://www.asknature.org/images/uploads/strategy/dc2127c6d0008a6c7748e4e4474e7aa1/biomechanics1.jpg). How do they get sunlight for photosynthesis? [deleted] &gt; Plants that specialize in acquiring water from fog are called nephelophytes.

How do the **nephelophyte plants** get sunlight for photosynthesis? Fog deserts aren't perpetually covered in fog, if that answers your question. I hope I did not misunderstand you. Even when foggy, it's not exactly pitch black. I don't know what the exact light levels are in the Atacama desert, but a foggy day is still brighter than the forest floor, where many plants adapted to the light levels live just fine. Sounds like you're describing a [cloud forest](http://en.wikipedia.org/wiki/Cloud_forest)! I've been to the one in [Monteverde, Costa Rica](http://www.monteverdeinfo.com/monteverdes-cloud-forests.html) and while I'm not sure that it *never* rains there, per se, the forest definitely does get its water primarily directly from the clouds passing through the high-elevation forests. Very cool! Also interesting to wonder how it would effect the development of science if we could not see the sky.

Lots of scientific and mathematical technique came from folks trying to figure out the motion of the moon, sun, stars and planets. If you want to explore this in SF, Stephen Baxter explores alternate earths where the moon forming collision went slightly differently. One of them involves an earth covered by a shroud of thick mist. The book is called manifold origin.

The society that evolves actually develops a stationary hurricane around one of the world's biggest peaks to study the sky. &gt; manifold earth

I can't find any book by Baxter with that name. Only Manifold Time, Manifold Space, and Manifold Origin.

 Apologies. You're right. All three are excellent, but I believe the book is manifold origin. What book of Baxter's is that? The Long Earth? It's from his Manifold series, Origin IIRC. That's the third of three, I would recommend reading all three in order, but they are fairly standalone.  The Long earth series is excellent and is a little similar, but the book is manifold origin.  It would be like we were on Krikket before they saw their first spaceship [deleted] Don't you think you'd end up drowning since you're like always drinking  Drowning means fluid in the lungs. Drinking means fluid in the stomach. But when you breathe in steam, you're inhaling it right? How come you don't drown after sitting in a sauna for a long time? Drowning happens because the liquid in the lungs stops you from breathing air. In a sauna, although the air is very humid, the water can't condense in your lungs any where near fast enough to do any harm, and you can just absorob it along with the rest of the mucous in your lungs. Mucus in the lungs, not mucous. Mucus is the substance, while mucous is the adjective describing something related to mucus, such as the mucous membrane. [deleted] [deleted] meug means slimy/wet, so that's where mucus comes from.

mucous comes from "of or pertaining to mucus", as ous means "of or pertaining to".  

Examples include:  adventurous, obnoxious, anxious Except the epiglottis only opens/closes one pathway at a time. You can either send contents to the lungs or the stomach. If the air is moist enough that breathing is drinking, you're going to have problems with one of them (barring an evolutionary adaptation). In theory, at least, you'd evolve a way to handle the excess water. Not sure how that would work, though...
 why not just have gills at that point depends on the % water to air ratio. If more air than water then lungs if more water than air then gills I'm thinking you guys have never lived in Florida. After three years I adapted to the 80%+ humidity. 

I then tried to take a vacation to Colorado. It did not go well: eye-stings to the point of needing artificial tears constantly, sore throat, and I had to lotion everything.  Eye drops in Colorado? No need to lie. It's legal there. Oh I wish. I visited in 2009. The clock went from 4:19 to 4:21 every day as I scratched and wheezed my way through my "vacation."

 Why not just have gills that lead to the lungs? You breath in collecting oxygen in the water through your gills, the the air goes to your lungs.  Respiration requires a moist surface.  I could see the water content put out by the tissue responsible for gas exchange to be reduced because extrinsicly-sourced water is more abundant.  Just a small physiologic tweak. Well I imagine it wouldn't be enough to drown you, but enough to make it so that you'd need to drink less than you do now. I live in Seattle.  During the winter, I drink a couple glasses of water each day and do just fine.  When I visit family in Colorado?  8+ glasses and I have to slather my entire body in moisturizer twice a day or instantly dry-freeze into Amon Hotep. You would have mold...lots of mold. It would cause health issues for a fair number of people. The thing is that H2O is a big greenhouse gas so it might get pretty hot. Maybe the habitable zone would be further from the star then. If a planet is good at trapping heat, it could maintain earth temperatures at further distances from its "sun".  You know how hot days really suck even more when it's humid? Sweat would do nothing  I think it should be noted that some life could exist in these conditions, but it would not support all life forms. There are many plants (and animals) that thrive in very specific rain cycles. Look at regions that have a specific rainy season each year, or alternately desert plantlife. Such fog/mist would not support the forms that have adapted to different conditions. Which is actually part of what makes biology so cool, since different lifeforms are really well suited to such crazy different environments.

Also, just for the record, if a global mist cloud did exist it would disappear within 24 hours. The earth would rotate, and at night the mist would condense out of solution. Then the next day the sun would heat the water up, causing some to evaporate. The water cycle is unavoidable. :) &gt;Also, just for the record, if a global mist cloud did exist it would disappear within 24 hours. The earth would rotate, and at night the mist would condense out of solution. Then the next day the sun would heat the water up, causing some to evaporate. The water cycle is unavoidable. :)

Totally possible on a planet without sunlight heated by geothermal activity, or something. Or a planet with some weather that caused the day/night solar variance to be minimal, like a lot of wind and/or or a thick cloud cover.  Are you really sure that a humid atmosphere is impossible to sustain? Obviously we aren't just talking about a one time thing, there would be a water-cycle to sustain it. Water would condense and then go into the solution again, why is that impossible? I think it would have more to do with adding other factors into our atmosphere to keep it at the right temperatures/stability to maintain a perpetual global mist that isn't possible because like r/ATownHoldItDown explained with the simple fact how the air heats and cools between the day and the night. Just look at the varied temperate zones, not even considering rotation, just the amount of near constant light exposure on a curved surface. While I wouldn't say definitively impossible, if there were some other elements added that made this simple fact irrelevant I'd hazard to guess we'd have much bigger problems on our hands than if life had to only survive through perpetual mist. There would be some other element, and likely far more menacing than some fog that life would have to battle through that makes the question moot. Because the mist would then be but a side effect to a much larger, and less benal problem. Well the story is that the mist came out of the ground continually. Pumped from some eldritch reservoir. The same source of water was supposed to be partially responsible for the great flood.  There are [small, coastal sections of the Atacama Desert](http://en.wikipedia.org/wiki/Pan_de_Az%C3%BAcar_National_Park) that  have ecosystems that rely almost entirely on coastal fog rather than rain. This is tangential to the biological question, but there's no way you could avoid convective precipitation unless the world was heated perfectly evenly. This means no planetary tilt, no 12-hour day/night cycles, and no land-sea contrast for starters. Genesis does not say that there was no rain before the flood--most of the flood water was not even rain to begin with.  It came from mostly underground sources. This is suggested by the fact that it describes that Genesis 2 describes streams coming up from the ground. Additionally, there is no reason to think that the normal cycle of evaporation and condensation for precipitation did not occur. I believe the coastal areas of Namibia get the majority of it's moisture (very little tbf) from the fogs that roll in off of the Atlantic.

There's other examples of places where think fogs are frequent and plants utilize the heavy condensation that develop and drip down their bodies.

Fortunately for us it's unlikely Earth would ever go rain-free. As long as the atmosphere possesses water and atmospheric particulates for the water to condense on to, rain will occur. I've been there, well north- west coast of South Africa just across the border from Namibia fog so thick you can't see across the road. It basically never really rains, the fog belt extends abt 8kms inland. Although its pretty much desert there us enough airbourne moisture to support potatoes and watermelons  Did you just abbreviate "to be frank"? If so, you're my new hero. [deleted] As long as there is some type of moisture and/or availibility of water in any given time, an organism can survive.  This mean to say a biomass can live if there is enough surface area in correlation to the density of the fog/rain's water.  Fog and rain are both water. [deleted] This isn't the place to discuss conspiracy theories and pseudoscience.   Naturally most people will go into a wild screaming session as soon as anyone mentions anything about the Bible.  But interestingly enough, in the Genesis account it mentions that there was a vast amount of Water suspended above our atmosphere, encircling the Earth (seemingly) and vast amounts of water that came from inside the Earth.  Both of which were released during the Flood.  This would account for several interesting things we have observed through science.  But recently there have been indications of VAST amounts of water locked inside of ring woodie inside the Earth.  Does this prove the Genesis account is true?  No.  But it does support the idea of vast amounts of water being inside the Earth to begin with. 
http://www.usatoday.com/story/news/nation/2014/06/12/water-earth-reservoir-science-geology-magma-mantle/10368943/
 Giant redwoods can get so tall due to fog IIRC The redwoods grow taller in Northern California and Southern Oregon because there is more rainfall there than Central California. You're right in the sense that they do pull moisture from the consistent thick mist along the coast. &gt;I was reading the book of Genesis and the account of no rain before the great flood.

No you weren't. The only thing close to such a claim in Genesis is in the Jahwistic creation narrative in Genesis 2, which states that it had not yet rained when Man was created. The claim that there was no rain before the Flood appears nowhere in the Bible.

The idea that Noah had never seen rain before is generally to be found only among crackpot "creation scientists", usually accompanied by overlaboured nonsensical toss about "orbital vapour envelopes" and the like.

I'm guessing this is where you got the idea. I had heard it before and remembered it while reading. It's a minor difference in time, the question is more about the logistics of the thing, not theological questions.  Genesis 2:6 NIV
[6] but streams came up from the earth and watered the whole surface of the ground.
 So the the Jahwistic creation narrative in Genesis 2? Exactly as I stated? Early 20th century physician Julius Wagner-Jauregg used malaria to 'cure' syphilis. It was known as [malariotheraphy](https://en.wikipedia.org/wiki/History_of_malaria#Malariotherapy). He won a [Nobel Prize](http://www.nobelprize.org/nobel_prizes/medicine/laureates/1927/) for it. It is also interesting to note that penicillin was discovered the year after he was awarded the Nobel Prize and was applied to treat syphilis shortly thereafter. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Is that not like trying to fix a house fire by bombing it to the ground? They had no antibiotics, and couldn't kill syphilis, malaria gave you a severe fever that killed syphilis, and they could cure malaria with tonic water (this is where the drink, gin and tonic comes from).

So the solution to cure syphilis was to give you malaria, and once the fever gets going, give you tonic water (really a few gin and tonics). You would be cured of both diseases. Tonic water was a whole lot stronger than what we get from the store today.

Similar to evicting someone by lighting the house on fire and then putting it out. It works, and you know how to put the fire out, you didn't know of other methods to evict the person. Haha that sounds way cooler. Thanks for the explanation It was the quinine that stopped malaria, the tonic helped make it palatable, and the gin more so. Early quinine formulas were primarily prophylactic, not treatment.

Once you developed chronic malaria infection, there was not a lot you could really do to get rid of it. Chronic tends to imply that it can be lived with, meaning that it is survivable. In a sense, but it contributes significantly to morbidity and mortality figures. A significant percentage of people in west Africa have chronic malaria. It's not a pleasant disease, and it can easily kill people with compromised immune systems.

Imagine having chronic recurring influenza that just pops up from time to time.

Car accident? Need surgery? Other infection? Your malaria pops up and kills you.

 Note that today's tonic water contains only a tiny bit of quinine.  The actual therapeutic version from back in the day would have been a lot more bitter and unpleasant than what we have now.  Ironically, people now use tonic water to make the gin more palatable, but originally it was the gin that was supposed to improve the taste of the tonic. maybe a better example would be when firefighters intentionally set fires to try to stop the path of spreading wildfires. Well, no. It says right there "While about 15% of patients died from malaria, this was preferable to the almost-certain death from syphilis." Oh, so that's kind of their old version of our Chemo therapy of today, huh?? [Technically, "chemotherapy" is older than malariotherapy.](https://en.wikipedia.org/wiki/Chemotherapy#The_term_chemotherapy) ...or any medication, really. 

There are always side effects, even from something as seemingly benign as Pred. The trade off is always a gamble, though there's usually a good way to bet.   If he really that evaluation, it's a progressive risk-benefit assessment for a drug. A drug is essentially anything that corrects, modifies or restores a biological function (loosely drawn from Italian/EU legislation), treating malaria inoculation as a drug the most recurring side effect was.. well, you get malaria but treat syphilis. I honestly think that's brilliant. Honestly its not far from what we do with chemo. There are people that die from it but its preferable to cancer Not even close.  Very few people directly die from chemo, neutropenic infections are likely the most common reason.  But it's not anywhere close to 15%.  People can get secondary cancers averaging about 15 years later.   [deleted] According to the wiki the syphilis he was treating was terminal and malaria was in comparison very treatable. He effectively brought the chance of survival from 0% to around 85% [deleted] [deleted] [deleted] [deleted] So,  sickle cell anemia protects from malaria,  which protects from syphilis.  Can we extend the chain?  But if you have sickle cell anemia, you can't use malaria to cure your syphilis.  If only syphilis cured sickle cell anemia, we would have a nice disease version of Rock-Paper-Scissors going. Doesn't matter, from hereon out I am playing malaria-sickle cell anemia-syphilis with my six year old.  It depends on how you want to interpret that question.  Let's take a classic example: [sickle cell anemia](http://www.nhlbi.nih.gov/health/health-topics/topics/sca).  Individuals who carry both alleles for sickle cell have the disease, which is serious.  However, individuals that have only one allele for SCA are protected from [malaria](http://www.cdc.gov/malaria/about/biology/sickle_cell.html).  

So is the disease beneficial to humans?  No, not if you have both alleles.  But you might make the case that it is beneficial if you are an unaffected carrier. Cystic Fibrosis is another example. Homozygous for CF = bad. But heterozygous for CF seems to have a protective benefit against Cholera. More specifically, it's protective against the lethal effects of diarrhea. It's thought that this is how it came to be such a prevalent mutation in some populations, because people without one CF allele would be more prone to die from Cholera. Very interesting. My professor from quite a few years back had laid the hypothesis a possessed a single CF allele had better water retention and wasted/lost less fluids than normal people. I'm not in research anymore, but I've always wondered what that hypothesis would eventually develop into. Thanks! [deleted] Cholera toxin activates the cystic fibrosis transmembrane conductance regulator (CFTR) to increase transfer of chloride ions into the bowel lumen. Other electrolytes and water passively follow, resulting in watery diarrhea.

People with cystic fibrosis have defective CTFR, resulting in an inability to appropriately transfer chloride ions across the cells.  This causes mucus in the lungs, pancreas, and other organs to get unusually thick and sticky, resulting in lung disease and malnutrition associated with CF.  As far as I know, the cilia are normal, though their function is likely limited by the tenacious mucus at the cell surface. It's probably worth explicitly mentioning that normal people have a normal Cystic Fibrosis Transmembrane Receptor, as that really makes a lot of sense There's also suggestions that being a CF carrier (i.e. not a sufferer) also protects against tuberculosis. 1/25 Europeans are CF carriers (most don't realise). Tuberculosis has been one of the biggest killers over the last 500 years (and still is) ..

http://www.newscientist.com/article/dn10013-cystic-fibrosis-gene-protects-against-tuberculosis.html#.VLBH04t338s From a certain point of view, there's an interpretation of how the Black Plague helped the 50% of Europe who survived it (from http://www.livescience.com/2497-black-death-changed-world.html)

&gt; Social effects of the plague were felt immediately after the worst outbreaks petered out. Those who survived benefited from an extreme labor shortage, so serfs once tied to the land now had a choice of whom to work for. Lords had to make conditions better and more attractive or risk leaving their land untended, leading to wage increases across the board.

&gt;The taste of better living conditions for the poor would not be forgotten. A few decades later, when lords tried to revert back to the old ways, there were peasant revolts throughout Europe and the lower classes maintained their new freedoms and better pay.

&gt;The Catholic Church and Jewish populations in Europe did not fare so well.

&gt;Distrust in God and the church, already in poor standing due to recent Papal scandals, grew as people realized that religion could do nothing to stop the spread of the disease and their family's suffering. So many priests died, too, that church services in many areas simply ceased.  Interesting - that's a very different interpretation of the question because it addresses how a disease affected humanity overall.  I was trying to think of examples of how a disease directly benefitted the health of the individual.

Very interesting contribution, thanks! Here is another example - Edward Jenner using cow pox to cure small pox. 

&gt; For many years, he had heard the tales that dairymaids were protected from smallpox naturally after having suffered from cowpox. Pondering this, Jenner concluded that cowpox not only protected against smallpox but also could be transmitted from one person to another as a deliberate mechanism of protection. In May 1796, Edward Jenner found a young dairymaid, Sarah Nelms, who had fresh cowpox lesions on her hands and arms (Figure (Figure33). On May 14, 1796, using matter from Nelms' lesions, he inoculated an 8-year-old boy, James Phipps. Subsequently, the boy developed mild fever and discomfort in the axillae. Nine days after the procedure he felt cold and had lost his appetite, but on the next day he was much better. In July 1796, Jenner inoculated the boy again, this time with matter from a fresh smallpox lesion. No disease developed, and Jenner concluded that protection was complete.

http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1200696/

 [deleted] [deleted] [deleted] You could go a step further and include diseases that don't affect humans directly, such as those that affect agricultural pests. Botrytis mold , aka "noble rot" is AWESOME for dessert wines, not so much dry wines and other fruits. That's what I was thinking about when I read the question. Are there any major examples of diseases afflicting other organisms that humans benefited from? Maybe not a measurable 'benefit' but a lot of times beautiful patterns in flowers are caused by viruses.  They don't hurt the flowers, but cause them to look a certain way that humans tend to find attractive.  It is probably a net benefit to the propagation of the flowers since humans will be more likely to plant more of them, as well. The same goes for a lot of the fancier variants of wood for furniture and art. Do you have any sort of source for this? That's super interesting!  http://en.wikipedia.org/wiki/Tulip_breaking_virus

The tulip mosaic virus is responsible for creating flowers so beautiful, they helped one of the first major economic bubbles.

This virus does eventually leave the bulbs unable to grow and flower, however.  Does penicillin count? Or cowpox? Like in the War of the Worlds? This is what makes the question in the OP one of the most interesting I've seen on AskScience in recent times. It's such a simple question, yet open to many different interpretations. From the word 'disease' (bacterial, viral, genetic disorder?) to 'beneficial' (directly benificial, or benificial in the long term?) and 'humans' (the individual or humanity as a whole?), it seems like every answer in this thread interprets the question in its own way. I guess not surprisingly we even have an answer about semantics.

I'm sorry for this ramble, I just really love this question! I'm not entirely certain if OP is just talking about pathogen type diseases, but if something is beneficial to humans, we typically don't view it as a disease. Like...if someone has a genetic difference that benefits them in some way, we don't view it as a disease. If I have more muscle than normal or a very resilient immune system or anything that makes me healthier, it's just looked at a benefit. If I have a genetic issue that harms me, it's viewed as a disease.  So it's sort of a definitional thing. If it's good, we don't call it a "disease" Kinda reminds me of the book Contact where all these social benefits were gained just by trying to build "the machine". If you've not read The Selfish Gene, I can't recommend it enough.

One of the things it explains is that a 'parasite' can generally be expected to benefit its host if and only if its reproduction is tied to the reproduction of the host.

There may be some redditor better qualified than I, willing to explain this further. [deleted] [deleted] If something benefited a human without causing a negative side effect, we wouldn't call it a disease. Your stomach is filled with all kinds of bacteria... but we don't call that a disease or infection because it's helping you. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I also read somewhere that being anemic greatly increases the odds of survival during the black plague.
The book was called Survival of the Sickest, I highly recommend it. IIRC, the descendants of the surviving population were also more resistant to certain subsequent diseases, though I don't remember which ones off the top of my head. HIV, according to a segment back when Discovery was still good. I'm not sure how much stock to put in that, though. I believe it was based on tests done on the residents of an Austrian (?) village, most of the residents of which descended from plague survivors, as that was the reason the village had been founded back then. Like I said though, I have no idea of the credibility but I thought it was interesting. I'd love for someone with more knowledge on this subject to chime in! It's more likely to have been smallpox, actually. The CCR532 allele hasn't actually shown to have any positive outcome on an individual's ability to survive bubonic plague, but it does confer survivability to vaccinia virus, which is very closely related to smallpox. I'll just quote a post I made previously:

&gt; The CCR5-32 allele, which has been implicated in resistance against HIV (CCR5 is HIV's coreceptor), is found in populations of European descent. It had been previously theorized to have come into prevalence due to the plague, however smallpox has actually been found to have been the [more likely contributor](http://www.pnas.org/content/100/25/15276) for this particular example of selection pressure by a human pathogen. Indeed, [the allele has been found in human remains dated prior to any known outbreaks of bubonic plague in Europe](http://www.nature.com/gene/journal/v6/n4/full/6364172a.html), but after the estimated arrival of smallpox. In fact, prior immunization to smallpox using vaccinia virus has been reported to [inhibit replication of CCR5-tropic HIV-1 in vitro](http://www.biomedcentral.com/1471-2172/11/23), and CCR5 expression renders cells permissive to vaccinia virus infection. It's also [been theorized](http://www.nature.com/news/2005/050307/full/news050307-15.html) that the Black Plague (or possibly smallpox) increased Europeans resistance to HIV. Thank you very much for that information. I will now read further into this topic. Sounds very interesting. If you wanted to take your interest further 

http://www.amazon.com/Distant-Mirror-Calamitous-14th-Century/dp/0345349571 It's things like these that make me go to a university library and read for hours. I'm going to piggyback on this and recommend William McNeil's Plagues and People. It's a history of how major diseases and epidemics have shaped history. If you choose to read it, get the newest version that includes the AIDS epidemic. It's a fascinating read. Especially if you live in tropical Africa, where this adaptation is found. It's reasonable to believe that some humans over thousands of years, evolved the sickle cell as an adaptation to the onslaught of malaria, as a survival mechanism.  Right - this probably explains why the mutation persists in the population.  Asymptomatic carriers had a survival advantage, even if homozygotes were at a disadvantage. [deleted] untreated homozygous sickle-cell sufferers rarely live to puberty and those that do are rarely in any shape to reproduce, especially females.

On the other hand there are other genetic and cultural adaptations to survive malaria that aren't as life crippling if at all harmful. Most are just differences that allow for more oxidants in the blood.
 A species doesn't mutate on purpose. The mutation is random, then is selected for or not depending on selective pressures, such as malaria infection. [deleted] Also, Tay-Sachs disease among Ashkenazi Jews in Eastern Europe evolved as a prophylaxis against Tuberculosis. It's not something you want, but when Jews lived in ghettos in high concentration, TB was a very real threat.  It's been a while since I read up, but I recall that the jury is still out on the theory that Tay Sachs providing TB resistance to carriers: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1685035/ Not OP, but I got the impression they meant a microbial infection. Isn't a genetic feature like sickle cell only considered a disease to the extent that it's harmful? I agree: that's why I said it depends on how you interpret the question.  But the definition of the word "disease" is much broader.

Disease: [a disorder of structure or function in a human, animal, or plant, especially one that produces specific signs or symptoms or that affects a specific location and is not simply a direct result of physical injury.](https://www.google.com/search?q=define+disease&amp;oq=define+disease&amp;aqs=chrome..69i57.4703j0j4&amp;sourceid=chrome&amp;es_sm=119&amp;ie=UTF-8) I'd like to add that if you want to explore "beneficial" from the social sciences perspective, the Black Death was "beneficial" to European economy. After the disease had mostly died down, the reduced labor pool allowed greater wages and labor rights for laborers, setting the foundations for strong guilds and trade unions. Yeah I was going to say sickle cell anaemia. It's actually one of the very few examples of heterozygous immunity. [deleted] [deleted] How about [Cowpox?](http://en.wikipedia.org/wiki/Cowpox)

It was historically used to vaccinate people against smallpox, since it's rarely fatal to humans and humans who have gotten over cowpox are usually immune to the related but much more dangerous smallpox virus.

It's scientific name, Vaccinia, is actually where we get the word 'vaccine' from. Cowpox and vaccinia are actually two distinct viruses. Unfortunately, the origin of vaccinia virus isn't really clear, as it has no natural host and is purely a laboratory virus (and was used in the eradication of smallpox). It's actually more closely related to horsepox than to cowpox, interestingly. It's also possible that it may have speciated from cowpox after continuous passage in humans, but the history behind it is pretty murky.

In terms of that wikipedia article, I'm not sure where they're getting the sentence "The virus, part of the orthopoxvirus family, is so closely related to the vaccinia virus that the two are often spoken of interchangeably", as I work in a poxvirus lab with vaccinia, and have never heard them being referred to interchangeably.  Thanks!  It is true about how the milk maids that got cow pox were mostly immune to small pox, right? Yup! That's indeed what happened, and how Edward Jenner first devised the idea as using it as a vaccine against smallpox. The cool thing about orthopoxviruses is that they're all closely related, antigenically speaking, so that infection with one confers protection to most of the others. Unlike influenza for instance, which experiences a good amount of antigenic drift and antigenic shift. Thanks for the info. The wiki article was a little misleading on that point. You should edit the article with the correct or less confusing information! Sounds like YOU need to make an edit to the wiki page. Isn't that how it's supposed to work? Experts offer edits, other experts agree, it's written in internet stone. That's the intention, but in reality:

Expert makes edit.

Some loser who has been married to the article for 8 years reverts edit because power trip.

Expert remakes edit.

Loser editor bans expert. Fun fact, Vaccinia is not actually cow pox. It more closely resembles horse pox. we don't know where the Vaccinia virus was originally obtained.  Wait. The vaccinia virus just...appeared? How do we not know where it came from? http://en.wikipedia.org/wiki/Vaccinia#Origin

No one knows because records don't exist. It didn't just magically appear, just someone forgot to write it down, or else it speciated from horsepox or cowpox at some point and the technology didn't exist to figure out when. This is in the 1800s at some point, so medical technology is quite primitive. Really good answer, I just read [this](http://nowiknow.com/the-smallpox-boat/) from Dan Lewis' awesome now i know daily email. A bit late to the thread but has anybody mentioned Gilbert Syndrome? Where high levels of bilrubin in the bloodstream can result in episodes of jaundice/ IBS/ nausea etc.?

Benefits from the elevated bilrubin levels may include the prevention of heart attacks due to the (bad) LDL cholestrol becoming oxidised before it can form plaque in the arteries.

Edit: A word
 I just posted this then saw you posted it. You're right. Bilirubin IXa acts as a potent antioxidant that is productive in what you conveyed [deleted] Our genome is thick with left over portions of viral DNA. Pieces of genetic code left after our ancestors were not killed by a viral infection and replicated during regular cell division. [Some of these may actually be benificial.](http://genetics.thetech.org/ask-a-geneticist/junk-dna-not-so-junky)

Note; I am not a scientist nor do I play one on TV. My favorite example of this is the endogenous retrovirus (ERW) that allows fusion of the cells lining the placenta. Without this ERW, reproduction in primates would be very different.  Do we have an idea of how reproduction would be different without those genes? Sure, we'd lay eggs, just like the rest of the vast majority of sexually reproducing chordates. Just how big would a human egg big? And what point of gestation would the egg be laid? The placenta evolved long before humans did.  For all we know, without placentas, humans wouldn't ever have evolved at all.

It's fun to think about. and which would come first? Don't forget about the RAG genes! They are believed to have been evolved from DNA transposons, and without them our immune systems would be horribly crippled. Only primates, not other placental mammals? How are scientists able to determine if that viral DNA is acquired by our human ancestors when they have a virus versus DNA that's a relic of the genome of our super-duper-ancient virus-like ancestors?  There are plenty of genetic "conditions" that have positive side effects such as Myostatin-related muscle hypertrophy which causes increased muscle growth. But this isn't considered a disease at the current time. It is important to note that we define diseases to be pathological or negative for humans, and this is dependent upon context. In our current calorie rich lives a high muscle low fat genetic condition sounds amazing, but in low calorie time periods it could have been a disadvantage. We have many many viral remnants throughout our genome some of which may now be useful to us. We are symbiotic with E.coli and many microorganisms that can also have dangerous variants or can cause problems when in the wrong place or amount. We have genetic disorders like sickle cell that can be advantageous in malaria infested areas and disadvantageous in others. We also have mental disorders such as hyper-aggressiveness that could have been beneficial in violent times but are more often now considered a problem. It really all depends on context, and since we define diseases to be negative based on the current context we are surrounded by "diseases" pretty much must always be seen as detrimental rather than beneficial. That's an important point about context. 

The SCA trait which has some benefit in regions where malaria is endemic conveys little benefit in regions where it is not. 

Same with violent men. Women now complain about them, but a few hundred years ago, you wanted a mate that could physically protect you if needed, which is not as needed now.  There are a number of well respected geneticists that hold the Black Death as potentially responsible for the genesis of the CCR5 mutation that causes immunity to HIV-1 in some Caucasians.  Stephen O'Brien published an article in the American Journal of Human Genetics traced the mutation to a selective event of historic strength approximately 700 years ago involving a pathogen that utilized the CCR5 gene.  This places it as a rough contemporary of The Black Death.  [deleted] Is it only caucasians? Or are some people from other races immune? Undergrad microbiologist that works in a HIV research lab here,

In my understanding, the CCR5 mutation is mostly in Causasions/European descendants. It is rare in asians and Africans. 
The mutation does prevent HIV infection, but it also causes people to be more susceptible to other things, as the mutation in the receptor weakens some of your white blood cells. For example, the mutation makes you more likely to die from west Nile infection, which could be a reason why it's rare in Africans.
Here's a short article that explains more: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3071059/

Now, there are other forms of protection that are mostly found in Africans, that doesn't involve the CCR5 deletion. Africans have a form of immunity called "immune quiescence" which is just a reduced immune response to infections.
HIV infects white blood cells, so if there is a reduced immune response during infection there will be less targets for the HIV to infect, and therefore your body is more able to clear the virus and prevent infection.

Edit: immune quiescence has also been noticed in men who have sex with men, and partners of individuals with HIV. It's mostly observed and researched. in African sex trade workers though.
Here's another article that talks about immune quiescence http://www.ncbi.nlm.nih.gov/m/pubmed/24257114/ It's more likely that it was smallpox, as CCR532 confers no survival advantage to animals infected with with bubonic plague, and there have been several refutations of the plague's involvement since it was proposed. 

&gt; The CCR5-32 allele, which has been implicated in resistance against HIV (CCR5 is HIV's coreceptor), had been previously theorized to have come into prevalence due to the plague, however smallpox has actually been found to have been the [more likely contributor](http://www.pnas.org/content/100/25/15276) for this particular example of selection pressure by a human pathogen. Indeed, the allele has been [found in human remains dated prior to any known outbreaks of bubonic plague in Europe](http://www.nature.com/gene/journal/v6/n4/full/6364172a.html), but after the estimated arrival of smallpox. In fact, prior immunization to smallpox using vaccinia virus has been reported to [inhibit replication of CCR5-tropic HIV-1 in vitro](http://www.biomedcentral.com/1471-2172/11/23), and [CCR5 expression renders cells permissive to vaccinia virus infection](http://jvi.asm.org/content/83/5/2226.long). Typically, misfolded proteins result in disease. For example, Alzheimer's, Parkinsons and Huntingtons are in part caused by a misfolded protein. However, there is a protein that is being examined for its benefits when misfolded. HAMLET (Human Alpha-lactalbumin Made Lethal to Tumor cells) kills tumor cells and does not kill healthy cells. You can find more about it here: http://onlinelibrary.wiley.com/doi/10.1002/ijc.24076/full 

You could probably argue that it is not a disease but it could easily have been one. In this case, a mistake turned out for the better. Either way, I think it is very interesting. Aren't these prions?  Yes, prions are misfolded proteins, but they are considered infectious agents and are transmitted from another organism. HAMLET, Alzheimer's, Parkinsons and Huntingtons are all different because the endogenous protein is not properly folded by the body. Human pregnancy lasting till full-term requires a sequence that was inserted by a virus in an extremely ancestral species (think something like a mole sized ancient mammal). So that is at least one example of infection leading to the ability to perform an important biological function. Really? That sounds interesting, do you have a link for that? [Lay summary.](http://www.slate.com/articles/health_and_science/doublex/2011/09/pregnancy_evolution_a_new_nature_genetics_paper_may_explain_why_.html) [Link to original research paper](http://www.nature.com/ng/journal/v43/n11/abs/ng.917.html)

Well, it's not as cut and dry as /u/Corgisauron would make it seem, but there is indeed a transposon that plays a role in regulating what genes get turned on during pregnancy, and that transposon was likely introduced into the genome via a virus. However, there is so much stuff going on during pregnancy that it's hard to say that full-term pregnancy *requires* that transposon. Another possible explanation is that the original transposon was actually detrimental to pregnancy. In which case, animals had to evolve to circumvent the problem, and eventually some sort of population bottleneck resulted in the "assimilated transposon" becoming the most prevalent genotype. I thought a popular theory was that humans evolved to give birth "prematurely" because of the size of the head, not the opposite. Yeah but non mammals "give birth" even *more* prematurely... they are laid as eggs. I know, I said "prematurely" compared to other placental mammals that can walk within a few minutes/hours after birth. I'm probably too late but...

Gilbert's disease is relatively harmless on its negative side (people who suffer from it might get mild jaundice when they're stressed out or sick) and on the positive side they have a significantly reduced risk of cardiovascular disease (the number one cause of death in humans). Yay me! Yes! A good example would be hemochromatosis, which had a large increase in allele frequency during the time of the plague.  It was found that, similar to sickle cell anemia and malaria, having the disease or allele gave a resistance to the plague that allowed those with it to survive and pass it on.  It is now found that 1 in 200 people from Western European descent have at least 1 allele for the condition.

If you're interested in the topic you should read "Survival of the Sickest"  by Sharon Moalem.  It goes into all sorts of things like this. There is one disease that proved to be of enormous benefit to a specific class of people in particular and then to humanity in general; cowpox.

Jenner observed that milkmaids rarely contracted smallpox but often came down with the relatively harmless cowpox.  He conducted an experiment that would be considered unconscionable today. He inoculated a young boy with cowpox, which the kid contracted and easily recovered from and then he intentionally exposed him to smallpox.  

He proved to be immune to smallpox, the process of vaccination had been discovered.  This lead to the eradication of smallpox.

  ...and the word vaccination was chosen for that procedure because of the Latin word for cow. A good book for you would be "Survival of the Sickest" which explains why Diabetes 1, hemachromatosis, and sickle cell anemia are beneficial. Also I'm not sure if this counts but the mitochondria that produce energy for our cells, are bacteria that live in our cells, reproduce by themselves, and are theorized to be an infection in single called organisms that are completely necessary for life. Mitochondria evolved from bacteria entering in an endosymbiotic event. It's not correct to say that they are bacteria living in our cells now You could argue that cholera outbreaks in London led to clean water - which is considered the greatest public health achievement in the 20th century.

The AIDS pandemic has put billions of dollars into research and developing new tests, increased our understanding of sexual behavior and immunology.  HIV 'capsules' are commonly used for DNA insertion and all that gene therapy

Cancer is basically one big study on genetics - we've learned a lot from that.

There are rare cases of people receiving head trauma and then being able to remember everything

EDIT: I think it is very important for humanity to ALWAYS make some good come out of a bad situation oddly enough Black Death (the plague in Europe) ended up being 'beneficial' to humans.

To my understanding, Italy was intensely overcrowded before the black death. After the plague swept through and wiped out all 50 million people across Europe, the survivors benefited by having extra food, space, and opportunities with business. Without the plague it's possible that the Itallian renaissance would've been postponed for quite a few centuries.- imagine how different life would be now if that happened: the humanist movements, the reformation, and exploration all happened around this time period in Europe.  

So yes the black plague was "beneficial" but not to the people who were infected, but instead to those who survived it. [deleted] [deleted] [deleted] You might find [this report](http://www.walnet.org/sos/cupidsdisease.html) from Oliver Sacks interesting.  Basically, an older woman who had contracted syphilis as a young woman had had it treated some time before penicillin was around.  It came back in her old age and affected her cerebral cortex, increasing her sex drive and making her "flirty and giggly".  They treated her with penicillin, killing the spirochetes (bacteria that cause Syphilis) and halting the progress of the disease, without reducing the effects that she enjoyed. Ah yes, I believe  it was included in the book he wrote; *the man who mistook his wife for a hat*. What about hookworms? Not technically a disease, but a parasite that has evolved in conjunction with humans and can cure allergies and asthma. Check out the awesome Radiolab podcast called "parasites" to learn more.  &gt; can cure allergies and asthma

This is a strange way to phrase it. The theory is that we adapted the allergy-specific part of our immune system to fight off parasites, and that the modern lack of parasites in certain parts of the worlds results in the increase of allergies in those areas due to the lack of regulatory input into that part of the immune system (it has to attack something, and if it doesn't find worms it thinks it's just not working hard enough and becomes more and more sensitive until it finds something). Giving someone a hookworm to cure allergies is sort of backwards, as hookworms are a disease, so you're trading one for the other. &gt; Giving someone a hookworm to cure allergies is sort of backwards

And yet, [it is a researched therapy for exactly that](http://en.wikipedia.org/wiki/Helminthic_therapy). Who says hookworms have to be a disease any more than the millions of bacteria in my gut are a disease? Gut flora can be both detrimental and beneficial to my health, depending on circumstances, diet, and flora composition, etc. Ditto for hookworms, so it seems. [Giving someone bacteria to fix their gut problems is also a therapy](http://en.wikipedia.org/wiki/Fecal_bacteriotherapy). I think more specifically, hookworms are not a disease, but a strong presence of them can cause one: anemia.  My understanding of Helminthic therapy involved worms of one gender (you'll notice all the used species are hermaphroditic), and involves exerting significant control of said worm populations within a body.  I think in this case, we would be considering weather or not to consider hookworms as necessarily parasitic, but potentially symbiotic instead.  

It's a very cool idea to combat autoimmune disorders.    
 I don't think *cure* is the right word. Hookworm infection doesn't *cure* atopy, if anything it's a prophylactic, subverting the immune system while it's present. This also doesn't happen in 100% of cases as there are still risks involved in hookworm infections.

Also, this is related to some of the replies to your post, a lot of people are saying the presence of parasitic worms "keeps the Th2 arm of the immune response busy". This isn't always the case. Certainly for hookworms and schistosomes, they aren't just keeping immune cells busy and hence preventing atopy - they actually have mechanisms to dampen and suppress immune functions.

I'd suggest the review article *Human Schistosome Infection and Allergic Sensitisation* by Rujeni *et al* 2012, for anyone interested. It discusses the parasite paradox, hygiene hypothesis, and the role of parasitic worms in immune responses. It also details how various schistosome life stages have an array of tools to use to suppress and counter immune function in humans. I was thinking about the bacteria in our stomach. Clearly a foreign invader and we are a host. Wouldn't that mean that the gut bacteria are a "disease" that benefits us? It just so happens that the products of their fermentation are not outright poisonous to us and we need them for 30% of our caloric intake. 

Certainly at one point in our respective evolution chains there was a species of microbe who's ancestors were harmful to some species of primitive human, but later mutated/evolved to benefit it's host organism. Perhaps by making them have to eat 30% less food to get the same caloric intake.   Not just your gut bacteria, but all the bacteria in and on your body. The question becomes one of semantics. Is that a disease, or are we symbiotes? A good portion of the cases of colic in infants is caused by an immune reaction to gut bacteria as your immune system comes to terms with them, so there is evidence for disease there. [Sickle Cell Anemia protects against Malaria](http://en.wikipedia.org/wiki/Sickle-cell_disease#genetics)

*The malaria parasite has a complex lifecycle and spends part of it in red blood cells. In a carrier, the presence of the malaria parasite causes the red blood cells with defective haemoglobin to rupture prematurely, making the Plasmodium parasite unable to reproduce. Further, the polymerization of Hb affects the ability of the parasite to digest Hb in the first place. Therefore, in areas where malaria is a problem, people's chances of survival actually increase if they carry sickle-cell trait (selection for the heterozygote).* [Urbach  Wiethe Disease](http://www.wired.com/2010/12/fear-brain-amygdala/) has a benefit of damaging the [amygdala](http://en.wikipedia.org/wiki/Amygdala) and making the suffer feel no fear. In a recent study, the researchers are thinking it more about [responding to external threats](http://www.nature.com/news/researchers-scare-fearless-patients-1.12350) than the fear emotion itself.

So maybe its a benefit if your recruiting assassins or commandos or something. AAV2 virus has [been shown to](http://www.medicalnewstoday.com/articles/234882.php) target cervical cancer and three types of breast cancer cells, but it otherwise harmless.  Also see [Not all viruses are bad guys: the case for reovirus in cancer therapy](http://www.ncbi.nlm.nih.gov/pubmed/15970267): "reovirus [is] a benign, naturally occurring virus that can effect tumor regression in animal models."

 You should check out *Survival of the Sickest: The Surprising Connections Between Disease and Longevity* by Dr. Sharon Moalem and Jonathan Prince. It discusses this idea in great detail. It's been awhile since I read it but it was really engrossing. It has a Freakonomics or Malcolm Gladwell feel to it, non-fiction that reads like fiction. Some people believe that cytomegaolovirus (CMV), which is a herpes simplex like virus that stays in your system for life, used to help us ward off parasites in a symbiotic manner.

That being said it has been shown to be responsible for the pro inflammatory effects that aging has on the immune system (aka inflamaging). These effects have led to things like rheumatoid arthritis or even Alzheimer's disease. 

It is not well known if the virus itself has these effects or just the aging.  Cystic fibrosis is an example much like sickle cell anemia.  Heterozygotes were protected (European populations) against the diarrhea of vibrio cholerae, whose toxin utilizes a chloride transport mechanism to facilitate massive water loss.  Cystic fibrosis homozygotes are the unfortunate collateral damage, as having both genes leaves chloride transport extremely impaired.

I'm sure there are other examples of how genes have evolved to protect us via heterozygosity, but confer diseases states in homozygous recessive individuals The relatively benign Cow Pox created immunity in those infected to the far more deadly Small Pox. 

In fact, it was responsible for the invention of the vaccine because of it. A scientist learned of the immunity it created from a local rumor and then used it to manufacture a smallpox vaccine. [deleted] There are tons of bacteria in the gut that help us digest food. Not sure if you consider that a disease but it's an outside organizing infecting us but doing good. 

Also, I think I remember from my bio class that they think mitochondria in our cells was initially a bacteria that found s novel way to replicate itself and is now s permanent fixture in our cell and helps with energy production or something. 

Edit 1: see Symbiogenesis A vaccine works by infecting the subject with an altered or weakened form of a disease causing microbe. So technically by "catching" the weaker form you become immune to the more dangerous form, and possibly other related diseases (like Cowpox).  [deleted] [deleted] I forget the name, but there is an autosomal dominant disorder that is common among Northern Europeans in which people normal for condition (aa) get iron from their diet in a normal way, but those that are (AA), get too much iron. However, many centuries ago most of the European diets where iron deficient. The people that were heterozygous (Aa) actually had an evolutionary advantage that they could take more iron from their irons-deficient diets than the "normal" people. Hemochromatosis, maybe? They store excess iron, which can be damaging in the long-term, but has been theorized to also have its advantages.  The [definition of disease](http://en.wikipedia.org/wiki/Disease) is that it is pathological, which would rule out a disease being beneficial.

----

Edit: To everyone replying that a disease process being pathological does not rule out it being beneficial, thank you. I get it. I knew and agreed with this when I posted my reply, but I wanted to get some debate/discussion happening. I did not want a hundred people telling me the same thing. What about any condition that isn't normal? Something that could be brought by a virus or by a bacteria that isn't normally found in humans. There are several relationships that can form between two organisms:

* parasitism (one harmed, one benefits)
* amensalism (one harmed, one is unaffected)
* commensalism (one benefits, one is unaffected)
* mutualism (both benefit)

One example of mutualism with humans is the microorganisms in our GI tract.  [Wikipedia lists a few other examples](https://en.wikipedia.org/wiki/Mutualism_%28biology%29#Humans_and_mutualism).
 With all due respect, your logic is faulty: being pathological does *not* rule out the possibility of being beneficial on some level, it just means it *is* harmful. A disease can be both harmful and beneficial, as in the case of sickle cell anemia. Clearly we would call a double-allele individual's disease pathological, and a single-allele wouldn't be necessarily be considered pathological, but *for the purposes of the question at hand*, I just wanted to point out that it's not that simple.

With that said, *please* feel free to point out if / how I'm wrong, I *do* like learning. :) You're right to point out the faults in my quick and dirty response, though I was thinking beneficial as ruling out harm.

I have a question for you on your sickle-cell anaemia example. If someone is heterozygous for the risk allele and therefore does not show the symptoms because they are able to produce sufficient amount of healthy red blood cells, would you classify them as having sickle-cell disease? you simply take a look at their blood under a microscope.  
heterozygous sickle cell anemia does very well show symptoms, carriers are only immune to malaria, because plasmodia (protozoa that cause malaria) simply die of low oxygen levels.  
someone with one allele of sickle cell anemia produces malformed erythrocytes (though less than those with two alleles), which makes their blood carry less oxygen.  
this of course impairs anything that involves physical activity, so it is still not much of a joy, although you are immune to malaria It depends on if he means "is it bad for this human" or "is it good for humanity", and also a bit of what "good" means. Certainly having been exposed to smallpox as a European worked out really well when they invaded the Americas. You could argue getting chicken pox as a child is also beneficial to a specific human, because getting it as an adult can have much more serious complications than you get as a child, which is why they used to have chicken pox parties before the vaccine was available. Yes, pathological to an organism, but may be beneficial to the larger organism of society.  Not sure if it was mentioned, but survivors of the bubonic plague in Europe have passed immunity to HIV to their descendants. During the big AIDS scare in the early 80's, individuals with clotting disorders were contracting and dying from HIV/AIDS found in the blood products they received. One individual did not get sick, even after many of his friends with the disease died from AIDS. This got a doctor thinking, and the discovery of the CCR-5 receptor gene's part in preventing HIV was found. Here is a short summary of the hypothesis and science behind it. http://www.pbs.org/wgbh/evolution/library/10/4/l_104_05.html

Edit: typo So the plague had an effect of increasing the percentage of Europeans who are naturally resistant to HIV. The thinking now is that it was actually Smallpox that led to the high numbers of the CCR5-delta32 mutation. 

Some researchers found that the plague wouldn't have been a high enough selective pressure to account for such a high frequency of the mutation. However, smallpox was consistently present during the last millenium and mostly affected (and killed) children, so that might account for the high frequency. It also uses the same protein (CCR5) as HIV to enter the cell. http://en.wikipedia.org/wiki/Retrotransposon
Many scientists believe that the L1 retrotransposon allowed human brains to be much faster than they normally would have been, and the current theory is that this retrotransposon started as a sexually transmitted disease that spread throughout the population. Bipolar disorder is not known as a disease in the traditional sense of being an infection of some sort, but is a series of chemical imbalances that flare periodically. It has some very negative characteristics, but it also has some good things that people feel are benefits. Many of the most driven or creative people find that their best work or accomplishments occur in their manic periods. In fact, some people with bipolar feel that the manias are so enjoyable that they choose to reject their medications so they can continue to experience them. My hubby has bipolar &amp; he is generally pretty diligent in taking his medications. Thank goodness though, because when he has been unmedicated in the past, the consequences of his manic or depressive behaviors are painful for him and for all of us who live under the shadows of them. I remember reading that in Nigeria a disease that somewhat "beneficial" was sickle cell anemia as malaria was also widespread.  Due to the parasite only  being able to survive off of healthy blood cells, sickle cells were not beneficial to them and the parasite would eventually die off.  Not exactly a complete win, but it is somewhat beneficial.  Cowpox a human disease prevents the more serious disease of smallpox. 
Cowpox is similar to, but much milder than, the highly contagious and often deadly smallpox disease. Its close resemblance to the mild form of smallpox inspired the first smallpox vaccine, created and administered by English physician Edward Jenner. Many diseases exist because they confer an secondary advantage that is stronger than the disease's disadvantage.  Sickle cell trait (protecting against malaria) is an example. Low back pain occurs due to an unusual vertical loading of a vertebrate spine, but allows us to walk upright, with all the advantages that confers.  Our [predisposition to pneumonia and choking] (http://www.npr.org/templates/story/story.php?storyId=129083762) occurs because we have lowered larynxes, which in turns allows us to vocalize in a more complex way, which helps the organization of larger groups, which confers a survival advantage. 


 You are saying that lower back pain is a disease? Or is walking upright the disease and lower back pain is the symptom? either way you are stretching the definition of disease. Really?

&gt; a disorder of structure or function in a human, animal, or plant, especially one that produces specific signs or symptoms or that affects a specific location and is not simply a direct result of physical injury.

seems to fit There's a theory that the mitochondria in our cells were standalone bacteria at one point that survived endocytosis from another cell and then developed a symbiotic relationship with the cell. You can read more on this theory [here](http://en.m.wikipedia.org/wiki/Mitochondrion#Origin). As 8% of your dna is viral yes there have been several. What they are? who knows. The virus is a critical part of human evolution.

Now there is more to diseases than ancient viruses. Are any others beneficial? yes of course. Your gut is swarming with bacteria which are beneficial to you. A strain of E.coli for example lives in your intestines we enslaved it. Outside of your intestines it will still cause infection but in your intestines it aids in digestion.  I think that the word disease denotes a negative connotation. There are plenty of organisms that live within the human body that make us more efficient organisms. We act as a host for them and in return reap benefits from their presence. These "diseases" or intrusive organisms have perfected themselves and separated from their harmful counterparts in the sense that they keep the human body not only alive, but healthier in order to nourish themselves. There is [a virus](https://en.wikipedia.org/wiki/Tulip_breaking_virus) which infected tulip plants and caused streaking in the flowers. This effect became quite popular in the Netherlands in the 17th century and the streaked flowers sold for higher prices. So I guess you could say that this disease was beneficial to humans. One simple example would be cowpox. In the 18th Century, 400, 000 of people would die from smallpox every year, with no cure, and the survivors there were often went blind.

Edward Jenner noticed milk maids (people milking the cows) were not contracting small pox. They were however contracting a less virulent disease, cow pox, which gave them immunity to small pox. It then became common for people to infect themselves with the cow pox virus (transferred from cattle) to prevent infection of small pox. This is still the case today!!
 The thing that comes to mind for me is E. Coli bacteria. Normally they live in your intestines and help you digest food. However, occasionally they can infect your bloodstream and make you very ill. This is why people are advised not to eat undercooked meat, because that's one of the major ways to get infected. [deleted] [deleted] Sickle cell anemia basically makes you immune to malaria.  If you look at areas where sickle cell anemia is commonly found, it overlaps almost exactly with areas where malaria has historically been common.  

That's why it's so common among black people.  It's because Africa was historically, and still is, the place with the highest occurrence of malaria.  There is a subset of northern europeans that have immune systems that are more protective against the HIV virion than other populations. Why? It is believed that the bubonic plague wiped out those with systems that were obviously not resistant to it. It left those with the "good" systems alive. Coincidentally, that same protection later was passed down to their descendants and helps to protect against HIV.

Also, we use some toxins from certain diseases in vaccines for other diseases in order to provoke a strong response against the disease we are trying to get the patient to respond against.

Also, a huge area of research currently is in using viruses engineered to transfer helpful genes to protect and treat disease. Look up Baltimore and his research into vectored immunoprophylaxis; in one study, he used an engineered adenovirus to transfer genes that coded for antibodies that attack the HIV virus. By using that virus, they were able to engineer muscle cells to produce antibodies against a disease that mice had never encountered before and it protected against future infection. There is a pretty interesting book that covers exactly this question. It is called survival of the sickest it looks at several diseases and is able to, for the most part, explain a beneficial trait which has lead to the disease staying in the gene pool. It is a very interesting read and its not too long either. It talks about both sickle cell and the black plague which I see have been brought up in this thread. Sickle cell trait and thalassemia when heterozygous will shorten the lifespan of red blood cells with very little clinical pathology to the patient. These diseases have a high presence in the areas surrounding the Mediterranean, Africa, SE Asia, i.e. lots of places where mosquitoes are rampant. The theory is that these were positively selected disease traits because a shorter RBC lifespan will stop the life cycle of malaria within RBC and allow the affected individual to recover, whereas non carriers of the traits will die of malaria.  The black olague might have been the genesis for western democracy. When the workers in england all died they wised up and started demanding rights. Basically the aristocracy had to give in because there were simply no other people to do what they needed done. Like unionism but in the 14th century. Yeah i know this will be buried and someone probably already provided the same answer but more in depth and with sources. But whatever. [deleted] [deleted] [deleted] It's estimated that roughly 10% of Europe is resistant or immune to HIV/AIDs because of the prevalence of Smallpox in the last millenium.

The HIV virus uses a protein called CCR5 to enter the cell, and so does the Smallpox virus. There is a mutation, CCR5-delta32, where this protein is non-functional, so both these viruses can't enter the cell. 

Just so happens that people who had this mutation would have been more likely to survive (and reproduce!) after a smallpox infection. Now their ancestors (on average 10% of Western Europeans) are also resistant (if they have one copy of the gene) or totally immune to HIV if they have two copies (are homozygous) of the CCR5-delta32 mutation.  So... Why don't we have a HIV vaccine yet? The resistance to HIV is caused by a genetic mutation of DNA. There tend to be ethical issues involved in altering human DNA. [deleted] Well there have been attempts to create drugs which can block the CCR5 receptor, but it's thought that HIV would likely mutate to use other cell receptors, and just kind of bypass the CCR5 receptor. (Not to mention drug discovery/development is fecking hard!!)
No doubt there has been a tonne of new research in recent years/months, but it's not something I've kept up-to-date with sadly. Follow-up question: Does surviving a specific disease boost overall immune strength? 

The hygiene hypothesis, for instance, states that growing up in too clean an environment results in a weak immune system and a tendency toward allergies and autoimmune diseases. [deleted] Not sure if it has been said already, but the human genome sequence has massive portions that do not code for anything in our bodies and are likely the genomes of bacteria or other organisms that we have incorporated into our own genome. The benefit of this is that when a mutation occurs, there is a much higher chance that it is in this region than in a region of DNA that is essential for survival.
 Gilbert's disease - a cause of low level jaundice (high bilirubin). Very rarely will cause dangerously high loevels in newborns (which may lead to brain damage), but mostly just cause mild jaundice. Long-term it may be benficial as bilirubin is a potent antioxidant. This might explain why Gilbert's is so common Clicked on this thread intending to post that.  It also significantly decreased the risk of coronary artery disease.


 There is some research to suggest that Toxoplasmosis, a disease prevalent in cats and rodents as well as people, might alter behaviors. In rodents, it appears to make them less adverse to risk, specifically things like the scent of cats, which is theorized to make it more likely to get eaten by a cat and therefore spread the disease. There's some studies which suggest that it also alters human behavior, specifically making humans with the disease seek out sex more frequently. It's otherwise harmless to most humans, resulting is a slight flu-like symptoms for a week. It's worse for infants or people with immunodeficiency. 

So basically what we might have here is a disease that gives you the flu for a few days, then makes you permanently more likely to have sex.  Interesting question. I published a paper on this a couple of years ago, so I'll try and summarize what we found (and bear in mind that other opinions may vary!). Basically, the overarching factor for fish in the deep seas is scarcity of food. As a result, there's a selective pressure towards extreme efficiency in swimming mode. As you go deeper, the fish community changes composition towards longer and more eel-like species - we proved this with data, and you can see the same trend within families. As active "hunting" predation becomes difficult if the ability to accelerate quickly to capture prey is impaired by this morphology, other adaptations to improve success in ambush encounters like the "snaggle-toothed" mouths or voluminous stomachs, or improve odds of escape like being very spiny or being armored, start to make sense. We proposed that this explains some of the macro patterns in fish diversity, such as the absense of sharks from abyssal waters due to the inherent "sharkiness" of their body plan, while their cousins the chimeras, with their whippy tails and spiny fins but similar biochemsitry, are found deeper. If you look at data from seamounts, you do see more characteristically "fishy" shaped fish, like roughies and alfonsinos, at depth, but the greater trophic flux from the surface to the deep which the mount provides probably explains this.

Edit: Ok, by popular demand I've uploaded a pre-print [here](https://pdf.yt/d/p07zU9T1tpyOLiio). Ironically, I can't access the published version of my own paper as the institute I work for now doesn't have a subscription. Down with the traditional publishing model, etc. You have a link to the paper? It's behind a paywall. PM me and I'll send you the pdf... Just link it anyway. A lot of people here are students and have access through university.  [deleted] [deleted] Mandatory plug for /r/scholar Yes please link or provide a cite. University access here. Unless it's an unknown low impact journal I have access to it and I'd be interested in reading it.

Also aren't we supposed to provide cites here anyway? [deleted] Here is a link:
 http://doi.org/10.1111/jfb.12266


This is derived from looking up the author / title / journal from the preprint:

Neat, F. C. and Campbell, N. (2013), Proliferation of elongate fishes in the deep sea. Journal of Fish Biology, 83: 15761591. doi: 10.1111/jfb.12266 You explained why efficient swimming and hunting/protection designs are important,  but i dont see any explanation as to why theyre not just as important for shallow water fish.  What are the selection pressures on "normal"  fish that cause them to be smooth and symmetrical when youve just stated that different designs are more efficient?  The closer to the surface something resides, the more plentiful the populations become. Because of how scarce other fish are at such extreme depths, the bodies must be built to last for much longer lengths of time without food. For comparison,  its the difference in the water usage efficiencies between a non-desert species and a desert species. Both could benefit from retaining a lot of water, but the desert species NEEDS to retain water in order to survive. If that wasnt part of their ability, then they wouldnt survive very long in that environment. I understand this.  But its not like deepsea fish have this big list of selective pressures on them and shallow fish dont.  Shallow fish have a different set of selective pressures that force them to not use the "more efficient"  designs of deepsea fish. And i want to know what those are  Evolution does not select for efficiency or complexity. Whatever survives passes on its traits. Shallow fish did not need higher efficiency designs to procreate successfuly. 

Deepsea fish, however, are in a highly competitive biosphere. This would create the pressures required to select for traits that allow them to survive to procreation.

Edit: cleaned up the last paragraph. Exactly. A fish would not evolved differently because the fish's molecules somehow knew that it needed to be slimmer in order to attack an enemy faster in order to survive, it just so happens that fish who are slimmer can attack an enemy faster, thus surviving and passing those genes along. Discovery channel does this all the time....."The butterfly has what appears to be eyes on it's wings to scare aware predators", when in fact they should say "Because the butterfly has what appears to be eyes on it's wings, predators are scared away".  [deleted] Reading /u/owls_with_towels original comment, it seems as though fish with more eel-like body plans are more efficient swimmers, but fish with fish-like body plans are better at acceleration (not to mention they can afford its energy requirements) and therefore better hunters. So fish living at depth with less food available need to be more efficient, and therefore develop the eel body plan with some additional adaptations to help with hunting/discourage predation. Those additional adaptations are some of the 'weird' things we see (eg bioluminescence).

In other words, shallow fish need to be able to catch other fish (or escape) in areas of high biomass, while deep sea fish need to be able to conserve energy. Please correct me if I'm wrong, /u/owls_with_towels! In short, the eel-like bodies of deep sea fish are more efficient, but have lower capabilities. Kind of like a prius vs. a semi truck. Another reason is, that because they live under high pressure, when we look at them in our environment, they are deformed, and not in their usual appearance.

For example: http://i.imgur.com/RHPq6vw.jpg For comparison's sake, here's what the blobfish normally looks like in water.

http://simbania.files.wordpress.com/2010/12/blobfish4.jpg

http://www.dailymotion.com/video/xi14j9_blobfish_animals

A lot more attractive if I might say so. It actually looks kinda... cute? Wow, thank you.  [deleted] [deleted] Seems kind of mean that we pulled him up here... He's probably quite uncomfortable :( You mean dead, right? Wouldn't he be more comfortable if he were dead? I mean, that's what the doctor at the euthanasia clinic said when I showed up with my beestung cat.  Why would you go to a euthanasia clinic because your cat had a beesting? That's like going to an abortion clinic because you felt the baby kick.  Maybe it wasn't *a* bee sting, but 500 bee stings. The neurotoxins would give the cat a lot of problems. [deleted] Not just pressure pushing in, but gravity due to air being less dense, causing the fish to look all droopy. Isn't it more of a divergence from the normal fish model? I'm thinking of the angler fish and similar species. It seems like fish either go with the eel model for efficient travel or they turn into little blobs and don't plan to move at all  Yes, this exactly! Things like frogmouths and anglerfish which don't do much swimming can effectively sit on the bottom and be happy little ambush predators. You don't see the trend I described in these taxa. The body plans of true flatfishes, on the other hand, are constrained by their metamorphosis, and their diet of benthic fauna, and they are pretty much absent from the deep sea, with the exception of things like the Greenland halibut, which seem to be evolving back into mid-water predators. Is there any kind of food chain chart/video, if you will, that illustrates this? It would be funny, interesting to see the succession of this as a pattern where the ambushers shaped one way consume ah whatever the level fish that they consume that is shaped another way and then the subsequent evolutions that adapt and create ever more dominant types, shapes, systems, what have you. 

edit: or rather do you know of any really good ones? &gt;  or improve odds of escape like being very spiny or being armored, start to make sense

It seems like this evolutionary pressure would exist at all depths.  Why don't we see more armored or spiny fish nearer the surface, where there are more predators? You do sometimes.  but it is easier to have a strong sturdy body in areas with less pressure.  so fish in these areas can swim faster or form huge schools or utilize camoflauge.  there's more to work with in the shallower environments, but even then you still find trends.  in shalow costal areas you find a lot more camoflagued fish where as in deeper water you find big fast fish or gigantic schools. Breeding pool and playing the odds, I would say. Shallow waters house great populations as opposed to deeper ones. Suppose we have a trait for spiny bodies (sp) and non-spiny (ns). In shallow water, the population is 200 (ns=100, sp=100). In deep water it is 75% less. Now spiny trait in hybrids are dominant but the spines are not significant to ward off larger predators. Non-spinies are just gobbled if caught. And double sp's successfully ward off predators. Each round of breeding is done by random pairing then they produce a copy of their pair and each round of survival goes like this: ns flip two coins (2 heads they survive), hybrids flip one coin (1 head they survive), and sp pure (survive). Now round after round shallow water should take longer for spiny genes to develop because the gene pool is so disperse whereas the deep water is more concentrated meaning rounds of survival would quickly wipe out non-spinies. Fish at the surface can see predators coming from far away. Growing shells or spins isn't as efficient as just getting out of the way before predators get you.  I believe it has more to do with being dark than high pressure.  Although in theory you could compare cave animals that live in total darkness with sea floor animals that live in total darkness.  

Darkness must account for the coloration, yet as far as I know cave animals don't grow shells or spines so that must be a water adaptation or possibly pressure?  Why would it be different?  What's the same? I read the paper and it is actually quite interesting. It leads me wondering, as I haven't looked into it before, how many of these deep species traits are divergent and how many are convergent. What species got pushed down there in the first place? Or, if the time scale is wrong, what first got pushed up here?

I liked your paper a lot, and it sent me on a bit of a marine biology journey! Thanks for your input! Since life started in shallow waters, it would seem reasonable that most or maybe even all the complex organisms at that depth evolved from species that originally resided in less deep if waters. &gt;Since life started in shallow waters

How is this known? We can know for certain that early complex organisms at least evolved in shallow waters thanks to the fossil record and where their fossils were deposited. I have a more general question, and it seems like you might be someone good to ask. Where does scientific method come in when you're evaluating evolutionary explanations for animal traits? When do you get a falsifiable hypothesis? I suppose you could say "if my theory is correct you'll find no sharks in abyssal waters"--but it seems like you have a pretty complete data set before you make the hypothesis, AND if a shark was found it wouldn't necessarily discount the theory if it had other adaptations to deal with the same problem.

Edit: I guess you could also take another fish and drop into a new environment and see what it looks like thousands of generations later, but that doesn't seem practical. That's a fair criticism. Most of this work was a happy accident which fell out of a decade's worth of trawl survey data. It's mostly conjecture and while it fits with the data we have, it would be hard to make testable hypotheses from it (hence publication in JFB and not, say, Nature!). But I guess more generally, I see a lot of articles or statements in nature documentaries where people say "this adaptation is because of this" and I'm curious if there's a way that anyone is using testable hypotheses on these claims. Sometimes the nature documentaries definitely overreach.  It's quite difficult to say something affirmatively with scientific rigor.  However, adaptive evolution is fairly well studied, so there are lots of rigorous examples to choose from.

For testing, you have a few options.  Because of the evolutionary timescales involved, you can't really perform experiments, but you can do observational studies.  If you think, for instance, that a bigger beak helps for nut eating, you can look at the spatial distributions of beak size and nuts.  A sufficiently strong correlation is reasonably compelling.  You could go the next step and look for evidence at the genetic level for a selective sweep at beak size QTLs (quantitative trait loci, i.e. genes associated with a trait).  By comparing the rates of synonymous vs. nonsynonymous nucleotide substitution, you can support selective pressure.

Now, all that is a lot of work, but constitutes a high degree of rigor.  That's the basic way to do it; come at the problem from more than one direction and look for reasonably strong correlations.

Experimental science is the gold standard, but that doesn't mean observational studies aren't useful or compelling. It can help if an animal has relatives in the same environment that don't have the adaptation because then you can look for which of their needs differ, or relatives in a different environment with the same adaptation because then you can look for which of their needs are still the same. Observation of the animal also helps. I recommend you read yourself some Gould. He talks about this at length, about the use of Just-So stories to explain traits. It is possible to find evidence to defend a selective explanation, but people do sometimes forget to do that.  So where does the Goblin Shark fit in? Gobin sharks are a great example of what I'm talking about. Fishbase gives their distribution down to about 1300m, so quite deep for a shark, but not deep deep (I think Monty Preide's [paper](http://rspb.royalsocietypublishing.org/content/273/1592/1435) states sharks are rare beyond 2000m and absent beyond 3000m - to give some context, we looked at data from trawling down to about 2100m). So, they're sharks, and have a traditionally sharky fusiform body plan, but if you look at their tails, they don't have the classic tail shape of a pelagic shark, but a much more heterocercal fin with a very elongated upper lobe, and this is as much of a nod towards the eel-like body form that sharks are able to make. Their feeding [mechanism](https://gfycat.com/TemptingSameHackee) is an example of what I was talking about where, as being able to accelerate quickly and engulf prey becomes energetically costly, adaptations to the jaw, like this where it can whip out in front of the body when something bumps the nose, become advantageous. Sadly, I never got to see one in the flesh.  Wow, what a fascinating gif.  Do you have any more information on that clip?  What was he biting at?  Was that the arm to an ROV?   [deleted] Since you study this, you should get [flair](https://www.reddit.com/r/askscience/comments/2aypoy/askscience_panel_of_scientists_xi/). I may have missed it, but does the enormous amount of pressure at these depths have anything to do with how they develop as well? Why don't deep sea fish go higher? I understand super-deep see ones can't go too high or the pressure will kill them, but are there really "shelves" or "floors" of the ocean, like there are levels in a supermarket or shopping centre? Where certain types of fish only live and never go higher or lower for any reason?

I mean, it must blow their tiny little fishy minds when a whale dies and drops down to the ocean floor. The chances of happening across a whale carcass at the bottom of the ocean must be once-in-a-lifetime. It is called a [whale fall](http://en.wikipedia.org/wiki/Whale_fall). The sudden influx of dense food in a relative desert leads to its own ecosystem.
 What do chimeras look like? I have heard of humans who have chimerism, meaning they have two different sets of DNA, but never deep-sea fish. [deleted] [deleted] [deleted] I can't stop thinking about how deep sea fish  would taste. Are they edible? Orange roughy was probably the nicest fish I've ever eaten (although I was consumed with guilt as it was about 100 years old!). It's pretty much "gone" now though... :-( There are extensive fisheries for other deepwater species like [black scabbardfish](http://en.wikipedia.org/wiki/Black_scabbardfish) and [Greenland halibut](http://en.wikipedia.org/wiki/Greenland_halibut). Others - not so much... What it'd taste like? They're a white fleshed fish like ocean perch (but kind of extra creamy). Good eating, yes, but not a totally unique flavour, so not such a big loss now that they're off the menu (would be a much bigger loss to see them go extinct!). Substitute tilapa and you can eat a pest fish instead. Some other fish that are off the menu are harder to replace in recipes, eg. swordfish, but - meh - eat something else instead. I often wonder if there is a bit of sexual selection that goes on with deep sea creatures that is quite different than the rest. Other than bioluminescence their really are no visual displays. Which would lead me to believe that other flashy or colorful or very beautiful structures give away to more versatile and economic structures that help more with survival than attracting mates.
 [deleted] &gt; ther adaptations to improve success in ambush encounters like the "snaggle-toothed" mouths or voluminous stomachs

This reminds me how military ships went from beautiful wood galleon type ships to WWII steel monstrosities and carriers.  The game got too competitive and novel solutions had to be tried, which added quite a bit of ugliness, for lack of a better term. Modern stealth ships are even weirder, with their angled panels and flat designs.  A 17th century sailor wouldn't even recognize a stealth ship as a warship. He's probably think it was a loose iceberg. This seems like a great answer, thank you for taking the time.  

I have a question about numbers.  Up near the surface, there definitely *are* numerous asymmetric or "ugly" fish, the frog fish being an example.  Is it possible that they exist at the same general population level as at very deep levels, but because of the overabundance of more normal fish they just seem like a desperate minority?  I don't have a very clear grasp of how densely populated the very deep ocean is, but I know that reefs and the like are incredibly populous with a small number of odd fish among the swarms of regular ones.   I missed your point about sharks: why aren't there sharks in abyssal waters? I linked to [this paper](http://rspb.royalsocietypublishing.org/content/273/1592/1435) in another response, but that's a really good question. The jury is very much out on the answer... I assumed it had more to do with the lack of light. There's no evolutionary pressure to look good to attract a mate, **have lots of colors to be distracting or camouflage, or to look impressive/intimidating.**

Edie: Geez, guys, of course they don't *have* to look good to attract a mate. I know it's a lot more complicated than that, but you have to admit that's something that plays a part in evolution. It's just a fact. I mentioned a good number of other reasons for aesthetics, too.  &gt; There's no evolutionary pressure to look good to attract a mate

Look good to whose eyes? There are a lot of organisms I would deem ugly who still mate without a problemo, because their own species don't find them so ugly

I believe OP put "uglier" in quotes for this exact reason. Obviously, but land mammals have a lot of pressure to look good for various reasons. "Attracting a mate" was only one example. Look at peacocks, for example. I highly doubt that it's got *nothing* to do with it. If deep sea fish could see, they would probably find snaggled teeth and spiny backs attractive,  since it helps the species be successful at gathering food and surviving. That's how attraction tends to work in other species.

Edit: guys, go easy on the downvotes with u/chokfull.. you're discouraging legitimate questions and good discussion.. not everyone knows everything and it's much better to help them learn than make them feel bad for not knowing. &gt;attractive,  since it helps the species be successful at gathering food and surviving. That's how attraction tends to work in other species.


Actually, a decent amount of sexual selection is more about showing you are a good enough provider to be able to waste energy or put yourself at a disadvantage - a peacock's tail is an example of this 
 [deleted] You don't seem to understand. Angler fish look hot to other angler fish. I don't think angler fish ever really see one another.  I mean, beyond just lack of light, isn't this the species where the males attach themselves to a female and devolves to a dangling set of gonads? Isn't that sort of assuming "looking good" is objective?  Do sea creatures have aesthetic standards? And if so are they similar to our "preferences" Many fish don't mate individually though, so sexual selection wouldn't play as much a part even for surface fish. I work with deep sea ROVs (remotely operated vehicles).  IMHO, most of the fish look like normal fish, but with larger eyes and other minor in appearance but major in usefulness differences.  Like tripod fish, normal fish with longer fins that they balance on.  I think part of the problem is that the strange, but often rarely observed fish get the most media play and attention.  The vast majority of what we see are things like cusk eels.  Not the most visually exciting fish... The sheer amount of people saying they are ugly because nothing can see them is mind boggling. Guys, a humans perception of a certain fishes appearance doesn't matter at all to the fish, it has no concept of conventional attractiveness. 'Not being seen' is more or less a valid explanation for why they have ugly colors though. If there isn't any light, there's no adaptive advantage to have bright colors, metallic scales etc. &gt;adaptive advantage to have bright colors

Exactly! [Check out this article](http://www.dtmag.com/Stories/Ocean%20Science/08-07-feature.htm) It has nothing to do with human perception. It's well known that the appearance of birds, for example, plays a huge role in mate selection. Symmetry, colors and shapes are important for many animals, not just humans.

When you take away light like in the deep sea or underground, appearance becomes meaningless, and animals would have no reason to evolve such traits.

Being "ugly" is not just a subjective human analysis, but rather something that takes into account the basic principles used by many species. This, I'm sure our human sense of symmetry must apply to other species to some dregree This was my first thought as well; would love to see if there's some sort of scientific analysis supporting it. But its interesting how almost archatypically ugly they are. A wolf's snarl, a spider, an insane grin, and many other classically scary things can be explained through human evolution. Big teeth on a wolf is scary, but we also have some down right evolution helping us find that extra scary.

Deep water sea creatures take that to such an almost specifically horrifying degree that you can't help but wonder. No one is saying that other, visible, animals evolved to be attractive to us. I'm not suggesting that there was a time when we dealt with enough deep sea, unseen, creatures that we would evolve to fear them.

But you just can't help but wonder why almost everything down there (before you get to the tinier animals) looks down right like the spawn of Satan. There are other weird factors to effect their morphology, like the lack of food, cold and pressure. But its almost like if you took the creepiest artist in the world, and told him to draw all the evil fish from below that exist in the dark, he would come up with something like this. My reaction to their hideousness seems to strong for it to be a sheer difference of morphology. Perhaps the whole idea of what is "scary" is some instinctive trait handed down from our distant ancestors. Before we were top of the food chain it probably behooved us to avoid anything with large teeth that looked like it could eat us.

*edit* Similar to how we quite often perceive cuteness across species. [deleted] [deleted] [deleted] Maybe there is something to the converse, though: Perhaps humans wouldn't have reason think those fish are attractive because they aren't a part of the environment that humans are exposed to. They really are the most alien creatures we know of, from human perspective at least. Many of the pictures you see on google about deep sea fishes are actually that of the fish AFTER they rapidly surfaced (depressurized) it. Not surprisingly, they are going to look very distended. Their bodies were not made to hold up in such low pressures. 


As for symmetry, part of the reason for that is that in the deep there is much less requirement for moving around fast and thus streamlined bodies are less selected for. Interesting, your reason was on the near opposite of /u/owls_with_towels who published a paper on the topic. However I can see both responses as valid. Nature is quite enigmatic! Well not quite, like the guy pointed out the fishes arn't out to out-swim their prey. And it is obvious from the way they look they can't swim quickly. I believe what he meant when he said "efficiency in swimming mode" is not so much to say they wade water very well (aka sailfish), but rather that they can catch prey very well as and when they are moving if by the chance it appears. Sudden snaps, traps, lures, all work well in this respect. We identify what things are supposed to look like based upon what is familiar to us. Surface fish come in a wide variety of weird shapes and sizes too, many of which aren't actually symmetrical, but we're used to them, and in our minds we identify fish as looking like that. 

They're more colorful than deep sea fish (many of which are actually quite symmetrical themselves), as they've evolved to use color as a means of attracting mates, warning off predators, or creating camouflage. In the deep sea, there isn't enough light to see normal color patterns, so the creatures there are often drab or transparent, replacing the usual displays of color with bio-luminosity.

Additionally, other factors in the deep-sea environment, such as increased pressures, have undoubtedly contributed to the development of creatures with different shapes and body structures than what we're used to seeing at the surface.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] In the dark, there is no pressure adapting your colour to your surroundings to hide from enemies.

Also, since there is no visuals, since there is no light, looks don't matter. It's all function over form, where no specific symmetry gives an upside, anything goes. that's actually *super* not true, unless I'm mistaken you've been caught speculating

red light gets filtered out, so some deep sea creatures have red coloring.  their outside absorbs most light, except for red, but that's ok because there isn't any red light.  red is camouflage down there, most of them can't even *see* red light.

except, of course, in the case of the Stoplight Loosejaw, which is unique in producing Red Bioluminescence.  Meaning, it has an **invisible searchlight super effective at illuminating camouflaged targets!**  The evolutionary arms race is truly stranger than all our fiction.

http://en.wikipedia.org/wiki/Stoplight_loosejaw Question, when we send ROV's deep underwater with lights on them, is it causing any harm towards life that normally doesn't see light? I know that there has been concern over this, blinding thousands of baby shrimp etc, but how much of a concern it is I do not know I've read elsewhere, probably on /r/science or here on /r/askscience, that they pretty much expect to kill things they encounter, but, like when taking samples, it's not a big deal because they can do more for conservation if they go down there than the few creatures they kill while they're there. Here is a previous thread about the question you asked: http://www.reddit.com/r/askscience/comments/2n1yd4/how_is_it_that_when_deep_sea_creatures_are_filmed/

Essentially, yes, the underwater life found in these expeditions probably is blinded. However, it is just assumed that only a very small number are blinded, and the population as a whole isn't significantly affected.  you are right for shallow depths where light still penetrates, after a few hundred meters or even miles down, there is no natural lighting from the sun, save for the odd photoilluminescence some species might bring to the table.

also one could argue that red isn't always specifically evolved to or selected for, but might also be a byproduct of being somewhat transparent and filled with blood. but that heavily depends on what species exactly you are looking at. even that might evolutionary be preferable in the specific habitat. They live under much higher levels of pressure much higher than at the surface ("several dozen times higher than at sea level"). Down there their bodies look much more symmetrical, but the air expands in them as the go into lower pressure (shallower) water, causing them to look asymmetrical I think it's that stuff like the swim bladder will puff up at surface, causing it to look bulbous. At depth it might look "normal".  This was posted elsewhere, but someone dug up pictures of the blobfish at it's normal depth and I'd say it looks quite a bit more cute than when they're unfortunately dragged to the [surface](http://www.reddit.com/r/askscience/comments/2rhsu0/why_are_deep_sea_fishs_uglier_and_less/cng8t6v). Beauty is in the eye of the beholder. That being said, we have an evolutionary distaste for certain bodily characteristics, especially those which remind us of insects and reptiles (because a number of species were venomous and therefore dangerous to us). Things like snakey or insect-like movement and body type, reptilian spikes and scales, lack of pigment, nocturnal eyes. Those sorts of features are subconsciously associated with danger, and we immediately wish to avoid them, or see them as "ugly". Lots of answers already talking about the darkness, drab colours to avoid being spotted, etc. But I there's another factor.

Consider that the lifestyles of these animals is quite different from those on the surface; form often follows function. Fish near the surface tend to be streamlined and sleek due to the hydrodynamic needs of their more active lifestyles. In contrast, most bottom dwellers are built for efficiency and are often slow scavengers or 'sit-and-wait' predators. Since they don't feed by constantly vigorously swimming around, being streamlined is less important.

Humans like sleek and streamlined. Think of a sports car, iphone or sports illustrated swimsuit model. Therefore we are biased towards the active swimmers. There is no selective pressure on appearance of these species in order to attract a mate via visual stimuli as mates won't be able to see visual displays (bright colors, elaborate body patters) or to camouflage into the environment since these species aren't exposed to enough light to be seen anyway. 

The appearance of these fish is fueled entirely by efficiency of their bodies to move, capture prey &amp; etc. [deleted] [deleted] [deleted] Right, but *why* are they "ugly" can be explained by perception of ugliness and diversification in water depth since ugliness a relative quality.  I agree that it's important to specify *why* fish are different as their environment gets deeper, but I feel that it's also interesting to investigate *why* people perceive fish in certain ways. it is an interesting subject, but it isn't op's question.  it could be rephrased "why don't deep sea fish look like tuna?" [deleted] Yes.  It's called [visual acuity](https://en.wikipedia.org/wiki/Visual_acuity ), typically about 1 arcminute (1/60th of a degree).

However, the eye is not at all like a camera you can assess in terms like megapixels.  The resolution isn't uniform, it's only that high in the center of view.  The eye also has a "blind spot" where the nerves go out that has no sensing cells. 

The eye makes up for this uneven resolution with super-deluxe image processing hardware that's capable of some very big apparent improvements.  The eye moves a little all the time in what are called [saccades](https://en.wikipedia.org/wiki/Saccade ) the information from which is fused in [Transsaccadic memory](https://en.wikipedia.org/wiki/Transsaccadic_memory ) to form the "pictures" we perceive of the world we see.  You can use [Johnson's Criteria](https://en.wikipedia.org/wiki/Johnson%27s_criteria ) to understand the difference between something the eye can detect and something you can see.   can you settle the "how many FPS" can your eye see I know measuring it in frames is inaccurate but could you explain why and maybe a better measure that frames? I can't answer your question directly but maybe add something of interest. There are indeed no frames (still composite images) as such in the visual system; the brain doesn't see things frame-by-frame. Actually what happens is that the visual information is separated into lots of different features, such as edges of a given orientation, colour or movement. The information is divided into all these features and processed further and further. Then at the end all this feature information is somehow merged into representations of objects etc. How this "binding" of features happens is as far as I know still very poorly understood, if at all. As for movement, in the relatively late stages of processing there happens a split between information on "what" and object is and "where" it is in space (presumably including movement). These parts of visual information are even processed by anatomically clearly separate pathways. So as you can see the brain works entirely differently than a video recording with frames :) This is why you can get some really strange disorders, like people who can't see motion. So do they end up seeing just the beginning and ending segment of the motion, or 'frame by frame' or what exactly?  I'm very curious about this.  I can't comment on that but another example is people who can't "see" faces. They can drive cars, read books, do anything that requires visual acuity but the human face is an enigma to them. This is an example of how the eye can't be thought of as a simple camera. It relies heavily on image processing which is intrinsic to its function.  The disorder you're referring to is [prosopagnosia](https://en.wikipedia.org/wiki/Prosopagnosia). It's a fascinating disorder because it has nothing to do with the eyes. The people who have it can see eyes, nose, mouth perfectly fine, but they are unable to integrate this information into anything meaningful. Most rely on voice, gait, and other cues to identify people, because the face is not helpful. To clear things up, you mean they can't recognize and remember faces, right? Cus just straight not being able to see faces would be weird. 

Edit - k I don't mean to be a jerk but you can all stop explaining this to me. Everything you're all telling me basically means I was right and that I already understand what you're saying.  There is a particular function in your brain which recognises faces. It detects 2 eyes, a nose, mouth, etc, and says "Hey! That's a face! Is it someone we know?" It's what makes you see a smiley face when I do this :)

For these people, that function doesn't work. The smiley face might as well be "k[" (and even now, your brain is trying to see a face in there somewhere - probably a sad one).

Edit: For people wondering, the condition is called [Prosopagnosia](http://en.wikipedia.org/wiki/Prosopagnosia)
 This function is part of what makes the human brain-eye system excellent at pattern recognition, but also makes it see Jesus in our toast. When I starting playing airsoft I was surprised by how much of a forest looks like a person holding a rifle, when you're looking for people holding rifles. [deleted] Must be why these images hurt to look at:

http://photos1.blogger.com/blogger/4256/375/320/four_eyes_illusion_1.jpg

https://c1.staticflickr.com/1/53/127526574_08ad4fc7f3.jpg

I can barely even focus on them properly. That is the most disturbing optical illusion I've ever seen. It's like my eyeballs' wetware is throwing off exception errors. Correct. And yet when you look at them upside down that little part of the brain stops trying to recognise a face and it becomes more comfortable to look at. 

People with this described disorder can of course objectively look at a face and know that it's a face. They can recognise loved ones and emotions be specifically focusing on certain cues and features rather than doing it innately. In fact I hear that a healthy brain can achieve much the same effect by looking at a face upside down (: Thanks for the headache Exactly yeah! It's like when the image recognition on your camera freaks out because of low-light or something and you see the little box flying around the screen.

 I wonder if my eyes would do the same thing if I looked upon the face of an extra terrestrial?   Could it possibly be because as humans we are taught to look into the eyes of a person, and that is the norm, but in this picture there is two sets of eyes, so our brain is trying to look at both sets at the same time which in turn gives you a head ache? Just speculating here. I have no problem focusing or even looking at these images. Eek terminator camera vision. that makes my mental landscape shudder. not like it disturbs me but  like wen you run you hand across something bumpy what an odd feeling 
 That first image is pretty much an exact representation of coming home at 3am after a night out and trying to watch Netflix.  

I can usually manage it if I watch with just one eye.   He looks really grumpy to me. Like one of those anime characters that have the weird diagonal wrinkles coming from their eyes.  But look at those glyphs, "k[", objectively. The really don't look *anything* like a face, much less a human face, but your brain is not only capable of seeing a face, but it is capable of taking a stab at the face's emotional state. And my brain did the same, and came up with the same conclusion! That is *incredible*! The human brain is astoundingly amazing. Is there a name for that particular disorder?  Sounds like a very interesting read. i've only ever heard it called "face blindness" (whoda thunk?) but a quick google of that let me to this barely-pronounceable nonsense: [prosopagnosia](http://en.wikipedia.org/wiki/Prosopagnosia). I believe it is prosopagnosia. I have a slight form of this. I know I recognize faces but it takes me a while to place the face with a memmory due to not remembering the face in the first place. Yesssss, precioussssssss... Is it someone we knowses? Has anyone tried giving them shrooms?  I wish I could remember the disorder... There's a great book called something like, The Woman Who Mistook Her Coat rack For Her Husband (or maybe I made that title up.... Brain?!)
I'll google that in a minute...

Edit: The Woman Who Mistook Her Husband For A Hat by Oliver Sacks, I was close...ish close. but i think you mean [The Man Who Mistook His Wife For A Hat] (http://www.amazon.com/The-Man-Who-Mistook-Wife/dp/1491514078)  I'm glad you mentioned this, because its a great read from a brilliant neuroscientist that is fantastic at communicating his work.  Also another interesting read if you're interested in these things is Phantoms  In The Brain by VS Ramachandran. Brilliant work . Everything by Oliver Sacks is extremely fascinating.  Even if you're not interested in neuroscience itself, it still grants a tremendous amount of insight into our identity as humans in my opinion.  Before reading his books, I never would have imagined that blind people have such a totally alien experience of life compared to sighted people.  I never would have guessed that losing all color vision would make it tremendously difficult to eat.  I would have assumed that giving a blind person sight would be a miracle - not a life-destroying disaster.  I highly recommend his books to anyone who is interested in what it is like to be a human for people who are different from ones' self. I second this, its on my list to dig through some boxes for his books, totally fascinating and he's a great writer too. [Prosopagnosia](https://en.wikipedia.org/wiki/Prosopagnosia). [deleted] close, but still no cigar :D http://no.wikipedia.org/wiki/The_Man_Who_Mistook_His_Wife_for_a_Hat

Very fun reading (set me up to be really disappointed in my neurology lectures/ward rounds) Given the context of the thread, I clicked the link and thought I had forgotten how to read somehow. Is that Norwegian?! I am a native English speaker/reader, and I feel like I can almost read parts of that.  Just want to butt in here and tell everyone that if they liked that book they'll love 'Into the Silent Land: Travels in Neuropsychology. It's brilliant. A fact I learned there, that's relevant here, is the case of this person whose brain wasn't processing the visual blind spot properly. Instead of it filling in the blanks using surrounding information, it filled it in with cartoons. So in his eyes he could see cartoons! How crazy is that?  Yes.  It's like how you cannot tell two zebras apart.  But they have that thing for all animals.  Here's a study that involved stimulating the facial recognition area mentioned in the previous comment. The face the patient saw warped before his eyes

http://healthland.time.com/2012/10/24/changing-faces-stimulating-the-brain-morphs-peoples-faces-before-patients-eyes/

There's a video floating around of the patient's brain being stimulated and him describing how the faces he saw would change For more about the special function our brain has on face recognition, 60 Minutes had a great feature about people who are impaired in that area. To get a sense of how specialized facial recognition is in our brain, [look at what happens when viewing faces upside down](https://www.youtube.com/watch?v=q8cXus7SNQY&amp;t=4m0s) (skip to 4 minutes in, if it doesn't automatically).

At [6:30 in that video, there is also a fascinating look into the opposite spectrum, super face recognizers](https://www.youtube.com/watch?v=q8cXus7SNQY&amp;t=6m30s), who remember a face even after an incidental meeting. This leads to surprisingly awkward social encounters, such as saying, "Oh yeah, we met before at a party five years ago, don't you remember?"

[60 Minutes on Face Blindness Part 1](https://www.youtube.com/watch?v=dxqsBk7Wn-Y)

[60 Minutes on Face Blindness Part 2](https://www.youtube.com/watch?v=q8cXus7SNQY) I can remember someone I've only saw once and seeing them again like ten years later. It's crazy.  And I can vividly recall where I saw them and what was going on.  Your ~~'re~~ brain processes faces through a different pathway, which is why this picture is difficult to understand.

http://i.imgur.com/0q224QV.jpg I may be wrong but isnt the face thing more of a problem with visual recognition rather than visual interpretation? making that an entire different subject? It's called change blindness, and you can simulate it by inserting a grey frame between two similar frames.

A good demo: http://www.gocognitive.net/demo/change-blindness

(Note how much easier it is to spot the change if you change the "mask time" from anything else to zero) I'd recommend a book called *the man who mistook his wife for a hat* by Oliver Sacks, if you're curious - I'm a layman, but found it interesting.  Frame by frame isn't a bad analogy actually. It can be like strobed images and can cause a lot of problems - try filling a cup of tea when you can't see the level rise and, more dangerously, try crossing a road when glancing at traffic shows you that a car is there but doesn't immediately tell you if its parked/stopped or driving.     [deleted] That's not how colour blindness works at all actually. Being colour blind means that your eyes are less sensitive to colours. I'm Red-Green colour blind so I see less of those colours than you do. I still identify most red things as being red. The difference is when colours are a mixture of red/green and another colour. The blue/greens for example are often more blue to me than they are to other people because I'm not getting enough green. You can replicate this by going to your monitor settings and turning down the red and green. Not all color blindness works that way. The problem can be located in the eye, optic nerve, brain, etc. So you're both not quite wrong, but you are over generalizing a bit. But yes the most common red green color blindness is because of the eyes All colour blindness does, in fact, work that way. All variants of colour blindness are an inability to see some or all of the different colours in normal light. There are different causes of colour blindness but they all result in the same defficiency. It is a decreased or completely absent ability to see specific colour or colours. It is not at all about seeing red as green or any other combination of primary colour.

It's more like a camera with faulty white balance where pictures come out more blue or yellow/orange than they should.

 [deleted] Yes, but perceiving motion isn't a conscious reasoning process. When you see motion, you don't go "Oh that ball used to be over there, but now it's over here, and now it's even more over here-- it must be moving towards me!", you just *see* it. If you had to go through the conscious reasoning process, you could never react to motion with any sort of speed or accuracy.

[Motion-blind](https://en.wikipedia.org/wiki/Akinetopsia) people recognize when they see something changing position that it is moving, but they have to consciously reason out the motion, which makes reacting to it quickly and accurately nearly impossible. Trying to picture how t hese people see the world is like trying to imagine a new color. Or like trying to think like someone with severe dementia.  There is an illusion that mimics being able to see a new color. I forget what it's called but only a small percentage of people can see it. It relies on looking at a yellow square and a blue one and having them kind of overlap. I was able to see it for a few seconds after some time. It's kind of like a mix of blueyellow but without turning green. It's pretty cool because it's merged. I might not be explaining it well but hopefully someone can imgur it here so I can do it again!

Edit: [Found it!](http://en.wikipedia.org/wiki/Impossible_color) Test is the blue yellow with the white cross in the center.

Edit: Fuck! I can't see it now. It doesn't really work for me...i see either blue or yellow or both but its not like an own color. But an interesting effect it is...my brain can't decide if its blue or yellow and the perception is changing back and forth. Huh. I see both yellow and blue layered and at once but it don't perceive it as green just yellowandblue. It's interesting. There is believed to be a subset of people who CAN see more than the usual colors everyone sees. It has to do with a mutation of (I believe) the X chromosome that causes an "extra" set of cones in the eye. This has not been 100% proven though. (And I may have misremembered some details.) Is it that they're unable to to distinguish between the movement of their perspective and the movement of objects in motion, or is that they can't mentally identify motion at all? Wikipedia's [akinetopsia](https://en.wikipedia.org/wiki/Akinetopsia) has a good bit of detail on the disorder. In most cases, the person has trouble perceiving motion, so the world looks like a bad movie reel where things "move" in a very jagged manner. The world lacks the fluidity that it should have.

If you think about trying to cross a street, you can get an idea for why this would be a big problem. The Wikipedia page discusses LM who is highly studied case of akinetopsia, and mentions the coping mechanisms that she learned, which involve relying on other senses (sound) to supplant the information lost in not being able to perceive motion. It's not exactly that they can't seen motion, but there's a specialized function beginning in the retina that reacts to motion and predicts where and object is going to be. As fast as neurons are it takes nearly 140ms to get information from the retina and all the way through the visual cortex, which is all *before* it gets sent off the motor cortex to generate some form of muscular action (which takes even longer).

So what happens when people lose their ability to perceive motion is that at some point in the line, something breaks, and the brain can no longer tell where something is going to be. They can still see it, but they can't tell you where it's going, if it'll hit them, or how they should react. Brain damage to core circuits can create some very unusual phenomena.

Edit: Having read u/a2soup 's comment I feel like I should add that they can still logically reason about movement, but reflexes and *feelings* no longer function at all. Yes, that's essentially what happens.  The signals coming directly from the retina are a hot mess of colors, shapes, and so forth.  It takes a huge amount of processing in the brain to organize everything into a coherent visual perception, and defects in that processing can have some very interesting effects. This is called [akinetopsia](https://en.wikipedia.org/wiki/Akinetopsia). Subjective reports of people who suffer from this say that they might start pouring water into a glass and then suddenly notice that it's overflowing. Or they might look down a street and see a car far away and all of a sudden it is right in front of them. Such severe cases are extremely rare and there have only been a handful of documented cases.  I don't know if this is the same, so I could be full of it,  but when I was googling saccades I remember reading reading some people's eyes don't utilize saccades properly or at all.  

Our eyes do this to keep constant stimulation,  you don't notice them but they're automatic,  but basically in these people's cases keeping their eyes focused on one,  unmoving thing they basically stop processing anything that's not moving,  and once something does move (or they move their eyes around)  everything is instantly back to processing as everything has been newly stimulated.

 Also,  I believe tunnel vision is your eyes losing that new stimulation outside of the succeeds.  That's why you'll still see the thing you're focused on but the rest slowly goes black.  [See for yourself](http://visionlab.harvard.edu/members/patrick/Demos/)

Your motion-detecting system strongly depends on luminance contrast, i.e. it is looking for bright things moving against a dark background or vice versa. So motion detection is much harder when looking at two objects with equal brightness (but different colors). Its like watching a video, but not fast enough (fps is lower than the standard 1/16th, after which our brain perceives it as motion). Imagine pouring a cup of tea. And you blink all the time so you can only see a single still frame of what's going on. And then suddenly that frame changes to the cup overflowing. I have had this experience personally, it's like the moving thing doesn't exist at all. It disappears from your model of the world while it is moving. However if you look closely where the object should be you can see it sitting there, so almost like frame by frame as you suggested. It's strange to know your brain just isn't processing it, so strange that I had a panic attack at the time of the episode. After getting some sleep I was fine and could see motion regularly again.   Perfect read for those with a casual interest in neurological disorders: http://en.m.wikipedia.org/wiki/The_Man_Who_Mistook_His_Wife_for_a_Hat And why taking psychedelic drugs is so interesting, when our entire image processing pathways get subtly altered I remember reading about this. Another strange related disorder is called blindsight, and it's pretty much the opposite of what you're describing - where people can detect motion of objects they claim they can't see. IIRC, there are two main neural pathways involved in visual processing: the tectopulvinar and the geniculostriate. The former handles things like processing motion, whereas the latter handles things like the form and colour of objects.

If a person sustains damage anywhere along the geniculostriate pathway while their tectopulvinar pathway remains intact, they can end up developing blindsight, and they will (for instance) be able to catch objects thrown at them that they claim they never saw coming.

Take this with a grain of salt because I'm going off memory. You're in the ballpark but they usually don't throw things at the blind person. ;) They do have them perform tasks that a "fully" blind person could not though. [Wikipedia entry](http://en.wikipedia.org/wiki/Blindsight).

[It's also the title of a really good sci-fi book by Peter Watts](http://en.wikipedia.org/wiki/Blindsight_%28Watts_novel%29). Blindsight in the book is metaphorical rather than literal. 

Looking at the Wikipedia [disambiguation page](http://en.wikipedia.org/wiki/Blindsight_%28disambiguation%29) I discover that it's been a book title at least 3x.  &gt; blindsight

That book was tough.  Probably among the best scifi I've read in a long time.

 [Blindsight](https://en.wikipedia.org/wiki/Blindsight) is usually the result of cortical damage to V1, rather than the pathway. [Akinetopsia](https://en.wikipedia.org/wiki/Akinetopsia) is the inability to perceive motion. Wikipedia has a nice rundown of the [cases](https://en.wikipedia.org/wiki/Akinetopsia#Case_studies). Interesting. Is that sort of like when you look at those swirly spirals that make everything you see afterwards seem to move around without changing location, except inverted? Would they perceive locations of things, and obviously know if something has changed location since they last looked at it, but not necessarily perceive the motion itself? The most interesting one for me is people who can't recognise faces but can recognise objects, and people who can recognise faces but not objects. Anomic Aphasia. Is this like the discolight effect then? When light flashes in intervalls and you only see "keyframes" of people? Is there a nme for that disorder? It's a type of [Agnosia](http://en.wikipedia.org/wiki/Agnosia) known as [Akinetopsia.](http://en.wikipedia.org/wiki/Akinetopsia) [Akinetopsia](http://en.wikipedia.org/wiki/Akinetopsia). It's also interesting to think of vision in terms of the "processing power" required to conduct it. While seeing in darkness, the brain devotes almost double the oxygen to processing vision. This is something we are made aware of in pilot training - without supplemental oxygen while flying at night, a person can experience symptoms of hypoxia as low as 5,000 feet because of how hard to brain is working to see. It's also things like this that makes wonder, when it comes to super-intelligent AI, if maybe our hubris is getting ahead of us and we actually still have a very long way to go.  so then riddle me this. I learned that when a wheel turns and we see it as actually spinning in the reverse (because the frames of the camera cannot capture a cycle in such a short amount of time depending on how fast the wheel is spinning) Why does this same phenomenon happen when we look at wheels with our own eyes?

(sorry for the totally improper language, just trying to spit out my thoughts) tldr of it is it's called the Wagon Wheel Effect, and that we're not sure. There are a couple of competing theories on the subject. 

One is the discrete frames theory (1996), but this theory has been a bit weakened by [further research](http://www.sciencedirect.com/science/article/pii/S0042698904002731) (2004) which showed that given an rotating drum and it's mirror image, motion reversals occur for one at a time, which means there isn't a single discrete frame in which both flip.

Another theory is more abstract, suggesting that when presented with ambiguous input, the brain applies a "best guess" algorithm, and this can be applied differently to different objects with the same behavior, so for 2 wheels spinning in the same direction, one can be seen spinning one way, and the other can be seen spinning in the other direction.

[Example of such ambiguity](http://www.geek.com/wp-content/uploads/2013/08/necker-cube.jpg)

[Another example you're probably familiar with](http://i.kinja-img.com/gawker-media/image/upload/s--GfSt4Ivs--/776683968121013538.gif) I've seen that woman spinning gif several times before, and today I stared at it for a very long time - I can never get her to spin counter-clockwise. Am I doing something wrong, is there something wrong with my brain, or what's the deal with that? It's not something I've been able to force ever. It helps for me to try to zone out / relax, and to look at her foot/shadow. Usually takes me ~30sec or so. What helps for me is to cover everything above her foot, and focus on seeing her foot turn the other way. When I then slowly reveal more of here I can see her turning the other direction. Try moving your finger in front of you following her raised foot in a circle in the opposite direction you're perceiving it.

edit: It's important to note that when the foot is moving on the front, it is either higher or lower depending on the direction she's rotating. Is the 2nd gif altered? Or is this really my brain and if so... What's the actual direction it's spinning - left or right? The direction the girl in the second gif is spinning is intentionally ambiguous. Because you can only see her profile it's under-determined whether she's facing toward or away from you at any given time. Thus, there's no canonical answer as to which direction she's spinning.  It's intentionally ambiguous. For most people, it will spin clockwise, and if you look at it long enough (30sec-1min) it will flip and start spinning the opposite direction. It may help to look at the shadow to facilitate this. If you notice, that effect only occurs in artificial light, and you are seeing the effects of the 60 Hz strobing present in all vapor lamps due to the AC voltage fluctuations. In general this is true, but not always. If an observers eyes are under vibrations this can be observed in continuous lighting conditions. In a vibrating airplane or eating are the most common examples. I've seen it happen while sitting in a car, would the vibrations explain it there? That explains why looking at LCD lights while playing a musical instrument can get pretty crazy looking. I used to play the trombone, and looking at a digital clock while playing certain notes would make the numerals float around and even appear outside the boundaries of the clock! &gt; Why does this same phenomenon happen when we look at wheels with our own eyes?

It doesn't in sunlight. However, if you are indoors, your lights might actually be flickering at 60 Hz depending on what type you have. Usually 120. Incandescents don't flicker but fluorescents blink twice in each 60-hz cycle.
 It doesn't happen when we look at a spinning wheel directly. The wheel just gets blurry.

EDIT: I was forgetting that the effect is visible under street lights -- presumably 60 Hz mercury vapour lamps. What /u/hammer166 says. See [wagon wheel effect](https://en.wikipedia.org/wiki/Wagon-wheel_effect#Truly_continuous_illumination) on Wikipedia. There's several theories. Can you point me to studies to learn more about what we know about vision processing? Or keywords and researchers to search on? Your best bet would be an introductory psychology or cognitive neuroscience textbook.

Otherwise, you can have a look at reviews and papers on visual processing in the brain on [Scholar](https://scholar.google.com/scholar?q=visual+processing+brain+&amp;btnG=&amp;hl=en&amp;as_sdt=0%2C39) or [PubMed](http://www.ncbi.nlm.nih.gov/pubmed).

I've found this [review on colour and form processing](http://journal.frontiersin.org/journal/10.3389/fpsyg.2014.00932/full), and this one on the [nature of vision](http://journal.frontiersin.org/journal/10.3389/fncom.2014.00135/full). Both are free to read. If you find anything that interests you but you can't get free access to it, let me know and I can send it to you. There is a Teaching Company lecture series series called Sensation, Perception, and the Aging Process that goes through some of the visual agnosias in some detail.  It should be pretty easy to find a torrent, but if you can't, pm me. 

Edit: TTC link
http://www.thegreatcourses.com/courses/sensation-perception-and-the-aging-process.html There is a coursera course that just started on this topic:

https://www.coursera.org/course/visualpercepbrain

totally free. Hell, it's not even the brain that does all that. Just in the retina there are multiple layers of nerve cells that process an image even before it reaches the brain. 

Just this week I read a paper about how the leading model is that retinal ganglia cells (the bottom layer) fire under one of two circumstances. 1) "on cells" fire when the presented image on that part of the retina goes from dark to light over time or if it sees a light spot surrounded by dark. 2) "off cells" do the reverse - respond to dark spots or darkness over time. These responses are computed over a few nerve cells and sends that info to the brain. This takes place over two or three layers of neurons, imagine what an entire brain can do. 

I can post the paper if there's interest, though it's highly technical. I can't remember if it's behind a paywall cause I'm not at my computer right now.  Our eyes move a little bit all the time, because our brain "fades out" data it already saw.

Because of this the "tunnel view" exists, as there are less sensing cells at the edge of our eyes, then in the centre, so that the minute movements our eyes make all the time might not be able to change what the cells outside precieve. The same goes for our blood vessels inside our eyes, while they're infront of our sensing cells, we don't see them, as their position doesn't change and they always cast the shadow on the same sensing cells, same goes for the "blind spot" you already mentioned.

Interesting video on youtube: https://www.youtube.com/watch?v=L_W-IXqoxHA I think this is a bit misleading, since you're talking about the processing of the visual stimuli in the visual cortex of the brain itself, but not the function of the eye itself.

The "FPS" question could be understood as "what rate do the light sensitive cells in the eye send new information"? There's already some kind of simple processing within the eye itself (like "encoding" the colors or using "data" from several cells), however there still has to be some rate of communication (even if it's probably not constant at all the time or the particular area of the eye) between the eye and the brain.

So the question would be, how large is the resolution of the eye on the time scale? That is, what's the shortest time when it can perceive and set distinct information for the brain for the processing?

There's definitely some kind of fuzzing in this though, since the eyes get analogue of "exposure time" - you can notice motion blur, especially when it's dark, if you for example wave your hand in front of you and of course there are many electronic devices which utilize this, especially displays, which are often flashing at very high rate  due to the way they're updated (time multiplexing), but the eye sees the image as constant. Great explanation! It's true that the theory of how the brain associates images and classes together is very poorly understood, but the best option I've seen so far has been the idea that the brain catalogs all of those "features" into a hyperdimensional manifold (this actually isn't as crazy as it sounds) and in determining the difference between a car and a truck each feature counts as a variable dimension. The relative value (determined by neuronal activity in specialized areas) creates a specific point in this multidimensional plane, which if that falls into the manifold of car we perceive the object to be a car. Even if we've never seen a car like that before, or had anyone tell us it was a car. It makes a lot more sense if you've taken any calculus that deals with four or more variables describing an object, but there was a brilliantly well written neuro paper that presented this idea, and so far the data supports the model.

Sorry if I sort of wandered off, but it sounded like you had a bit of an interest in how the brain works and might want to hear a bit more about featural binding :) If you want to hear a bit more or have any questions feel free to ask! Visual neuroscientist here, confirming that binding is entirely an enigma. Do you mind me asking what you have a degree in? I'm very impressed with your knowledge; I'm working towards a degree in neural biology. Making a switch from psychology and it's been time consuming to say the least but my transfer to a research university has been approved for this fall so the work has been worth it. Can't begin to describe how stimulating it is to read about how our brain functions...

Thank you for taking the time to explain how our brain processes images. If motion is only handled at the object-recognition level, then what explains motion after images such as when you walk on a trail for an hour then stop suddenly and there is an illusion that everything is sliding forward, or when you spin around ten times then stop and it looks like the whole world is spinning - these happen regardless of there being things you can recognize and it's based on regions of the visual field rather than content? A better way to think about it is that your vision emerges over time, more like a [progressive jpeg](https://www.youtube.com/watch?v=TOc15-2apY0).  Since there is no time = 0 to start vision, where all the neurons are silent, it's hard to say what the framerate would be.  Some regions of the brain can process things extremely quickly without knowing what they are (e.g. you flinch when an object approaches), but others take longer ("is that really Bob I see across the street?").

We detect things by having neurons fire more.  Neurons can fire in a millisecond, and up to 100Hz.  So we know the first visual information may reach primary visual cortex from the eye in about 10-50 milliseconds.  But it's not "refreshing" at that rate, it's just a lag relative to the original photon hitting a photoreceptor in your eye.  Areas that identify objects reliably dissociate around 200 ms.  But to think that you're refreshing slowly is a misnomer.  You've got areas that are gradually coming online, but the information headed to them is constantly changing.  And you don't have to perform the same operation all the time - if grandma is on your right, and moves a little bit, you don't need to wait 200 ms to figure out that grandma is still there. Yeah, this guy is good. You can also think about the input as a rolling array of synapses concurrently firing and refreshing. Your visual cortex knows you, and it knows how best to fill in any gaps. 

You're able to process time differences in sounds arriving from one ear to the other with your auditory cortex at a temporal acuity of just one millisecond. Once the information is in your auditory cortex, the math can be done on which sound arrived first. (This is actually how we locate the source of low frequency sounds; high frequency sounds are located by an inter-aural intensity difference). 

This makes me think, I'd like to do an experiment where people receive visual input of a light into each eye independently, and there a slight delay between the onset of the light from one eye to the other. We could shorten the delay and see what the inter-ocular temporal resolution of the visual system is.  By practicing can we get faster/better at this? Is it just our physical abilities that improve or can we actually make our neurons react quicker to some degree? An additional point is how much prediction the brain is doing - not everything we see is direct sensory input. A lot of interpolation and guessing happens in the brain, predicting what we'll see next, correcting predictions based on current inputs.

I remember hearing a neuroscientist say in an interview that he believed that our sensory experience may be as little as 10% real-time input and 90% prediction/internal projections. (I don't know how widely his numbers are believed, though.) That's probably pretty accurate.  The visual system is essentially reconstructing the visual scene in our mind.  You can see failures of this reconstruction process - we call them visual illusions.  Vision is not just a simple feed-forward process - we see rapid feedback throughout the visual heirarchy, and even longer term feedback to v1 on the order of 200-400 ms.  We percieve a realtively stable environment because our whole perceptual system makes assumptions based on what we've seen before (in the short ms time frame), but also what we've already exerienced (in the life time frame).

Its an area of interest dating back to the 70s, called ecological vision, where people realized that just looking at the response properties of a single stimulus ignored the whole environment.  

So maybe a better way to think about it is that maybe it is 10% realtime input, but the 90% prediction is operating at probably something like 98% correct, so what do you really care? Just a few small corrections:

&gt;Neurons can fire in a millisecond, and up to 100Hz

Excuse me, the [occulomotor system](http://www.psy.vanderbilt.edu/faculty/schall/pdfs/TheSuperiorColliculusCh3.pdf) would like a word. These neurons can fire upwards of around 250-300 sp/s. (Figure 3.3, page 63)

&gt;So we know the first visual information may reach primary visual cortex from the eye in about 10-50 milliseconds.

[Median response in V1 is ~60 ms.](http://webvision.med.utah.edu/imageswv/Lats.jpg) Sure.  The general point remains.  neurons fire quickly, but the information they represent does not typically come from a single "fire."  It rather comes from lots of firing, and from neighbors that fire a lot.  They can fire really slowly or burst very fast, and this depends on internal properties of the cell as well as the cell's direct connections.

Similarly, we can count the synapses from photoreceptor to visual cortex to get the shortest latency possible, although the actual recorded time that a V1 cell is reliably dissociating presence or absence of a stimuli may be much later.  By the time we say V1 has a stimulus, that stimulus has already hit most of the dorsal system and started feedback to V1.

The story remains - the visual system can be extremely quick, and it is a rapidly expanding network starting at the eye, where information goes in multiple directions.  So we can't just think about it as some computer analogy where your brain is a dumb display of a CPU generated environment. A great resource with information about this question:

http://www.100fps.com/how_many_frames_can_humans_see.htm

And another:

http://amo.net/NT/02-21-01FPS.html
 http://www.reddit.com/r/pcmasterrace/comments/2853dd/fps_and_you_a_history/

TLDR:  People can notice changes (frame drops, blurs, objects appearing and then disappearing) in as little as 1 frame in every 600 per second.  This is also why the goal of VR is 10k resolution at 1k FPS - this pushes the 1 frame drop/stutter per 1000 to non-identifiable. If I live to see 10K at 1000fp, I will consider myself to be an old man.  My childhood NES will seem like a damned horse and buggy. The hard part isn't necessarily the 10K or 1000fps, but the graphics. Okay, it would take an incredibly expensive and advanced screen, but the bigger issue is creating a realistic virtual world at that resolution/frame rate. I'm pretty sure that with perfect emulation, most higher end PCs could run Mario at something crazy like that, but that isn't all that amazing. After all, the game has been out for decades. No, the greatest achievement would be to get something like Star Citizen or Crysis to run at 10K and 1000fps. Even if the screen itself cost millions, I guarantee the computer needed to do that would be astronomical in price. Wrong. Texels and pixels are something very differents, and you are confusing the two right now.  
The only limit to screen resolution right now is the bandwidth of the frame buffer. And it can be VERY VERY high in modern graphic card. Look at stuff like Ati's Eye infinity. Displaying a 3240 * 1920 display is no problem at all for average gamer graphic cards.
On the other end, despite the much higher resolution, your game won't look prettier. One texel will be displayed on 2,3 pixels instead of 1.  
Because game pretyness and sharpeness is actually limited by the "power" of the graphic card, while resolution is just the suze of the matrix being filled, with not much impact on the complexity of the object you are handling.  
Resolution is quite easy to achieve. I bet most modern computer could run crysis at 10k if some setting were allowing it. 
The 1k fps game is very doubtfull. Most games have monothreaded physic engine that are bound to the fps, and we haven't made much progress in single threaded performance over the last few years. (Still stuck at around 3.2ghz). 
So even if the graphical part would be a 10k, a lot of these images would be identical because the game state would not have changed.   &gt;  The 1k fps game is very doubtfull. Most games have monothreaded physic engine that are bound to the fps, and we haven't made much progress in single threaded performance over the last few years.

You could simulate things in 60 fps and then extrapolate in quaternions for in-between frames. If you're comparing the horse and buggy to the average car then I'd say the NES already is a horse and buggy compared to the current consoles or an equivalent PC. That writeup mentions the oft-quoted mythical fighter pilot test but gives no source.

The Wikipedia articles source all their claims, but the reddit amalgamation and the forum "sources" don't actually give any credible information.

A much better explanation to the limits of human eye "frame rate" would be its [absolute threshold](https://en.wikipedia.org/wiki/Absolute_threshold#Vision). It appears that over half the test subjects were able to detect 1ms stimulus, which would translate to that reddit writeup's mythical "1000fps", even though it doesn't take into account what *kind* of stimulus was measured. The closest you can get to FPS or refresh rate with the eye is how quickly the rods and cones reset their sensitivity after being activated, so they are ready to activate again. This isn't uniform across the entire retina and happens on a cell by cell basis so that, in the aggregate, we end up getting a mostly constant steam of visual information. I used to write a photography blog and wrote about this very subject.  Essentially, the low end of the spectrum is around 20 frames/sec, where after that things become "choppy".  This ends up being a baseline for a lot of animation.  
  
On the upper end of the scale, I've heard everything from 100 fps, to 250 fps, to ridiculously high estimates of 1000 fps.  The problem with the high end estimates is that they depend on brightness.  If, let's say, you're staring at a black screen, and I flash a bold lettered word in white in one frame at 1/200 sec, you'll likely notice it.  Hell, you might even notice it at higher frame rates, but that then depends on how bright it is, size of the screen, whether the image is capable of creating an afterimage and individual people's different rates of perception.  
  
If you're asking what frame rate people playing video games might pick up, well, it'll be lower because the amount of afterimage you'd get from something like a videogame would be harder to detect with all the distractions that are typical in a virtual space.  You can then rely on something known as a limen, or the basic level of perception.  Scientists tried to discover what the limen threshold was and created something called the absolute threshold which gets into some meaty science that I'm not very well versed in, so maybe someone can pick it up from here.  Also you can read this [Wikipedia Entry](http://en.wikipedia.org/wiki/Absolute_threshold#Vision) to get your started. &gt; On the upper end of the scale, I've heard everything from 100 fps, to 250 fps, to ridiculously high estimates of 1000 fps.

It's actually trivially easy to come up with thought experiments that show that a 1000hz could still be distinguishable as discontinuous/discrete animation frames.

Wiggling a white cursor on a black background at 60hz while keeping the eyes fixed in a single location results in very apparent animation strobing/discontinuity (depending on how fast you wiggle the mouse, you're seeing many discrete frames of cursor animation with hundreds of pixels separating them).  At 120hz you've doubled the updates and halved the distances between frames.  What frame rate would be required to get no visible pixel skipping?  A lot more than 1000hz for sure.  Assuming the brightness is sufficient that any one frame would still be visible at all, it's clear that this sort of example could easily get you into double digit khz before it's a physically continuous blur... and then you need only move the cursor a little faster and you'd see the discontinuity again. &gt; What frame rate would be required to get no visible pixel skipping?

Any rate in fact, as long as you move the cursor one "pixel" between frames, with said pixel being sufficiently small. So, on a 4K monitor the cursor would have to move unbearably slow simply because the pixels are so small and moving something one pixel isn't moving it much, and you only have 60 frames per second. On an NTSC CRT it'd move faster. Now scan a CRT at couple kHz (doable on a fast analog oscilloscope), and you can move it at a decent clip. You are not describing time resolution. You are describing space resolution. You could set a camera with a shutter speed of 1 second and aim it at your monitor then wiggle the mouse at 60 hz and guess what? It would see individual separate cursors.

To see time resolution you need to distinguish whether two cursor positions happened at the same time or at different times. One way to test this would be a computer program that randomly either flashes two dots at the same time, or one in one frame and one the next. And ask you to tell which situation happened. In the context of frame rates, people are talking about the perception of animated motion which is inherently both spatial and temporal.  My example is not meant to be taken as evidence of extreme temporal resolution of the eye, or even anything to do with the eye itself, but rather as a disproof of commonly touted frame rates being some sort of catch-all physical upper limit.  The fact that it's a byproduct of the discrete nature of the samples (frames) rather than the how the eye processes information doesn't change that. It's sometimes called "critical flicker fusion frequency" and it varies with brightness, contrast, target size, target color and target eccentricity.

It's tested in visual physiology experiments by a sine-wave variation; we used a spinning polarized filter.

The peripheral retina is more sensitive to flicker than the center.

 Just to tack on to this, the military did tests regarding how short a frame could be for someone to still get useful information from it. 

A picture of an aircraft was flashed on a black screen for 1/220th of a second and was still recognised by pilots. 

Note that there's still a difference between that and the apparent latency, discern able differences in fluidity of movement and latency of movement are likely detectable well above 400fps.  It's been awhile since I studied this. I found the book [Contrast Sensitivity of the Human Eye and Its Effects on Image Quality](http://www.amazon.ca/Contrast-Sensitivity-Human-Effects-Quality/dp/0819434965) very useful at the time, but it might be outdated. Unfortunately I don't have it with me here right now, so I'll go from memory on the topic.

To answer your question, "how many FPS can your eye see" depends on what you mean by "can see". For example, I recall experiments that were something along the line of a black screen where a white image was flashed in a single frame and viewers signaled if they were aware that an image had been shown. (Obviously there would be a reaction lag, but that is largely irrelevant to the study.) I recall that people could detect the single image up to more than 200 FPS.

But is that "seeing" it? They couldn't describe the image, just that there was a flash, IIRC.

Another study I recall (not in this book, I don't think) was evaluation of whether people could notice the difference between videos at different frame rates, obviously with some controls using the same frame rate to detect a false positive rate. I believe they used a high frame rate as the reference, and varied they lower one to higher and higher rates.

I believe that there were responses better than guessing of statistical significance somewhere up to the 60 FPS range, but that most people fell off around the 30 FPS range, meaning beyond that most people can't see any difference of the higher rate. (Of course this will depend on content of the video, and I do not recall the details of the different content tests.)

I know this can't settle anything and I wish I had the references in front of me, but it's been a decade since I did projects where this was relevant.
 &gt;I believe that there were responses better than guessing of statistical significance somewhere up to the 60 FPS range, but that most people fell off around the 30 FPS range, meaning beyond that most people can't see any difference of the higher rate. (Of course this will depend on content of the video, and I do not recall the details of the different content tests.)

This depends HEAVILY on several factors.  Namely, the resolution of the video, the pace of the video, what was being recorded, the viewing distance, whether the video was rendered with motion blur, and I'm sure many more that I can't think of right now.  Without knowing these things, the study is about as valuable as toilet paper.

On a low resolution CRT display, it would be harder to recognize the difference.  Comparing 30fps and 60fps without motion blur is night and day compared to with it.  From a distance, it's not nearly as apparent either.

I just find it very hard to believe that I'm part of some extremely small group that has the exclusive ability to not only tell 30 from 60, but 60 from 120, without any trouble or hesitation, especially considering the state of deterioration my eyes are in.  And yet, everywhere I look, people keep suggesting that's the case. What really matters is having a refresh rate of 60 or 120. IIRC there's no [positive] increase in smoothness when you go above 60fps on a 60hz screen, so the reason 120/144hz monitors are gaining popularity is because they DO allow you to see the difference. Going from 60hz to 144hz was like night and day when I upgraded, so I find it hard to believe there are people who can't see it.  Well yes, but I assume that's a given.  If the test didn't use higher refresh rate displays, it's a complete farce and worth *less* than the aforementioned toilet paper. There is also the problem of input lag which compounds the frame rate issue. You can definitely tell the difference between 60 and 120 fps in games  and movies so eyes can do more than that.  You can tell the difference between 120 and 144hz.. It's quite easy to tell the difference between 50 and 60 too. With practice you can questimate the FPS of a monitor within +-(5-8fps)
 Even without practice I noticed a difference between a 144hz gaming monitor and a 240hz monitor at my University. 

I'm not sure where the "human eye can only see at 30hz" myth came from but it's laughably incorrect. You might be thinking of the "flicker fusion threshold", which describes  the frequency above which an eye detects a continuous image.
http://en.wikipedia.org/wiki/Flicker_fusion_threshold

For humans this is in the 60 Hz range (http://xcorr.net/2011/11/20/whats-the-maximal-frame-rate-humans-can-perceive/) for direct perception.  It might be as high as 120Hz for indirect perception (i.e. the eye detects it but the information isn't available to consciousness). I don't have a link, but a gaming enthusiast compiled a bunch of information a while back, and the math pretty much showed that you can gain useful information that you actually have time to process up to about 300 FPS.  The information gained decreases at an exponential rate as you gain more FPS, though, so after about 120 FPS, the information gained is pretty inconsequential. [deleted] Fun experiment:
Take a video of your eyes while reading (a text with longer lines), and then   again when trying to follow a horizontal line as steadily as possible. Last, try following the line by following a pen tracing the line.

Without following an object, you cannot move the eye without saccadic movement.

(sorry, english is not my first language) So when tracking an objet theres no saccadic movement at all? Well, when we did those self-experiments, you could not really see any saccadic movement... &gt; Yes. It's called visual acuity, typically about 1 arcminute (1/60th of a degree).

To add to this, a classic physics argument is that this acuity is given by angle lambda/D (in radians) where lambda is the wavelength of light and D is the input aperture (pupil size).

This applies to all optical instruments, and amounts to the smallest dot that can be made by the optics given diffraction effects.

In arcmin, it is (lambda/D)x(360x60)/2pi.  

Assume that lambda=0.5e-6m (green light) and D=0.005 (5mm pupil) we get a resolution of 3.4 arcmin.  The real value is a bit better because the 'smallest dot of light' is really a 'smallest peak' and we can distinguish between partly overlapping peaks of light. On the subject of saccades, Vsauce has an interesting video about it. Link: https://www.youtube.com/watch?v=BTOODPf-iuc

There is also one about the resolution of the eye specifically that I have not watched yet.  This should be higher up. I don't quite understand why people ask questions here without simply googling it first. It must also be said here that during a saccade our central vision is blind. The central vision's image is sampled when the image stops moving across the retina. By coincidence it happens usually at the end of a saccade, but you can easily conjure setups where you're in control of it. For the EEs amongst us, think of a Set-Reset latch. The start of the saccade Sets it, and unlocks the possibility of an exposure to take place. Then, when the image stops slipping on the retina, the Reset and the exposure take place, and the central vision system becomes idle again.

Our central vision is a temporally sampled system, with sampling frequency *rarely* exceeding 10Hz. During reading it's around 4-5Hz. That's it in a nutshell.

Our visual system is very, very interesting :) When I am stargazing and looking at the Orion Nebula, why can I see better with my peripheral vision than straight on? The rods (black and white) and cones (colour) in your eyes aren't evenly spaced around. You have more cones in your fovea (center of your focus) relative to the rods around. Cones require more light to activate, so you'll see better at night if you try to consciously use your rods, which means you'll have to try to focus your attention 'off-center' to see better at night.  Here's an interesting experiment you can do related to the lack of cone density in peripheral vision:  
  
Take a few colored flash cards (each a different color from the rest) and hold one out at arms length in front of you. Now move the card to the edge of your vision. You'll be able to clearly identify the color all the way to the edge.  
  
Now take all of the cards and shuffle them behind your back. Then slowly move one of the cards into your field of view and stop as soon as you can see it in your peripheral vision. Keep the card at the very edge of your vision and identify the color.  
  
My particular experience with this is almost a rainbow of hues with temporary solid gray shifts as my brains visual color matching software tries to decide what to do. I have tried something similar but I can always guess the color. I tried using 3 different colors. I can't remember what show it was but I remember seeing a documentary about blind people still able to sense things in front of them using the "blind" receptors in the eyes even though they couldnt actually "see" it. It's gonna bug the hell out of me now that I can't remember the program it was on though. Conditions like this illustrate the fact that the visual system is composed of many parallel processing streams. If there is damage to a certain part of the visual system, one might lose part of the ability to "see" but not others. In a case like you described maybe the person is not able to consciously see anything, but the retina is still more or less intact and at least some information from the eye is still getting through (perhaps not to all the right places). 

Other examples include being not able to see motion or to recognize faces. People with "motion blindess" describe for example pouring water into a cup and seeing first a "frozen" image of water running and then the cup suddenly overflowing; or a car being far away and suddenly right next to them. Face blindness or prosopagnosia can lead to many awkward situations, as you might imagine. There are even patient descriptions of people who can recognize faces but somehow lack the emotional part of this recognizion (visual information is sent to "emotional" parts of the brain as well); famously some have come to the conclusion that their loved ones have been replaced by aliens or robots, as they look identical but do not arouse any feelings of emotional attachment. The condition you are thinking of is called "blindsight", in which damage to parts of the visual pathway (e.g., [loss of rods and cones but not melanopsin-containing retinal ganglion cells](http://www.sciencedirect.com/science/article/pii/S096098220702266X)) or visual cortex (e.g., [the primary visual cortex](http://www.ncbi.nlm.nih.gov/pubmed/19320547)) results in loss of the ability to *consciously* perceive visual stimuli, but still some residual unconscious ability to perceive visual stimuli, such as the ability to correctly guess whether a light is switched on or off. "Blindsight" is also the name of an excellent "hard" sci-fi novel by Peter Watts, and he describes this very thing. And for those who don't already know, not only is it a good read, it's also freely available online licensed under creative commons. http://rifters.com/real/Blindsight.htm

I got a copy in paperback and the epub edition on my tablet. Would not having a blind spot have an effect on our vision? Correct me if I'm wrong, but the brain "fills in" the information that the blind spot doesn't receive, so would having that info have any measurable increase in our visual acuity? Well when you have both eyes open, one eye fills in the other's blindspot so it's not a problem. Your brain only interpolates what's in the blindspot when you close an eye for a fun proof of blindspot experiment:  Make two dots next to each other (left right, not up down) on a piece of paper, about an inch or two apart.  Close one eye, put the piece of paper close to your face, and look at the dot closest to your nose, with the other dot towards the outside of your field of view.  Slowly move the paper away further, until the dot on the outside disappears :)  That's your blind spot!

Or here ya go http://i.imgur.com/pQG7gKC.gif.  Put your face close to the screen and pull your head back slowly Visual acuity is only measured in the center of the visual field where the photoreceptors are densest.

In the right eye, the blind spot occurs in the right field: at the corresponding spot in the left field, visual acuity isn't nearly as good as the macula and it's too far from center to affect acuity for letters of any reasonable size.
 A video you might find interesting on this subject 

http://youtu.be/4I5Q3UXkGd0 Yea, from the wiki, [90 million cones](http://en.wikipedia.org/wiki/Cone_cell) and [125million rods](http://en.wikipedia.org/wiki/Rod_cell), since you need 3 cones for one color and B&amp;W pixels stand on their own using the color information from the nearest cone, it's about equal to 125-150million pixels (about equal to 12,000x12,000px display) and a pixel is about [31.46 arc seconds](http://en.wikipedia.org/wiki/Fovea_centralis) in size.

But it feels like more, because you can move your eyes and sweep those pixels over a larger space. Taking the number of photoreceptor cells as the number of "pixels" might be a bit  misleading. Already in the retina the information is processed by many converging (and cross-talking) cells and networks. Thus nowhere in the nervous system there is a representation of an "image" that would be composed of as many data points as there are photoreceptor cells. But if you were to somehow dissect all the photoreceptor cells, measure their individual outputs and map them to an image, I guess you would get a 100+ million pixel image, although I'm not familiar enough with the matter to know if that would happen (or if the image would make any sense). You could say the same for digital images. Whether it's [DCT transformations](http://en.wikipedia.org/wiki/JPEG#Discrete_cosine_transform) in JPEG images, or [bayer filters](http://en.wikipedia.org/wiki/Bayer_filter) in CCDs, the measure of pixels is often a bit misleading. When you move your eyes and sweep those pixels I believe it is called "Sub-pixel image localization" which is a type of superresolution. It's a method of getting an image of higher resolution from a device of a lower resolution.

http://en.wikipedia.org/wiki/Superresolution Rods and cones are only half the story, the optic nerve is the other half that needs to be taken into consideration. From [wikipedia](http://en.wikipedia.org/wiki/Optic_nerve)
&gt; The optic nerve is composed of retinal ganglion cell axons and glial cells. Each human optic nerve contains between 770,000 and 1.7 million nerve fibers,[1] which are axons of the retinal ganglion cells of one retina. In the fovea, which has high acuity, these ganglion cells connect to as few as 5 photoreceptor cells; in other areas of retina, they connect to many thousand photoreceptors.

This means that the total amount of cone cell data streaming to the brain at any moment in time for each eye is perhaps 0.6 - 1.5 million color values. (The rods are going to be the ones that are bunched into thousands of links) so if we get screens with 12k x 12k resolution (a bit less than ten times what is common in computer screens now), we will basically have reached the cap, and our eyes can't notice any improvement in resolution?  It depends on the distance, you already can't differentiate 720p from 1080p at a distance of 17 feet on a 50 inch display.

http://i.imgur.com/ir7M1Nb.png

A 30 inch display at 20 inches viewing distance will only need an approximate resolution of 4400 x 2500 to match your eye capabilities.
 We'd only need that resolution if we were covering our whole field of view. A computer screen doesn't take up our whole field of view. this reminded me of a question I've occasionally had involving the "fps" of a human eyes. do our eyes collect images in a similar manner that a camera does - as in x amount of images a second - (or at least does our brain process it that way) and do we have a "max amount of fps" that we can see? or do our brains process this information in a completely different way? Humans see completely differently from cameras. Your brain doesn't check what the cells in your eyes are reporting at a fixed frequency, the cells in your eyes send electrical signals whenever they manage to detect a photon striking them. These signals are then processed by the brain in a whole manner of different ways. And the way in which the information is processed by the brain has the largest impact on how you perceive things. The best way to think of it is as being able to see changes rather than collecting a series of pictures of what is there at different moments in time.

As for what kinds of things you would and wouldn't be able to see, it depends largely on persistence of vision and the flicker fusion threshold. This is what makes a particularly strong flash of light appear to last much longer than what it actually does, and what makes you perceive flickering artificial light as continuous lighting. The actual flicker fusion threshold depends a lot on color and absolute intensity of light, but mostly on lighting contrast. So light flickering in a dark room would appear constant at a much lower frequency than light flickering outside in daylight. Usually at frequencies somewhere between 20-70Hz depending on intensity, lighting differences, and the individual person.

This is something absolutely different than how short of a flash of light you are able to notice, though. And tests have been done both demonstrating the ability to detect and identify the silhouette of a specific plane flashed at less than 1/220th of a second (by the USAF) and being able to detect just handfuls of photons entering the human eye in extreme low light conditions. And then you have things like being able to identify visual patterns in artificial imagery that wouldn't occur with real life motion. Like seeing multiple copies of your cursor on your screen if you shake it back and forth really fast, both due to image persistence of the display and persistence of vision. Something that could only be resolved by having the display show images at a rate higher than the rate of pixel movement. It's more like a CID (Charge Injection Device) than a CCD (Charge Coupled Device).  Essentially, it doesn't scan lines, but your brain gets updates when individual photoreceptor cells fire off membrane action-potential signal cascades.   (The sequence of "updates" for signal vs. non-signal is inverted of course, but not discussed here.)

The individual photoreceptive proteins respond usefully to electromagnetic radiation in three wavelength ranges between 0.4 and 0.7 m.  This corresponds with the atmospheric EMR non-absorption window hovering around that range.  Absorption for these bands probably results in a specific conformational change for those proteins.

There is even an interesting kind of signal averaging going on within the cells and at the neuronal level.  If an insufficient number of photoreceptive proteins activate in a short enough span of time, then the cell membrane potential will not be triggered.  Likewise, if a down route neuron requires several inbound axonal junctions to trigger to get above threshold for signal propagation, it can filter out minor signals. http://www.100fps.com/how_many_frames_can_humans_see.htm

I like how they get started:

 	

How many frames per second can the human eye see?
This is a tricky question. And much confusion about it is related to the fact, that this question is NOT the same as:
	

How many frames per second do I have to have to make motions look fluid?
And it's not the same as
	

How many frames per second makes the movie stop flickering?
And it's not the same as
	

What is the shortest frame a human eye would notice? @WRSaunders has a good answer, but I just wanted to add an analogous answer:

Actually the resolution on the human eye isn't what gives us most of our acuity. We perceive an incredible amount of acuity, when at about 20 inches our eyes are capable of giving us about 170dpi (pretty good, but not jaw-dropping, think 10 megapixel camera) at the fovea and is actually quite poor as you move to the periphery (worse than oldest camera phones). If you got a live feed of the raw electrical data from the eye and put on a monitor the images would be barely discernible (a very small hole in the center would have decent acuity). 

Our brain is what gives us most of our acuity. The refresh rate or fps on your eye are near infinite (i.e. continuous electrical signal from the light, though we only perceive a refresh rate of about 1000fps), that allows the brain to do some pretty incredible and accurate hypothesizing about what we are actually seeing, and gives us the incredible acuity that we perceive. Since the brain is doing a lot of complex cobbling together of the electrical data we don't actually perceive at about 1000fps though human beings can only detect changes at a max of about 200 fps.

Given all of this it is actually really difficult to say what resolution we see at.
Here's a good video:
https://www.youtube.com/watch?v=4I5Q3UXkGd0 Vsauce touched on a similar topic before I believe.

https://www.youtube.com/watch?v=4I5Q3UXkGd0 An interesting side note, John Carmack, a leading engineer in virtual reality, estimates that our eyes would need approximately 16K screens to bridge the gap in virtual reality from pixelated screens to indistinguishable from real life. I feel old, to live in a time when it makes sense to tell computer-savvy people _who_ John Carmack even is, and not even tying his name to game development anymore ;-) The eye works by detecting differences and boundaries, then our brain fills in the rest. My neuroscience prof always told us our visual resolution is roughly equivalent to 120 megapixels. At the center of our vision we have 160,000 cones (sensors if you will) per mm^2 However, move 20 degrees away from center and it drops to 8000.  It's not uniform. Our brains do a lot of remembering and guessing to paint what we think is a full-res picture. 

Edit:grammarz I think of is as "resolution on demand" - a picture or movie needs to provide all the resolution up front for all of it, but looking at reality gives you the resolution for whichever part of the world that you care about. It get's the center of vision and focus, it gets saccades to get an even finer resolution than a single 'snapshot' of the eye can do, and so effectively we have the maximum resolution at all directions and ranges, combining the data from all the different eye positions. I'm sure you could theoretically count the number of rod and cone cells in each eye and the number may roughly equate to a pixel density... but it still wouldn't be a smooth conversion because your brain doesn't necessarily use all of the raw sensory data collected from these cells when images are "displayed" Because we don't see the "pixels" of our own eye (i.e. the rods and cones) we can say that the image processing part of the system (i.e. the brain resolves those issues. Like the optical low pass filter in a digital camera smoothes out areas of contrast to avoid moire. One measure of a lens's resolution is MTF or modular transfer frequency. What this boils down to is the density of line pairs that can be resolved by the lens and when the circle of confusion renders line pairs indistinguishable. 

So the resolution of the eye should not be thought of in terms of pixel density like a camera or screen but understood as limited by the physical properties of the lens: the diameter of the aperture (pupil) and the focal length.

This is discussed at length [here](http://www.clarkvision.com/imagedetail/eye-resolution.html) I just ran some numbers.. If the eye's resolution were quantified as, say, half of a pixel width on a 20" wide HD monitor 2 feet away (where double the rez would be Apple's idea of "retina"), a 180 degree field of view would allow for eventual processing of ~210 Megapixels worth of detail. 

It's going to take VR gear a bit more time to get there, especially at 60fps in stereo.

However, the center area of the retina capable of seeing that clearly is probably less than 5 degrees across, yielding a mere ~14 megapixels of high-res imagery at a time. Everything else is peripheral, and is orders of magnitude lower resolution. Try to read this sentence from beginning to end without shifting your eye. Doesn't work. At least for me.

Anyways, it seems that a little bit of eye-tracking may be critical for near-future VR gear to be able to bring life-like detail. I once read that it was around 250 megapixels, so your 210 sounds pretty close. right on Um I don't know if this is the answer you are looking for but there is a really easy answer straightforward answer with an actual mathematical equation behind it. Back when I was taking histology we learned about a very important equation called the Rayleigh Criterion. It is a fairly straight forward equation the gives the minimum resolvable distance of a lens using specific wavelengths of light. Now this was important in Histology because we needed to understand how a microscope resolves things and just exactly what we had the ability to see using different types of scopes and different objectives.

Here is a link to what I am talking about http://en.wikipedia.org/wiki/Angular_resolution

Now to answer your question the minimum resolvable distance for the human eye is generally accepted to be .1mm or 100 microns meaning that our eyes can't tell the difference between between one thing or another if they are smaller than .1mm   The theoretical best resolution of the eye would be dependent on the spacing of the photoreceptors in the retina and pupil diffraction limitations.  I believe it equates to about 20/8 vision on the snellen scale if memory serves me correctly (Which is much better then 20/20). The visual cortex is retinotopically organized, meaning that spacial information is preserved by the physical structure of the brain. Neuroscientists use the term voxel to describe the smallest unit of visual input, If I remember correctly. There is an overall calculation to somewhat describe the visual field, but it's not necessarily the same as a monitor's resolution, it's more like a camera's resolution, which indicates the density of visual receptors that would receive input from light from the lens.   Resolution: Analog. There is a limit to how small a thing the human eye can see, so there is a distance minimum of the width of some thing it can see. The eye's resolution is therefore that distance. It will vary from person to person. Current microbiologist, future dietitian here:

Yes, some of those calories would "pass through" and not be able to be digested.  Unless your body is used to utilizing a massive amount of calories, it's not going to waste energy having and maintaining receptors in your gut that almost never get used.  For instance, you only make so much bile at a time, which is necessary to absorb fats.  If your gut gets overwhelmed with more fat than you can possibly absorb, it's going to pass through the region where fat is absorbed...which is a relatively short region, and get turned into massive amounts of gas later on down the line.   This gas is the result of microbes in your gut inexpertly fermenting fats, which is a nutrient they are not used to utilizing, so they break it down inefficiently, making gases as their own "poop".  You may absorb some of the other products these microbes create as a result of this breaking down, but it won't be as calorie-rich as if you were able to absorb the fats as fat.

If you consistently eat high calorie foods, or a particular type of nutrient, your gut and its microbiome will change in response to that level of intake, and you would absorb those calories more efficiently.

TL;DR?  The second one. &gt; If you consistently eat high calorie foods, or a particular type of nutrient, your gut and its microbiome will change in response to that level of intake, and you would absorb those calories more efficiently.

Could that be one reason most diets seem to work at least at first? If you suddenly change your diet, your gut microbiome won't absorb the new food very efficiently for a while.

What kind of time scale are we talking about for readjustment? Most fad diets work by quickly reducing temporary water-retention weight. For example, glucose is osmotically active, and to maintain isotonic balance between the extra-cellular and intra-cellular environments the body can hold onto a large amount of water. If you reduce glucose content below normal (low carb diet for example) the extra water is flushed away and the loss of a significant amount of weight is apparent.

However, this is weight-loss, not actual fat loss. For fat loss, it is a lot more complicated, depending on multiple factors, including insulin, glucagon, cortisol etc.

For physiologically healthy individuals, one would need a net energy expenditure of 3500 kcal over metabolic requirements per pound of fat (in reality you wouldn't be able to purely lose the fat, but this is just a simplification).

In regards to your time scale question, I suspect that changing the composition of your gut microflora would take longer than the time most diets (at least the fad variety) start to plateau (mostly due to the water retention loss and not actual body mass loss). If glucose causes so much water retention, why don't doctors prescribe low carb diets for high blood pressure like they do with low salt diets? That's a really smart question. But here's why it wouldn't work, unfortunately. 

Unless you're a diabetic or have some other intrinsic problem with glucose metabolism, your body regulates your blood sugar in a pretty narrow window. Eating a high carb meal only transiently elevates your blood sugar for a short time before your pancreas pumps out the insulin and either stores the glucose as glycogen stores or uses it immediately for energy. So while yes, glucose is osmotically active and pulls water along with it (which is what causes the damage to your kidneys, eyes and nerves in longstanding uncontrolled diabetes), it's not going high enough for long enough to be affecting your blood pressure. Also, your body has very good counter regulatory systems (norepinephrine, cortisol) that elevate your blood sugar by breaking down glycogen stores and doesn't depend on your food intake. So even if you eat a low carb diet, your body is going to keep your blood sugar within that normal range. 

Tl;dr Eating a high carb meal won't raise a healthy person's sugar high enough to have a noticeable effect on blood pressure, and your body keeps your blood sugar within a certain range even when skipping carby meals, so it would be impossible to do anyway.  Would low carb diets reduce blood pressure in diabetics?
Also
Would a diabetic running their bloods lower than normal reduce blood pressure? Also good questions!

We like our diabetics as close to the normal range of blood sugar as possible. We do this through medications and insulin, but our first recommendation is exercise and a change in diet. Essentially what we do recommend to all diabetics is a low carb diet (but not a no carb diet because they're at high risk of making a dangerous amount of ketones and can go into a life threatening state called DKA). Uncontrolled diabetics can go even into the 500's. Does this make their BP higher? Probably. But I don't know if it's to any noticeable extent. I bet it's been studied, but I'm not sure. But a low carb diet is going to help control their sugars and help them lose weight, which definitely will lower their blood pressure.

For the second question, you'd have to artificially make their blood sugar go low with insulin or oral hypoglycemic medications, since like I mentioned before the body has ways of keeping your blood sugar from going low unless we're giving you meds that drive it low. And we try very hard not to do this for several reasons. Diabetics are used to higher sugars and feel like crap when their sugar is low, and it also has been studied that low blood sugar in hospitalized patients causes all sorts of bad things. So in general, the risks of low blood sugar outweigh any theoretical, and probably negligible drop in blood pressure you might see. 

Definitely smart questions. This is how we come up with new ways to treat serious problems (look up fecal transplants for recurrent. C. Diff.).  [deleted] [deleted] [deleted] [deleted] [deleted] http://www.nejm.org/doi/full/10.1056/NEJMct0911013

Some actually do. Part of that article does talk about a low-carb Mediterranean diet. But they also mention how in those studies, weight wasn't controlled between the two study groups. And it states the low-carb group lost more weight than the DASH dieters. I wonder if they drop in blood pressure was due to the weight reduction, as opposed to the low-carb diet itself. http://www.medscape.com/viewarticle/836445
" Sugar, Not Salt, May Be at Fault for Hypertension
Lara C. Pullen, PhD
December11,2014" It's important to note the distinction between a "fad diet" causing an initial loss in water weight and an initial loss in water weight being how "most fad diets work."

Low carb (particularly ketogenic) diets do cause a drop in water retention when you use up the glycogen in your liver, but they also aid in the loss of body fat:

http://www.ncbi.nlm.nih.gov/pubmedhealth/PMH0056190/

http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2716748/ &gt; aid in the loss of body fat

All diets that induce a caloric deficit aid in the loss of body fat with equal efficacy. Regardless, there are benefits to pursuing a ketogenic diet when fat loss is the desired outcome. While a calorie deficit is critical, it doesn't describe the hunger response of an individual, and thus the sustainability of a particular eating pattern. Low Carb diets allow insulin to remain low and fat stores to be burne din the context of reduced hunger cravings. Also, your comment assumes that protein intake is at a constant level, or at least enough to minimize muscle catabolism. 

That all being said, I'm not disagreeing with your comment at all. Most organs &amp; tissue in the body have an excellent capacity to utilize both fats and carbs. The body should be good at using both fuels. [deleted] [deleted] Many diets engineer a spontaneous reduction of intake, even if they don't actually say anything about eating less. Low carb works because protein is very filling, and fat by itself is not very appetizing. Low fat works because even though carbs are more palatable by themselves, they're not as calorie-dense. Fat and carbs together (especially with salt) are very palatable and are easy to overeat (potato chips are the perfect example), so generally they'll limit one or the other. The restricted choice is also important -- people consistently eat more when there are more choices. &gt; your gut and its microbiome will change in response to that level of intake, and you would absorb those calories more efficiently.

Have been some animal studies involving stool transplants to transport the microbiome from an obese subject to a non-obese subject and seeing the weight changes in the non-obese group? Yes, a recent study was done with rats. Introducing certain gut bacteria to lean rats caused them to become overweight. I am posting from mobile but I will link the study when I get home.  Yes, in mice http://www.nature.com/news/gut-microbe-swap-helps-mice-shed-weight-1.12688 I read an abstract a few months ago that claimed your gut bacteria could secrete chemicals that would make you crave the type of food they were best at digesting.  I'd look for it if I wasn't at work all day but it sounded interesting. Not so sure this is fully correct. The human GI tract is amazingly redundant...in any given normal meal, almost all of your carbs/fats are absorbed before the second half of your small intestines even begin. Are the receptors you are referring to glucose/galactose/fructose receptors? As far as I know these aren't down-regulated for any reason, but I could be wrong about that. As to the bile, yes you could theoretically overwhelm your bile production, but with how content release from the stomach works, only an amount that is able to be handled by the downstream GI system is released over time. So while some calories would pass through (as they always do), I don't think it would be any more than a normal meal. Please feel free to correct any of this info though! I just finished my GI block in med school so this is actually good practice :D thanks for your input [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Do you have any sources on this? What about some numbers? How much bile is needed per gram fat? A typical gallbladder in an adult male has a volume of very roughly 20ml. How fast can bile be released? 

And what about proteins and carbs? You'd think there was evolutionary incentive to have a buffer capacity in case of large meals as those would add valuable energy to build up fat reserves. You'd also think that there would be mechanisms to stop feeding when nearing that capacity, such as loss of appetite or even vomiting. [deleted] How long does it take for this change to occur? This is false. The uptake capacity of fat is hypothesized to be around 1000 g (~ 9000 kcal) of fat per 24 hours. [1]  

Actual experiments have confirmed that even at an intake of over 600 g (5400 kcal) of fat per 24 hours. Parts of the gut can act as a resevoir for the fat until more capacity for absorption is available. Even at intakes above 500 g per 24 hours, absorption efficiency exceeds 90%. [2]  

1. Simko, V. L. A. D. O. "How much dietary fat in therapeutic nutrition?." Bulletin of the New York Academy of Medicine 66.2 (1990): 164.  
  
2. Kasper, H. "Faecal fat excretion, diarrhea, and subjective complaints with highly dosed oral fat intake." Digestion 3.6 (1970): 321-330.
 [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I'm just going to leave this paragraph here from H.M. Sinclair (Laboratory of Human Nutrition, University of Oxford) in his "The Diet of Canadian Indians and Eskimos" from 1952 symposium proceedings; emphasis mine.

&gt;The Eskimo is apparently able to digest and absorb very large amounts of protein and fat at a single meal.  In times of plenty, 4 kg of meat daily is a common amount and much is taken at a single meal : they do not usually take food in the morning.  Consumption of larger amounts such as 15 kg has been observed on occasion, and Ross (1835) considered that an Eskimo ' perhaps eats twenty pounds 
of flesh and oil daily', **which I suppose is possibly 46,000 Cal.** Parry (1824) thought he would test the capacity of an adolescent Eskimo ; the food was weighed and, apart from fluids, he ate in 20 h 8-1/2 lb. meat and 1-3/4 lb. bread **(about 15,700 Cal.)** and ' did not consider the quantity extraordinary '.  But this is trivial compared with the feats of the Siberian Yakuti who eat 25-30 lb. meat daily, and there is no record approaching the 35 lb. of beef and 18 lb. of butter (providing about 112,000 Cal. and occupying a volume of the order of 5-1/2 gal.) alleged to have been eaten in less than 3 h by each of two Yakuti (Simpson, 1847.) 

One wonders if the Yakuti had very deep pockets and somehow spoofed Simpson by stuffing them full of beef and butter when not being observed. First off, love that username.

A couple of things about the Eskimo/Inuit diet, maybe you or someone else here can shed some light.

First, is the amount eaten that high due to maintenance of homeostasis?  They are living in arctic/subarctic conditions, and I'm guessing it takes a lot of energy to stay warm up there.

Second, is it really true that the extremely low carbohydrate diet that those population groups eat for much of the year have good health effects?  Low-carb advocates constantly single these people out as examples, and the claim is that incidents of heart disease and metabolic disorder are far lower among traditional Inuit than among those who have adopted a modern Western diet.  I'm asking this mostly because I've never found a direct source for these claims. I only have a couple of minutes to fire off a quick reply, but:

1) Yes. Gotta eat a lot of calories to slog through the snow, kill seals, drag it all back home. But it's not as hard as that, really; the Inuit and similar groups have adapted remarkably well- well enough that "prepared" Europeans would starve and freeze, *even after observing how the natives did it seemingly effortlessly.* I would recommend "Fat of the Land" by the Arctic ethnologist Vilhjalmur Stefansson. The [pdf is available online.](http://highsteaks.com/the-fat-of-the-land-not-by-bread-alone-vilhjalmur-stefansson.pdf)

2) Health effects are contestable, if for no better reason than that it is impossible to do similar studies today. People will be happy to point out the modern Inuit and Inupiat suffer a slew of medical problems, but- then again, they don't eat and live like their ancestors did. The introduction of Westernized foods, starting with the construction of the Distant Early Warning Line, was a catastrophe, one documented in [When the Eskimo Comes to Town](http://journals.lww.com/nutritiontodayonline/Citation/1977/05000/When_the_Eskimo_Comes_to_Town_.7.aspx) written in 1977. The teeth rot, for one thing. Introduction of tobacco and other factors have made it impossible to compare health factors.

Then there's the argument that they "didn't live that long," due to the tough life, meaning they shouldn't develop cancer as Westerners did, anyway. [This blog](http://wholehealthsource.blogspot.com/2008/07/cancer-among-inuit.html) discusses cancer, and the next entry discusses the longevity issue.

But I will note this: cancer in the Inuit was rare enough that its appearance merited publication in the pre-DEW Line days, i.e.: pre-1950s.

I will happily agree that the statistics are wonky because 1) old medicine isn't always good medicine and 2) there are some difficulties in the statistics due to age, but I would humbly suggest that the subject merits additional review by those unfamiliar with the extant literature. It is intriguing. How did the Inuit deal with what seems to be a serious lack of fiber in their diet?  [deleted] Thanks, Polly!  Feels good to get that cleared up, and I will definitely check those sources. [deleted] [deleted] It all depends on what you are eating.  Different substances are absorbed at different rates so it is more about the source of the calories.  Sugar is easily broken down and absorbed so eating 10000 calories from sugar might be more completely absorbed than 10000 calories from something harder to break down like fiber. 
In this case however I don't think it's as much about absorbing the nutrients as it is retaining them.  If we have too much of anything and our body is not able to convert in into adipose for storage as quickly as we take it in then we will expelled the unused portion.  So theoretically you would be able to store the excess nutrients from 1000 calories a day more easily thus having a larger overall impact on your weight.  That is the really simple answer though and there are a ton of other variables that can play a factor in that such as your overall health and metabolism as well as the composition of the meals you are eating. 10,000 calories of sugar is around 2.58kg (5 lb 11 oz).  If you ate that all at once, it might spoil your day. That's 4 family-sized packs of Oreo cookies (192 cookies). I don't know what would kill me first, the guilt or the sugar overload. 

http://www.snackworks.com/products/product-detail.aspx?product=4400003327

Edit: This is just 10,000 calories and not 10,000 calories of sugar. Sorry. Oreos also have fats, minimal protein, and non-sugar carbohydrates in them so to get the equivalent sugar via Oreos you'd probably have to eat 2-3x what you stated Thanks. 

So that would roughly be 20,000~30,000 calories? [deleted] [deleted] [deleted] How are you getting 4 packs? Wouldn't it be 11.5 packs? 

(14 g/serving)*(16 servings/pack)*(.00220462 lbs/g)=0.49383 lbs/pack

(5.6875 lbs)/(0.49338 lbs/pack)=11.5 packs  1 pack of cookies has 48 Oreos which are 2560 calories. 4 packs of Oreos would be 10,000+ calories.

I suck at math. Please, correct me. 

Edit: Ahhh, I missed the "calories of sugar". I was just looking at calories. Thanks for the correction!
 [deleted] [deleted] putting it in perspective, 10,000 calories would be any of the following:

 - 7.5 large big mac combos with coke

 - 5 double-steak burritos with a side of chips&amp;guac from chipotle

 - 9 pints of ben &amp; jerry's americone dream

 - 41.6 chocolate brownie cliff bars


 - 2 to 3 jars of peanut butter, depending on brand and type

 - 3.3 large pan pizzas with pepperoni from pizza hut
 
 - 72.6 lbs of watermelon

 - 47.6 hershey bars

 - 95 bananas (for scale)

some of them would be physically impossible to eat due to volume.  others would be painful.  others are totally doable.

i think i'm just agreeing with your point that it really depends on the source of those calories. I'm curious - which of those are totally doable?! They all seem physically impossible to eat in one go. [deleted] [deleted] I could probably have done the big macs at some point in my life.

I could probably do the 5 burritos now, though I'd be feeling pretty bad after #3.

2-3 jars of peanut butter is probably the easiest.

I am under 200 pounds, and rarely eat super large quantities of food, so I'm sure some other people could handle it. [deleted] &gt; 95 bananas

The banana/potassium thing is way over-exaggerated.  They're not the best source by a long shot.  [Pretty much any green vegetable knocks it out of the park.](http://www.whfoods.com/genpage.php?dbid=90&amp;tname=nutrient)

One medium banana has 422mg of potassium.  So, 10 only gets you to about the RDA, which is not a maximum.  Potassium chloride isn't the form in bananas, but even that, the lethal dose is something like 2600mg/kg.  Adjust for the molecular weight of potassium proper vs potassium chloride, *assume that the potassium in bananas has the same lethality as potassium chloride* (which we can't, as there have been no reports of dietary overdoses), and I'm getting an LD50 of 3.2 bananas/kg (for an ~average banana).  Not going to assume anybody's weights, so do your own math, but way more than 95 for an adult.

(Full disclaimer, it's 7am and I haven't been to bed.  YMMV on the exact math, but the concept should be approximate.) And if you want to look at healthier foods and blow your mind a little bit, to hit 10k calories consuming just chicken (148 cal per cup), broccoli (31 cal per cup) and wild rice (166 cal per cup) you would need to eat (roughly) *29 cups of EACH food*. That's:

**9.6lbs** of chicken.

**5.8lbs** of broccoli.

**10.5lbs** of rice.

A total of: **25.9lbs of food**. That's like 24 chicken breasts, 11.6 small heads of broccoli and well, 10.5 pounds of rice. This is another thing that irks me about weight loss and weight conversations; if you're complaining that someone can eat so much without gaining weight make sure you look at WHAT they're eating as well. You can literally have 3.3 pizzas from pizza hut, or about 26 pounds of food and still hit the same caloric intake.





 &gt; eating 10000 calories from sugar might be more completely absorbed than 10000 calories from something harder to break down like fiber.

I should think so, since fiber is, by definition, food that you can't break down and digest.

A better example might be protein, fat, or complex carbohydrates. Some fiber your body can break down. Or rather the bacteria in your digestive system can break it down first and your body can finish off the rest of the process. But it is much less than normal carbohydrates.
[Source](http://en.wikipedia.org/wiki/Dietary_fiber#Fiber_and_calories) That is definitely NOT the definition of fiber.  First off, 'food' requires the subject in question to be nutritious, so if you can't break it down, it is not food, by definition.

Secondly, as /u/bloodyusernames below me has said, some types of fiber your body CAN break down.  Fiber is a carbohydrate, and certain types can yield up to 2kcals/gram. If you are only considering energy expenditure, maximum daily energy expenditure in humans is between 4 and 5 times BMR (basal metabolic rate) based off of research looking at Tour de France cyclists. The biomass accumulation question is a little harder to answer, but it also relates to BMR and is regulated by hormones, internal gut morphology, existing body composition that can signal for increased deposition of fat, glycogen stores, etc.

Examples of the extremes of energy assimilation in a natural system (i.e. not force feeding, no artificial manipulation of hormone levels) are shorebirds during migration. During migration several species have energy assimilation rates more than 7 times their BMR which translates in an ability to increase lean body mass by ~10-15% a day to recover from and fuel up for long migratory flights. Can you imagine if a 180 lb person could pack on 18+ lbs of mass...in a day? Is the average or maximum energy expenditure notably different during early puberty?  I would expect at least the average to go up by quite a bit as the body is forming bone and doubling muscle mass. [deleted] [deleted] This article shows that during the tour de france the major type of energy source is carbs.  During such huge efforts, the riders are expending up to 5000 kcal a day (in addition to basal metabolism).  Unfortunately we are not really designed for recouping that energy so quickly, but the best way to do it is with simple carbohydrates like sucrose, fructose, or glucose containing items. 

http://www.bicycling.com/tour-de-france-archives/2011-tour-de-france/eating-tour-de-france

 But if you weren't exercising, would your body just hold it for energy, fat stores etc?  Yes.  Excess carbohydrates can be converted to fat inside fat cells for long term storage.  Later, when you need energy this fat is metabolized for fuel.  Think of fat as a storage system.  Your car has a gas tank so it can operate for long periods without refueling.  Fat serves a similar purpose for humans.  The human body is marvelously capable of extracting nutrients from food, which is probably not surprising when you look back at our hunter-gatherer ancestors and the unreliability of their food supply.  This works against us now that we have such readily available high caloric processed food causing us all to get fat.

So a single 10k calorie meal should be processed and digested without much difficulty as the digestive system has processes in place to handle large meals (assuming the 10k worth of food you chose to eat could all fit in your stomach, or the meal was eaten over a few hours, and the chosen food did not contain irritants). 

However, prolonged repeated high calorie intake (usually fat) has been shown to modify human digestive physiology by [paradoxically promoting increased energy intake and the development of obesity.](http://ajcn.nutrition.org/content/86/3/531.full)
 &gt;the unreliability of their food supply

Your comment is, overall, great, but I believe this is a common misconception.  Researchers in the American midwest were curious how much time nomadic hunter-gatherers had to dedicate to hunting and foraging each day, and they found that they could gather enough calories from gathering a wild grain in 3 hours that they could live on it for 3 days.  Also, when hunting, taking down something like a deer provides enough food for a large group for days, to say nothing of things like bison (where the problem really becomes being able to store the food).  Also, being nomadic makes things a lot easier.  As a tribe follows a food source like a herd of bison, they are constantly moving through new sources for foraging.  

Starvation didn't become a big issue until humans settled down and started agriculture.  Agriculture nearly killed us off.  Naive farming led to regular famines as the soil became stripped of nutrients.  Settling in larger groups also led to resource scarcity, easily spread disease, and other things.  It took a lot of time for humans to get the hang of agriculture as opposed to just walking over the next hill to find a pristine source of food. That seems counter-intuitive, TBH. If hunting and gathering is that easy, and agriculture is that difficult, why would ancient man ever have stopped the former and started the latter? 

Not saying you're wrong; after all, history is filled with bad decisions. I'm just saying, I'm going to need more than some guy on Reddit saying that to convince me. Have any sources? 

EDIT: Ah wait, I just noticed you said the American Midwest. Now it makes sense. After all, the natives there never did give up the nomadic hunter-gatherer lifestyle until the European colonists showed up and wrecked their shit. I doubt those findings are as applicable to many other areas, but then, I'm no expert.  Most hunter/gatherer cultures around the world that have been studied by Anthropologists spend a similarly small amount of time in food-producing activities. For example, a study of the !Kung in southern African found that despite inhabiting an arid, impoverished area, they spent an average of 17 hours a week hunting and gathering food.

It's fairly commonly accepted that humans only switched to settled agriculture wherever and whenever their population density grew too large to be sustained by the hunting/gathering lifestyle. Farming can support larger populations in a smaller area than hunter-gatherers (more calories).  So, even if they're less happy with their lot, there will be more of them.  It also allowed the development of an upper class, who could organize these larger numbers of people into civilizations, and develop technology, weapons, medicine, philosophy, etc.  You can see how this would result in even larger populations over time.

If you read what the hunter-gatherer lifestyle consisted of, I will say on average it was a happier way of life until recently in many areas.  I'd rather have been a hunter-gatherer or pastoralist than a typical person from most any other lifestyle at any time pre-1900, that's for sure.   A lot of people completely forget about ketosis and the body using fat (ketones) for primary energy when carbs/sugars aren't available. Protein can be turned into glucose as well (Gluconeogenesis). Your brain, heart and most parts will use ketones. That's how these natives didn't have to eat 3, 4, 5 times a day like people do now. All people mostly do now is constantly carb up, over and over. Your liver can only hold around 100g of glycogen, muscles around 400g or so average and your blood stream about 40g of glucose. Rest turns into triglyceride (bodyfat) or passes through.  The book 'Sex At Dawn' is where I originally read about the study, and it discusses a lot of the social and material differences between nomadic cultures and agricultural ones.  They never really approached the idea of 'why did they settle down' and I think it would be impossible to know with any great certainty.  Many of the negative consequences of agriculture weren't immediately obvious.  I imagine there was a significant contingent that really liked the increased control agriculture gave them.  It invented ideas of private property, and enabled collecting much larger amounts of property.  It made men 'kings of their castle' and enabled them to exert extreme control over both their spouses and their children (both of whom came to be seen as private property).  Other things, like malnutrition caused by lack of a varied diet, and famine due to poor farming, were things they simply didn't have the knowledge to understand as coming from agriculture.  As another commenter mentioned, the situation was probably different on the savannahs in Africa.  But, of course, Africa is not where agriculture was developed.  People may have tried, but they were apparently not successful until they hit the far north of Africa and moved into the 'fertile crescent' region. [deleted] [deleted] I wonder if there have been studies that looked at people with bulimia or binge eating disorder. It is difficult to get all of food you eat out before you start digesting it, if you binge on a lot of food (like bulimics do). Even so the large amounts of calories ingested in binges (by people with binge eating disorder more acutely) vs. people who just overeat all the time, would reveal whether they are absorbed differently.  I'm really disappointed in how vague and generic that answers are on here. I was hoping someone would go into detail about how 10,000 calories worth of chyme gets absorbed when the part of the small intestine that does the most absorption, the jejunum, is pretty short, only 2.5m long.  The duodenum is where the enzymes get put in for the breakdown and the ileum mainly absorbs vitamin B12 and bile acids and some leftover nutrients. But I'm not getting how 10,000 calories worth of it will almost all get somehow efficiently taken in, especially considering the surface area of the particles &amp; how relatively fast things move through.  The colon is mainly just water absorption and the bacteria there turn some of what's left into short-chain fatty acids.  I haven't seen anyone post good enough proof that you can really absorb 10,000 calories in one go (which I assumed meant in one eating session).  But people are posting about how athletes eat 12,000 in one *day*.  

Can someone actually go into some science-ish detail about the exact way food, including the time length and how much gets processed and absorbed in each section in ONE MEAL of 10,000 calories? 

I don't know myself &amp; I was really glad this was asked here but I was hoping for more than just basic answers. 

raging_asshole below posted good examples of just how much 10,000 calories is.  I just don't believe an average human (without a big stomach) can really process a 10,000 calorie meal completely.  Pretty sure I read in Sir Ranulph Fiennes book about Captain Scott, that polar explorer were/are able to take in a maximum 7,500 calories per day, based on typical level of fitness etc. And that whilst on their expedition Scott's team were likely burning about 10,000/day due to the physical activity (pulling a sledge on foot to the South Pole). This meant that regardless of availability of food they were going to deteriorate physically as they lose weight, burn fat and then lose muscle mass, simply because their bodies couldn't store energy quickly enough to keep up. what food can they carry with them thats so calorie dense? Pemmican.

Quoting the Arctic explorer Stefansson in his "Fat of the Land" (emphasis mine):

&gt;Peary retired from active field work in 1909. There were then available only two techniques that made long polar journeys feasible; one to live by hunting, the other to carry the things needed. Peary was the unquestioned master of the second technique. It seemed to his explorer friends, as it did to his publishers, that he ought to write a book explaining his methods so that they would not be lost to future generations. The result was Secrets of Polar Travel, New York, 1917. I quote from pages 78-79:

&gt;"Too much cannot be said of the importance of pemmican to a polar expedition. It is an absolute sine qua non. Without it a sledge-party cannot compact its supplies within a limit of weight to make a serious polar journey successful. . . . **With pemmican, the most serious sledge-journey can be undertaken and carried to a successful issue in the absence of all other foods.**

&gt;"Of all foods that I am acquainted with, pemmican is the only one that, under appropriate conditions, a man can eat twice a clay (on sledge journeys Peary used only two meals, morning and evening) for three hundred and sixty-five days in a year and have the last mouthful taste as good as the first.

&gt;"And it is the most satisfying food I know. I recall innumerable marches in bitter temperatures when men and dogs had been worked to the limit and I reached the place for camp feeling as if I could eat my weight of anything. When the pemmican ration was dealt out, and I saw my little half-pound lump, about as large as the bottom third of an ordinary drinking-glass, I have often felt a sullen rage that life should contain such situations.

&gt;**"By the time I had finished the last morsel I would not have walked round the completed igloo for anything or everything that the St. Regis, the Blackstone, or the Palace Hotel could have put before me."**

My own experiences have been similar. If you're hungry, it's delicious. But it is extremely filling, and satiety is reached quickly, at which point it's "ugh, pemmican." Looks and tastes like a candle made with sawdust. I remember hearing about them eating a sort of frozen biscuit that was mostly made up of lard I remember reading somewhere that it's normal to lose 10lbs to 20lbs climbing Everest. The amount of food that is absorbed by your digestive system, depends on what it is. Refined sugar is largely ingested, because it is unaccompanied by fibre. Fibre greatly influences how much food passes through you. The more fibre, generally the fewer calories absorbed. Soda, which is liquid sugar, is obesity's genesis. So... If a person filled up on metamucil and water along with everything else it would balance out? Good question, I would like to know that as well, looking forward to a reply. The military reckon on a minimum of about 4500 kcal/day for normal winter ops as a "neutral diet". Himalayan mountaineers need rather more at around 7000 kcal/day for the duration of an expedition and they tend to lose weight (this may be an issue with altitude sickness or the shear difficulty of preparation/consumption at altitude). The body seems to be able to cope with both. There's a difference between in one sitting and throughout a day. Interesting though, wasn't aware of the huge amount of calories that had to be consumed. Yes, less of an answer but more background material. However, neither the military on duty nor climbers have much time or opportunity to snack so this would be split into generally two or three meals per day. I'll update the post later with links to research on cold weather/high altitude US military rations which also gives meal calorie breakdowns.

It should be noted that the cold itself is less of an issue with modern clothing but rather the resistance to physical effort. This tends to turn any period worked into an extended gym exercise. Naturally, the metabolic rate goes very high so fats are burned rather than stored. [deleted] [deleted] [deleted] In this case would that mean, based on a 1000 calorie per day in take regimen, a 10000 calorie day would keep you nourished for a further 9 days before you would have to eat again to follow your regimen? You'd still get hungry. Although, if you took in water (and electrolytes) &amp; fasted for a few days straight, you'd just be using your fat stores without issue (ketosis). You'd have to get passed the hunger feeling though, which subsides once you start producing a lot of ketones.

Why did this get downvoted? Are you saying using fat for fuel is bullshit?  One hurdle to consider is that the muscles of your intestine responsible for peristalsis can slow or stop completely, giving the intestine more time to absorb its contents, and the biome there more time to engage in digestion or denaturing of contents. Pancreatic Physiologist and MD with decades of experience here. Although bile plays a subsidiary role in digestion its primary role is in absorption of fat. Protein and carbohydrate absorption do not require bile. Certainly a portion of your 10,000 calorie day would be one of those two substrates as well as fat. The pancreas is profoundly the primary source of digestion of nutrients. Although one can theorize reaching a point in which you overwhelm the capability of the pancreas to digest a meal, in clinical experience, in the absence of diseases like diabetes and pancreatic exocrine dysfunction, this phenomenon is not seen. Exocrine function is the process by which pancreatic digestive enzymes process nutrients in the gut to make them available for absorption. And sadly we see examples every day in which individuals consume massive amounts of calories and absorb every one of them. Reference our global obesity epidemic. You might also be startled and dismayed to discover that one can easily consume several thousand calories in one meal at an average restaurant. A rich pastry for dessert can approach 1000 calories.
Regarding the microbiome, it is noteworthy that after exposure to gastric acid the contents of the small bowel, where essentially all absorption takes place, is sterile. The contribution of gut flora to small intestinal absorption is insignificant. 
Parenthetically, when large doses of nutrients are delivered intravenously it is possible to overwhelm the body's capabilities for absorption, primarily of glucose.
If we carry your query to say 50,000 calories the question I would pose is how can you consume that and not finally start to vomit? What if you ate something not easily digested? Such as corn? How much would a person have to eat in raw corn to consume 10k calories? From what i understand corn has a pretty high calorie but low nutritionally value? If you recall the Olympic swimmer [Michael Phelps](http://en.wikipedia.org/wiki/Michael_Phelps) ate [12,000](http://www.michaelphelps.net/michael-phelps-diet/) calories a day while in training. The point is that your body's use of the calories you eat is variable depending on how many calories you force it to burn. 

If you train like an Olympian you will probably use much more of the 10,000 calories than you would if you were on the couch watching the Olympics. 

That being said, eating all 10,000 calories at once is not the same as eating that much a day. If your stomach doesn't explode or your body doesn't shut down from glucose overdose, you'll probably pass most of it 1 trillion stars * about 40% of the galaxy is visible / [3.9 billion pixels](http://www.spacetelescope.org/news/heic1502/) = 100 stars/pixel. So using the photo to count stars is definitely out of the question.

The way we estimate the number of stars in a galaxy is [by the mass of the galaxy and the average star](http://www.space.com/25959-how-many-stars-are-in-the-milky-way.html). This hasn't changed with the new high-res photo, as far as I'm aware. We can estimate the number of stars from mass only when we know the fraction of the mass that reside in luminous stars in the first place.  84.5% of the mass in the universe is dark matter, and we first found out about it because galaxies (and clusters) have far more mass than can be accounted for with stars (or dust, or gas). 

The original estimates of the number of stars in galaxies were based on the measured light emitted by them, and our knowledge of how star masses are distributed. 

Since the estimate from mass and the estimate from light were so ridiculously divergent, and since the rotation speeds of stars did not slow down with distance from the center of galaxies, we learned that every galaxy is overwhelmingly a huge halo of dark matter (which we still don't know what is), and that atomic matter like stars and people are almost an afterthought.

Only when we had independent estimates of the breakdown between atomic and dark matter could we use mass to estimate the star count in galaxies.
 I'm still not sold on Dark Matter being anything more than a human measurement error.  I think the closer and closer measurement we get the less and less Dark Matter we will need to explain the discrepancies.  Its like that "coast of Britain" problem, and we only have sticks that are as long as Britain. If we presume all matter is as we know it, then we cannot explain the rotation of galaxies. The way normal matter interacts will naturally clump all the matter into the discs we see at galactic scales (this is due to collisions). However, if all matter in a galaxy is distributed in such a fashion, we cannot then explain the [rotational speed of stars in a galaxy](http://en.wikipedia.org/wiki/Dark_matter#Galaxy_rotation_curves). 

Dark matter is a proposal that there is matter with mass but which has no electric charge, color charge, etc, and so does not interact in any way other than through gravity. This means no collisions and therefore a much more spread out and also spherical distribution in the galaxy which then accounts for the galactic rotation speeds.

There could be [alternative explanations](http://en.wikipedia.org/wiki/Dark_matter#Alternative_theories) to galactic rotation, but I wanted to clear up the reason dark matter is proposed and point out that it isn't only a case of a [discrepancy between what we see and what we measure](http://en.wikipedia.org/wiki/Dark_matter#Galaxy_clusters_and_gravitational_lensing). I'm glad you linked to alternate explanations, because your opening statement isn't exactly true. If we presume instead that we don't currently have a perfect understanding of the nature of gravity, then we can still presume that matter is as we know it, without the invocation of exotic undetectable forms of matter.

Much like the orbit of mercury could not be fully explained with newtonian physics, it could be that the winding problem cannot be fully explained until we have a better handle on the bending of spacetime on galactic scales.

There's even the possibility that a supermassive black hole simply affects spacetime in a way that we don't yet understand.

Dark matter is something that should be more accurately thought of as 'here there be dragons', because the only evidence currently for it being a real physical thing is gravity itself, and we haven't exactly gotten a precise handle on just what that is yet. Is there a force carrier or isn't there? How exactly does mass bend spacetime? Are there any sorts of rules to how spacetime bends on larger scales?

All we really know is that based on what we can measure, the motion of stars in a galaxy behaves differently than we expect, and we're not really sure why. 

It could very well be than in 200 years the search for dark matter will have been as just as pointless as the search for luminiferous aether. The clever bit will be figuring out the experiment that proves it either way. Modifying gravity is way more "here there be dragons" than dark matter! We already know that particles that interact only through the weak nuclear force and through gravity exist - they are neutrinos. Adding another member to our family of fundamental particles is a much smaller jump than arbitrarily changing the equations of gravity to fit what you want!

This is a really weird situation where the general public has exactly the opposite opinion to the majority of scientists. But just because modifying gravity worked last time doesn't mean it's the correct solution for every single time a similar problem comes up! Yes, modifying gravity worked for the problem of the orbit of Mercury, but missing mass (Neptune) was the correct answer for the problem of the orbit of Uranus.

So we now have General Relativity for gravity. But it's very hard to justify any modifications to General Relativity. The issue is that GR is basically the simplest possible solution to the constraints we have. And if we make things more complex, we really need to justify them very well, because otherwise we're just adding epicycles. Simply changing the parameters and adding extra terms to make gravity "fit" the orbits - which is what many alternate gravity theories have done - isn't very convincing or satisfying. It's also really hard to test, because it's so flexible. There's only one simplest solution, but if you're making it more complex, you can change it however you want. This makes it really hard to disprove modified gravity, because you can always just modify it again to make it fit again. Being so difficult to disprove makes it a less useful theory, and one with less predictive power.

But dark matter is on much more solid ground. We have some good theories about particles and their interactions, and so we can constrain things pretty well. We don't get to invent any type of particle we like, because we know the kinds of physical laws that particles follow. This is how we are able to say that the majority of dark matter is not made of neutrinos. Neutrinos are too small and thus move too quickly to collapse into galaxy-sized haloes. That's the level of precision we're dealing with in dark matter: we're not just looking for some mysterious invisible particle, we've already found plenty of invisible particles and we've ruled them out for not being quite right.

Adding an extra particle also isn't nearly as arbitrary as modifying gravity. There are a number of sensible extensions to the standard model of particle physics that add in whole new families of particles. The neutralino of supersymmetry was popular for a while, but more recent experiments are making supersymmetry seem less likely. The most popular candidate right now is the stale neutrino.

And that illustrates the difference between the two approaches. Modified gravity is saying "well, who knows?" and changing the equations to fit observations. But with dark matter we're on solid ground - we have known things to work with, and we have specific things to test for. These things aren't mysterious or arbitrary, but are concrete things we know where to look for if we build the right equipment and do the right experiments.

Plus there's the Bullet Cluster, which gives pretty good evidence that the mass is not always where the light is - a pretty good argument for dark matter. Physics isn't my "thing," so to speak, so if this is really silly I apologize. But, is it possible that in the same way gravity is different on the quantum scale, that there could somehow be a model of macro-gravity that doesn't rely on dark matter in a similar way that we're currently looking for a model of quantum gravity?

I'm probably super behind-the-times on this kind of thing. All the physics you learn before QM is QM-lite - that is to say, the behavior of objects as they get bigger and bigger emerges from the probabilistic context. You *could* describe the whole universe, big and small, in QM. It would be a pain in the ass. But, if we were QM-sized, wave electromagnetism would make perfect sense, and we'd be able to make approximations of QM to derive the electromagnetism we teach in E&amp;M college classes.

The reason for this is contained in the mathematics - if you look at the distribution of a few many-order-number of probabilistic actions, the number of likely outcomes collapses. The bell curve 'pinches' into the center, for example. If you have one particle of gas in a box, it could be anywhere. If you have a quintillion particles and count how many are in a given small cube, it'll be roughly the same as any other cube.

This logic doesn't imply there should be any other level of emergent behavior. Why would a galaxy act differently than a solar system, when both are just big fluid masses orbiting at a great distance from one another? The galaxy doesn't seem contain any object or feature which could not exist independently, or exist in a smaller system. Compare this to light rays, which make no sense in a quantum context.

So it's not impossible, to answer your question. We just have no reason to think it is that way (and it would be a substantially more complicated solution than others that are regularly proposed). Thanks for your explanation.  Another ignorant question - is there a theory for why we haven't detected the effects of dark matter at the solar system level?  Is it theorised to all be closer to the galactic core, between galaxies, etc. and therefore not in our neighbourhood? Since we don't know a thing about its properties, besides its noninteraction with light, we don't know where to look for it either. And frankly, space is really very large. The likelihood of it being right around here is about the same as its likelihood of being anywhere else in particular, which is small. I would just like to point out that it seems like it is sadly becoming the rule not the exception for the public to have the exact opposite position as the people who study a given issue for a living (aka scientists). This thread has been linked to from elsewhere on reddit.


 - [/r/bestof] [/u/Astrokiwi explains why dark matter is more plausible than alternate theories of gravity](http://np.reddit.com/r/bestof/comments/2t82om/uastrokiwi_explains_why_dark_matter_is_more/)


 - [/r/goodlongposts] [/u/Astrokiwi responds to: In light of the new high-res photo of Andromeda, is there any chance that we will be revising our estimate of the total number of stars in the galaxy? (currently 1 trillion) \[+41\]](http://np.reddit.com/r/goodlongposts/comments/2t8yly/uastrokiwi_responds_to_in_light_of_the_new/)

*^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote ^or ^comment. ^Questions? ^Abuse? [^Message ^me ^here.](http://www.reddit.com/message/compose?to=%2Fr%2Fmeta_bot_mailbag)*

 Agreed completely. Looking back my first sentence was too strong a statement. I was only trying to indicate to OP that there are two issues dark matter addresses:

1) The discrepancy between the amount of matter we "see" and the amount indicated by [gravitational lensing](http://en.wikipedia.org/wiki/Dark_matter#Galaxy_clusters_and_gravitational_lensing).

2) The discrepancy between our model of stars' orbits in a galaxy and what we observe.

Unfortunately, if our issue is only an imprecise measurement of ordinary matter (a la coast of Britain), then only issue #1 is addressed and we would have to come up with another model to address issue #2.

Dark matter is only our best theory because it solves 1&amp;2 with one stone and does it without modifying our existing theories. We have no theories which preclude matter without spin, charge, etc. and so it is a reasonable theory only in that it is not impossible and solves some outstanding issues in astronomy.

That does not mean it is ideal, as yes, we would love to have a theory which can be more easily confirmed. I would think that a new understanding of the nature of gravity would be at least as exotic and undetectable (as shown thus far) as is the proposal of dark matter. 200 years?

150 years ago, Maxwell's Equations were brand new.

The Schrdinger Equation is less than a century old.  And as you pointed out, the Aether was believed to exist just about a century ago.

At the dawn of the 20th century, the consensus among scientists was that they could explain *everything*.  The remainder of eternity would be spent just refining the little details.

I think it's fair to say that just 100 years from now, scientific understanding will be dramatically different.  If not 50. Or 10. But couldn't our estimate of the matter in non-luminous dust, or in black-holes be wrong and account for the same discrepancy? The probabilities of that are very likely less, but  are they zero? The important part of dark matter is the "spherical distribution in the galaxy" which is impossible with traditional matter as we understand it. We could observe black holes nearer to the edge of galaxies where the additional mass is required to be (according to observations), yet we don't, and non-luminous dust can still be accurately estimated and observed with the light that we do see.

Then, there's the sheer amount of dark matter. There is about 5.5x more dark matter than ordinary matter in the universe. That discrepancy cannot be accounted for in dust. That idea (regular matter that's just hard to see) is called [MACHOs](http://en.wikipedia.org/wiki/Massive_compact_halo_object) in cosmology. It's not a popular theory, wikipedia does a good job explaining why:

&gt;Theoretical work simultaneously also showed that ancient MACHOs are not likely to account for the large amounts of dark matter now thought to be present in the universe.[6] The Big Bang as it is currently understood could not have produced enough baryons and still be consistent with the observed elemental abundances,[7] including the abundance of deuterium.[8] Furthermore, separate observations of baryon acoustic oscillations, both in the cosmic microwave background and large-scale structure of galaxies, set limits on the ratio of baryons to the total amount of matter. These observations show that a large fraction of non-baryonic matter is necessary regardless of the presence or absence of MACHOs.[citation needed] It's too much for a measurement error and been corroborated too many times. It's not like 10-25% of mass is unknown dark matter, it's over 80%.

It could be that the vast bulk of the Universe is a series of subatomic particle that has mass but is not observable (yet) and we haven't figured out how to detect it or it could be something else but the only way to make dark matter less is to quantify the stuff that dark matter is.

Either way the mass of our galaxy is probably right give or take 3%. We're just not capable of seeing more then 3/4 of what exists yet. The case for dark matter being real is actually very strong.

I know nobody who has made [the case for dark matter being real](https://medium.com/starts-with-a-bang/dark-matter-in-galaxies-proven-ebcbea1a5402) better than Ethan Siegel. Give it a read.

(PS: I think this is a fair question, and I think it is unfair to downvote objections instead of replying) This is a great link! Thanks for posting it. &gt;  Its like that "coast of Britain" problem

It really isnt!  There are some superficial similarities, but the reasons for postulating dark matter are *totally* different from either the coastline problem or measurement error (which are also different from each other).  Other commenters are enlarging on the details well, but I just want to emphasise how much of a difference there is here.

Its more analogous to the way that [Neptune was predicted](http://en.wikipedia.org/wiki/Discovery_of_Neptune#Irregularities_in_Uranus.27s_orbit) by noticing that Uranus observed orbit was different from what calculated based the previously-known planets.  We know roughly how large our measurement errors are, and the discrepancy here is much larger.  So we can be pretty certain theres something big out there affecting things; and we can work out some things about it, even though we cant observe it directly.

Theres a lot of controversy over what dark matter is, or whether its even something thats enough like ordinary matter for the name to fit.  But as I understand, theres no serious school of thought that its just a measurement error or something like that. If you want to use Dark Matter to explain the ways galaxies observed rotations don't match our predictions, then you have to arrange it (in many cases) into a sphere around the galaxy. The reason people say it's not just "ordinary matter" is that ordinary matter would never form a sphere if it could possibly form a disk. When a swirling cloud of particles and rocks collides with itself, the angular momentum averages out in a way that results in a disk. Dark matter, as it's currently proposed, can't do that, or it wouldn't correctly explain the galactic rotations we observe. If you use dark matter to explain the discrepancy that it was proposed to explain, then it would have to be an exotic form of matter with special properties. There are definitely phenomenon which require either exotic matter or unknown physics to explain. The galactic rotation curves are the typical example: as you go from the center of a galaxy to the edge, you would expect the stars to orbit slower and slower based intensity of the light we observe. However, we actually see them orbiting at close to the same speed all the way to the edge. The only way to explain that using a "measurement error" is to make a bubble shaped cloud around the galaxy. But Galaxies are disk shaped for a reason; it's the result of collisions between all the stuff in the galaxies. So to have this bubble shaped extra mass, it would have to be matter you couldn't bump into. If it spent the last 13 billion years bumping into stuff, it wouldn't be a bubble any more, it would be a disk. All the matter we've observed so far can be bumped into. Even light bumps into things. Even neutrinos do it rarely. This would be matter that is fundamentally different than any matter we have observed, ever. That's why it's called Dark Matter.  Except that it keeps growing, the amount of "other stuff" needed to account for the results.  The problem he mentions: http://en.wikipedia.org/wiki/How_Long_Is_the_Coast_of_Britain%3F_Statistical_Self-Similarity_and_Fractional_Dimension Thank you for answering OP's question. Would a photo 1000x higher resolution do it? Question is, since the one trillion was an estimate based on the mass of the galaxy and the average star, why not recalculate that number given the contents of this picture? Should not the picture be totally bright if there were 100 stars per pixel? Or am I getting something wrong? 1. 100/stars per pixel is an average. It's so many more towards the center of the galaxy

2. Andromeda is really far away. Even darker pixel can contain many stars. Open a portion of the image with a photo editor and really look at the "dark" pixels. You'll find every color in the spectrum. How do you measure the mass of stars and planets? Especially ones that are so far away?  Astronomer here with relevant username!  Short answer: I doubt it.  The reason is even though it's an astounding photograph, the majority of stars are too faint to image that far away.  Red dwarf stars make up the far majority of the individual stars in our galaxy, for example- like 90% of them- and are super faint.  Like Proxima Centauri, the closest star to us just over 4 light years away, is a red dwarf, but you need a telescope to see it.

So while this picture is great for working out stellar dynamics in a big galaxy and the like, you're still just seeing a small fraction of all the stars in Andromeda. So what is the magnitude limit? How bright are the dimmest stars here? Are any stars shown the brightness of our sun?  Limiting magnitude is going to depending on the filter. In the optical filters, the depth is limited by stellar crowding as opposed to detection above background, so the depth is a function of radius within the galaxy. 

If my memory serves, the limiting magnitude in the outer disk corresponds roughly to stars of around 1.5 solar masses, but I could be remembering that bit incorrectly. 

See http://www.astro.washington.edu/groups/phat/Observations.html Just posting for reference, [here](http://www.abc.net.au/interactives/zoomify/1.1.0/?images=2015/hs-2015-02-b-full_jpg/&amp;background=%23000&amp;minZoom=fit&amp;startZoom=fit&amp;attribution=NASA,%20ESA,%20J.%20Dalcanton,%20B.F.%20Williams,%20and%20L.C.%20Johnson%20%28University%20of%20Washington%29,%20the%20PHAT%20team,%20and%20R.%20Gendler&amp;abcnewsembedheight=500) is a zoomable version of the image that is mentioned in the title. If you zoom in fully, the amount of stars that become visible is quite astounding. If someone finds a better version that is viewable online, please feel free to provide a link.

Edit: Someone posted this [alternative link](http://www.spacetelescope.org/images/heic1502a/zoomable/) below. It allows you to zoom in much further, but note that the last zoom level seems to take quite some time to load (at least for me), so it appears to be really pixelated for a while. It is also cropped so that it fits into a rectangle, so you are missing a bit of data in it. I have created a quick resolution comparison between my first link and this version, you can have a look [here](http://i.imgur.com/MG8kEtU.jpg). 

The original 4.3 GB can be downloaded [here](http://www.spacetelescope.org/static/archives/images/original/heic1502a.psb) though please don't hammer their servers if you don't really need it (**Even better:** The guys over at /r/science created a torrent and shared a [magnet link.](http://www.reddit.com/r/science/comments/2rgj3a/hubble_takes_the_biggest_image_ever_of_andromeda/cnfxs72)). 

[Here](http://imgsrc.hubblesite.org/hu/db/images/hs-2015-02-a-full_tif.tif) is another smaller version at 348 MB. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Wait, so each tiny speck is a star and each of the larger brighter ones is another galaxy? Well then o.o There's actually a bunch of different things going on in this photo - it's really amazing cos we get such a detailed view of the stars in Andromeda, *plus* a few stars in our own galaxy, *plus* some other galaxies entirely, and then some!

Here's a great picture pointing out some of the features in a section of the photo:

http://cdn.slashgear.com/wp-content/uploads/2015/01/hs-2015-02-c-xlarge_web-600x400.jpg The much brighter ones are more likely to be stars in our own galaxy that are getting in the way and are essentially out of focus, though I believe the + pattern is the diffraction pattern from the spider vanes used to hold the secondary mirror. Yep, the + diffraction pattern is because the secondary mirror used to take this had four spider vanes. There would be six lines in the pattern if it had a six vane spider. Only stars within our galaxy have this pattern, because they're much closer. Oh I see, I was wondering why some didn't have the pattern. Thanks so much! Can you explain the optics behind it? I'm curious now... There's a very short explanation [here](http://apod.nasa.gov/apod/ap010415.html) and an extremely in-depth one [here](http://www.telescope-optics.net/spider.htm). Everything astronomical is at 'infinite' distance. It is impossible for even the nearest star to look out of focus while looking at a distant galaxy. Due to the limitations of the optical equipment, the brighter stars will perhaps look bigger or unsharp because there's simply so much more light coming off them. Yep makes sense. I'd imagine the stars in our galaxy give off enough photons to form the diffraction pattern reliably, but for the stars in Andromeda/much further away, there maybe just aren't enough photons reaching the telescope to form a solid diffraction pattern over the exposure time. It may also be giant star clusters, right? I'm not really an astronomer/cosmologist, so I can't say for sure. It seems reasonable, though I'm not sure of the distinguishing features of a star cluster compared to a star in our galaxy, compared to a galaxy behind Andromeda.

~~EDIT: just looking at the image, there are some bright spots with the diffraction pattern and some without. I'm not sure what that means though. Any astromomers know?~~

EDIT 2: /u/Yar987 answered this with impeccable timing [here](https://www.reddit.com/r/askscience/comments/2t5lj6/in_light_of_the_new_highres_photo_of_andromeda_is/cnw0ew6). Only stars in our galaxy have the diffraction pattern because they are much closer. At this distance, all light rays are essentially parallel, so focus is probably not an issue. [deleted] [deleted] [deleted] [deleted] [deleted] To my understanding, each of the tiny specks is a distant star, the very large and bright ones with diffraction patterns are stars within our own galaxy that are between us and Andromeda, effectively "in the way" of the picture. Though if you zoom in and pan around, you'll see a few distinct oval shapes or faint spirals that are larger than the distant stars but smaller than the closer ones and have no diffraction patterns. Though it's hard to tell because even a picture this massive is relatively low in detail, it's safe to assume those are other spiral galaxies somewhere beyond Andromeda.  How much of the color/light in that picture is enhanced or added? If I was in a spacesuit close to the Andromeda galaxy, is that what it would look like? In terms of colors the picture contains near ultraviolet, visible and near infrared spectrums^[1](http://www.astro.washington.edu/groups/phat/Home.html). So it's slightly beyond the vision capabilities of the human eye. 

My guess: compared to what you could see with the human eye (ignoring intensity) the most exaggerated thing in the picture is probably the amount of visible dust. The colors themselves are probably pretty close to reality.

Maybe [this](http://i.imgur.com/EpuhHJa.png) gives a sense how much intensity was added by Hubble. The picture features Andromeda relative to the moon.
 &gt; If someone finds a better version that is viewable online, please feel free to provide a link.

Hubblesite has [this one](http://hubblesite.org/newscenter/archive/releases/2015/02/image/a/format/zoom/), but I much prefer this one to both of those:  
http://www.spacetelescope.org/images/heic1502a/zoomable/ So is the bright spots the stars in this image? All the tiny "dust" looking dots, what are these? The tiny dots are stars. The brighter ones are just closer/brighter stars. [deleted] The tiny dots are stars in Andromeda. The large fuzzy dots are stars in *our* Milky Way galaxy.  Just, so insane that I didn't believe it myself either... 

But NASA confirms it http://www.nasa.gov/content/hubble-s-high-definition-panoramic-view-of-the-andromeda-galaxy/#.VL-lyNLF-54 Quick question: whats that chubby blue star on top-center-right?  Likely to be a star in our galaxy that's in the way of the photo. Same thing as the tiny dots but  much closer  Is each one of the things I thought were pixels, actually stars? [deleted] [deleted] Is there a source where I can download this picture in the same quality? I looked around on the internet but I can't seem to find a decent source that offers the same quality as the original. If I recall from the last discussion, the FULL image data (which you likely need special tools to open) is 4.3GB. The largest regular .jpg from the NASA site is the 350MB one that /u/shit_dicks* mentioned. 

*^(only registered last year? Can't believe that wasn't already taken.) http://hubblesite.org/newscenter/archive/releases/2015/02/image/a/warn/ I'm on mobile so this url is the best I can do, but here you can find the image with a 17348 x 5558 resolution. It's 350 Mb, and the detail is astonishing.  How large will the image be? 100 GB? 10GB? 5MB? I'm really curious. Is there a torrent available?  Full resolution images available for download, if anybody is interested:

http://hubblesite.org/newscenter/archive/releases/2015/02/image/a/warn/ That's actually not full resolution, the biggest you can get from there is 17384 X 5558 px. [Here's](http://www.spacetelescope.org/images/heic1502a/) the original PSB file with the full 69536 x 22230 px. Why Hubblesite does not provide the full res I don't know. I thought the full res image was 4.3GB? ~~If someone can name a good torrent site, I will happily seed like crazy.~~

http://www.reddit.com/r/science/comments/2rgj3a/hubble_takes_the_biggest_image_ever_of_andromeda/cnfxs72

(will seed permanently) I know this is late, but...this is the first time in a while I've seen something that actually just made me sit there with my mouth hanging open.  Thanks. [Here](http://adsabs.harvard.edu/abs/2015AAS...22521303J) is a link to the abstract of the talk(?) given at the American Astronomical Society meeting, possibly a paper to follow...

The crucial term used for understanding this image is "spatially resolved", which is to say they have separated each star out, rather than being smeared into a continuous background glow.  Note the stars have individual colours assigned indicating different types of stars.

Apparently this was part of a citizen science project getting members of the public to count star clusters within the image, the goal (maybe) being to identify star formation rates between dense clusters and loose clusters.  The results confirmed the theories...  The brain is an incredible structure with complexity, abilities, interactions and wonders that we may never understand. The entire human body is composed of an estimated 35 trillion cells with more than 300 different types all working together for the benefit of the whole. Along with our "human" cells more than 100 times as many bacteria, viruses and other microorganisms live in and on us any mostly contribute to the well being of the entire body. We and all the rest of the living beings as well as the non living materials and structures of the planet make up a whole biosphere that may be more complex than the rest of the known universe. So combined with the rest of the universe which we are indeed a part of we are participating in a most amazing dance of subatomic particles, energies, planets, stars, gas clouds and galaxies. We are made of the smallest things and part of the great great universe. That's nice and all, but I don't really see how that's relevant to the question. Are stars colliding like crazy with each other as they get closer to the center? Do we pick up those kinds of collisions?

Blows my mind to think of what it must be like closer to the center. Blinding light everywhere or just a really beautiful night sky? I might be wrong but I'm pretty sure even though it seems that way to us, the stars are still massive distances apart [These slides](http://abyss.uoregon.edu/~js/ast122/lectures/lec26.html) give stellar density at the center of a galaxy as 100 stars per cubic parsec.

This results in a mean distance of 0.1 parsec or 0.4 light years between stars. To put this into context, if a perfect twin of our sun would appear 0.4 light years away, it would have the same brightness as Venus - visible by day, but only faintly. 0.4 light years is still pretty far away.

So no, no collisions. [deleted] [deleted] There was another post here on AskScience a bit ago asking what the odds were of accidentally hitting a celestial body if you were to blindly shoot through the entire galaxy, including the core.

The answer was infinitesimally small.  I'd link there but I'm on mobile and already running late for work. No. Even the future collision between Andromeda and the Milky Way is not likely to result in more than a handful of stars actually colliding, if that.

Think about it this way: Our sun is 1,391,684 km wide. Its closest neighbor is 40,678,000,000,000 km away. There is about 30 million times more empty space than there is star! Even in much denser regions of galaxies, it is not exactly cramped. &gt; There is about 30 million times more empty space than there is star!

*within the line between these two particular stars. I see what you are getting at, but the wording is misleading. An estimate for the proportion of volume occupied by stars is that cubed, or one in three sextillion. That is absolutely correct, of course. I simplified it a bit too much :)

So, galaxies by a first approximation are completely empty. The average distance between stars is something like 2 light years. Also I once saw an image of what the sky would be like close to the galactic core it was basically like constant daylight. Possibly. Andromeda is a good gauge to use for our galaxy. It's very much the same as ours, but larger. We can use this image and get an idea of the amount of stars in Andromeda, combine it with the estimated mass of Andromeda, and apply this 'ratio' to our galaxy's mass, which is currently being debated quite a lot. By looking away, we learn more about here. I know Andromeda is accepted as bigger as far as the number of stars and all but isn't the MW more massive due to a larger amount of dark matter? (Mass is estimated with acceleration)

I don't think we have an accurate guess for the mass of M31! (Andromeda Galaxy)  isn't dark matter distributed equally across the entire universe? Or it may be dark energy but the Andrmeda is more massive in every sense of the word No, dark matter is not distributed equally. It clumps like normal matter due to gravity, the difference being is that it doesn't feel electromagnetism or perhaps some other forces as well so it doesn't interact and passes through matter and itself. Do we have evidence that dark matter passes through matter? Neutrinos also pass through matter, it's nothing that's difficult for types of matter to do. It just depends on the forces they interact with.

Dark matter should exist to account for the mass, but if we can't find it; that simply means we have a problem detecting it. We have a problem detecting things due to how we detect them. Particles that interact with electromagnetic interactions we use those types of detectors. For the weak force we'd use another type, particle collisions etc etc etc.

Neutrinos were hard to find until we made detectors for them. Dark matter we need to make detectors for. That's hard to do unless we narrow down what it MIGHT BE. Problem with dark matter is we know it exists, just not what it is. Yes? If it interacted with matter, even faintly, we'd be able to detect it like we can detect other weakly interacting particle like neutrinos.  Dark energy is distributed equally. Dark matter is found in big clumps within galaxies and between them in a kind of a spiderweb looking thing. Is it? It's much bigger. 40%
[Reference]( http://m.wolframalpha.com/input/?i=Size+of+M31+vs+Size+of+Milky+Way&amp;x=0&amp;y=0 )

I recommend Wolfram Alpha for such questions! So just a quick question for anyone that can answer but what's exactly in the center of a galaxy? I've heard a black hole is the predominant theory but wouldn't a black hole leave a dark spot at the center of the galaxy where the event horizon starts rather than the bright ball of light that we typically see at the center? We can't see the center of the galaxy regardless of what it looks like, there is stuff in the way.... But no, a black hole is not a black dot or black ball... What you would see if you could directly observe it is a very bright accretion disc and what looks like a distorted shape behind it. That distorted shape is actually the light bending around the black hole, showing you what is on the other side via gravitational lensing. Think of looking through a raindrop at a scene behind the drop... But on a massive scale.  Thanks for the reply! Also i was a little impatient and looked for some answers myself and apparently supermassive black holes like the one in the center of our galaxy are so large that the gravity around it is actually weaker (displaced gravity over more surface area) so stuff isn't as easily sucked in so apparently there's stuff flying around it very close to its event horizon. Apparently even if you were able to get close enough or zoom in enough to take a picture its likely you would never see the "black" spot of the black hole as it has a "cape" of sorts of gas, asteroids and a bunch of other stuff swirling around it at crazy high speeds. The supermassive blackholes in the center of galaxies are so dense that their radius is quite small (The radius of our solar system). In comparison to billions of stars surrounding it, the light drowns out the small black spot.  If you make a picture of the Milky Way as large as a typical 1024x1024 screen, then one pixel is about 100 light years wide.  4 square pixels contain all the radio signals ever emitted by the human race. That's the scale of our influence on the entire universe.  4 pixels out of a million if the galaxy is as large as the screen.  Wow, we really have no chance of ever influencing the universe on a global scale, do we? We're nothing. Global? No.

Universal? Maybe. When I see pictures like this, it only reinforces my belief that there is absolutely ZERO chance of us being the only intelligent life in the universe. I can't see any scenario where this would be the case. There is just too much out there for that to be the case. In fact, I'd wager that other life is more probable than not in the universe. 


And then my mind wanders and I think of the possibilities- the range of life. From life that is far more advanced than humanity, to life that is just starting. 

And then I freak out a bit when I think of the distances involved. How you could literally float through nothing for thousands of years before hitting anything. Yet the universe is still so full of stuff.  [The Fermi Paradox](http://waitbutwhy.com/2014/05/fermi-paradox.html) "The Fermi paradox (or Fermi's paradox) is the apparent contradiction between high estimates of the probability of the existence of extraterrestrial civilization and humanity's lack of contact with, or evidence for, such civilizations." Really good blog post on possible explanations to the Fermi paradox... long, but worth it. Some mind blowing stuff in there. You mimic my exact thoughts.  I've also wondered, what if WE are the most intelligent life out there.  I know it's a small chance, but what if "life" in the universe consists of being as intelligent as Chimps, or Dolphins?  How depressing would that be? &gt; I've also wondered, what if WE are the most intelligent life out there. 

_so far_. At one point, the most intelligent life on earth wasn't a fraction as smart as chimps or dolphins. [deleted] Probably not by much. With images like that your dim stars are confused (you can't tell them apart) and you only see the variation in bright stars, as a result you keep the exposures short because you're not going to resolve anything dim. The vast majority of the stars in galaxies are smaller than the Sun, I don't think you will see these in these images due to confusion limits. Hubble has to look way out in the halo of most galaxies to see the dim stars. From the page on the survey I don't even think they could resolve a sun like star in that image. We also have a very good handle on the number of bright ones like the ones seen in the images.

The interesting questions are whether or not the type of stars formed varies though the galaxy. However the big debate in that area of research is the low mass end. JWST will be better for these studies due to better infrared resolution, E-ELT much better still. In short, what ultimately stops cell processes after death is lack of oxygen. Without oxygen ions to fix electrons on the cellular level, cells are unable to function or reproduce, and they begin to decay. 

For some cells that require constant oxygen (such as neurons) this can happen almost immediately (within minutes) after death. For other cells that are not quite as oxygen thirsty (such as in the transplant organs) this can take between 30 or 60 minutes. Structural cells which require even less oxygen, such as in bone and connective tissue, can survive for around 24 hours after death before cell death occurs.  What happens when you hear about people who have fallen into a lake and are dead for 4 hours then revived?  How do the cells survive without oxygen?

Edit: As others have noted it's not 4 hours.  The longest incident I could find was 80 minutes.  Still interesting.

Edit 2: Doctors induced hypothermia in this patient for 48 hours while she awaited a liver donor.  It was done to preserve her brain. 33 degrees!

http://yalemedicalgroup.org/news/article.aspx?id=6556 A drop in body temperature from submersion slows the body's metabolic processes, thereby prolonging cell and tissue preservation. 



Therapeutic cooling is used in hospitals on witnessed cardiac arrests as soon as they enter the ER, for just this reason. 




Edited to add: four hours is a stretch, though, in my experience.  In the OR for a few types of cardiothoracic surgery, they sometimes use a combination of cooling and deep sedation to try and protect the brain during periods of circulatory arrest.

Most procedures in this area are done on cardiopulmonary bypass - blood is circulated through a heart lung machine to get oxygen while the heart is worked on, for example.

But in a few cases (pulmonary thromboendarterectomy for example) they will do part of the procedure on bypass and then do the most delicate parts on full circ arrest.  Usually only 20 min at a time, because the adult brain doesn't do well for longer.  

Interestingly in the one before / after study of the effects of this on the brain that I've seen - people did better after surgery.  Presumably due to other effects (better overall cardiopulmonary function and health?).  I was quite surprised.

[Deep hypothermia for surgery]( http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(11)61144-6/abstract)

 [deleted] [deleted] Note: this is more due to the anti-inflammatory effects of cold (same reasons behind why you put ice on a head bump).  Key thing the cold does is slows biochemistry down.  Same principle that applies with refrigeration - slow germ's biochemistry and growth to meet our preservation needs.

In the context of medical use, this effect is useful for two reasons:

1) Slows metabolism down, reducing resource consumption and prolonging tissue life (e.g., the prolonged life of a hyperthermic drowning)

2) Slows inflammation down, increasing the amount of beneficial healing that is possible (e.g., its use in surgery) [deleted] Cold has anti-inflammatory effects due to the biochemistry slowing down.  Normally, an injury (planned, like a surgery, or unplanned, like an accident) would trigger your immune system into GO mode.  Big picture, this is a good thing, of course, but most of those first steps involve a mostly unhelpful biochemical version of a rush hour traffic jam (among other things) to the site of injury, prolonging healing time.

So the cold slows all of that down, making disturbed tissue less able to sound the inflammatory alarm, calming the powerful "freak out" first steps, which keeps the cellular "roads" open for the beneficial healing cells and signals to do their work faster.  The simple example is the bump on the head to keep unhelpful swelling down; the surgical example is a deep extension of those same properties.

EDIT: Several of inflammation's many effects are indeed protective, e.g., recruiting germ-recognizing and germ-killing immune cells to the front lines. If only beneficial things happened, that'd be great, but unfortunately it's a whole bunch of things happening all at once, and definitely not all to healing's benefit.

In the traffic jam analogy, it's as if a toxic chemical truck spilled its contents on the highway, but every fire truck/ambulance/emergency vehicle in the vicinity immediately responded to the scene. The closer they were, the faster they got there. But in order to open the road back up (aka heal), the hazardous chemical truck had to get there, but now it can't. The cold effectively slows up that immediate first response, avoids the traffic jam, and allows for the hazardous chemical truck to get there to do its job. if the inflammatory alarm as you put it is mostly unhelpful, why hasn't it been evolved out overtime? [deleted] [deleted] [deleted] From an immunological point of view &amp; speaking as a lab hamster:

In terms of disease response, the inflammatory response is highly helpful &amp; helps create an environment that is hostile to most pathogens hence why it was **evolved IN &amp; remains**. 

High temps actually slows down viral/bacterial replication (makes viral enzymes work less efficiently &amp; stuff) which buys more time for the body's own immune response to kick in &amp; fight off the invaders.)

(Localized) inflammation is also a very great way of getting a very strong immune response right to the pathogen. 

Increased permeability at the site of inflammation means you can get a strong localized response greater than what you would risk in the entire body because your response molecules will float around you &amp; exit where there is increased permeability (caused by localized inflammation), very simple &amp; convenient. 


Unfortunately systemic (everywhere, not localized) inflammation is very bad.
(.-.)

Addendum: "At the expense of healing time" isn't exactly right. 
Overall an organisms' healing time would likely be much higher, if not impossible, if the wound was infected. 

Also humans are odd creatures. Compared to other animals, they sacrificed proper healing for speed. (scarring, clotting, etc.) Kind of freaky how effective scars are at quickly plugging up wounds.

Other animals such as the african spiny mouse &amp; salamanders have longer healing times but are able to properly regenerate. On a cellular level, we are basically complicated chemical reactions. Heat speeds chemical reactions while cooler temperatures slow them down. [deleted] [deleted] [deleted] Why aren't antihypoxic drugs a standard therapy? There are so many great animal studies. Are any of them FDA approved? If not, that is probably the reason they aren't being used.

And getting something through clinical trials is usually very expensive so there often needs to be good profit potential for it to happen. Do they add anything for antifreeze in deep hypothermic situations? They've started using this for major wounds too by replacing the blood with a cold saying liquid to nearly stop cell processed giving time to operate on the body in 'suspended animation'. It's amazing what happens at such lot temperatures.

[NewScientist article](http://www.newscientist.com/article/mg22129623.000-gunshot-victims-to-be-suspended-between-life-and-death.html?full=true#.VLbR1FuIzVo) Pretty sure that there has been a couple cases approaching a few hours. And animal studies show around 3 hours max time for a very cooled (like 5 degrees celsius) dog. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [Here's](http://www.cbc.ca/news/canada/british-columbia/christine-tink-newman-s-medical-miracle-revived-from-near-death-1.2591379) a case where a woman was injured at 2 AM after falling off the edge of a trail near her ski chalet, and wasn't found until next morning.  Rescuers had to perform cpr on her for 2 hours where she lay in the snow, as the well was too deep for a helicopter rescue.  

She made a full recovery.  Even kept her fingers and toes.   What is the difference between this type of process and simply freezing to death?  I'm just gonna come out and ask what witnessed means in this case? Just simply that someone saw it happen, so that we know the timeline. Initiating the cooling process too long after the cardiac event is futile. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] They are not truly dead, and you need cold water to achieve that. Their body goes on slow mode. It is called the [Mammalian diving reflex.](http://en.wikipedia.org/wiki/Mammalian_diving_reflex) Based on the numerous accounts of this that I've read; it's generally the case that the person hasn't "died" in the true sense of the world. Their body has usually gone into a state of almost hibernation, so the said cells and organs would use very little oxygen. These situations, you'll find, are also accompanied with extreme cold. I think it depends on your definition of being dead, but [a lady in Norway](http://en.m.wikipedia.org/wiki/Anna_B%C3%A5genholm) fell in a frozen river for over an hour,  and went for like 3 hours without a heartbeat.   Her body temperature was like 55 degrees and for awhile she held the world record for surviving the lowest body temperature.  [deleted] This goes back to the most basic rule of chemical reactions: The lower the temperature, the slower the chemical reactions take place. The process of ADP being turned to ATP is slowed, and even once the cell runs out of oxygen the process of organic molecules breaking down is slowed. In theory, a human body kept at 0K could be stored somewhere for thousands of years, then thawed out and resuscitated.  The problem is the freezing and thawing part. If either process is too slow, ice crystals form, perforating the cell membranes.  

On a side note: Does anyone know how anaerobic respiration would react to a lack of oxygen? While I don't think there are any instances of people being underwater for four hours, the basic idea here is the cold. The extremely cold water slows the metabolism, which presumably slows the demand for oxygen. 

Think of your body as one big chemical reaction. If it gets too cold it slows down, with unpredictable results, and the same for too hot. Which would explain why frozen things don't rot as quickly, or even at all. How do you preserve a body a 4 degrees below normal temperature? So if i were to have a heart attack out in the snow, would i have a relatively higher chance of revival in the cold? Possibly.  They actually use a cooling protocol on heart attack victims when they arrive at the hospital and then slowly rewarm.  In a few cases this actually seems to work.   So my skeleton is alive inside my dead body for 24 hours?

Cooooool thanks mr skeltal What ultimately causes death in the sense that a person has crossed the line of no return?  

Of course, getting shot in the head would be nearly instantaneous because of trauma to the brain.  But what if you were shot in the stomach and bled out slowly?  Do you need to lose enough blood to cause lack of oxygen to the brain?  

Lets take it one step further and say you were shot in the heart - would that be as instantaneous as being shot in the head (heart not pumping oxygen to brain) but as ChicagoCowboy stated in his/her answer above - neurons still take minutes to die because of lack of oxygen.  Would this then mean the only true instant "kill shot" would be a head shot?
 There are two medical terms for death, clinical death and brain death. Clinical death is absence of pulse (heartbeat) and respiration, while brain death is a bit more difficult to define, but in essence "patient" is brain dead when there is no brain activity left.

But this are just arbitrary lines that we use in everyday practice, death in itself is a process and not an instantaneous event. For example, after cardiac arrest (clinical death), neurons in brain take 4-10 minutes to become irreversibly damaged, since they are cells that are most sensitive to lack of oxygen. 

However different cells in body have different levels of tolerance for lack of oxygen and there have been recorded cases of bones and cartilages surviving up to 3 months after clinical death. Among less sensitive tissues are also pancreas, kidney, muscles (where individual cells are viable for a few hours, this doesn't mean that whole organs are), so really death is a long process with poorly determined start and end, outside of clinical terms.

And to answer to your questions, modern medicine determines line of no return as brain death, which is caused by lack of brain perfusion, even if patient has pulse and is breathing (usually on respirator). 

If you were shot in a stomach you would slowly bleed out, which would cause your heart to stop and neurons in brain to die. When heart stops pumping blood you loose conciousness in a mater of seconds, so hear shot is pretty much instant clinical death, followed by brain death at some point later, but this would all be happening when patient is in coma, so it doesn't make much difference. 

Shot in the head is in theory survivable, so whether it causes instant death depends on type of brain injury, but normally you would loose consciousness instantaneously, with brain and clinical death following soon, due to lack of respiration. &gt; neurons in the brain take 4-10 minutes to become irreversibly damaged. 

What causes that 'irreversible damage'? I understand that without oxygen the cell has no way to repair itself or function in any way, but why does it get damaged at all instead of just hanging out until oxygen is restored?  Low oxygen causes aerobic synthesis of ATP (cell "fuel") to stop, which in turn causes electrolyte disbalance do to failure of Na/K pump. This causes depolarization, which has several catastrophic effects on neurons specifically and other cells as well. You can read more about that [here](http://en.wikipedia.org/wiki/Mechanism_of_anoxic_depolarization_in_the_brain)

There is also fall in intracellular pH due to CO2 and lactate accumulation, which damages proteins directly in a same way as any other acid would.  The cell is completely dependent on the presence of several factors. First of all, the fact that there will be less and less oxygen will mean that the PH of the blood will lower, and in effect of that your protens will change of shape. Consider it like this: if you boil an egg and you let it cool down, it won't be fluid again. This is because the proteins which make up the egg whites are changed of shape. The same happens when you change the PH of the blood, and the proteins which are responsible for crucial tasks, for example the making of molecules which transport energy, will change form, and new ones can't be made again. You won't be able to get the waste substances out of your blood, so in order to keep the concentration of the substances diluted in your blood at 0.9%, water will slowly seep out of your cells, this is a process over which your body has no control. This will also change the shapes of proteins, and will for example stop your DNA from sending messages across your cells.

So there are several factors which will all result in the death of the cell. The fact that certain factors need to be kept (almost) at a stable level is called homeostasis. It is one of the things some people call the characteristics of life, along with metabolism, reaction to the environment and reproduction through genetic material.

What exactly will kill your cells first, I don't know. I haven't had enough biology classes to be able to estimate such a complex question.  this is very helpful, particularly the egg metaphor, great explanation of the irreversibility of this specific change in biology/chemistry.  Why does less ovygen mean lower pH? Oxygen is carried through your blood, and it is used by the cells. These cells 'burn' fuels with it, and then CO2 is deposited into your blood. When CO2 comes in contact with water, a chemical reaction (partly) ensues, CO2 + H2O -&gt; H2CO3, which is a weak acidic substance. When there is less oxygen in your blood, it probably means you are not breathing out anymore, and no more CO2 can escape your blood, meaning the pH will be lower. Also, your cells need O2 to 'splice' glucose (sugar) into smaller parts, in order to be able to digest it and get energy from it. If there is no O2 left, they will in order to get a small bit of energy splice them in halves. This will mean that one molecule of glucose will be made into two molecules of lactic acid. This  happens when you for example run very far, and then suddenly you get huge cramps. The lactic acid in your muscles affects the cells, and in a stress response, the muscle will use a small bit of energy, in order to draw a lot of blood in. This will help oxygen come into the muscles again and help get rid of the waste substances. Contrary to popular belief, the CO2 we breathe out was actually a part of sugar. There is no direct reaction C + O2 -&gt; CO2.

The catabolism of sugar proceeds in three different parts.

* The first part(Glycolysis) cleaves the sugar(C6H12O6) into two Pyruvate(C3H3O3). This takes 2 ATP, this releases enough energy to form 2 NADH and 4 ATP.

* The second part(Krebs cycle or Citric acid cycle) is more complex. It is the part that release all the CO2. [See here for more info on what happens here](http://i.imgur.com/YIsfMbg.jpg).

* The third and most important part is the oxidative phosphorylation. As the name implies, this has to do something with oxygen.
After the first two steps(Glycolysis and Krebs cycle), there is a lot of NADH and FADH2. These are energy carriers, but cells mainly use ATP. To create ATP, the high-energy electrons are released from NADH and FADH2 and pass through a couple of proton pumps to create a H^(+)-gradient. The oxygen will now take two low-energy electron to form O^2- and bond with some H^+ to form water. The protons want to return to the membrane, so they go through an enzyme(ATP Synthase) that uses the energy of the flowing H^+ particles to turn ADP+P into ATP. This process can make up to 30 ATP per molecule of sugar.

tl;dr CO2 comes from the waste products of sugar breaking. Other waste products of this are high-energy electrons. O2 is required to clean up some mess. [This explains a lot.](http://i.imgur.com/10oslJF.jpg)

Why did I tell you all of this? To answer your question: Your cell would be unable to carry all the low-energic electrons out.. Also, ATP production without oxidative phosphorylation is too low to keep up with energy demands.

Source: I study Biomedical Engineering. Book: Essential Cell Biology (Alberts et al.) &gt; modern medicine determines line of no return as brain death, which is caused by lack of brain perfusion

Then do neurons instantly die when brain perfusion (which I just looked up and seems to refer to a pressure gradient) falls below a certain level, and it's the brain perfusion that has a time lag after cardiac arrest? Or do the neurons survive for 4-10 minutes after brain perfusion drops below a threshold?

Either way, is it the brain perfusion itself that's measured to "call" a patient? Or do they measure something else? &gt; Then do neurons instantly die when brain perfusion (which I just looked up and seems to refer to a pressure gradient) falls below a certain level, and it's the brain perfusion that has a time lag after cardiac arrest? Or do the neurons survive for 4-10 minutes after brain perfusion drops below a threshold?

Yes, neurones survive for 4-10 minutes after cardiac arrest (zero perfusion) after that they can't be brought back to life even if perfusion is restored. Although be aware that there are differences between individuals, so it is possible to survive after more that 10 minutes of cardiac arrest.

Brain perfusion is basically blood flow through the brain, and is dependent upon [cerebral perfusion pressure (CPP)](http://en.wikipedia.org/wiki/Cerebral_perfusion_pressure) and cerebral vascular resistance. When heart stops pumping CPP falls to zero immediately, so there is no delay there. 

Brain death is a different concept entirely, it refers to lack of activity of brain and can happen even if perfusion is constantly maintained.

So basically sequence of events usually goes as follows:

Fatal gunshot wound in heart-&gt; cardiac arrest (clinical death) -&gt; no brain perfusion -&gt; 4-10 minutes -&gt; brain death


&gt; 
&gt; Either way, is it the brain perfusion itself that's measured to "call" a patient? Or do they measure something else?

They will either call clinical death -lack of hear beat, or brain death (usually by EEG). Since no brain perfusion means 100% brain death (after a few minutes) technically they can call that as well.
 It does indeed.  That is why in the Vet manuals they recomend a shot to the head with a .22.  Well, that and the fact they don't want you to miss or hit and area that doesn't cause the heart to fully bleed out instantaneous.  It is such a wonderful accident that nerve tissue dies first. It's possible that death would be much less pleasant (or more unpleasant) otherwise. And surely an accident, since natural selection doesn't effect how systems function in situations from which individuals never recover (or interact meaningfully with other individuals). what if you artifically pumped blood and circulated oxygen in the lungs This happens all the time to keep people "alive" while they collect transplant-able organs and the like. But, the medical community would still consider the person technically dead if they have suffered brain death - once your neurons die and cease functioning, nothing is bringing them back to life. You can connect them to life support, connect them to a feeding tube, and the rest of their tissues will continue to act as normal - but they won't wake up, won't be aware, and won't ever be the person they were before suffering brain death.  Why not? If a cell runs out of oxygen, it obviously won't be able to perform any of its functions anymore, but what stops it from functioning again once oxygen is restored?  What processes cause that irreversible damage? Because, once the processes that utilize the energy from oxygen ions have stopped, no amount of oxygen re-introduced will "kick start" the process again. If the loop is broken, the loop stops. 

Think of the oxygen like putting gas in your car to keep the engine running - once the car runs out of gas, the engine will stop - and it doesn't matter how much gas you flood the car/engine with, the engine won't just start working again (we have to turn the key...but on the cellular level, there is no "key" to restart the process). Is there any current attempts that you know of that are trying to find that metaphorical key? From what I understand, there just isn't one - once cells have stopped their processes due to cell death, there is nothing that can even be theoretically done to restart the electron transport chain and reverse any damage done to tissues and organs. Good news - no zombie apocalypses in our future! The metaphorical key doesn't exist, because when the engine runs out of petrol/gas, it inhales all the petrol sludge at the bottom of the tank and screws itself up forever. There is a growing cryo industry that is trying to find what could get something started again. 

Bioengineering and Nanotechnology are areas that are trying to discover how this process works. At this point though it is all theoretical and falls into a weird realm of "science." Not only this, but once brain death has occurred, medicine needs to perform all the functions of the brain, including secretion of hormones.  [deleted] [deleted] [deleted] What happens to neurons when someone exhales and holds their breath for an extended period? Suppose you could do that without your reflex action to breath kicking in - you would most likely suffer CO2 poisoning before oxygen deprivation.

In fact, you can't sense oxygen deprivation at all, which is why things like carbon monoxide are really dangerous. Rather, CO2 is the stimulus for breathing in/out, making your heart pump more/less. I'm struggling to figure out what you mean by CO2 poisoning. You would definitely feel an intense urge to breathe caused by CO2 buildup prior to actually losing consciousness from oxygen deprivation, but whether or not that would actually cause any significant cellular damage or physiological impairment in that time frame is a little suspect. Of course, significant CO2 retention from hypoventilation, even in acute time frames, can cause significant and damaging acidosis... I just don't know if that could happen in one breath's worth of CO2 production BEFORE death by hypoxia.  When you breathe, you're not completely depleting your blood of oxygen between each breath. Evolution has provided us with a breathing cycle that attempts to keep the maximum amount of oxygen in our blood stream at all times, thankfully.

So when you hold your breath, your blood is still providing oxygen to your cells...but your breathing reflex forces you to continue inhaling before your blood stream is depleted of oxygen. In fact, you'll pass out from low oxygen before you die - and when you pass out, your body will continue to breathe normally, restoring oxygen to your blood and brain. Its basically a reflex to prevent death.

Can holding your breath for too long cause neurons to die? Certainly - but it isn't likely to affect your neural processes in a significant way. Surely they only decay if there are bacteria/wildlife about to cause the decay. ie. theoretically, if someone was cooled to absolute zero (and ignoring processes like ice formation causing physical degredation etc). would a person be 100% revivable after any length of time? That's the central idea to cryo-genic freezing, but in real terms its only theoretically possible. 

Even if you could cool somebody to the point that their cell processes were slowed significantly or stopped, it would have to be near-instant to prevent freezing from occurring. Upon warming back up to "revive" them, it would again have to be almost instantaneous, so as to prevent the super-cooled water molecules (and other substances) in their body from freezing on the way back to normal temperature.  Amorphous water can be formed(with extremely fast cooling rates, which are currently impossible for a human body), which prevents the damage caused by ice crystals. 
Although I still don't get how you could restart the process after stopping it.  Although cooling is effective as you say, there are other processes besides microorganisms which cause "decay" in the sense of irreversibly damaging the corpse. Even without any bacteria, cells will accumulate waste products without the energy to transport it away, which will damage the proteins of the cells. The point is, cooling also slows down the biochemical processes which generate the waste, as well as the biochemical processes involved in bacterial life. I remember reading about 10 years ago about research covering the "cell death" as oxygen levels deplete, and that the problem wasn't so much oxygen depletion within minutes, but the sudden restoral of normal oxygen levels - with dogs, monkeys, and a few human extreme situations, they were able to bring back from "dead" hours after clinical death by reintroducing oxygen gradually and managing temperature carefully. 

The basic idea is that, upon death, you could chill the body quickly to perhaps 40 degrees, buying as much as 8 hours to be brought back to life by slow re-oxygenation and temperature increase. 

I never heard of it since, but it was originally in a reputable magazine, EG NY Times or comparable. Would you mind weighing in on that? Neurons are sensitive little buggers. Sometime as simple as a patch clamp experiment can take a long time to get used to because the neurons die so often even though you're constantly giving them oxygen bubbles, they're just that sensitive. (Assuming they're not already dead or lysed before you even find them under the scope.) 

1) I thought it because of the lack of energy supply that this happens. 

2) can you expand on this quote? Sounds interesting as I've always wondered about the role oxygen plays in cellular respiration. 

&gt; Without oxygen ions to fix electrons on the cellular level, You're correct - but the lack of energy is directly related to the lack of oxygen. The only reason that non-plant organisms breathe oxygen, is so that mitochondria in our cells have a final acceptor in the electron transport chain.

Its pretty complicated, but the electron transport chain uses a series of protein compounds set in the wall of the mitochondria, that transfer electrons from electron donors (such as the NADH created by the citric acid cycle) to electron acceptors (such as Succinate created by the citric acid cycle) via redox reactions.

This electron transfer is coupled with the transfer of H+ ions across the mitochondria membrane, which creates an electrochemical gradient that is the driving factor for ATP synthesis within the mitochondria. 

The final acceptor of electrons in the electron transport chain is molecular oxygen - so without oxygen, those electrons have nowhere to go, so the electrochemical gradient isn't established, so ATP isn't synthesized. 

This is also called Oxidative Phosphorylation.  that was a great explanation, thanks Anaerobic respiration?  Are you asking about anaerobic respiration, or suggesting it as a way to avoid cell death? So if you were to be put on an oxygen device soon after death, then your body would still be alive? This is basically what's happening when someone is on life support - without the machines pumping blood and forcing air into and out of the lungs, the person would be dead. 

If someones loses their pulse, or stops breathing, they can still be kept alive or revived (cpr, defibulators) - but if they actually die, ie brain death, then they can't be brought back to life - their other organs might be able to be kept functioning via life support. Is this also how they are able to keep the organs healthy before they are donated to someone on a transplant list? There are a few problems with this answer here. 

Oxygen ions are not used to fix the electrons, rather O2 is terminal electron receptor in the electron transport chain which is used to produce ATP essentially. But hydrogen **ions** are transferred against the gradient.


 what if we keep oxygen flowing around without a heart? what would happen, would it be like a state of coma? this terrifies me. does this mean when we die, your brain will still be on? like for those four minutes will you realize what is happening and you just shut off? Death is essentially when your neurons stop firing - as we've seen millions of times, the lack of pulse or the lack of breath is not sufficient to declare a person dead. 

So when we talk about neurons actually "dying" a minute or two after death has occurred, we're not talking about an actual awake person, who is aware that they are dead for 4 minutes before the lights go out. We're talking about someone who is definitively dead, has no consciousness, where some of the cells in their body are still trying to do their job before the lack of oxygen shuts them down. If you could pump oxygen in a dead body for a prolonged period of time, will it stay fresh? (Assuming it was also given the right nutrients) No not really - life is such a complex combination of chemical reactions and feedback loops, that pumping oxygen into a dead body would be the equivalent of plugging more extension cords into a computer who's hard drive and mobo stopped working. Cool, it has all the juice it needs, but that's not going to make the system's work in cohesion again.  &gt; some cells that require constant oxygen (such as neurons) this can happen almost immediately (within minutes) 

Does this mean there are a few minutes after death when consciousness still remains? It depends on how death occurred, but in an example to another redditor here I touched on reports of people being beheaded retaining function in their faces for 10-11 seconds after decapitation occurs (blinking, mouthing words, making facial expressions of terror). That would suggest that, depending on how death occurs, consciousness is possible.  So if we chopped someones head off and were still able to supply oxygen to the body would it still be able to process things. Like if we put food into the stomach would the food digest?  If neurons can survive for minutes after a person's death, does that mean the person is still able to think? It's hard to say really - the person is completely unconscious at that point, and combined with the fact that the alarms in their body for trauma, lack of oxygen, and potentially lack of blood are at full blast, there is likely to be very little brain activity at that point.

That being said, in the examples that I gave earlier about reports of decapitation showing people being able to mouth words and blink for about 10-11 seconds after death, it suggests that if conscious at the time of death, and if that death is as sudden as decapitation, one could use the last of the ATP in their tissues purposefully.  What if we evolved to such that our cells can anaerobically function? Would we be immortal? That isn't likely; for complex organisms, aerobic respiration has evolved for a reason - it provides us more energy, and molecular oxygen is more readily available than environments that are devoid of it. 

The vast majority of anaerobic organisms are what's called an obligate anaerobe - meaning that, if oxygen is present at all, they die. 

Also, anaerobic organisms (prokaryotes, a lot of bacteria, most extremophiles) still die. Nothing is immortal I'm afraid - and actually some of the most long-living organisms on the planet are aerobic eukaryotes (3,000 year old trees, 500 year old whales, 200 year old lobsters and tortoises, etc). Its actually oxygen that begins the process of "dying."  Death is the end of function but actual dying is caused by oxygen, not lack of. Lack of molecular oxygen to mitochondria causes death - but in terms of dying due to "old age", you're correct; its a combination of DNA degradation over a life time of cellular reproduction, and oxidation of our tissues from just being alive.  [deleted] Very much temperature dependent tough. If you "die" in cold enough conditions you can be revived hours later with virtually no tissue damage. That's not *quite* correct - there are some extreme examples of that reportedly happening, but by and large you would still be dead in those events. It's an EXTREMELY slim possibility that you'll be revived...otherwise we would just start putting terminally ill people in ice until we had a cure.  Hours. Not years. Please read my post. If you change temperature variables in resuscitation scenarios you can significantly increase survivability. I said nothing about years, so I'm not sure what exactly you're pointing to in my comment? 

In resuscitation scenarios where someone has just recently stopped breathing or lost a pulse (ie minutes, not hours) then yes, decreasing temperature to slow down cellular processes can drastically increase the likelihood resuscitation occurs.

However your original comment didn't describe resuscitation scenarios, it just said that people who die in cold conditions can be revived hours later, which is not correct 99% of the time.  You think curing cancer will be a quick process? And it is more than 1% of the time. A lot of reasearch is going into temperature reduction in resus.  Nobody is talking about cancer? What are you trying to add to the conversation? &gt; otherwise we would just start putting terminally ill people in ice until we had a cure.

Read that as a cure for cancer as am on my phone.

Here are some links for what I'm talking about:

http://www.newscientist.com/article/mg22129623.000-gunshot-victims-to-be-suspended-between-life-and-death.html#.VLhCqyusVc8

http://www.resuscitationcentral.com/hypothermia/cooling-techniques/

http://en.wikipedia.org/wiki/Anna_B%C3%A5genholm

http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074242/

Putting people into a hypodermic state does seem to help.

 &gt; Structural cells which require even less oxygen, such as in bone and connective tissue, can survive for around 24 hours after death before cell death occurs.

I knew it!  My damned spooky skeleton will be running around without me! [deleted] Loss of circulation (say, from cardiac arrest) leads to three main problems for the tissues: loss of oxygen, loss of supply of fuel molecules like glucose and fatty acids, and buildup of waste products. Some cells are more susceptible to major dysfunction due to these factors than others, primarily as a result of their metabolic needs. 

Loss of oxygen and fuel results in a decline of the cellular ability to produce ATP, the small molecule that the cell uses for the majority of its energy needs.  Lack of ATP results in decreased function of the sodium-potassium pump that maintains the cellular ion balances resulting in water influx and swelling of the cell. Other active cellular processes that require ATP also begin to decline in function. Additionally, the local changes in the chemical environment including decreased pH from C02 and lactic acid build up can affect the membrane permeability. Other cellular changes include changes to the structure of the chromosomes/nucleus, detachment of ribosomes and mitochondria from the cytoskeleton. 

Ultimately, either damage to the mitochondria releases a number of molecules that cause the cell to turn itself off (apoptosis), or the damage to the integrity of the cellular membrane(s) is so great that it ruptures, or small packets of digesting enzymes are released that chew up the cell. Either way, energy dependent cellular processes for the most part halt by that point. This can take minutes for brain neurons, which have very high energy requirements, to hours and almost days for say, cartilage cells, which do not require much energy at all.  Nice reply, but can you throw in some time scales? How long does it take for a single cell to die from lack of supplies/build-up? Depends on the type of cell. Brain neurons and cardiac myocytes have extreme energy requirements and minimal energy storage, so they start suffering from reversible ischemic injury within seconds of inadequate supply. Irreversible injury takes roughly 4-5 minutes with cell death in less than 10 minutes, at least in the large cerebellar pyrimidal neurons, which generally are the cells most susceptible to injury. If I recall correctly, cardiac cells can last up to 20 minutes before irreversible damage occurs.  That would be subjective based upon the cell type, function, and metabolic demands (i.e., those that require oxygen the most will suffer the quickest without it).  But ~30 minutes without oxygen/glucose would cause irreversible cell death in neuronal tissue.  There are a few animal models or cell line cultures, that peg it around 30 minutes. Completely cell dependent. Not all cells are created equal - some cell types are more resistant to hypoxia/anoxia than others, but for a laundry list of times they can be anoxic before apoptosis, I don't have a laundry list. Scales of magnitude? Seconds, minutes, hours? Minutes for some, hours for others. Certainly not a few seconds, but not days/weeks either. And extreme cold/hypothermia slows down these processes at a cellular level?  Yes, which is why you hear stories of people who fall into freezing water who are revived after hours under the ice.  There's that old medical adage "They're not dead until they're warm and dead." Several types of tissue may survive considerably longer after circulatory arrest, and some bodily functions may persist for several hours after clinical death. A timeline:

* 0 min: The heart comes to a rest, the blood does not flow any more, the body's cells start to die due to lack of oxygen and nutrients as well as accumulation of toxic metabolic products. Depending on their demand for energy, tissues perish slowly or rapidly. This stage between individual and complete death of all cells is called the intermediate phase.
* 6min: Irreparable brain damage due to a lack of oxygen. Neuronal tissue depends heavily on the full amount of energy only the oxygen-dependent metabolisation of glucose in the citric acid cycle and the respiratory chain can supply, while the oxygen-free glycolysis may provide only about a fifth of that energy. If the patient may be resuscitated after this point, severe brain damage is almost certain.
* 15min: Heart tissue starts to decay. Successful resuscitation after this point is not only becoming more and more unlikely with every minute, but the chance for further life-threatening cardiac arrhythmia due to decay of cardiac tissue (besides from the event that caused cardiac arrest in the first place) is quite high.
* 15min: In case that no resuscitation was started, by now, blood has followed gravity and pooled in vessels and tissue nearer to the ground, forming postmortem lividity that can realign and reshape for up to 12h, eventually staying in place.
* 30min: Perspiratory glands may still excrete sweat after injection of adrenalin.
* 2h: Kidneys survive until this point.
* 2h: Rigor mortis develops, causing the muscles to become stiff, reaching its full extent until about 6h after cardiac arrest.
* 8h: Rigor mortis may still develop after it was broken before.
* 15h: Pupils can still be dilated or contracted with drugs.
* 20h: Blows to the muscles may still cause electrical discharge, resulting in reactive contractions.
* 30h: Bone and cartilage tissue dies.
* 36h: Sperms can still be gathered for following deep-freezing and later artificial fertilisation.
* 48h: Gut bacteria multiply rapidly, eventually breaching through the intestinal walls. Putrefaction develops in the abdomen, soon spreading throughout the body.
* 48-72h: Rigor mortis decreases, limbs become limp again.
* 72h: Corneal tissue can still be gathered for transplantation. Since the cornea has no blood vessels and survives only on the nutrients it receives through diffusion and the oxygen from the air, this tissue survives the longest.


*Note that most of these points in time vary heavily depending on many aspects such as ambient temperature, humidity, cause of death, health of the particular tissues before death etc. The given numbers represent ideal or near-to-ideal circumstances in terms of a slow decay without any considerable cooling.*

EDIT: Sperms are viable for up to 36h, not 72h as previously stated. Rigour mortis isn't a one-time event, it happens in stages over a number of hours.

As ketosis (the lack of new nutrients in the blood stream) sets in, the body begins to stop cell development and regeneration. This begins about 4 hours, 4.5 hours after you last eat. The first thing to happen is the cells continue to excrete carbon dioxide, it has no were to go so it builds up until the pockets in the cells rupture, releasing enzymes that start to break down cells from the inside out, after the cells have been broken down a whole army of different bacteria begin to feed on this..the last of the food chain is the worst, maggots and beetles eat the remains, all that is left is bone and not all the bone, protein in the bone is broken down and after a long time even the bone turns to a fertile dust, ashes to ashes.  Then why do we still find dinosaur bones? No maggots around?

Edit: Thanks for all the answers guys. I really should have have it through. Dinosaur bones that we find today have been fossilized. After being buried, the conditions were just right in some cases to preserve them.  Are there instances where we've found actual dinosaur bones? I thought that most fossils were at least partially (if not completely) composed of minerals that have occupied empty, broken down space within the specimen. This means that they're basically just casts/replicas composed on various minerals, and not technically "preserved" bones. Well it depends on how you define the bone.  They aren't just "casts" of the bones...the calcium is literally replaced by the rocky material around it.  If you cut it open you find the interior structures altered as well so you can see the inside of the bone as well as the outside. 

It becomes a philosophical question.  At what point did it stop being the bone and start being a fossil.  If I get a hole in my socks and patch it, is it still the same sock?  What if after I've patched it so many times that none of the original sock remains? Is it still the same sock?
 [This is one of the foundational thought experiments of the field of study known as ontology.](http://en.wikipedia.org/wiki/Ship_of_Theseus) Most dinosaur bones broke down in exactly the way described above. Only the ones that were quickly buried in a substance that excluded these bacteria allowed the fossilized remains that we find to be saved. Often, the fossils we find were quickly buried in a tar pit, mudslide or other such event/place which served to preserve the bones from the usual decay. Rapid covering of sediment can prevent oxygen from reaching the microbes. Those dinosaur bones are typically covered an not left to rot. I.E. Mudslides, avalanches, tar, and the like. It's rare to find fossils because the events leading to their preservation are one in a million chances. Bit with their being millions of dinosaurs it's bound to happen Does this still happen for people who have been embalmed. Does it just make the process longer or are different bacteria involved? From [Wikipedia] (http://en.wikipedia.org/wiki/Formaldehyde#Tissue_fixative_and_embalming_agent):

"**Formaldehyde-based solutions are also used in embalming to disinfect and temporarily preserve human and animal remains.** It is the ability of formaldehyde to fix the tissue that produces the tell-tale firmness of flesh in an embalmed body. In post mortem examinations a procedure known as the "sink test" involves placing the lungs of an animal in an aqueous solution of formaldehyde; if the lungs float it suggests the animal was probably breathing or able to breathe at the time of death." Adding to what others said, there is a myth that fingernails and hair continue to grow after death. What actually happens is that decaying and dehydrating skin actually retracts, leaving the fingernails and hair stubble to become more prominent, giving the illusion of growth. This is the process that led people from olden times to think some dead people were vampires or undead, when they open up dead people's coffin, because there's some misfortune in their village and they blame it on supernatural sources. [deleted] No oxygen means the electron transport chain has no terminal acceptor which means ATP synthesis stops. Well there's still a little ATP here and there from things like glycolysis but not enough to sustain anything for long. Once the cells run out of energy, they die. A little TL;DR but pretty straight to the point.  You might have heard this already but asside from the correct "lack of oxygen" answer, with digestion in general it's different. Your digestive system cannot handle everything that is put into it so it depends on your flora of gut bacteria to digest what you eat into substances that your body can actually process and use.

When you die, your gut bacteria do not die. They actually start to eat you from the inside out because the body functions that keep them at bay are no longer working. Oxygen is the bottleneck. It's the oxidizer that must be present for pretty much all cell energy generation functions.



Different cells will stop working due to lack of oxygen at different times. Neurons are particularly hungry for oxygen and will start taking damage only minutes after an oxygen shortage. Depends on which processes you are referring to but they all ultimately stop when they run out of reactants.

Once your brain dies the majority of processes stop when the cells in question run out of oxygen. However, not all activity in your body is controlled by your brain, are controlled at all or require oxygen. A large part of human digestion is due to enslaved anaerobic bacteria within your digestive tract. These bacteria, that you need in your gut, go wild after death and are responsible for a large portion of your decomposition. As you cannot live without them their actions are a bodily process. In essence your gut has its own flora, fauna and resulting ecosystem! Ultimately all processes stop when they run out of fuel. How long it takes depends on several factors such as mass of the person in question and of course ambient temperature. 

Side note: The temperature factor is why we can harvest organs from the dead and reboot them, to an extent, as the crash in temperature causes them to run out of reactants at a much slower rate. The organ harvest guidelines are a good baseline as after 5 minutes, at body temperature, the organs are too far gone to harvest. As a follow up question: You say that, after 5 minutes at body temperature, the organs are too far gone to harvest. Is this 5 minutes after cessation of circulation (or rather, adequate perfusion)? In a prehospital setting, for example, a car accident, how can we expect to harvest organs in 5 minutes? Do EMS providers have some sort of "preservation" protocol in cases of non-viable patients who are confirmed organ donors? Interestingly, this process is slower than you'd think.  Some researchers have recovered viable stem cells from cadavers up to 5 days after death:
http://www.newscientist.com/article/dn23034-cadaver-stem-cells-offer-new-hope-of-life-after-death.html#.VLbwaCujOSo Aren't cadavers properly preserved in ideal conditions? And was the OP asking dead people in general or dead bodies we bury into the ground? This will probably get buried and go unnoticed but here goes.


I have a semi-related question, how long is sperm still viable after death?  Under ideal circumstances, about three days. Source? Thanks for your remark. I looked it up in medical literature and it seems I was wrong  I mistook 3 days for 36 hours, the interval in which motile sperm can be still obtained, although 24 hours is commonly recommended for successful results.

Shefi, Raviv, Eisenberg, Weissenberg, Jalalian et al: [Posthumous sperm retrieval: analysis of time interval to harvest sperm](http://humrep.oxfordjournals.org/content/21/11/2890.long). Hum Reprod. 2006;21(11):2890-3
Webb: [Raising sperm from the dead](http://onlinelibrary.wiley.com/doi/10.1002/j.1939-4640.1996.tb01795.x/abstract). J Androl. 1996;17(4): 325326. Probably a lost cause given the number of upvotes the top comment has received, but I feel the need to point out that while [it](http://www.reddit.com/r/askscience/comments/2salhs/is_it_possible_that_a_mountain_taller_than_the/cnnr3cs) is correct in the sense that Everest probably represents about the highest mountain we'd get on Earth, the explanation provided along with that is a gross (and largely wrong) over simplification. There are many physical limits on the height of mountain ranges, which include:

**Work Required to Continue Building Topography** This is probably the one that gets closest to what is being described in that top comment (["whereby they cause the earth's crust to compress from sheer mass"](http://www.reddit.com/r/askscience/comments/2salhs/is_it_possible_that_a_mountain_taller_than_the/cnnr3cs)), but has less to do with isostasy and more to do with work (in the energy sense) involved in building topography. For mountain ranges like the Himalaya that are built through the collision of continents, this collision represents the energy input. At a certain point, the amount of work required to continuing to increase elevations exceeds the input and it is "easier" to simply expand the mountain range laterally. For those interested in a technical treatment of this, check out [this paper](http://www.colorado.edu/geolsci/faculty/molnarpdf/1988GSASpecPaper.M&amp;LyonCaen.pdf). 

**Isostasy** Isostasy is an important factor, but within that, the really important point is the nature of the lithosphere that the mountain range is sitting on. While thinking of topography on the Earth from a purely isostatic standpoint (i.e. blocks floating in water) works to some extent, the better description is in terms of flexure (i.e. blocks sitting on a taut sheet of elastic). The height of a mountain range (the height of your block measured relative to some reference) will depend on the density and size of the block and the strength, essentially the thickness of the elastic sheet. You could imagine the same exact block having very different heights depending on whether the sheet is very thin (sinks down a lot, block is not very high) or very thick (doesn't sink much, block is much higher). In terms of mountain ranges, this basically depends on the type of material in the mountain range, the shape of that mountain range, and the nature of the lithosphere it forms on. This is largely why Olympus Mons on Mars is as high as it is, not the gravity, but rather because the thickness and the rigidity of the Martian lithosphere is much much greater than Earth's and thus can support larger loads. Coupled with the lack of active tectonics and a fixed source for magma from a hotspot leads to a giant volcano.

**Pressure-Temperature Conditions at the Base of a Mountain Range** Probably one of the most important aspects for collisional mountain belts, like the Himalaya are the fact that they have reached the height they are by crustal thickening, basically the crust being deformed and stacked on top of itself. Because of the isostatic/flexural response, as the crust thickens, elevations increase but the depths (and thus the pressures and temperatures) that the bottom, or root, of your mountain range is experiencing also increase. At a certain point, the temperature and pressure conditions reach a point where the material making up the mountain range will change into a very dense rock called [eclogite](http://en.wikipedia.org/wiki/Eclogite). The eclogite will be denser than the mantle rocks against which it is juxtaposed, which is gravitationally unstable, leading to a process called [delamination](http://en.wikipedia.org/wiki/Delamination_%28geology%29), where this dense elcogitic root detaches and sinks into the mantle. Going back to the isostasy discussion, there is now a reduced thickness of crust which on the long term will lead to a reduction in elevations of the range.

**Climate** Another huge factor is the effect of climate and erosional processes on the height of mountain ranges. There is a relatively popular idea referred to as the "glacial buzzsaw" which predicts (and has been largely born out by data in many of the Earth's active mountain ranges) that mountain ranges generally will not exceed a certain height because of the actions of glaciers, check out this [video that describes the "buzzsaw" in a simple way](https://www.youtube.com/watch?v=lLfM1FB58yA). Glaciers are incredibly efficient erosional agents, so once a mountain range reaches heights sufficient to start forming glaciers, the glaciers in turn buzz down the peaks of that range. The height limit imposed by glaciers would obviously depend on latitude (higher latitudes can support glaciers at lower elevations), general climate, and the precipitation patterns in the mountain range (still need precipitation to form glaciers).  I have a related question and maybe you are one who could answer it. Could there have ever been a deeper ocean trench than the Mariana's trench? What is the theoretical limit on how deep an ocean trench could be? This might be a bit simple, but I would imagine it have to depend on the angle of subduction due to resistance of the overriding plate, plus the depth at which the plate melts. I could ask one of my professors about this if you are interested?
 Okay, follow-up question that I've asked /r/geology without a satisfactory answer.  

In Colorado, there are zero mountains above 14,500', but there are around a thousand between 13,000' and 14,500'.  That seems like a very abrupt cutoff considering the different ranges and peaks have very different orogenies, from the relatively recent Sangre de Cristos (~5 million years old) to other peaks of the Laramide Orogeny (~80 million years ago).  

Any guesses as to which of the factors you list are most at play?  The short answer is no. The Rockies, and many other generally inactive, yet rugged mountain ranges are weird. The origin of the high topography of the Rockies has been variably attributed to a purely isostatic response to erosion related to the destruction of the orogenic plateau (likely similar to the modern day Tibetan plateau) that once existed to the west of the Rockies, uplift driven by some sort of deeper dynamic processes (mantle upwelling, etc), magmatic inflation, large variability in rock strengths/resistance to erosion, large climatic changes, or some combination of all or mixtures of those factors. As for the exact control on peak height, I don't have a good answer. I've never seen any papers on glacial activity being a driving factor behind the elevations within the Rockies, but that doesn't mean it didn't potentially play a role (I work on primarily, young active mountain ranges, so the Rockies and similar, old and mostly dead mountain ranges, while interesting, are a bit more out of my expertise).  So is it fair, as a layman, to understand that geologists don't precisely know why the rockies exist?  That was something I'd roughly taken away from my undergrad geology classes.

Also, given that the Sangres are (according to wikipedia at least) only 5 million years old, are they not considered a young range?  

Anyway, all this stuff is really cool to me, and I regret not continuing my path into geology.   It is fair to say that *this* geologist doesn't really know if the community has settled on a single cause for the maintenance of the high topography of the Rockies. We know a great deal about the original deformation events which created the Rockies (e.g. the Laramide orogeny), but the most recent event was ~80 million years ago, so the continued presence of high topography is an interesting issue. Doing some quick poking around on the Sangre de Cristos, the current manifestation of them appear to be related to extensional faulting, while the rocks exposed in the core of the range mostly record the history of convergent deformation that is largely responsible for the rest of the Rockies. So, their youngness is related to this relatively more recent extensional deformation.

Like any science, geology is relatively specialized. I have spent the better part of ten years studying active convergent deformation in eastern europe / central asia so asking me in depth questions about old deformation in the western u.s. and the topography associated with it is a little like going to an ear nose and throat doctor and asking them to listen to your heart. I can provide some info because of general training and keeping up on literature that seems interesting, and I probably could provide a detailed answer but it would require a lot more reading and digging than I currently have the time for, but ultimately, my inability to diagnose your problem should not be misconstrued as the inability of the proper specialist to do so. I wish I'd read your comment first, or at least before I commented on that other thread! This makes a lot of sense. As a structural engineer, the isostasy limit seems to be analogous, at least in some ways, to a foundation sitting on a weak clayey soil. The main factors that would come into play would be the flexural strength and rigidity of the "foundation", the elasticity of the layers underneath (analogous to the clay), and the size and shape of the mountain range. Thanks for your informative response.  I wanted to find out more about the "glacial buzzsaw" and among other things I found [this news article](http://news.yale.edu/2010/09/16/new-findings-cut-through-glacial-buzzsaw-theory) ([Nature paper](http://www.nature.com/nature/journal/v467/n7313/abs/nature09365.html)), which seems to show that in at least one area on Earth (the Patagonian Andes), glaciers can actually help a mountain grow rather than limit its height. 

What do you think? It is certainly an interesting idea and they have some relatively compelling evidence to support their hypothesis. Intuitively it also makes a fair bit of sense. The key issue comes down to the extent to which a glacier moves/flows. Unsurprisingly, for a glacier to erode it needs to move with respect to the rocks it overlies, a completely static glacier won't really erode much. The internal dynamics of a glacier depends on the climate of the region in which it is formed, so basically, if an area is cold enough throughout the year so as to keep the glacier(s) mostly immobile, than a glacier ceases to be an efficient erosion mechanism. The presence of the glacier (and the climate necessary to maintain it) also means you don't really have erosion by rivers, which is the usual workhorse for eroding mountains, so you now have high topography which is essentially being protected by the glaciers. 

While Thomson et al present a lot of convincing evidence for the Patagonian Andes, I think the big question is how common is this scenario in the geologic record and what are the conditions necessary to develop this situation. Similar high latitude and tectonically active areas still appear to be heavily influenced by glacial activity (a case example is the St. Elias range in Alaska) so there needs to be some combination of latitute, altitude, and local climate dynamics that conspire to make glaciers a constructive force in terms of topography. 

TL;DR - Convincing argument for this particular region, but likely the exception rather than the rule.   The tallest mountain of all time is probably around the height of Mount Everest because mountains hit something called the [isostatic limit](http://en.wikipedia.org/wiki/Isostasy) whereby they cause the earth's crust to compress from sheer mass. Olympus Mons is another mountain that reaches the isostatic limit, but is significantly higher because of Mars' reduced gravity and less active plate tectonics. The field of paleoaltimetry deals with this and similar questions.

EDIT: Damn, this blew up. Lots of questions here I don't know the answer to. I'm not a geologist, just a nerd who remembered a tidbit from an undergrad geology class I took 8 years ago, then confirmed it with Google. =/

EDIT 2: [Just found this!](https://www.youtube.com/watch?v=jIWhzYq16Ro) Thank you for the great and clear answer! Depending on how you view it, Mauna Kea could be a contender.  I'm typing this on my phone otherwise I'd include links, but read up on the Hawaiian-Emperor seamount chain--it's an undersea mountain range that makes up an archipelago in the Pacific (which includes the Hawiian islands).  Obviously most of these mountains are undersea, but Mauna Kea is 10,100 meters from base to peak!! And is compressing the earth's crust, and so the peak is getting closer to the center of the earth - making it look like the mountain is shrinking. BTW, a great mountain to go to the summit of. [deleted] Is the summit underwater? No; in fact, it's so high up that there is a collection of astronomical observatories located there, due to dark skies, clean air, and its position above most of the cloud cover. And snow!! There was a blizzard warning up there when we had a big storm a couple weeks ago!  A blizzard warning in Hawaii? [Apparently.](http://www.bigisland-bigisland.com/images/mauna-kea-hilo-snow.jpg)

Also, "Hawaiian Ski Adventures" are [a thing](http://www.aloha-hawaii.com/big-island/snowboarding/). The reason the observatories are on top, is because it's the furthest land mass from the Continental dust on the planet. Can you explain that further? Winds scouring a landmass will load dust, both that resting on the landmass and that it erodes. The bigger the landmass and powerful the wind, the more dust the wind will load (that's a source of "blood rains" and "blood snows" in some countries, wind having loaded reddish dusts from deserts and unloading it with precipitations at higher latitudes, leaves a mess afterwards).

Because of how sensitive optical observatories are, dust-loaded air will make observations more difficult or impossible. A very remote oceanic location away from continental windpaths will have very little dust cover, increasing optical observation windows. So that's why only cities next to mountains can have an observatory?  Cities far from mountains may have an observatory, there are many small ones near sea level even. It's the large, most useful and most well known that are in the mountains.


They are also generally far from cities because of [Light Pollution.](https://en.wikipedia.org/wiki/Light_pollution) Nope, [its peak is 4,207 m above sea level and is one of the five shield volcanoes that make up the beautiful island of Hawa'ii](http://en.wikipedia.org/wiki/Mauna_Kea).

Edit:peak not peaks I just got a ridiculous image in my head if mountain climbing getting even more dangerous because there are sharks circling the summit As the other answers have said, not even close. Perhaps the wildest experience of my life is getting in a car in 90F weather in August and having to put on full parka and gloves before reaching the summit. Upon getting to the top, I was absolutely freezing and lightheaded from low oxygen. Fell asleep on the return trip and woke up back at the bottom soaked in sweat because I still had my parka on. &gt;  lightheaded from low oxygen. 

Our rental car barely made it up, the engine was just sputtering along as we neared the summit... probably one of the reasons the lease specified we weren't allowed to take it up. No, it is the highest point in Hawaiian Islands at 13796 ft above sea level. 
Edit: 4205 meters As others have said - quite the opposite! It's one of the volcanoes of the tropical island of Hawai'i.

It's tall enough that there's [skiing and snowboarding](http://www.hawaiiinfoguide.com/hawaii_skiing.htm) in the winter! Another QI viewer? Mauna Loa is just 118 feet shy of Mauna Kea's elevation, but it is by far more massive. It's striking the difference in size.

It snowed recently on both mountains, so I was up on both of them playing in it! In fact, base to top, [Mauna Loa is taller than its next door neighbor, Mauna Kea](http://hvo.wr.usgs.gov/volcanowatch/archive/2002/02_02_21.html). Mauna Loa also takes the pure size crown - it's 80,000 cubic km in volume, or 3,200 times as massive as Mt. St. Helens.

I was also on MK for the snow, but the rangers didn't let us up past the visitor's station because of the blizzard on the summit. Can Mauna Kea really count?

Wouldn't a volcano like Mauna Kea be receiving substantial buoyant force from the water surrounding it? Obviously it doesn't actually float, but basalt is only about 3x denser than water. 

If you drained away the water surrounding Mauna Kea, would the whole thing collapse? This is a good thought, but not quite right. The water is affecting the mountain, but in the other direction. The mountain sits on the earth's crust, which sits on the gooey semi-liquid mantle. The water, also sits on the earth's crust, which sits on the gooey semi-liquid mantle. 

The water is actually just adding weight to an already compressed crust. It doesn't provide any buoyant force up because it's not the mountain that's being pushed down. It's the crust the mountain and water sit on.

For an analogy, imagine sitting in a boat floating on the surface of a lake. If you put water into the boat the boat sinks a little. The ocean basin acts like the boat and the mantle underneath the crust acts like the lake water. You put more of anything in the boat (the ocean basin) the crust will have more weight and it'll sink a little.

For it to have a buoyant force up, the water would need to also surround the crust. 

The Mauna Kea is more spread out than Everest and it doesn't have all the other mountains around it so closely (the Hawaiian islands are spread out mroe than the Himalayans) so it doesn't actually compress the earth's crust as much. I also think the rock is less dense than Everest, making it less heavy by volume, but I can't confirm that right now.  Mauna Kea, and all of the Hawaiian islands are formed by the Hawaiian hotspot, and over time the ocean crust moves along towards the subduction zones (towards Asia). You can track the plate movement by looking at underwater topography (anyone can do this, check out Google Earth). The hotspot is also much less dense than anything around it, and acts as a sort of crustal car-jack.  Basically, there's no buoyancy because the water is on top of it, but not underneath.  Like a rowboat filled with water sitting in the driveway. &gt;The Mauna Kea is more spread out than Everest and it doesn't have all the other mountains around it so closely (the Hawaiian islands are spread out mroe than the Himalayans) so it doesn't actually compress the earth's crust as much. 

Given this, could a mountain attain even greater heights if it doesn't have a mountain range so densely packed around it? The only way the bouyancy of the mountain is affected is in regard to the surface area of the boundary between the crust and the mantle in the affected area, am I right? But on the other hand, the water is less dense than rock, so in practical terms there *is* less weight pressing on the crust than in the Everest case at an equivalent distance from the barycenter of the Earth. Since Mauna Loa is not a point mass acting on a hypothetical ideal oceanic crust, and Everest is not a solitary mountain but rather part of an enormous uplifted mountain/plateau complex that has a wide array of forces acting on it, the difference *should* matter a little bit, eh? yeah. I didn't consider that. 

However, oceanic crust is more dense than continental crust (which is why is subducts under continental crust). Taking that into consideration, the Hawaiian crust may deform more around Mauna Kea than the continental crust around Everest. 

I think this is beyond my minor in geology... Hopefully someone else can answer better :/ How could it experience buoyant force when the water has no way of getting underneath it?  The water only adds to the weight does it not? The definition of "highest mountain" that makes the most sense to me in this context is "what is the mountain that is the highest from the Earth's center of gravity, accounting for rotation-induced and tidally-induced bulging".  Mauna Kea definitely doesn't come close to Everest in this accounting because its peak is substantially lower.  Yes, Mauna Kea has the misfortune of having a much lower base, but it's not clear to me why this shouldn't count against it, as the base itself bears weight just like the structure of the mountain, and given that the two are largely even composed of the same materials, does it really make sense to distinguish the mountain as being fundamentally different from the base?  The higher base upon which Everest rests on is itself load-bearing, and structurally counts just as much as the mountain. If distance from center of the the Earth is the qualification for tallest mountain, then [Chimborazo](http://en.wikipedia.org/wiki/Chimborazo) in Ecquador is the tallest mountain, due to the equitorial buldge.

What I've generally read/heard is there are three methods for determining tallest mountain: height above sea level (Everest), height above base (Mauna Kea), distance from center of earth (Chimborazo). If you *really* wanted a good answer, you'd probably want "height above the center of the geoid, adjusted to account for centrifugal forces due to rotation". But /u/CydeWays did specify that part of his definition as highest from the centre of gravity of the Earth accounting for any rotational or tidal "bulging". By this I believe he means treating the Earth not as an oblate spheroid but taking the average distance from centre to land surface which would be somewhere between equatorial distance and polar distance from the centre.

Earth has an equatorial bulge of around 25-odd miles at the equator and so if you account for this Chimborazo wouldn't be the highest point any longer and I believe that was OP's point. :). Thank you, glad someone actually read what I said. I guess it depends on how you want to define the base? If you look at a cross section of mt. Everest, it goes FAR below sea level, if you include the crustal material supporting the mountain and not just the arbitrary amount above some elevation chosen to be zero. In that case you have to look at something on the order of 40-60 km (not 100% on that offhand but it's close) of mountain!

On the other hand, yeah Mauna Kea is something like 11 km high from the ocean floor...but it also only sits on about 7 km of similar material which you could consider a homogeneous base. In that respect Everest in an easy 20 or so km taller than Mauna Kea. 

 Nice point.  Didn't think that technically would be relative for Mauna Kea as well.   Technically the height could be defined from the peak straight down to the center of the Earth. I suspect what we are dealing with is the total weight that the substrata can bear.  Having much of the volume taken up by water, as in the case of Mauna Kea, would result in much less compaction as compared to having that volume taken up by mountain, as is the case with the Himalayan plateau. IIRC, Olympus Mons is roughly three times the height of Everest. Mars also has 1/3 the gravity of Earth. Makes sense. This is a rule of thumb that I use, and I have given quiz problems in my physics class where the student has to use the equation: 

    g_earth x h_earth = g_mars x h_mars

to get the height of Olympus Mons this way. It's a fun exercise in dimensional analysis and teaches them something about surface gravity (I hope) and it's a great simple example for understanding how quantities relate (i.e. how this thing changes when that thing changes).  

In fact, I wonder if this can be used to predict the potato radius? Assuming constant density for all rocky bodies, do you hit a point where the limit of the maximum height of a mountain on that body is greater than the radius of the body itself? The equation above comes from the same sort of derivation as [was used to derive the potato radius](http://arxiv.org/ftp/arxiv/papers/1004/1004.1091.pdf) for studying elastic limits of materials. 

Edit: 

[So here's the math](http://www.wolframalpha.com/input/?i=sqrt+%28+8848+meters+*+9.81+m%2Fs^2+%2F+%28Gravitational+constant+*+5.51+grams%2Fcc+*+4%2F3*pi%29+%29) where that gravitational constant and density are used to calculate surface gravity assuming a sphere with the same density as the earth. 

**We get about 240 km for the radius where this happens, which is totally in the 200-300km potato radius given in the paper I cited above!** 

I'm going to go show my friends. 

 You are so enthusiastic about physics, it emanates through your writing :D Mars is also largely isostatically locked. There is little if any tectonics on mars there for there would be basically no isostatic response to the load. This was my first thought after reading the top response.  I seem to remember hearing that one of the problems in trying to terraform Mars, is that it doesn't have a liquid core, thus doesn't have a magnetosphere. Correct, the lack of a magnetic field is the primary reason for its loss of atmosphere and thus inability to maintain liquid water.

From memory I think there was a theory that the cooling of the core was related to the massive bulge on one side of the planet (the side Olympus Mons is on) "Hi, Mars, is that Olympus Mons or are you just happy to see me?" As terraforming efforts go, putting up a magnetic field on a planet cold enough for dry ice to exist on its surface will likely be one of the easier ones, particularly if high temp superconductors continue to advance. [deleted] But it will have 9 times the surface area at the base if they're the same relative shape  could you assume if a large collection of less dense raw materials were in the same location on the crust it would be able to reach a higher height due to less force due to gravity being applied on the mantle? Yes, assuming that less dense material can support its own weight to that height.  Build it out of weaker material and it may compress itself instead of the crust beneath it. Of course. It could also be ever so slightly taller (probably not even a few millimeters) if it were sitting on the equator, due to centrifugal force and -since the Earth is wider at the equator *because* of that force- feeling a bit less gravity. On that note, would it be possible for a planet to exist where the isostatic limit was outside the atmosphere?  Or at least high enough up that it was effectively a vacuum? Yes.

The most obvious example would be a body, like the moon, that for all intents and purposes doesn't even have an atmosphere. Interesting question! Say we're only interested in planets which actually *have* an atmosphere (or the answer is too easy!) The atmosphere's height is relatively insensitive to how much it weighs -- it only depends *logarithmically* on the surface pressure (since the mass is exponentially distributed in altitude). There's a characteristic scale to the atmospheric height: it's the balance between the pressure of the gas, trying to inflate itself, and the weight of the gas, trying to collapse itself. The pressure scales with the absolute temperature (1); and the weight scales with the (molar) gas density (2), and with the planet's surface gravity (3).

https://en.wikipedia.org/wiki/Scale_height    
(^ has a table of planet's atmospheres)

So those are the three main parameters we could twiddle. (I don't know about the isostatic limit; maybe a geology person will address that)

There's no point looking at the surface gravity, since the mountain-height limit depends on it in the same way (it'd just cancel out).

You'd get the shallowest atmosphere with a dense gas (high molecular weight), at a low temperature. Take the earth's atmosphere for example: it's mostly N2 (weight 28 amu), at ~300 K, with a scale height of 8 km. You go up 8 km, the density goes down to 1/e ~ 36% of sea level. At 16 km, 1/e^2 ~ 14%. Everest is about 9 km from sea level (~1 scale height).

If you moved the Earth as from the sun as Jupiter, the temperature would be roughly halved. So the atmospheric scale would shrink to ~4 km; Everest's summit would be above two scale heights -- above ~90% of the atmosphere.

At the distance of Neptune, the temperature would be ~40 K and the scale height ~1.5 km. But then, earth's atmospheric components would all be frozen cryogenic solids, like the nitrogen ice that covers the surface of [Triton](https://en.wikipedia.org/wiki/Triton_(moon%29). So we wouldn't have a [meaningful](https://en.wikipedia.org/wiki/Triton_%28moon%29#Atmosphere) atmosphere.

Hydrogen and helium would remain gases at very low temperature. But you wouldn't find them in on an earth-size planet, since they're light enough to [escape the atmosphere](https://en.wikipedia.org/wiki/Atmospheric_escape). And anyway, low molecular weight makes atmospheres *taller*, so that's not useful.

 Does this increase or decrease tectonic shifting? In other words, is the area subject to increased amounts of earthquakes because it has so much mass on a given area? Somewhat related to your question, I wonder if the regular convective currents in the upper mantle are slowed down in areas where there is a huge mountain or chain of mountains on top. In other words, would the large weight above (relative to areas where the crust is much thinner) increase the "drag" or friction at the crust-mantle interface? Whoa, does that mean Mauna Kea is only as tall as it is because of buoyant force from the ocean? No, islands don't sit on top of the ocean, like a boat, they form at the base of the ocean and build up. So water doesn't have any buoyant force on any mountain/volcano.

Mauna Kea is only as tall as it is because of the somewhat arbitrary base they're measuring from (the surface of the sea floor near Mauna Kea). The point that you pick as the base of the mountain is going to determine how tall you think the mountain is. You could make a similar argument that Everest is shorter than Mount Kilimanjaro, since Kilimanjaro rises up steadily on its own from sea level, whereas Everest is just a peak on the top of the 4,000 meter Tibetan Plateau. But that's a silly argument. 

If you get bored you can dig a trench to a mere 1,000 meters below sea level around Mt Everest, and then you could say that Mt Everest is taller than Mauna Kea from each of their respective bases. But really those would both only be the top-of-the-bases you were measuring from, and people wouldn't suddenly think that Everest was any taller.

In reality, all mountains are built up on top of the Earth's outermost layers of crust. The weight of a mountain range pushes down the crust by different amounts. See second image here: https://en.wikipedia.org/wiki/Lithosphere

Compare also two types of volcanos: http://www.geology.sdsu.edu/how_volcanoes_work/subducvolc_page.html [deleted] Right, and I guess the water that's making it "buoyant" doesn't exert any force on the ocean floor...

Imagine a scenario where you could take a bucket perfectly full of water and place it on a scale.  In this hypothetical world, anytime water trickled over the edge of the bucket it would no longer register on the scale. Then, you put a toy boat in it, the bucket would overflow, but the scale would read the exact same weight.  Because the toy boat only displaces the amount of water equal to its weight.  Now, redo the experiment, but this time you put a rock in the bucket, some water would overflow, but the scale would read **higher** because the rock is more dense than the water it displaced.

Surrounding a mountain with water should not "lessen the relative pressure of the rock on the ocean floor."  It should make it greater. Let's try another way of looking at it.  If all I care about height, then naturally a skinnier structure is better than a broader structure, because the skinnier structure will have less total mass than the broader structure, and will thus exert less force on the base.  Think skyscraper vs pyramid, with the skyscraper being a better way of attaining a given height given a certain mass.

Well, a mountain that is anchored deep underwater is more analogous to the skyscraper in my example than a mountain that is anchored above water, because the water is substantially less dense than rock, and thus exerts a lot less downwards pressure on the plate than the rock surrounding the above-water mountain.  For the same height, you're using a lot less total mass, thus less downward force on the plate.  The problem is that there aren't any volcanoes *large* enough to reach a higher height than big mountains on land, because the handicap in initial height is insurmountable given that additional height obeys a cube law with mass. [deleted] This doesn't make sense to me.. wouldn't the ocean have an opposite effect, as it is adding weight on top of the mountain? For example, if I have a leaf on top of the water, it floats, but add enough water *on top* of the leaf, and it will begin to sink as there is more weight on it. As I presume there is not enough water inside/under Mauna Kea to counter act the weight of the water on top of it, it would seem to me that the water would cause Mauna Kea to compress more, not the other way around. 

Of course, I am not even close to an expert and could be talking out of my ass :) Suppose we built something as tall as the Burj Khalifa on top of Mt Everest. Assuming the foundation was as stable as it is in Dubai would there be a greater tendency for it to fall due to it's height being over the isostatic limit?  Burj Khalifa has approximately zero mass compared to Everest. It's weight that matters, and as long as we're talking about mountains that can naturally form, height is somewhat correlated with weight. A 10 km high mountain would be a completely different thing from a hypothetical Everest with a skyscraper on top. Who cares about the straw that broke the camels back! What about the building that destroyed a mountain! The crust is partly elastic (the other part is earthquakes), but rather thick and stiff, so weight placed on it tends to average over a large area. Even though the Burj Khalifa weighs something like 500,000 tons(empty), and this is a serious weight in comparison to the footprint of the building, miles of bedrock below it spread that weight over hundreds of square miles of mantle. 

The other factor is that Everest weighs like 6 trillion tons. an extra million is not going to make a difference. Everest is literally a million times heavier than Burj Khalifa

TLDR; The isostatic limit is only for mountains. You could build the Burj Khalifa on Everest. &gt;You could build the Burj Khalifa on Everest.

That would the ultimate evil villain fortress. Except for the fact that it would be the most visible and easily targeted structure on the planet.  But see, the heroes would assume you have some kind of ridiculous defense system in place, and they'd be afraid to touch it.  That or they'd assume it couldn't POSSIBLY be your real base of operations.

Because only a true madman would build such an easily noticed secret lair.

The true defense system is running it as a hotel so that it's packed with innocent tourists, providing thousands of human shields. The downside: Fat tourists in Hawaiian shirts trying their hardest to find and touch the Death Ray.  Yes, but it would have sharks swimming around the summit. Because I got all the way down here and it's time to go meta, dammit.  Structural engineer here. That's a really interesting suggestion. All I can think about now is the crazy wind forces that would be on that structure.

But as the other commentor pointed out, Burj Khalifa's weight would be insignificant compared to that of Everest. The building would be helped somewhat by the much lower density of air up there. Around half sea level I believe.  But does the lower density of air reduce wind speeds? I obviously have no experience with buildings on top of mountain peeks, but for regular structures on flat ground, wind speed actually increases inverse-parabolically the higher up you go, and is essentially zero at ground level due to friction (similar to liquid flow near the boundaries in pipe flow). However, I imagine at the peaks of a huge mountain range like the Himalayas, it's much more complicated, with wind vortexes, different atmospheric conditions, etc. It increases wind speeds actually, but the force exerted by the wind scales linearly with air density, and I'm pretty sure density drops faster than speed rises. 
A 70 km/h wind on top of Everest would feel weaker than a 50 km/h wind at sea level. But the isostatic limit assumes constants such as mantle density and crustal density. If these vary, the isostatic limit varies as well.  The limit is said to be almost 10 000 meters (we don't know exactly). This is according to my geology professor. Wouldn't it depend on the density of the rock?  iirc Everest was something relatively low density, I remember something about an experiment looking for the gravity pull caused by the rock, and it was less than expected. Yes, it depends on the density of the rock; the limit is *about* 10 km for that reason. Most crust material is ~2.5-3 g/c.c., and we can't really accurately calculate the density of a mountain this big.  Isostacy is the most limiting factor when determining mountain height. However, the fact that mountain ranges influence their own weather/climate also leads to increased rates of erosion in comparison to lowlands, causing them to reach a "maximum" elevation. Just as climates are colder as you get closer to the poles, it also gets colder with increased elevation (eg. Mt. Kilimanjaro is 3 degrees south of the equator and was glaciated less than a decade ago/might still have a few small glaciers left). This causes precipitation to fall in the form of snow. With enough snow, glaciers grow. In turn, glaciers erode mountains with great efficiency.  To add to this from a geological point of view. The earth has essentially been cooling since the start of earth history. It is therefore believed that the earth's crust is presently more rigid than ever before. Making the possible max height due to isostacy at its greatest. So Everest is likely the tallest ever mountain.  it should be said the tallest mountain as measured from its base is mauna kea in hawaii, even though half of it is underwater. I want to say thank you for posting something I can understand the whole way through.  Usually ask science gives me the following:  "Yes, but stuff I don't understand...". "No, but stuff I understand..." Or "Well, certain studies show stuff I don't understand.". I get it, you wanna flex your knowledge, but even Hawking can break it down into laymen's terms. You answered helpfully and to the extent of your knowledge, and admitted your no expert or pretend to know more than you do. Right on brah, keep rockin How does isostatic limit relate to height? Do all mountains increase by roughly the same mass to height ratio? That's awesome!  I always knew about how dramatically Mountains can change over time, but I never thought of one being taller than Everest!  So if we survive and terraform Mars into an Earth like planet, would it be possible to climb Olympus Mons like one would Everest? Would it be too high?

Because, imagine that view! Could this mean that Mount Everest actually underwent one or more of those compression fases in the past ? And that it (over the course of millions of years) is 'constantly' switching between growing in height due to tectonic pressure and shrinking in height due to the mass compression ? Is this the reason why the tallest mountains in the US are all around 14000 feet? There are a whole lot of 14000 ft peaks in the US but none are higher then that, except Denali of course, but thats in Alaska.  Now I'm wondering if a city (large enough) can have an affect on this as well. I don't expect an answer just speculation, very interesting. &gt; less active plate tectonics

I'm curious. Does this mean that other planets experience earthquakes? Do other planets have something similar to our continents? Thanks geodan What about their base being underwater and the rising out of the ocean to the limit? This answer has really 'peaked' my interest in geology!

But really, thats fascinating! So followup question.  Why is Olympus Mons on Mars instead of Mercury which is smaller and has less gravity?
 The actual maximum theoretical height of a mountain ON LAND on Earth is around 10km, which is right about where Mauna Kea is today, and roughly twice what we see with Everest. Contrary to some of the other answers, it's entirely possible for a mountain to exist at those heights...albeit temporarily. Someone even did the math: http://talkingphysics.wordpress.com/2011/09/08/how-high-can-mountains-be/

Basing his calculations on the mountains load on the crust underneath, and the failure point of granite, he worked out that the maximum height for a granite mountain on Earth is roughly 10km. Beyond 10km, the granite would simply crumble under its own weight and collapse. 

_h_`max`  210^8 N/m^2 /(310^3 kg/m^3  10 m/s^2 ) 10^4 m = 10 km

While that's the maximum theoretical height, everyone else is correct when talking about practical maximum height. The isostatic limit would normally prevent mountains from ever approaching this height through the processes which normally raise our peaks, and erosion typically kicks in to help keep mountains from achieving that maximum potential.

However, this does *not* mean that mountains could not have achieved these heights for brief periods. Massive volcanic events such as the one that created the Siberian and Deccan Traps, or the Ontong-Java Plateau in the South Pacific, could have created mountains that reached this limit. Given a large enough vent, more conventional volcanoes might be able to reach heights well above Everest (though the calculations would need to be redone to account for their weaker source material.) Massive asteroid impacts could have also created peaks that approached this limit. Certain types of earthquakes could theoretically generate mountains of that size almost overnight. The Giant Impact Hypothesis, which supposes that the moon was generated from debris originating in Earths impact with another object, would have almost certainly generated mountains of this size.

All would have been very short lived as the crust sank beneath them and erosion tore them apart, but it's certainly POSSIBLE that mountains significantly taller than Everest have briefly existed  on the Earth's surface. Given the planets long and violent history, I think it's probable that Everest has been eclipsed at least once.  Could you explain how 10km is roughly twice the height of Everest? I believe its about 8.8km tall as measured above sea level. Considering the base of Everest is nowhere near the ocean I would assume a meaningful height measurement to be from base to peak.

While the base of a mountain is pretty subjective to define it is usually tied to the average elevation and grade of the surrounding area.   Topographical prominence is what you're reaching for I think yet it's still generally a poor expression of how gargantuan a mountain is.

It's particularly not useful when it comes to Everest because topographical prominence relies on parent peak which Everest by its nature does not have. Its full height = its prominence.

So the simplest thing when talking about tall mountains is just to take sea level although that means Everest's base is basically on the sea shores of India. What is short lived in this geological timeframe? Months, years, centuries?  * *"When discussing mountains, there is a huge difference in definition between tallest and highest. Mount Everest is the highest, but the tallest mountain on earth is actually in Mauna Kea in Hawaii.*

http://knowledgenuts.com/2013/07/21/mount-everest-is-not-the-tallest-mountain/

And in reference to your question, I'm sure it's likely that there were taller mountains at some point, but I doubt it's possible to tell.  Base to peak, the "tallest" mountain completely above water is Denali in Alaska. And the mountain furthest from the Earth's core is Mt. Chimborazo, Ecuador due to the Earth bulging around the equator because of the spin. suprise suprise.

I was just reading about this mountain today while I was suposed to be working. Although my collegue and I were looking at it as the closest place on earth to the sun.

neat !


edit: Letters &gt; Denali in Alaska


The *smallest* mountain in the world is [Mt Wycheproof](https://en.wikipedia.org/wiki/Mount_Wycheproof) in Australia which stands 43 metres (141 ft) above the surrounding grasslands. ["View from Mount Wycheproof lookout."](https://upload.wikimedia.org/wikipedia/commons/a/a4/Mt._Wycheproof_Lookout.jpg) Those mountaintop views man, they're something to behold. What makes that a mountain not a hill? Is there a clear definition, or is it just a question of arbitrary designation? Its part of  a defined range and a notable peak.

Hill are more of high points in a generally undulating landscape Yeah, there's no clear definition and it obviously varies enormously between countries. 
 According to the USGS anything above 1000 feet is a mountain, anything under that is a hill. In the UK I think it's 2000 feet.

But Hill and Mountain pretty much are arbitrary, you should refer to it by the method of formation. e.g. It's not a hill it's a dome(formed by diapirism). Or the Appalachian Fold and Thrust Belt. I don't know about the particular one in question but what determines it is generally how it forms.  Some of that sounds like something I would make up

"the Wycheproof area is known to have its own unique mineral, known as Wycheproofite.  Wycheproofite can be characterised by its pinkish colour and its transparency" Try Mt Tenpou () in Osaka, Japan: altitude of 4.53m. I made a solo ascent in April last year and captured [this picture](http://i.imgur.com/gYNrxuc.jpg) of it. The peak is actually the square tile in the bottom-right corner; I didn't know that at the time, which is why the tile is partially outside the frame. There is actually a Mount Tenpou expedition society located in a nearby caf; they will give you an official certificate for 100 yen. Osaka aquarium is nearby, and is worth checking out. Laborde Mountain in New Orleans stands 43 feet above the surrounding lands. &gt; Laborde Mountain

According to wikipedia, Mt Wycheproof has "the distinction of being the smallest **registered** mountain in the world". What that registry is and how they define what a mountain is would be interesting to read. wouldnt that be a hill? Everything I find regarding this claims that to be incorrect. The tallest from  sea level is Mt. Everest, but from base to summit, is Mauna Kea.

Mt. McKinley is only the highest in North America. 

http://www.livescience.com/32594-which-mountain-is-the-tallest-in-the-world.html

https://en.wikipedia.org/wiki/Mount_McKinley He said base to summit "completely above water". So Mauna Kea wouldn't fit because although its entire height from base to summit is 33,100 feet, only about 13,796 feet is above water. Whereas McKinley at 20,237 feet has a base-to-peak height of 17,000 to 19,000 feet according to Wikipedia, because it is surrounded by plains that are only 1,000 to 3,000 feet above sea level. Ask yourself this. If you (Denali) are 6 ft tall and I (Everest) am 5 ft tall but I'm standing on 3 foot tall step stool (Tibetan plateau), am I taller? That's the whole concept and the very thing I said in the beginning. In case your wondering the base of Everest is not at sea level.  How is the base of a mountain defined?  In silly arbitrary ways. We should only be concerned with it's elevation above sea level IMO. Which sea level? Mean? Local at the nearest straight line to coast? Account for tides? Is there not an average sea level? Yes but at the equator it would be deep below ground and at the poles it would be far up in the sky, it would be an effectively useless measurement.  Depends. Which sea? And which coast of the sea?  Western coasts have higher levels due the the centrifugal force caused by the earth's rotation. Sea level is well defined on earth (less so on mars, they use a slightly different measurement there).

&gt; Sea level is generally used to refer to mean sea level (MSL), an average level for the surface of one or more of Earth's oceans from which heights such as elevations may be measured.

From wikipedia. So normally when talking about sea level you are not actually talking about vertical distance to the water, even at the coast, as this would change with every wave. Seems like you could define the base of a given peak as the lowest elevation contour line that includes the peak but no higher peak. Within what range?

As a software engineer I would propose something like "The height between a local maxima and the lowest local minima in any direction" but that's such a PITA and then you have to decide upon how much elevation gain do you need to call something a local minima (essentially the height resolution we are concerned with)... why not use the height above sea level or the distance from the center of the Earth? Height above sea level or center of the Earth is perfectly fine if you're just looking for numerical geographic extremes. But if you're a mountaineer, you probably care more about topographic prominence. In fact, that's the algorithm I mentioned: http://en.wikipedia.org/wiki/Topographic_prominence Best method in my opinion is actually furthest away from the centre of the earth, which goes to [Chimborazo in Ecuador](http://www.neatorama.com/2011/11/01/the-farthest-point-from-earths-center/) In my opinion that's an awful definition, sea level at the equator is is further from the centre of the earth than many mountains. Sure, that's even better, but difficult to determine(?) Mountains taller than Everest exist now.  Mauna Kea is 1400 meters taller than Everest.   Everests claim to be the worlds tallest mountain is based on the fact that its summit is the highest point above sea level on the earths surface. All Everests 8,848 metres of mountain are above sea level. From base to summit Mauna Kea measures 10,200 metres, but the first 5,995 of those meters are below the surface of the ocean. If the title of tallest mountain was measured from base to peak, Mount Everest would actually be third, behind Mauna Kea and Mount McKinley in Alaska. average elevation of the [Tibetan Plateau] (http://en.wikipedia.org/wiki/Tibetan_Plateau) is 4,500 meters... on the Nepal side of the mountain elevation drops faster than the Tibetan side, but when I traveled through the region I remember getting pretty damn far away from Everest before there was significant drop in elevation

I guess it depends on how much of the Himalayas you count as "base", but the [Everest](http://en.wikipedia.org/wiki/Mount_Everest) Wiki puts it at between 4,200 meters and 5,600 meters, leaving a height above base between 4,650 meters and 3,650 meters... it's not much higher above base than Mt. Rainier, if at all. The Appalachian Mountains in the Eastern United States, while not as tall as  Everest, were the height of the Alps and Rocky Mountains today. They formed around 400 million years ago. There are some sources that say they reached the heights of the Himalayas, but I am not sure if they are true. Pangea was formed 270 million years ago and broke up 70 million years later.

http://en.wikipedia.org/wiki/Appalachian_Mountains On a slightly tangential but related topic, I never realized how complicated calculating the "height" of a mountain can be until I saw this video.  It was pretty eye opening, done very well and worth watching.  The Minute Physics folks put out some great stuff:

https://www.youtube.com/watch?v=q65O3qA0-n4 [deleted] [deleted] [deleted] http://en.wikipedia.org/wiki/Mauna_Kea
have a read of this wiki page. It talks about the tallest mountain in the world from base to tip, which is twice that of Everest'. So with that in mind if measuring from base to tip it's definitely possible. Of course. Everest's height is not limited by gravitational forces or any other geological force. It is  just the current highest mountain range. Greater tectonic forces likely existed in previous ages which resulted in higher mountain ranges, as there were certainly more violent collisions than the collision of the Indian plate  with the Asian continent. It looks like some more intelligent folks may have already weighed in but I thought I would give my input  Indeed!  Many geologists believe the Appalachian Mountains were once as tall as the Himalayas, potentially with their own "Mount Olympus".  However, over time, they were eroded away, giving the East Coast its amazing sand and outer banks.  Also, Mount Olympus is no where near the tallest mountain we know of.  As many have pointed out, Olympus Mons of Mars is much taller, as are several others.  This link has a more definitive list: 

http://en.wikipedia.org/wiki/List_of_tallest_mountains_in_the_Solar_System 

And it is important to note that Mount Olympus is not the tallest mountain, just the highest point on Earth (I say "just", but it's still impressive!).  The title of tallest mountain belongs to one of several underwater mountains, which form volcanic archipelagos such as the Galapagos and Hawaii.  I've seen Mauna Kea listed as the tallest, but that should be easy to research. When you say Olympus, you mean Everest, right? Shannon has estimated the number of possible legal *positions* to be about 10^(43). The number of legal *games* is quite a bit higher, estimated by Littlewood and Hardy to be around 10^(10^5) (commonly cited as 10^(10^50) perhaps due to a misprint). This number is so large that it can't really be compared with anything that is not combinatorial in nature. It is far larger than the number of subatomic particles in the observable universe, let alone stars in the Milky Way galaxy.

As for your bonus question, a typical chess game today lasts about 40 to 60 moves (let's say 50). Let us say that there are 4 reasonable candidate moves in any given position. I suspect this is probably an underestimate if anything, but let's roll with it. That gives us about 4^(250)  10^60 games that might reasonably be played by good human players. If there are 6 candidate moves, we get around 10^(77), which is in the neighbourhood of the number of particles in the observable universe.

The largest commercial chess databases contain a handful of millions of games.

**EDIT:** A lot of people have told me that a game could potentially last infinitely, or at least arbitrarily long by repeating moves. Others have correctly noted that players may claim a draw if (a) the position is repeated three times, or (b) 50 moves are made without a capture or a pawn move. Others still have correctly noted that this is irrelevant because the rule only gives the players the *ability*, not the *requirement* to make a draw. **However**, I have seen nobody note that the official FIDE rules of chess state that a game is drawn, period, regardless of the wishes of the players, if (a) the position is repeated *five* times, or if (b) *75* moves have been made without a capture or a pawn move. This effectively renders the game finite.

Please observe [article 9.6](http://www.fide.com/component/handbook/?id=171&amp;view=article). On mobile - it shows up as 1043. It's actually 10 raised to the 43rd. 

:) just to clear up any confusion.  Bobby Fischer often said he was bored of normal chess because the game positions and strategies could be too easily memorized so that play on even the highest level was more about remembering the positions from prior experience and proceeding rather than having to rely on pure analytic thought and deriving the best move.
In fact, he felt so strongly that high level chess was just memorization for the best players and not true inherent skill that he favored a variation of chess that had the back row of pieces positioned in random order for each game so there could be no use of prior memory for the tactics that would evolve in that particular game.



I think it is interesting to point this out because the permutations of practical/logical games of chess, especially as the play level becomes higher, is much more narrow than this number. An easy example is the first 10-15 moves of chess rarely deviate from a collection of openings in high level play because the resulting game would confer a clear disadvantage and therefore, somewhat like evolution, have been naturally selected out of the potential game pool.
So its ironic, that as you get better at chess, it becomes easier to memorize the game and there are less unconventional positions you have to routinely consider as represented by this higher than astronomical number.



EDIT: I found more on [Wikipedia](http://en.wikipedia.org/wiki/Bobby_Fischer#Fischerandom_Chess) , including a quote from Bobby Fischer:


Fischer heavily disparaged chess as it was currently being played (at the highest levels). As a result, on June 19, 1996, in Buenos Aires, Argentina, Fischer announced and advocated a variant of chess called Fischerandom Chess (later known as Chess960). The goal of Fischerandom Chess was to ensure that a game between two players is a contest between their understandings of chess, rather than their abilities to memorize opening lines or prepare opening strategies.
In a 2006 Icelandic Radio interview, Fischer explained his reasons for advocating Fischerandom Chess:



"In chess so much depends on opening theory, so the champions before the last century did not know as much as I do and other players do about opening theory. So if you just brought them back from the dead they wouldnt do well. Theyd get bad openings. You cannot compare the playing strength, you can only talk about natural ability. Memorisation is enormously powerful. Some kid of fourteen today, or even younger, could get an opening advantage against Capablanca, and especially against the players of the previous century, like Morphy and Steinitz. Maybe they would still be able to outplay the young kid of today. Or maybe not, because nowadays when you get the opening advantage not only do you get the opening advantage, you know how to play, they have so many examples of what to do from this position... and that is why I dont like chess any more... It is all just memorization and prearrangement..." "An easy example is the first 10-15 moves of chess rarely deviate from a collection of openings in high level play because the resulting game would confer a clear disadvantage and therefore, somewhat like evolution, have been naturally selected out of the potential game pool."

I think you really nailed it there.  The fact that moves might be *possible* has no bearing on whether they are remotely plausible.  An entity (person, computer, disembodied head) playing the game with the slightest inclination of playing competitively would self-select out of the vast majority of possible plays.  Thus, as I see it, those ineffectual or detrimental moves should not even be lumped in with the compendium of possible plays because they're just, well... stupid.   :) &gt; "An easy example is the first 10-15 moves of chess rarely deviate from a collection of openings in high level play"

It's a large collection; Rybka opening book is 4 gigabytes (not text!) and some of the games from the current Wijk super-GM tournament are out of book within 10 moves.

 What's the digital size of a chess game? I know that chess games can be stored as pgn (player's game notation) files, but how many bytes does each move count as? The 43-move example game on Wikipedia's article on [PGN](http://en.wikipedia.org/wiki/Portable_Game_Notation) is 738 bytes. Ignoring comments but including the move number, moves are 8 to 12 bytes. Depending on the size and number of comments - and the information in the tags - it could be arbitrarily large, but a bit under a kilobyte is probably a good guess for the average, if the files are stored in an uncompressed form.

If you don't care about readability, it would be possible to express each move as four bytes (the first two being the coordinates of the target piece and the second two being the position it is being moved to). If a typical game lasts for 50 moves, then it would take up about a two fifths of a kilobyte; with a small amount of metadata, a bit over half a kilobyte might be reasonable.

EDIT: Yes, I know that this can be reduced to 12 bits using the naive encoding I've proposed. You can stop telling me now. Read the rest of this thread! You can encode a move as 1 byte. There are no positions with more than 256 valid moves. You just generate the valid moves, then a 0 encodes the first valid move, a 1 encodes the second, etc. With some clever compression, I think you can go down to about 20 bytes per game on avereage, if you disregard game metadata. Add in some Huffman encoding and I bet you could get it down to an average of like 5 bits per move. If you used a nave chess AI to sort the possible moves by value, you could probably get down to 2-3 bits per move on average.  With arithmetic coding you'd probably be below 1 bit per move for a decent portion of moves. There are only 64 squares, so a move only requires 12 bits, not 4 bytes, as 6 bits can specify the start or end square.

As there are only 32 pieces, you only need 5 bits to specify the piece, and 6  to specify the end square. So you can also do it in 11 bits.

So a 43 move game can be encoded in 473 bits or 30 bytes. And if you consider that no piece can move to all the squares at any given time, you can reduce it further.   As far as I can tell the most possible move choices you could have would be a queen in the center with 27 possible destinations.   That would let us get down to 5 bits of destination, for a total of 10 bits/move.  

That cuts the sample game down to a only 430 bits. Since there are only 16 pieces on each side, they can be noted with 4bits. Destination can be denoted with 6 bits (64 positions). Assuming knowledge of previous moves you can denote just as much information with 10bits. without computing all possible moves every turn. The smallest (bytewise) turn in PGN would be something like...

     1. e4 e5

Which is 9 bytes (including the trailing whitespace)

While the largest (bytewise) turn possible would be something like...
        
     39. Nxf7 Rxe1+

which is 14 bytes (counting the trailing whitespace)

So we are looking at 9 to 14 bytes per move...

4GBs of games in PGN would be about 6,956,000 games. 
4GBs of 15 turn openings in PGN would be about 8,000,000 openings

 I will now only play with the most illogical moves, when I win I shall mention you in my award ceremony as a new Grand Master. It's a little bit the same with Rubix Cubes. (Or any orientation puzzle). There, xx^xx huge number of possible combinations of pieces and positions and orientations that can happen. But given the number of solving algorithms in even the most advanced quick solve methods is less than 100, it's pretty much the same all around. I feel like Chess is the same thing, in a slight way. You may have a huge number of possible positions involving pawns, and number of pawns on the bored, but the truth is that you're often seeing something much more simple like, "Queen within range of take, non-parallel piece move to shadow block." Which piece is shadow blocking once the pawn moves? Rarely matters, bishop/knight, doesn't matter, it can't move that direction. Rubix cubes has been completely solved on a computer. Many of the possible positions are isomorphic to others, which narrows it down.

The fact that chess *hasn't* been solved (yes, computers are better than people, but we still don't know whether white or black or neither has the advantage in a perfect game), shows that it's more complicated than Rubix cubes. Still, before the bound was proven at 20, there always existed a slightly higher upper bound (which reduced over the years). [This](http://www.cube20.org) site has a nice table with the history.    

I think the differences are more considerable in terms of one being a 2 player game and one being a permutation puzzle. I don't think that the fact that chess hasn't being solved makes it more complicated. I do think that the bounds on the number of states/variable nature of moves do make it so though. Rubik's Cubes (named after Erno Rubik) typically find a lot of their permutations from scrambles as well as the patterns of solution, but they're moved through so quickly that they're not usually worth noting. Late 90s - 2000s Bobby Fischer was simply a raving lunatic. You can't place much weight on his statements about chess, they stem more from his perceived slights during his career decades earlier or more recently after his 1992 match than from any objective basis.

And Magnus Carlsen basically proved him wrong by becoming the clear best player in the world while having significantly worse opening preparation than his peers. [deleted] [deleted] [deleted] and if you want to see how big that number is,

&gt;100 000 000 000 000 000 000 000 000 000 000 000 000 000 000 Oh thank you for clearing that up, I was very confused as to how it could be so low.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Thanks for that. I assume it's also 10 ^ 105 then? No, that's 10 ^ 10 ^ 5. Why did you input it that way instead of 10 ^ 100000? Just wondering if there's a standard notation here. I am not sure the exact reason in this case because I haven't read about chess, but that notation is used sometime to show ordering.  Like there ar 10^5 ways to order something and then 10^10^5 ways to order those groupings.  It better illuminates what exactly you are counting.  
 Repeated exponentiation (towers) will be used if the exponent itself is too large to compactly display.  The potential typo version (10 ^ 10 ^ 50) would be one of those.

So, 100000 is "ok", but its right at the edge of us being able to quickly visually parse.  (is it five zeros or six?) 10 ^ 10 ^ 5 is more "communicatively precise". *

Sidenote, there was a great post here a few months ago about we count and how visual and cognitive limits create a little balance-- long story short: we can kind of count a maximum of about 4-5 objects at a glance.  

\* if you assume your audience performs exponent towers top down-- which is standard, but towers are not the most familiar objects to the public. [deleted] [deleted] [deleted] Thanks, I figured it must be something like that. To put 10^10^5 into perspective: 

There are 10^80 protons in the Universe. Now imagine inside each proton, we had a whole entire Universe. Now imagine again that inside each proton inside each Universe inside each proton, you had another Universe. If you count up all the protons, you get (10^80 )^3 = 10^240, which is nowhere near the number we're looking for. 

You have to have Universes inside protons all the way down to **1250 steps** to get the number of legal chess games that are estimated to exist.  Man those numbers make my headspin. Graham's number is something else thats just mindbogglingly large. This doesn't even come anywhere close to Graham's number, that one too large to even write down in exponential notation!  You don't even have to leave the first level of Graham's number (g1) to unceremoniously crush the total number of possible chess games. You might like Knuths up-arrow notation, which can be used to notate numbers that are much much bigger. Short summary: 3  3 is 3^3, 3  2 is 3^3, 3  3 is 3^3^3, 3  3 is 3^3^3^...^3^3 with 3^3^3 copies of three. And so on.
http://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation Check this out about Graham's number. Takes the time to put it into perspective and still impossible to even begin to think about. 
http://waitbutwhy.com/2014/11/1000000-grahams-number.html If we had all the processing power in the world working on solving chess, I wonder how long it would take to exhaust all possibilities or to find a perfect strategy. Imagine that every single subatomic particle in the entire observable universe was a supercomputer that analysed a possible game in a single Planck unit of time (10^-43 seconds, the time it takes light in a vacuum to travel 10^-20 times the width of a proton), and that every single subatomic particle computer was running from the beginning of time up until the heat death of the Universe, 10^1000 years  10^11  10^1000 seconds from now. 

Even in these ridiculously favorable conditions, we'd only be able to calculate 

10^80  10^43  10^11  10^1000 = 10^1134

possible games. Again, this doesn't even come close to 10^10^5 = 10^100000 . 

Basically, if we ever solve the game of chess, it definitely won't be through brute force. 

Edit: corrected a number  Additionally, the future of chess seems to be longer games, which push further away from opening theory and into more unexplored territory.  For example, Magnus Carlsen has won many games that appeared to be "equal," and recently played the second-longest ever game in a world championship match (122 moves).  Players who want to compete at high level will be unsatisfied with quick draws, and that means more moves per game, which means more permutations possible.   I'm not sure if this is a general trend or just Carlsen. He has a particular ability to grind out wins late in those equal positions that many would accept as draws. yes lol, that's just Carlsen. He is famous for grinding out drawn endgames. He loves the Berlin defense and other offbeat openings. Like he played the Qd8 Scandinavian Defense against Caruana and won. That 122 move game was a draw and the last 50 or so moves didn't even need to happen and did receive some small criticism for it.  I do agree with you that games will be getting longer on average but that was a bad example of your point.

To add, I don't care if the game is 200 moves as long as the game is played the way a player wants to play it. [deleted] It strikes me as a funny thing to use Wolfram Alpha to confirm that 100000 - 80 = 99920. Eh, to be fair, it's really really easy to see how you could miss that it's actually simple math.

Someone might not see 10^10^5 as 10^100,000. And even then, they might not remember off the top of their head that you subtract exponents when you divide them.

I bet he just literally calculated 10^10^5, and then divided it by literally calculated 10^80, and the calculator spit out 10^99920.

I had to stop and think, "why is it 100,000-80? Oh yeah because those are the exponents, and when you divide those you subtract the exponent", so I can see how someone else would do the same! Yeah...

It also strikes me as funny to use 10^10^5 when you can just write 10^100000 Just to note, that is the number of protons in the observable universe, not the entire universe. For all we know there could be infinite protons in the entire universe.  Curious: Where does that 10^80 estimation come from? How do we even estimate that? Such a good answer.

Just to add one, it's very obvious that the word "infinite" can not possibly apply to Chess. We have a set number of possible moves each turn, which means there are a set number of games possible. There is a very large difference between a real, finite number, and infinity.

***Edit:*** So, let me be clear. My wording was poor. Having a set number of possible moves each turn only means there are a set number of games ***because chess has a finite end point***. Obviously, draws should be taken any time they occur, or else the answer to this question is "just move your kings around forever, never winning. answer : infinite possible games". In chess this happens either A) after the same move is repeated 3 times, or B) after 50 moves have been made with no pawns moved/pieces captured.

Also, note, just because there is an enormous amount of games possible, that doesn't mean no two games have been the same. Actually quite the contrary, due to the nature of chess it's *very* likely that two identical games have been played. Couldn't a game technically go on forever if someone kept checking and moving out of it? These are still legal moves and novice players do tend to take a long time to actually get to check-mate. 50 move rule and three fold repetition exists to prevent an infinite number of moves. In the official rules, no, for a few reasons. First is the fifty move rule, which states if there have been fifty moves without a pawn move or a capture (and probably castling, although I don't know for sure), then the game is drawn.

Second is the three-fold repetition rule, which is often misinterpreted to mean if you and your opponent do the same move three times in a row, you draw. The actual rule is that if the same position appears on a board three times, the game is drawn. The difference is subtle, but basically if you move all your pieces on the board and then come back to the exact same setup (nothing different in terms of pawns or castling rights), that counts as a second time. Do it again, and the game is drawn.

The wrench in this is that a draw must be claimed, so if neither opponent claims the draws here, they can move forever. But then we're getting kind of theoretical because yeah, both opponents can move their knights back and forth forever without claiming a draw, but it's not really in the spirit of chess. Tournament conditions usually include that the arbiter may declare a game drawn even if neither player claims it. 

[FIDE regulations](http://www.fide.com/fide/handbook.html?id=171&amp;view=article) now include that the game is drawn (without a player having to claim it) if repetition occurs 5 times, or 75 moves without a capture or pawn move.
 Not much of a chess player, so the three-fold repetition is an interesting concept.  In Go, you are not allowed to repeat a position (same pattern of stones on the board).  As long as Komi is non-integer, then every game can eventually result in a winner &amp; loser. &gt;  We have a set number of possible moves each turn, which means there are a set number of games possible.

Let's play a simpler game called the red-black game. On each turn, you say either "red" or "black", and I do the same. We carry on until we get bored. **Edit** Let's further assume that neither of us has infinite patience, and so we both get bored after some finite, but unbounded, number of moves.

At each point in the red-black game there are only finitely many moves available, and all plays are of finite length. Nonetheless, the set of possible games is isomorphic to the set of finite binary strings, which is isomorphic to the set of [dyadic rationals](http://en.wikipedia.org/wiki/Dyadic_rational), and it's fairly easy to see that those sets are [countably infinite](http://en.wikipedia.org/wiki/Countable_set).

**Edit** or one could flip the binary string about the decimal point, and interpret binary strings as natural numbers expressed in binary. That set is *obviously* countably infinite :-)

You may enjoy thinking about the related [Hypergame paradox](http://www.math.cornell.edu/~mec/2006-2007/Games/hypergame.html) :-) I understand this thought process, but the only reason for this is that there's no end condition to the "red-black" game. The game is made to be infinite in the first place.

Chess has a clear ending, if you follow each decision tree for ever possible game, it will either end in A) a stalemate, B) a draw decision, or C) checkmate.

If you ignore draw decisions or stalemates, you could chop the games off after a certain point and just claim them as "finished", because checkmate is no longer possible, and the game would go on forever. It's a certainty that two games have been played if you count things like the [two-move checkmate](http://en.wikipedia.org/wiki/Fool%27s_mate) I mean, technically, it is infinite. Say the players just moved their queens back and forth between two positions for a good portion of the game. They could do that anywhere from 1 to an infinite number of times and then finish the game. (10^10 )^5 = 10^50

10^(10^5) = 10^100,000

No. of atoms in the universe ~10^80

Thus there are 10^100,000 / (10^80 ) = 10^99920 times more legal chess games than atoms in the universe.

Edit: The word *times* Actually, this is the ratio of chess games to atoms, not the difference, which is perhaps even more impressive. ( 10^100000 - 10^80 ) = 10^80 ( 10^99920 - 1 ) = 99919 9s followed by 80 0s. &gt; The largest commercial chess databases contain a handful of millions of games.

So would that mean that any game you played has a high chance of having been played already and is recorded somewhere?  In chess, there's a moment when a game deviates (if it ever does) from a well known sequences of moves each player has memorized. They call this going "off book".

[radiolab](http://www.radiolab.org/story/153799-games/) Somewhere between non-zero and 100%, yes.  Most "average" players play chess in a very predictable, statistically significant pattern, even down to their blunders. E.g., out of 20 opening moves, only 3-4 are consistently seen amongst Master players (E4, D4, C4, Nf3, etc.).  Only 2-3 are consistently seen amongst rank amateurs (E4, D4, Nf3).  Out of so many second possible moves, only a small percentage are usually seen, etc.  My Math is absolutely atrocious. I'm kind of ashamed to ask this, but what does this: 4^250  10^60 mean? When I do both in a calculator I get different results, so I assume that the  symbol means we are rounding down? It just means approximately equal to. When working with such large numbers quite a bit of leeway can be accepted. Awesome thank you. Not every game will be vastly different, though. There are that many possible combinations of legal positions, however, in your average game, there may be a far more common and repeating sequence of positions. Look at a deck of cards for example: All the cards in a 52 deck can be arranged in 80,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000 (roughly) different ways. Meaning every time you shuffle the deck you are statistically likely to have a new combination that has never existed before? No. Because when you open the deck new, it's all in order. Chances are that first shuffle on a new deck has been repeated plenty of times, and after that still, plenty of times, and after that still. Same with chess, every game will start with the pieces in the same spot, meaning that it's rare that a position has never been done before, given the amount of chess games played. I'd argue that the number of games is actually infinite. Suppose two people just move their knights back and forth for n-moves then play the game as normal.  Its sort of trivial, so I wonder if your numbers had some constraints that would rule this scenario out. Actually, according to the [rule of Threefold Repetition](http://en.wikipedia.org/wiki/Threefold_repetition), that ~~would~~ could just result in a draw if it happened three times. So it wouldn't have any real impact on the number of ~~legal~~ logical games. The game does not automatically draw though, it only provides both players with the *opportunity* to claim a draw. It's the same with the 50-move rule. In most cases, one of the players will of course claim that draw, but technically, it could go on forever.  I think it's reasonable to not include games involving forced repetition beyond the apparently non-mandatory limit in the total count of possible games, because they are not *interesting*.  No useful analysis can come from comparing two games otherwise identical, except in game A the same two moves were repeated 76 times and in game B those moves were repeated 78 times.  Chess is a game of perfect information and zero chance.  Strategies are defined solely by the current board state, not by any history of the moves.  How many repetitions it took you to reach the same state is thus irrelevant, and thus the two games that differ only by a different # of repetitions across the same states are not different games in any meaningful analytical sense. It seems like one could actually simplify the answer to OP's question by taking advantage of this to start with all the possible *ending* (checkmate/stalemate) configurations, eliminating those that are duplicate for any given board rotation, and eliminating those that are duplicate for king-side/queen-side knights and rooks.

Possibly even more opportunities for elimination due to pawn promotion "reviving" king-side/queen-side pieces.

Once all the possible ending configurations are defined, then you could just play the games backward in the most efficient manner possible and *voil*. Totally different and unique games could and do result in the exact same ""ending (checkmate/stalemate) configurations"" so eliminating those is not going to work. 

Probably due to the movement of the pieces, which apart from the pawn (sans promotion) have a reversible and infinite continuum possible. &gt; It seems like one could actually simplify the answer to OP's question by taking advantage of this to start with all the possible ending (checkmate/stalemate) configurations [...] Once all the possible ending configurations are defined, then you could just play the games backward in the most efficient manner possible and voil.

That's how [endgame tablebases](http://en.wikipedia.org/wiki/Endgame_tablebase) work.  They're up to seven pieces so far.  

The problem with generalizing this is that there are too many possible ending positions. I was not aware. So just to verify, if the Rule of Threefold Repetition occurred, either player can force a draw, without the need for the opponent's approval?  Yes, but to be pedantic, when the same position appears for the third time, either player may unilaterally "claim" a draw. "Force" has a slightly different meaning in chess.  Does it have to be 3 times in a row? What if you did the same move twice. Moved something else and then back to the original twice? Seems like this could be a good strategy to give yourself move time to think of your next "real" move. No it doesn't have to be in a row. If the same board state appears for a third time in a particular game, any player may declare the game a draw. No, actually. Though it doesn't happen often. The rule is if the exact position is repeated 3 times, a draw can be claimed. Which means casting rights, en passant rights etc must also be the same Another detail here is that a player can only claim a draw when it is his turn to move.

If the current position has not occurred 3 times, and your move would produce a position that has occurred 3 times, and you want to claim the draw, you have to announce your intention to make the move and call the arbiter over .

The reason for this is that it's disruptive to the opponent to offer them a draw while they are thinking about their move; when it was legal people could do it as a time-pressure tactic.
 Either player can "claim" the draw, not "force" it. In chess "force" means you've left the opponent only a single (usually bad) legal move. If the opponent protests the claim, the tournament director (or arbiter if it's a professional match) will then examine the move sheets to determine if the claim is correct or not. There are various penalties possible for incorrect claims depending on the time limits of the particular game. 

Which is why keeping an accurate score is a requirement in the game.  And the Rule of Threefold Repetition is slightly different in online games. For example on chess.com and chessfriends.com it is automatically a draw.   If there is a finite number of board positions, and a finite number of times that they can be repeated, then the number of possible games must also be finite. He's suggesting the games would be infinite since you could move around back and forth. But that's kind of irrelevant. Were more interested in the number of positions, which is definitely finite, as you said. &gt; Were more interested in the number of positions, which is definitely finite, as you said.

Actually OP was interested in the number of *games* (i.e. sequences of positions). True, though the bound you get from that is far, far greater than the one you get from the fifty move rule. If they only did it twice at a time, but at many points through the game, they're still legal moves. I think you might have the same misunderstanding of the repetition rule as I had before reading the link from FirebertNY.

According to the rule, it does not matter whether the position was repeated three times consecutively or whether they were spread over the course of the game. The rule is that if the pieces on the board are ever in the same position as they were on at least two previous other points in time, then a draw can be invoked. Not only must the pieces be in the same position, but the same game options must be present -- so for example, neither side could have lost a right to castle or capture en passant. That's a nuance that is also often overlooked. And because of that nuance, there are a whole class of positions which are by definition non-repeatable.  That's true for the number of legal games, but if we're answering OP's bonus question of number of *logical* games, that wouldn't really come into account. Logical is gonna be sort of arbitrary though, isn't it? True, I suppose forcing the game into repeating the same position three times could be considered logical if your end goal is to force a draw for whatever reason. If the other player has no better move than to continuously repeat his own move as well, then the game is destined for a draw anyway. It is sort of arbitrary although a working definition for this question would be "A move that advances the game in ones favor" EDIT: So a repetition would not be considered logical if it isn't in the person's favor to do so.   That might affect whether the # of games are considered infinite or not, but it would not affect whether or not the game of chess is "solvable".  Any series of moves that leads you back to a position that you previously were in would be written off as meaningless to the solvability question.

If chess is solvable, then some computer in the future could create a system for always winning  or always drawing. If no piece was captured and no pawn was moved in 50 moves, the game is officially a draw No, under these conditions one of the players may CLAIM a draw, but it is not automatically a draw. Yes, but under the proposed situation, there is no reason not to draw.

It also falls under the three fold draw.
 Plus, if you look at it logically, if two players move back and forth from the same positions with any sort of loop, it cuts the loop out of the actual gameplay, acting for all intents and purposes as if they never played those moves. This would be enough to make them finite again. Would be cool to pre-calculate all the possible chess moves in a tree-like data structure, so that a computer can win just by traversing that tree. We need those Yotta Byte harddrives asap. Top answer says there are about 10^43 legal positions. So just to enumerate those (1 bit per position) you would need storage of 10^18 yottabytes. And for actual tree structure you would need quite some more bits per position. Plus the time to populate all that... Might take a while!  How could you store each position in 1 bit? I believe you would need 6 bits to account for all 64 possibilities on the board.  Even that wouldn't be enough. There are 12 unique pieces, so each square needs 4 bits to determine which piece is on which square. There may be a better system that slightly reduces this number. Technically you would also need a counter that keeps track of how long it's been since the last capture or pawn advancement. And 4 bits to keep track of whether a player can castle. And maybe 4 bits(maybe less) to say whether en-passant is available.

 &gt; so each square needs 4 bits to determine which piece is on which square.

That's not really true, there's far more empty squares than pieces, so you would store it by where pieces are rather than a grid of all the squares.

A trivial solution would be to go row by row, indicating the type and column of a piece in that row, then a break marker to show we go to the next row.

That would need 4 bits for the piece type + 3 bits for the column number for each piece = ~ 224 bits for a full board, add in little extras for denoting a castle/enpassent type rules, in addition tot he row breaks, and you are looking at about ~256 bits to store a position in the worst case scenario.  When you account for the fact that many positions are going to have much fewer pieces than a full board, and that you could probably make further optimizations, I would estimate 10-20 bytes average / position if you are enumerating every position possible.

EDIT: Oh, and I forgot the possibility of  a 'third dimension' of compression here, where you could easily make positions based on other positions.  Like I could say 'position 237 is exactly like position 236, except I moved this pawn to this spot' and that would significantly reduce storage space.

If you were really hardcore into saving space, you would make an algorithm to reconstruct the board state based solely on the position number, rather than store every possibility.  i.e. create a way that if you feed '32479' into it it comes up with a unique board position that only occurs with that number, and it creates that board position every time you give it that number. Assuming you can use single atom to store a bit of information, there are not enough atoms in our solar system to store all those moves. In fact, there are not enough atoms in the visible universe to store all possible combinations of chess. 

So, the solution is to seriously prune the tree. Which leads to the question which positions do you leave out? And the software tool that helps us answer that question is called a chess engine :D.  &gt; In fact, there are not enough atoms in the visible universe to store all possible combinations of chess. 

I don't think that is actually true. There are 10^80 elementary particles in the universe. That means 10^37 particles per board state. Even discounting that the majority of elementary particles don't form atoms, that should be enough to encode all the information. So technically, it's not infinite? Even technically it's not, since if the same board arrangement comes up for the third time, you can call a draw. The number is finite, but mind-bogglingly high (though not as high as to require [Knuth's up-arrow notation](http://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation)). A question there - the rule that a game is may be ruled a draw if the same arrangement comes up three times, that's only if one of the players call it, right?  If neither player DOES, a game could conceivably go on for ever?  Or am I wrong? Yes, but this trivializes the answer to the problem by allowing infinite loops. For this question to have a meaningful answer one would need to consider a game a draw as long as a draw can be called. Point being, a high enough finite number appears in practical terms identical to an infinite one; In chess, no two games you play are alike, let alone the same...

(unless you're one of those douchebags that just memorize cheap openings and spend your days beating random 12 year olds on the street in six moves) thats just it, the number of true variations is actually pretty small. almost all are derivatives of a core set of a 1000 actual games. Claude Shannon, a famous mathematician and engineer, estimated the game tree complexity of chess which is roughly the number of possible games of chess. The lower bound has been put at 10^111 to 10^123.

Like you already alluded to these numbers don't mean much since we as humans tend to just kind of suck at even grasping numbers this big. So let's go smaller. If grains of sand is what you want then grains of sand is what you get! How many atoms are in a grain of sand? A whole lot, around 10^19 or 10,000,000,000,000,000,000. Now for one major leap. If there are that many atoms in a grain of sand then how many are there in the observable universe? Around 10^80. Full stop. Go back to Shannon's number. It's bigger, way way bigger than the number of atoms in the observable universe. To put this another way if you could create a machine where each atom the machine stored a single node in the game tree of chess - that machine would be larger than the known universe. Specifically about 10,000,000,000,000,000,000,000,000,000,000  or 10^31 times larger.

That number is still way too big to work with. Let's go crazy. There are about 10^6 grains of sand in a standard coffee cup. Let's squish our universe down to the size of an atom. Get enough of these universe-in-an-atom guys and put enough of them together to make a single grain of sand and then enough of these sand made of universe-atoms to fill a coffee cup. So how many of these coffee cups of sand of universe-atoms would it take to fill the size of this chess machine we made where each atom is a single node? The size of one of our rather dense cups is 10^80 * 10^19 * 10^6 = 10^105. The game tree complexity of chess has a lower bound at 10^111. So now we can finally start approaching this. It'd take a million (or 10^6) of these cups of sand of universe-in-an-atoms to finally fill up our chess machine. So yeah, it's pretty fair to say that the number of chess games is effectively infinite. These analogies were awesome, thank you. But why is there so much sand in one standard cup of coffee? It was a windy day at the beach? Thanks for a great response  Just for fun, let's do the Shannon calculation.  The absolute basic, highest possible estimate of the total number of permutations says that the board is an 8x8 grid and each piece can occupy any of those 64 spots on the board.  There are 32 pieces, occupying 64 candidate spots, so the answer'd be:

* 64^32 = 6.3 * 10^57 possible game states.

Now, this is wrong, for a great many reasons, not the least of which is that it treats every piece as distinct, so pawn A occupying e4 and pawn B occupying f4 is treated differently from A &amp; B occupying f4 and e4, respectively.  It also allows for pieces to occupy positions that is impossible, like a pawn on the first rank or a "black" bishop on a white square.  It also fails to account for squares being occupied: You can't have two pieces at the same location.

If we *only* eliminate the taking-up-the-same-square error we get:

* 64! / 32! = 4.8 * 10^53 possible game states.

But we can do better.  The total number of game states for one side can be modeled this way:

* T = A^K * A^Q * A^N * A^R * A^B * A^P

...where A^K is the total number of candidate positions for the King, A^Q for the Queen, etc...

* A^K = 64
* A^Q = 63
* A^N = ( 62*61 )/2
* A^R = ( 60*59 )/2
* A^B = ( 29 * 29 )
* A^P = ( 56 * 55 * 54 * 53 * 52 * 51 * 50 * 49 )/8!

Note, it really doesn't matter whether I allocate the King's spot or the Queen's spot first.  There'll be a 64 term in there for the first piece you allocate.  There'll be a 63 in there for the second.  That's the total number of states for one side of the board.  We can calculate the other side, roughly the same way, just starting at 48 available spots instead of 64.

* T^w = 1.612 * 10^22
* T^b = 7.491 * 10^19

* T^0 = 1.20 * 10^42

But we can still do better, because we are only considering the states where all 32 pieces are still on the board!  What happens when there are 31 pieces on the board, and one is missing?  Well, we can do the calculation 31 more times, but that's a daunting task, and we can probably make a simplification.  We can note that taking a single piece away reduces the number of permutations by a factor of 32 (the last piece we place adds 32 permutations).  We can also note that there are 32 differerent pieces we can take away at that point.  That means the number of states with 31 pieces on the board is roughly equal to the number of states with 32 pieces on the board.

It does get more complicated, though.  For 30 pieces we reduce the number of permutations by 33 * 32, while we multiply that by the number of pieces that could be removed by 32 * 31.  So for 30 pieces it's the original estimate times 31/33.  For subsequent combinations, it's 31*30/33*34, 31*30*29/33*34*35, etc...

So the new total would be given by:


* T^' = T^0 * ( 1 + 32/32 + (31 * 32)/(32 * 33) + (30 * 31 * 32)/(32 * 33 * 34) + (29 * 30 * 31 * 32)/(32 * 33 * 34 * 35)... )

I plugged this into a computer program, because I can't think of a quick and easy way to calculate it, and I got 6.03, so now our new (and final) estimate is:

* T^' = T^0 * 6.03 = 7.24 * 10^42

Very, very close to the Shannon estimate. Your estimate doesn't take into account that any of the pieces (except the kings) can be off the board. You could include that possibility by increasing the number of possible locations by 1 for every piece except the king.  The extra location would be "off-board". It didn't when you posted, but I've since added that.  The post's been evolving &amp; editing.  It just took me a while to script out the java program to do that calculation.

In case you're curious, this is the output of the program which calculated the sum:

    C:\Users\nunya\Desktop&gt;java SumCalculator
    32 pieces:      1.0
    31 pieces:      1.0
    30 pieces:      0.9393939393939394
    29 pieces:      0.8288770053475937
    28 pieces:      0.6867838044308633
    27 pieces:      0.5341651812240048
    26 pieces:      0.38979621332562514
    25 pieces:      0.2667026722754277
    24 pieces:      0.1709632514586075
    23 pieces:      0.1025779508751645
    22 pieces:      0.05754372853972643
    21 pieces:      0.03014195304461861
    20 pieces:      0.014720488696209089
    19 pieces:      0.006691131225549585
    18 pieces:      0.002825144295232047
    17 pieces:      0.0011054912459603663
    16 pieces:      3.998585357728985E-4
    15 pieces:      1.3328617859096616E-4
    14 pieces:      4.080189140539781E-5
    13 pieces:      1.1424529593511387E-5
    12 pieces:      2.9121349944244712E-6
    11 pieces:      6.720311525594933E-7
    10 pieces:      1.3947816373876277E-7
    9 pieces:       2.5829289581252364E-8
    8 pieces:       4.22661102238675E-9
    7 pieces:       6.038015746266786E-10
    6 pieces:       7.41510705681886E-11
    5 pieces:       7.670800403605717E-12
    4 pieces:       6.500678308140437E-13
    3 pieces:       4.3337855387602915E-14
    2 pieces:       2.1313699370952254E-15
    1 pieces:       6.875386893855566E-17
    
    Total:  6.032877080900416
 And if there are promoted pawns? For the most part, it's implicitly accounted for by just pretending that the point *wasn't* promoted.  There's very little difference in a position where there's a pawn on, say, e8 (promoted) and then moved back to, say, e4, and the pawn *just being a pawn* on e4.  This is why I **didn't** disqualify first-rank pawns, which is obviously impossible unless they've been promoted to a Queen.  (*Yeah, that's the ticket!*)

There are some very small differences, since now the number of fungible pieces change.  Now there are two Queens (and no difference if their positions exchange), and seven or less pawns (and no difference, etc...).  Oh, and occasionally someone will underpromote to a knight, usually in cases where it leads to an immediate win. Anything combinatorial gets really big really fast. The interesting thing for me is actually how SMALL chess really is. Lets use the 10^42 number people are throwing around.

10^42 &lt; ( 2^4 )^42 therefore 10^42 &lt; 2^168

An RGB pixel on your monitor can display 2^24 colors. If we line up 7 pixels in a row, the number of color combinations we can display is ( 2^24 )^7 which is 2^168.


This means we only need seven pixels to enumerate every legal position in chess. That's an interesting analogy. It also kind of adds in that most humans wouldn't be able to differentiate a color from the neighboring color "options." Like [BA3269](http://www.color-hex.com/color/ba3269) would be nearly impossible to tell apart from [B93168](http://www.color-hex.com/color/b93168).  After much tab switching, my question is: are there people who can tell the difference? The quality of your monitor will make a difference in addition to your own visual acuity.

If you're viewing on a TN panel, you might have trouble.  If you're viewing on a properly calibrated IPS monitor in the correct light settings, not so hard. That's kind of my point. If you move a pawn one turn, then a knight the next, or you move a knight one turn then the pawn the next, almost nobody would be able to tell the difference. They would either had to have watched you do it, or looked at the opponents pieces and figure out why you chose your past moves. There's probably a group of people who could demonstrate that given that the display was both precise enough and accurate enough to represent those different colors correctly.

More generally, this concept was termed the [just-noticeable difference (JND)](https://en.wikipedia.org/wiki/Just-noticeable_difference) back when people were first investigating these phenomena. Depending on the specific stimuli, some people will have a much larger JND than others, but they could have a much smaller one on another JND test.

Here's an everyday example: Let's assume someone else has the remote, and they're adjusting the volume on your TV while you make popcorn in an adjacent room. Changing from 12 to 13 doesn't seem to make to much of a difference. Make the jump to 14 and, well, you still can't really tell. Suddenly though, you realize that the TV is loud, and at this point you've discovered your JND. Yup.

Another analogy of that kind was "How many different possible Windows icons exist?"

It used to be 32*32 pixels, with 256 colors each, waaay back in windows 95 days. 1024 pixels with 8 bit each, so 2^(8192).

Unimaginably many. So many that all computers every build by humankind till the end of the universe together will never be able to store all of them.

Nowadays, with 128x128 24bit icons the result is obviously even bigger, but lost a bit of its unexpectedness.
 Depending on which rules you are following chess can be actually, truly infinite if you aren't following any of the rules regarding *stalling*. Since players can alternately move their pieces back and forth between two squares without making any progress that means a game can last forever.

I believe most official rules institute bans on these sorts of things after a certain number of stalling moves but it varies how many are allowed depending on the ruleset.

More interesting would be asking how many moves can be made in *timed* chess matches. These matches have a set amount of time for each player and if that player's time runs out they loose. Common times are 60 seconds, 5 minutes, 20 minutes, etc.

In 60 second games for example, total playtime cannot exceed 2 minutes. If the players are exceedingly fast for every move and each use exactly 1/4 of a second per move the total possible number of moves would be:

120(seconds) x 4(moves a second) = 480 total moves.

According to [this source](http://www.chess.com/chessopedia/view/mathematics-and-chess) most games only last 30-60 moves and the number of possible positions for that many moves is already extremely huge, but the article also mentions how many likely *logical* moves that contains - somewhere between 2 - 4 million. So for 480 total moves the total number of *legal* moves is unreasonably high. The official rule is that the board may not repeat the same position 3 times. If it does, the game is a stalemate.

Playing with a clock also helps games not be infinitely long for people that don't play with this rule. &gt; If it does, the game is a stalemate.

That's just a draw, not a stalemate.

Stalemates are a specific category of draws, when the player whose turn it is doesn't have any legal moves.

edit: grammar Is that a draw? I thought it was a win for who forced the stalemate Nope, that's a draw. You can actually "swindle" half a point out of a losing position by forcing someone to stalemate you. my bad &gt; The official rule is that the board may not repeat the same position 3 times.

As has been mentioned repeatedly elsewhere in the thread, [this isn't true](https://en.wikipedia.org/wiki/Threefold_repetition). The Threefold Repetition rule grants the ability to *claim* a draw. It doesn't 'force' a draw if neither player wants it. Not true as others mentioned - a player could claim a draw at that point but it's not mandatory.

Along similar lines is the 50-move rule. A player can claim a draw if there are 50 rounds of moves (50 moves by each player, or 100 total moves) without either a capture or a pawn move. There are a finite number of static positions, and a game is said to be drawn when the same position is reached three times. It follows that the number of possible chess games is finite. If you relax the "3 times" rule, then the number of games would be infinite, but in a kind of trivial sense (the players would not be making the best moves possible). No finite thing is virtually infinite. Check it out: 

Pick any inconceivably humongous number. Like consider a number so large that if you converted all of the matter in the universe to ink, you still wouldn't have enough ink to write this number down using a font so small you'd need a microscope to read it. A number this large has to exist. Let's call it G. Now notice that there are ridiculously "more" numbers larger than G than there are numbers smaller (in magnitude) . How is that so? Well, there are "only" G non-negative integers smaller than G. But it's easy to produce a number that's more than G bigger than G. You can just look at 3 * G. But then there's also G^2 or G^G or G^G^G. And on and on. 

This means that even if there are so many possible games of chess that it would be impossible for a supercomputer to observe them all within the lifetime of the universe that that number is still not even remotely virtually infinite.  What do you think virtually infinite means?

Because I thought it means "so large it might as well be infinite" Well, 'might as well be infinite' is still not well defined.

My comment wasn't an attempt to argue with anyone, really. Or say that the OP is 'wrong.' It was just an excuse to talk about big numbers and infinity, because I think that's interesting.  His point is "might aswell be infinite" only has meaning on the context of a problem

e.g "i would crack this lock but the combinations are virtually infinite "

i.e relative to the scales of the problem infinity and the actual finite solution are indistinguishable.

OPs question has no "problem" so virtually infinite is a horseshit term in the context op used it.

 Just think of it as the inverse of 'almost continuous.' Where, within some margin or error, the result looks the same as if it were produced from a continuous structure.

So 'virtually infinite' has a free parameter for your level of precision: how big must something be for you to not care if it is an order of magnitude bigger?

Surely, this is not that hard to make well-defined... &gt; No finite thing is virtually infinite.

Yes, but a game with a finite number of pieces and positions can produce an infinite number of games because it has a potentially infinite dimension of time.

Take a board with only two kings. Move each of them back and forth forever, without calling for a draw. You've generated a chess game which is an infinite sequence of moves. This theoretical chess game can never be completed because it is a true infinite sequence.

There is, in fact, an infinite number of chess games. Of course it can. I wasn't arguing that chess is finite. That isn't the point I'm making. I'm just saying that things are either finite or infinite. There is no 'almost infinite.' &gt;There is no 'almost infinite.'

While I agree, I think the term is still a useful tool for describing a number. For a number so ludicrously large like G, the difference between it and The Infinite might as well be a distinction without a difference to the average person (not a professional mathematician). The "almost" serves the purpose of preserving the sanctity of the boundlessness of "infinite" yet having the "infinite" implies a number so vast is it beyond any plausible comprehension or usefulness (more digits than molecules in the observable universe or something). Maybe a better term could be "effectively infinite" to convey the pointless massiveness of the number. Sure you probably shouldn't use it in the academic setting, but rather it could save some explanation during a dinner party. This is just a definitional problem. We need to define what we mean by virtually infinite. Since it is trivially true that any finite number is closer to 0 than infinity as you point out, all you've done is define virtually infinite the same as infinite, essentially ignoring the word virtually.  Probably too late to be seen here, but compared to 'go', chess is childs play. Computer have figured out how to play chess REALLY well, but a game like go is much too complicated for a computer at this time. Go is much closer to having infinite possibilities than chess. I had trouble searching for the exact statistics due to the game's name but each game is basically a snowflake. It's very unlikely that that exact game has been played before.  The [Go and Mathematics](https://en.wikipedia.org/wiki/Go_and_mathematics) wiki entry has a lot of info on amount of legal positions and game tree complexity, around 10^170 legal positions and something like 10^300 to 10^800 for number of possible games on a regular 19x19 board.

And interesting side effect of this is that go is a lot less about memorization (as per the comment about chess by Fischer mentioned earlier in the thread) and more about extrapolating from subsets of the board to the whole board and intuition (in the sense that there's rarely any 1 perfect move but rather some good and a lot of bad moves to chose from, with no clear cut way to select which good move to play), and it's quite hard to consider all likely moves and counter moves ahead of time.

On a side note, one of the nice features of go is the handicap system, which allows  players with different skill levels to still have challenging games, which is something I quite like. &gt; Probably too late to be seen here, but compared to 'go', chess is childs play. 

I understand where you are coming from, but from a human standpoint, this is meaningless.  No human mind will ever "solve" chess or go.  So, to a zeroth approximation, they are equally complex.

I think the thing that differentiates go from chess is the fact that in go, you are not attempting to destroy your opponent, as you are almost forced to in chess.  The best go strategy is to let your opponent live, just a little smaller than you.

Your best strategy in chess is to weaken your opponent, and then crush him.

I am doing a poor job explaining this, but to me the games feel different.  One is not better or harder than the other -- but the approach to success is different. I hope it didn't seem like I was implying Go is better, just that the number of unique games vastly outnumbers the unique chess games (and also because many people put the two games in a similar 1v1 strategy board game group together). Partly because of the lack of a standard board size, you can place a piece anywhere on the board, there are more spaces, etc. So if OP is trying to comprehend infinite possibilities in a boardgame, Go would be a better place to look.  [deleted] This is what I always argue. In almost all modern RTS games, you have to be aware of your pieces, their positions in relation to themselves, their positions in relation to the enemy, some sort of economic aspect, decision-making in regards to new pieces entering the battlefield, terrain type, landmarks, stationary usable objects, your actual field of view, and a whole other axis (Z) to worry about. Not to mention you have different classes or commanders, which use different unit types, have different abilities, the maps change constantly and you have to worry about many more units. In chess you only have to take into account the first three points.

I think arguing that chess is the most complex game ever is short-sighted and downright asinine. I think it could be argued that games like Starcraft, Company of Heroes or Planetary Annihilation are significantly more complex than chess. I am a titled chess player and have seen Go been played. Attempted to learn it. It's completely mind boggling how intricate this game is. I mean chess is intricate, but go puts the in in intricate. Suggesting that it's infinite is just misunderstanding what infinite means.  There is an absolute finite limit on the arrangement of physical objects.

I'm currently working on the computational side of the rook problem (how many rooks can be placed on any given board, chess or otherwise), and through so many calculations of just putting stuff down, 2^n jumps out a lot.  While exponential growth is pretty serious, there's a hardcap on the number of ways to place things on the board at all.

If you completely discard the rules of chess and just say you have 32 distinct pieces, you can place the first piece on the board in 64 positions, then the next piece in 63 positions.  Since this only carries till the 32 pieces placed, it's 62!/32!

Approximately 4.82x10^53 for an absolute hard cap on the number of arrangements that 36 pieces can make on an 8x8 board.

I wanted to go into more, but I just noticed the time.

It's technically finite, but unreasonably large to achieve. I know it's not relevant, but before visiting reddit I was just working on my chess program, (it's called Sconvolt, nothing good, I just work on it as a hobby), and I was noticing that, to think 7 moves ahead, the program evaluates about 60 million board combinations (depending on current position), in pure alpha-beta-pruning, without any heuristics This will probably be buried under the massive number of comments, but if the number of legal games is higher than the number of subatomic particles in the universe, then does that mean that chess is impossible to solve? I mean, even quantum computing essentially uses subatomic particles to mark bits, so even if you made a computer as big as the observable universe, the number of bits generated from that still wouldn't be enough to map all of the possible games of chess, even while assuming that each game took exactly one bit to store. Or am i making a wrong assumption? Former mediocre tournament chess player here.

In theory, yes. But in reality, there are only a few opening moves that are not clearly disadvantageous. So, we limit our analysis to White's rational opening moves like E4, D4, C4, Nf3, etc and Black's best responses to those openings.

Expert play tends to revolve around certain opening patterns, because these are generally agreed to be the best openings for both sides. So, at the Grandmaster level, the Sicilian opening gets played a lot, while the King's Gambit (popular in the 1800s) is much less common.

For that reason, I would say the number of reasonable positions is much smaller. How can popularity of chess moves change over time? Maybe because statistics that were not around back then show certain moves to be successful more often? Because perfect play has not been discovered, so improvements are constantly being made.  An interesting contrast to [boxing](https://en.wikipedia.org/wiki/Boxing#Stance), where changes in the rules (the introduction of gloves) were the impetus for a [change](https://en.wikipedia.org/wiki/File:Cribb_vs_Molineaux_1811.jpg) in [technique](https://en.wikipedia.org/wiki/File:Attitude_semi-enroul%C3%A9e1.jpg). To add to what others have said, it's an odd combination of certain lines being known at the time to be advantageous to one side, and fashion. 

Kasparov stopped playing the King's Indian after losing some games in it to Kramnik, and even players at a low enough level that their games weren't really affected by cutting-edge knowledge of world-class players stopped playing it, because hey, if Kasparov doesn't believe in it, obviously it's no good. See also Fischer damaging the reputation of the Sicilian Dragon and so forth. Basically, yes. The King's Gambit was common in that era, as it favored attacking. Later in the 1800s, Steinitz started to innovate with some very effective defensive positions. He showed that by effectively defending against an unsound attack, you could set up a counterattack.

http://en.wikipedia.org/wiki/Wilhelm_Steinitz

Later, the Sicilian became the more common opening when a number of Grandmasters used it effectively to create counterattacking chances for Black. Yes.  Also, Grandmasters analyze chess games and sometimes come up with a variation that is actually so good to counter a line that the line no longer gets played.

Now that computers are better than humans at chess, most Grandmasters use computers to come up with opening lines and counters.  Computers sometimes come up with lines that aren't necessarily intuitively correct at first, but prove advantageous over the course of the game.

I used to play chess as a kid (never competitively) and recently tried getting back into it after many many years.  I've started watching chess videos on Youtube.  There are a lot of videos analyzing famous games that are available to watch and most of the time, the person analyzing the game also runs a chess engine to help him with the analysis. Even with that, it's still going to be a huge number. Figure if games lasted an average of 40 moves, that's 80 total moves - even if there were say 4 good moves to choose from each time, that's 4^80 combinations. On a basic level, infinite implies that there can not be a maximum number to the variations in a game.
Any game of this nature has a finite number of moves, responses and outcomes.
The number of possible moves, games and outcomes may be huge but it CANNOT be infinite

The rules are set, there are only a finite possible moves

EDIT: the only way it can be infinite is if you have an infinite number of moves for the first move. This is not the case 
&gt;
Bonus question:
As there are many legal moves in a game of chess but often only a small set that are logical, is there a way to determine how many of these games are probable?

This right here is arguably the important part. Other people have already discussed how many moves are possible, however the vast majority of possible moves will be tactically unsound. The challenging problem is eliminating these worthless alternatives without computationally exploring them, while not accidentally eliminating valid possibilities. 

I don't have experience with chess, but my company just finished an optimization program of something relatively simple in comparison - choosing the mix of 12 possible options, every year, on 20 products, over 10 years. You have to develop methods to try and eliminate obviously bad solutions without removing tactically valid ones - back to chess you may want to leave yourself "open" as it may be a trap for your opponent - the same is true with my product mix problem - it may be better to lose money on one product if it means you can make more money somewhere else. 

While the laws of physics don't expressly prohibit "solving" problems like this by exploring every possible solution, and knowing what's the "optimal" decision from every possible scenario, it's realistically impossible to ever computer the possibilities. This is different from a game like tick tack toe, which is solved, and thus there's an "ideal response" to every situation.  &gt;virtually infinite.

A complete nonsense term in this context, infinity is infinitely larger than something finite.

so when discussing if something is infinite or finite, "virtually infinite" is a nonsense term that is actually wrong I would read virtually infinite in this question to mean "from a human perspective". sure, virtually infinite is nonsense mathematically, but practically, a number as large as possible chess games is pretty much unreachable. human kind will never play anywhere close to all the possible chess games even if thats all humans did all the time.  What I would like to know is whether they are getting any closer to defining what a "perfect" game looks like.. As in, both sides playing perfectly, and what the result would be... Anyone have any ideas or doubts as to whether this "most logical" game can be determined now or in the future??? [deleted] [deleted] [deleted] While "virtually" infinite is a fair characterization, the game is not infinite. If there are 50 moves in a row without a piece being captured or a pawn being moved, the game ends in a draw. Because pawns have a limited number of moves, and there are a limited number of pieces that can be eliminated before the game ends in a draw because there is insufficient material for a checkmate.

If I have counted correctly, there most possible legal pawn moves is 88 (it is less than 6 for each pawn because they have to get past each other, but one pawn being taken another after moving 4 lets another 3 move all the way to promotion).

Then there are 26 pieces that can be captured (4 pawns had to go without extending the turn count to pawn captures, and the kings stay on the board). Then there are 49 filler moves in between each one.

So the largest number of moves possible in a game of Chess is 48*50, or 2400.

where things get really nasty is with the number of legal moves on any given turn. And this number is going to go up at first, as space opens up and pawns promote to queens (which have more options for how to move). There are a number of ways to calculate the upper bound on the number of moves, you could look at the maximum number of pieces able to move to each tile (16 * 64 squares (edge tiles have fewer options), which gives 1024 as an upper bound, you could calculate the number of moves each piece could make on a clear bard with ideal positioning (27*9 queens + 14 * 2 rooks + 13 * 2 bishops + 8 * 2 knights + 8 * 1 king), which gives 321 as a bound.

By this method, we can show that there are no more than 321^2400 or 4.1 * 10 ^ 6015 legal chess games. We know there are less, because not all pieces can be simultaneously placed in the positions with the most available squares to move to, and some squares will be blocked by other pieces, and some of the moves result in checkmate or stalemate, and some take pieces more rapidly than once every 50 moves.

Looking at games that a decent player would actually play is interesting, and can be done with chess databases. We can get a set of a bunch of games, and see how frequently each first move was played, and how frequently each second move was played, etc. Within the games stored, we can calculate which partial games are most common for a given number of moves.

We can also compare the number of games recorded to our 4.1 * 10 ^6015 figure. Computer scientist here.  The top AI for solving chess look something like 14 moves ahead.  So all posSibley places you could move in the game.  Then all possible  place I could  move for each of those moves.  The tree expanses very fast.  The predition is done assume the enemy is using the same method.  This can all be done using things like alpha beta pruning with heristica.  A harder gave to solve is the game GO 14? My laptop running stockfish can go 30 moves deep usually fairly quickly. Where did you see 14? Depth 30 means 30 half-moves (i.e. 15 moves) which is in line with Missionmojo's answer You're correct about half-moves, but even still SF in TCEC gets over 45 half moves regularly even so. Yes thank you for that No, it can go thirty ply or fifteen turns. People use "turn" and "move" interchangeably, obviously he meant turn. Well technically a half move is one ply, but I get what you mean. In any case 14 is too low. How does it choose which move to make? We can count the number of possible board states, given that there are a finite number of spaces on the board and a finite number of possible pieces on the board.  Lets call the set of possible board states S.

Due to the rule of 3-fold repetition, we know that each state may be used at most twice without resulting in a draw.

Therefore we can find a finite upper bound to the possible number of states that can be used in the game: 2S.

We can find a finite upper bound on the possible number of games that exist by calculating every possible ordering of the set of all board states: 2S! .

Therefore, while the number of possible games is extremely large and difficult to calculate, we can see that it does in fact have a finite upper bound as is not infinite. I can do better than that. To solve chess perfectly you don't have to know about all possible games. You only have to know the optimal move for every board configuration. Which brings the complexity down to S, which is still astronomical, but way better than 2S! There are definitely not infinite games.

Chess includes drawing rules where if the same position is repeated 3 times, or, if 50 moves pass and a piece is not captured and a pawn is not moved, then the game ends in a draw. Combined, those two rules completely rule out any infinite loops in the game and every game will definitely end.

You can proceed to make a naive upper limit on the number of possible games (use some factorials and just casually toss exponents in) and come out with a definitely finite number.

The phrase "virtually infinite" is awfully imprecise and people really just ought to say "too large to fully comprehend". But to answer your question something like 10^100000 is a good estimate of the number of possible chess game. It looks like this [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] It should be noted that the number of realistic chess game outcomes is substantially lower. In order to get a number of that magnitude, you have to include gobs of strategically awful moves that not even a beginner player would make. It depends on the humidity of the indoor room. If the indoor room is small and not ventilated, the moisture from the drying clothes will quickly raise the humidity of the room to the point that is significantly slows down the drying of the clothes. If you place a large dehumidifier in the small, ventilated room, or if you give it good ventilation (open some windows) it will keep humidity low and keep the drying time short.  It also depends on the humidity out doors as well.  I had friends in the Costa Rican rain forest that claimed that hanging clothes to dry outdoors simply didn't work.  The humidity caused them to stay damp.

As a person who lives in a dry, near desert climate, drying indoors is a win/win situation, as the clothes dry quite quickly and I don't have to run my humidifier as hard when I am drying clothes indoors. [deleted] [deleted] [deleted] [deleted] [deleted] The type of fabric is a major factor too as I have easily dried my travel clothing in a rainforest after they were soaking wet.

Most people are using cotton which is lousy at drying compared to some of the modern tech fabrics.  I have a travel tech shirt I can wash in a sink, hang up indoors, in within a few hours it is dry.  Meanwhile a non tech shirt that is smaller but not cotton will take overnight in the same conditions. What if they arent traveling?  What should they wear to easily dry their clothes? Uh, the same thing? You don't have to be traveling to wear "travel clothing" [deleted] Polyester holds smells because [the properties that help it wick away the moisture also provide a great location for bacteria to grow](http://singlosport.com/blog/the-reason-synthetic-fabric-smells/).

I have tried just about everything to get rid of the smells but ended up just throwing away the shirt that had it worst. Merino wool is the best compromise, dries fast, wicks, doesn't smell.  Expensive tho. Wool is a very popular fiber for homemade cloth diaper covers because of this. The logic of the fact that wool outdoes synthetics is quite elegant when you consider how many sheep it has successfully clothed for millenia. How does merino function in a warm, humid environment, though? Or even a warm dry (say, desert) environment?

I've seen some merino garments in hiking shops and they were very lightweight, so I'm not imagining a sweater per se, but wool is still wool and wool is warm so is it a problem in the heat? Really well actually.  If you get thin merino shirts they do a great job of keeping you fairly cool and dry, even in the heat.  Obviously thicker wool doesn't work for this, but you can find some nice thin merino base layers that are great for warmer environments. Soak the clothes in cold water and white vinegar for 15 to 30 minutes, then wash as usual (err on the side of less soap, actually--and no fabric softener!!!) until the final rinse. Add a cup of vinegar to the final rinse and dry on low or hang dry. Drying on high heat helps lock those awful smells in, which is the opposite of the goal here.   I stopped using fabric softener a couple of years ago when I realized (after a few tests) that this was what was making my clothes smell. I had changed the detergent, changed the fabric softener, used the dryer instead of the clothesline and disinfected the washing machine a couple of times to no avail. As soon as I stopped using the fabric softener, the problem was gone. I know that it's a bacteria problem, but does fabric softener actually increase the amount of bacteria? It just creates a film between the clothes and detergent that keeps it from getting really clean!  That's part of the reason the vinegar soaking works.  And it's why you do it before and then after your detergent has been washed out--you don't want a barrier there.

I've heard if this happens to your towels and that sort of material that you can actually wash them without detergent on high heat a few times to strip them of this buildup, and then they'll be ready to go again!  

I haven't actually tried it yet and I don't think the method would be safe on regular clothes but the science is sound! If you like the extra softness of fabric softened clothes but hate the expense and resulting odor of in-wash fabric softener... try the dryer sheets kind. Works pretty damn well and is a good compromise. Just don't use it on your towels, they'll pick up water better off of your body if you do *not* use the sheets. I think this would work on most shirts, but didn't work on mine unfortunately :). I also tried the baking soda paste over the area twice but no luck. It was a Coca Cola brand shirt from a few years ago when they were trying to give off an "eco-friendly" vibe by recycling their plastics into clothing. I like to think that's why it held smells so thoroughly. I have that problem with many of my shirts holding residual pit odor, and a few weeks ago (after nearly a decade of trying solutions) hit upon success with 2 parts hydrogen peroxide and 1 part blue Dawn dish detergent rubbed into the problem areas and then laundered. This is a color safe laundry stain treatment and it works well on many stains. Must be mixed fresh each time unless you have a lightproof bottle to prevent the hydrogen peroxide from breaking down. http://www.scientificamerican.com/podcast/episode/synthetic-fabrics-host-more-stench-producing-bacteria/ [deleted] [deleted] What fabric is this 'tech' made of? Anything but cotton, really. Polyester is the most common, but there are quite a few synthetic and semi-synthetic fibers to choose from, and a garment can be made from a blend of different fibers and the shape of the fibers can also be altered to change the feel and other bulk properties. Basically nothing used in clothing is as hard to get dry as cotton. Lightweight Merino wool is probably the best tech fabric.  It dries as well as any synthetic and (very importantly) doesn't build a up a stench they way polyester does.  I've got some Smartwool brand stuff that is the tits.  It's not cheap though. And it's so great at regulating warmth for you. It's warm when you need it to be, but never too warm except on hot summer days. And if it gets wet, it stays warm and doesn't *feel* wet. So much more comfortable than cotton. You never really notice it's there. 

I wear merino wool exclusively every single day from October to April.  It's perfect for cyclists and skiers and other sports where it's cold and you sweat.  [deleted] [deleted] SE Asia here. In a city.  
We hang our clothes outside in the shade. They do dry properly most days. But when it rains, forget it. Your clothes stay damp even when they're covered from rain. [deleted] [deleted] [deleted] [deleted] I just learnt this in hawaii, putting our towels our to dry at night on the patio, and waking up to them super damp! You have a humidifier, is it like a bowl you hang out over the radiator or a more sophisticated machine? Where I am from people have dehumidifiers to prevent mold  I have two humidifiers and they are electric.  Each can pump about a gallon of water into the air every 8 hours.  I don't run them year round, as we have a rainy season in the spring. My humidifier attaches directly to my furnace and I can direct the warm air output through it.  It has a replaceable fiber wick and is fed from a water line run from a nearby water pipe.  In the winter, the air gets very dry and the whole - house humidifier helps keep static down and makes it more comfortable. [deleted] I can definitely confirm this from military experience. Uniforms would dry within hours in the desert but take days in swampy areas, even with similar temperatures and wind conditions. Slept in a costa Rican rain forest once. The bed sheets were damp.  Plus, I was terrified of bugs.  &gt;  I had friends in the Costa Rican rain forest that claimed that hanging clothes to dry outdoors simply didn't work.

You don't have to be that hard core to have this problem.  Here in Boston we have some days during the summer where nothing dries even in the sun. Not sure I've ever heard a near-desert climate called "win-win" before...

Edit: nvm, read that backwards It doesn't work terribly well in Scotland either, not least because it'll probably rain before you need to take your clothes down :-) Unfortunately the excess moisture from drying clothes indoors in the UK's climate [can cause health problems](http://www.bbc.co.uk/news/uk-scotland-20176376). I live very close to the beach (Humidity is v. high)

It takes quite a long time to dry. (7-8 hours minimum) Don't forget about the use of air movement for disrupting the boundary layer around the clothes.  This is imperative if you want quick drying.

OP: this same sort of idea is utilized in convection ovens as well. This doesn't really answer the question though does it? The question is between a breeze and sunlight.  &gt; If you place a large dehumidifier in the small, ventilated room, or if you give it good ventilation (open some windows) it will keep humidity low and keep the drying time short. 

Wait a minute.  Would that be economically feasible?  I know dryers use a ton of electricity but I can't imagine that a large dehumidifier would be very cheap either. I don't think anyone is suggesting this is an optimal strategy or a good idea, just that the humidifier would reduce the drying time of an item hanging in a small humid room.  Only try this if your dryer breaks and you've got an urgent deadline that requires that one wet item. The best driers are condenser driers as they are essentially de-humidifiers that suck the moisture out the air and heat it with the waste heat of the compression process. That's actually makes sense.

 Topic related question: How about if I am trying to iron a wet cloth, it feels like the cloth is drying faster if I iron it for 1 min and then let it cool it off. Is humidity building between iron and the cloth (and that is why drying faster?) or is just a wrong feeling? How about if I don't use such a 'unnatural' heater.

Basically I want to know if something will dry faster if the temperature will rise and after that fall (to the temperature of the room or even lower, something like a cosine), repeating the process until the clothe is dry. Some factors that change drying times include the temperature of the air and water, the type of fabric drying, and humidity.

If it is much more humid outside than inside it might be be better to dry it inside because the more humid the air is, the less water evaporates.If the room isn't well ventilated and becomes very humid the clothes will dry more slowly or not at all. You also wouldn't want to dry outside if it's 40 degrees.

With the iron, introducing all that heat causes water in the cloth to turn into steam. The steam visibly billows off my clothes when I iron them. That and the heat introduced from the iron would reduce drying times. There would be less water and more heat in the fabric. So effectively, you want  a large gradient difference in moisture AND air movement to ensure the gradient is maintained on the surface of the fabric? Yes, exactly. That is why air movement is so useful for drying! It constantly disrupts the stagnate layer; a gradient from ambient humidity to saturated air in direct contact with the wet surface.

A good idea to minimze this further might be to maximize the surface area in contact with the outside. A humid atmosphere quickly builds up on the inside of the clothes which effectively stops evaporating at this side and halves the effective surface area. I suspect supporting the clothes on some breathable wire support might improve drying time considerably. Does moisture leave the room in a sunny but lowly ventilated area? It is less likely to - an extreme version of a sunny but poorly ventilated area would be something like a greenhouse, lots of glass windows for the sun's heat to get in, but little airflow for that heat to dissipate, especially once it has been absorbed by the water in the room as it becomes steam.

Replace the plants with wet clothes and you still have a similar situation, rather than dry clothes you'd have hot, damp ones. Not if you live here in Florida. Ventilate the room and the humidity skyrockets.  It depends on how much you have of each.  "Drying" is just the water evaporating into the air, and the air can only take so much.  The sun only helps this to happen by raising the temperature, and the breeze only helps by moving the air that's already absorbed the water, and replacing it with presumably less saturated air.  

If you were in a sealed environment with 100% humidity, no amount of sunlight would dry your clothes, and likewise, no amount of breeze at 100% humidity blowing by would help your clothes dry.   ^^^ This! Lol everyone is saying 'depends on this', 'depends on that'. Obviously it depends on the relative amount of each, and there is no way to know which method would be faster without defining several external variables. Its a cost-benefit, it depends on your local humidity and access to dehumidification, as well as your tolerance for sun damage (the sun's energy degrades the dyes and even the fabric) as well as environmental hazards. I'm not personally sure, but my guess is that at low humidity, 'air' drying would be more than sufficient (water&gt;&gt;&gt;air so faster fan=faster drying) while at (relatively) higher humidities the sun's energy would be necessary since (water&lt;&gt;air) so a faster fan isn't really speeding anything up. 

In your specific case, my guess would be either adding convection to the indoor sun approach, or finding a sunny spot outside with a breeze would be ideal. If speed is ever a serious issue, just go to a laundromat?

Really interesting question, but besides controlling for specific environmental factors, there's really no way to determine (from a generalized perspective) which of the two forces is relatively more potent.  Not only that, but the UV radiation from the sunlight damages your clothing, aging them quicker.  Definitely a breeze,  hands-down. Without it the air close to the surface of the fabric will quickly saturate. Moving the air will keep the delta humidity between fabric and air high, creating a more efficient exchange. The sun on the other hand will add more energy to the system, increasing efficiency slightly. Consider how much heat energy you need to boil water..  To be fair, "breeze" here is very low speed. Refreshing the dry air next to the surface would only require a bit of agitation, whereas the speed required to significantly increase the heat transfer coefficient of dry air is really high. (The heat transfer coefficient of air is approximately 10.45 - v + 10 v^1/2 in W/ m^2 K.)  
As for sunlight, [here's a map of the solar flux](http://www.nrel.gov/gis/images/map_csp_us_july_may2004.jpg) in kWh/m^2 / day. In some locations, the solar power significantly dominates in modelling the evaporation rate of water from a surface, especially considering those areas are also usually places of low relative humidity. 
 kWh/day. There's a good unit. Why not just kW? Weird, right?  
It's a sum of the kWh/m^2 one can gather over the course of a day. The normal vector to the sun is maintained by assuming two-axis tracking, but it's summed over a day's sun exposure.  
It tends to be used for calculation of PV requirements for small-scale home solar installations with a bit of battery backup, so people just want to know what kind of power they can generally expect. Generally comes, as mentioned, from solar power. Systems are sold in "kW" meaning "if you get exactly standard power under standard conditions" [1000 W/m^2, 20 deg. C, practically never happens] but the average kW is more like 20% of that [depending considerably on many minor details.] Combined with "my electric bill is in kWh" these units are actually LESS confusing when figuring out what you'll get for your money. 

Ed. to attempt to clarify: if you buy a 10 kW system you will not get 240 kWh in a day. Because night happens, among other things. You'll get more like 40 kWh in an average day. More in summer, less in winter.  If it were just kW it is hard to tell exactly what it means. Is that instantaneous? Over 1 second? Over an hour? (Because Power is Work applied over a period of time. P = W/t. There are many other formulas but this one helps us explain what you are asking about)

These units tell us what the change in time and space is, so we understand that this is how much power occurs over a square meter in the timespan of a day Right... But you can choose and work with any time period if you're given the average wattage. And there's two time units. You can give just the average wattage and the relevant time period, which is a day, and have a workable measure for energy. The reason it's given in kWh/day is because it's the standard units when talking about energy production. Sure we can go all the way back to just voltage and get up to Work and then to Power and we can talk about Pav and whatever other things you like. I was just trying to explain to someone who seemed to not know how it worked where the per day would have come from.  I'd guess the map was probably made to show where solar panels would be most viable, so it weights cloudiness and other factors (which is why California and Nevada are much redder than the misnamed sunshine state). Also wouldn't the sunlight increase the temperature of the air surrounding the surface, causing it to rise and creating a minor air flow cycle? Yes it would, and that little bit should be more than sufficient to bring in fresh air, especially if it's indoors where the air is cool and sunlit objects are significantly hotter. The drying effect of room temperature air does not come from the fact that it's warming the clothes (in fact, you can dry clothes in air that's _colder_ than the wet fabric). Isn't evaporation different from boiling?  It is, but more water fits in warm air, so the relative humidity goes down if you heat air, and the relative humidity is what matters. Boiling means that the average temperature of every molecule is 100c. Evaporation means some molecules are over 100c and can break the surface tension and escape. Moisture on the clothes keeps continually evaporating at room temperature,  but it needs to be transfered to another medium like the surrounding air, or else it won't leave the cloth.

The transfer rate is affected by a factor that takes into consideration the cloth temperature (higher temperature means quicker evaporation) and the dryness of surrounding air. Thing is, the evaporation rate doesn't show a linear variation according to temperature, meaning doubling the room temperature won't double the transfer rate. Not even close. 

No matter if you're in the desert or a tropical environment, it's true that the air in contact with the cloth is more humid than than the air that's a few meters away. 

If you would model the moisture transfer speed, it should be something like


**Humidity transfer** = *F(Cloth Temperature)* * *(Cloth Humidity - Air Humidity)* * (Air Flux) * K


Where:

- transfer is measured in [water mass / (surface unit * time unit)]

- K is some dark constant like Stefan Boltzman's but for humidity

- Air flux is [volume/time]

- F(cloth temp) resembles specific heat


You see that transfer increases with temperature, difference of humidity between cloth and air, and air flux.

If you leave the piece of cloth in direct sunlight, without any breeze reaching it, the air surrounding the cloth will get so humid it can't take any more humidity. Some convection will happen that will make the air move without a breeze, but it will be slow and inneficient. Even at maximum F(cloth temp), the difference of humidity will be close to zero, and the air flux will be small too.

If you leave the piece of cloth in the shade, but receiving a lot of breeze, then you would be applying a high air flux, and the air surrounding the cloth would be continually refreshed, so it will never happen that the air's humidity level approaches the cloth moisture level. Even when the cloth is cooler than it would be under direct sunlight, the evaporation rate would still be in a similar order of magnitude.

**TD/LR: a lot of air, the dryer the better.**



 This sounds like just a thought experiment, but if it's real world:  The UV in direct sunlight is going to bleach anything that isn't white.  Shade/Breeze if you want your clothes to retain their color. I dry my whites in the sun so the UV ray kills everything better than bleach, and then I send them through an x Ray machine just to make sure I got everything. FYI, you might like to know that it's better for the longevity of your clothes to be hung in the shade. When hung outside in the sun, they will fade much faster over time. You can slow this by turning them inside out, but the better is to dry them in the shade outside. There are some other benefits to drying outside, and that is that they pick up the smell from outside, so it smells fresher when you put it in. I'm assuming it's some type of radiation that causes the fading? I've heard the same happened to the US flag in space. I'm wondering how does radiation cause fading on colored fabric? Is it just breaking down the pigments? Yes, it's radiation of the ultraviolet kind. UV wavelengths knock electrons out of atoms because they carry quite a bit more energy than visible light and their wavelength is just right to do this. Knocking electrons out means you're changing the molecule's visible light absorption properties. We call this "fading."

In space, the american flag is probably fading a bit faster because it's also absorbing UVC rays which are absorbed by our atmosphere (thankfully).  Is it just breaking down the pigments? 

Yes. More or less. You probably shouldn't use the sun on anything other than whites. It depends on the magnitude of the breeze and the sun, and I don't know if this is theoretical or you actually want to dry your clothes, but sun can change the color, especially of wet clothes. It's energy breaks down the chemicals that make the pigments.  [deleted] You can turn your clothing inside out while drying in the sun to minimize the visible discoloration. My mother was adamant about we doing this when hanging out laundry, and I never understood why. Thank you for bringing light to this! [deleted] Wouldn't this be the same as say.. wearing clothes outside, which is where clothes are typically worn?  Completely irrelevant to OP's inquiry. Do you sit in the exact same spot in the sun for hours on end, as clothes do when being dried? Clothes are worn inside as well.  Unless you are specifically talking about a jacket, most clothes are worn more inside than outside simply based on that's where most people spend the majority of their time. Yes wearing clothes outside also causes fading. Why cause more bleaching than necessary?  Chem E here, used to run industrial dryers. Drying is two separate actions: heat transfer and mass transfer. think of a dryer with a plugged vent line. Clothes get hot but they never get dry. So you need both heat to vaporize water and a lower water content atmosphere that water can escape to. 
So to answer your question: it depends. You really need both operations ( heat and mass transfer) to dry objects.  Clothes dry because their moisture level exceeds the moisture level of the environment. The magnitude of that difference dictates the level of moisture at which equilibrium will be reached (the point at which the clothes won't dry anymore, because the environment and the clothes have the same moisture level). The amount of thermal energy from the sun dictates the rate at which that equilibrium is reached.

In a large, open environment that's dry and sunny, your clothes will reach equilibrium quickly (relative to the next examples) and be pretty dry.

In a large, open environment that's dry and cloudy, your clothes will reach equilibrium more slowly and be equally dry.

In a small glass container put out in the sun, your clothes will reach equilibrium quickly, but that equilibrium will be pretty moist relative to the last two examples; the moisture in your clothes will raise the moisture of the local environment until they're the same, then no further.

In a small glass container put out in the shade, your clothes will reach equilibrium more slowly, but again that equilibrium will again be relatively moist.

As to the question of which is better - it really ends up depending on how quickly you want to your clothes to dry (sun is better) and how dry you need them to be (large, dry environments are better)! I used to have to hang my clothes for awhile and I found that the sun will dry your clothes fine, but it does cause damage faster. Make sure to use liquid fabric softener trust me I lost a few good shirts. Don't hang to hot or early if they are in the sun to long it will kind of fry get crispy. A nice breeze does dry faster when there is sun too. It used to take longer if I had to hang up just in front of a fan with no kind of warmth adding a heater is great and made it faster. But the best option would be a warm shaded area with a breeze. Like a carport. Don't dry dark clothing in the sun, it fades them quickly. Once or twice if necessary, sure, but not a frequent thing.

Depending on the humidity, a breeze is usually best because air circulation promotes drying. Personally, I like drying things when there's a nice, brisk wind. The flapping of the fabric acts as a natural fabric softener. Wearing clothes that have just been straight up dried without a breeze usually results in them being stiff or holding shape wherever they were pinned, depending on the fabric. [deleted] &gt;Damp climates (like the Pacific Northwest)

This entirely depends on the weather, and where you live. 

If you live on the east side of the cascade mountains, it's dry as hell and it does not rain all that much. 

If you live on the west side, it's only dampish when it is raining outside, or misty. If it is not raining (like today for example) it tends to be exceedingly dry. We tend to have some very dry winters and summers. It rains, of course, but the humidity does not get that high. In fact, on the whole, the west side of the united states is much dryer than the east side. I lived in upstate new york and went down to the DC area last summer. It was my first time having the experience of taking a shower, walking outside, and having my shirt look like I jumped in a pool within 10 minutes. Texas in the summer is much the same way.  It depends somewhat on the result you are looking for. Also, humidity, temperature play a part, as does how wet the garment was when it came out of the washer. In general assuming the washer has a pretty good spin cycle, a stiff breeze in low-to-middling temperatures will get you a pretty stiff garment. Warm sunlight on hot day will get you a much softer garment. To summarize what most people would have to say: it depends. Drying is a combined heat and mass transfer process: liquid water is absorbing heat and phase transforming to a vapor and is then moving away from the saturated clothing to the dryer (hopefully) air. The rate at which this drying happens is influenced by both the rate at which the water can vaporize and the rate at which the water vapor can move into the air. It would really depends on the conditions as to which one of these rates was limiting the process. It's a bit complicated however, because indoors the shirt is in a stagnant air environment and we can assume all heat transfer is from radiation. But because it is stagnant, the air will become localized more humid around the shirt and decrease the rate of vapor transfer from the shirt. Outside, you will still have some radiation from the ground, buildings, etc., but convective transfer from the moving air will matter as well. Additionally, the moving air removes the water vapor as it leaves the shirt preventing any decrease in the rate of mass transfer. So in the end, without knowing quite a few factors and developing a mathematical model for the process, it really is just a guess. I love science but as a housemaker, I believe sunshine with a light breeze outdoors gives the best results. Anything you dry inside increases moisture and delays the drying process. Get a clothes dryer (they are cheap on ebay) for winter(with ventilation fan so that air goes outside and not back in the room) and hang outside in spring/summer/autumn.  I live in the UK.  I leave my clothes to dry in an unheated room, and it takes a couple of days.  Obviously heat would make it go quicker, but if you're not in a hurry, why bother?  The most important thing to consider is humidity.  The UK has very low humidity at this time of year, so with a window open clothes will dry just fine.  With the window closed it will be hard for the humidity to equalize with the outdoors, and the wet clothes will saturate the air in the room, making drying slower. I live in an apartment and I've experimented with different ways to dry my clothes (to the annoyance of my roommate) and found a way that works and annoys my roomie less.  Basically I hang everything on hangers in the bathroom and space them a hand width apart to get circulation.  Most bathrooms have a fan to suck out the moisture and I only wash my clothes in the evening so they can hang dry all night.  Pants are more trickier but throwing them over a closet door works fine.   Kids these days are so lazy. Remember when we had to actually figure things out for our self? Trial and error? Hang 2 sets of cloths (of roughly equal quality/water saturation) one set in the shade/wind, the other set in the sun. Check in every so often. You tell me what works better through the scientific process.  Did this exact problem in Che 306: heat and mass transfer.  convective heat transfer is always faster and to all the jackasses trying to get specific with the level of humidity quit being dicks, not everything has to be a examined from every angle.  The answer is wind, even a slight one Moving air is better than stagnant air.
Dry air is better than humid air.
Hot air is better than cold air.
Lots of access to open air for the clohtes (a large space/ outdoors/clothes are not squished) is preferable to small, cramped space. 
Moving air is likely the most significant factor, though. Use your best judgement. Find an area that is very dry and hang. Then apply dry heat, like a space heater or ceramic source.   
High temps=faster evaporation  

Low exterior humidity=faster evaporation

Some areas of teh country get high temps and high humidity, or low temps and low humidity, so it's not exactly optimal everywhere you go. In the middle east and desert regions, the high heat and low humidity can be extreme enough to ruin many types of clothing, which is why finer clothing care tags say "Tumble Dry Low Only" I hang dry my clothes indoors.  I string them up in my bedroom, open the door and a window to give cross ventilation and put a fan blowing out the open window to draw air from the room.  On a normal day they'll be dry in around 5-7 hours though I usually just leave them up over night.  I mainly provide all that ventilation so that moisture doesn't become trapped indoors and cause mold. Oh, I love this one! In fact, I like answering it so much that I wrote an [FAQ answer](http://www.reddit.com/r/askscience/wiki/astronomy/expansion_gravity) about it, and recommend you read that. But for the lazy, here's an executive summary.

The expansion of space really only makes sense at the very largest scales. There's no "expansion force" that's ever-present in the Universe. Instead, it might be more helpful to think of the expansion as a *description* of what's happening. On large scales, galaxies, and other things, are moving away from each other. And on smaller scales, where things aren't moving away from each other (due to gravity), then by definition there is no expansion left.

---

By the way, people will commonly object that there *is* a force driving the expansion, namely that due to dark energy. Dark energy does indeed (or at least should) have an effect on very small scales, and that effect is miniscule and dwarfed by other forces. But that effect actually knows nothing about what the Universe on large scales is doing. The Universe could be accelerating, decelerating, or even collapsing, and on small scales dark energy will always provide a little tiny repulsive force. Wait I thought that space expanding described a very real phenomenon, wherein the actual distance between any two points is growing over time. That's another way of phrasing the same thing. But as I said, it only is true on very large scales. Do you mean it's only observable on large scales, or that, literally, space is not expanding *at all* on Earth? At all. I...am now very confused.

Why not? Think of 2 continents moving away from each other on earth's surface. Their relative size isn't changing, just the space between them. Those continents are made out of atoms. What about the increase in space between individual particles? If there was zero force between particles, they would, in principle, move apart because of expanding space. But, because there are very significant forces between particles, the space between them does not expand.

Part of the problem of the intuition here is thinking that the space is expanding, but the particles are just sticking together. In fact, space and particles affect each other. The forces that act on the particles also act on the space and keep it from expanding, essentially.

It's much like mass doesn't just exist *in* space, but it warps the space it is in. That's what the force of gravity is -- a warping of space due to mass.

Try this for an analogy. Imaging a large funnel/cone-shaped container where the large end is facing up and pointy end down. Water is being pumped in from the pointy end. A bunch of toothpicks are floating on the top of the water. Now as the water comes in, the surface area of the water at the top of the funnel is getting larger as the water fills up the funnel. Those water molecules are being pushed up from below. But the toothpicks are not getting longer, being stretched, or pulled apart. However, the distance between the toothpicks is generally increasing. Unless, of course, two toothpicks are, say, touching and there is a some small cohesion. Then they stay together as a group.

Perhaps toothpicks are too simple. Try a small, thin piece of wood or paper floating on top. They don't expand either. (Ignore the water dissolving the paper, of course.)

Similarly, our particles, atoms, molecules, planets, starts, and galaxies all stay together as a hole, more or less oblivious to the expansion. Even our local super-cluster of galaxies will stay together in the long run (this is the cohesion analogy). It is only as the effects of gravity have less and less effect at larger and larger scales does the expansion of space have any real effect on expanding the space (analogous to the surface of water in the funnel).

 Another question, this has been bugging me for many years. Based on Newtonian laws, Earth or any random planet, if ejected into a space where it wouldn't be affected by any external magnetic field, say another planet, star, galaxy, supercluster or the Great Attractor, would never stop rotating around it's axis. Is this true? If the universe freezes up completely, and the core of the stray planet freezes up as well, would it do anything to affect it's rotation? 

Also, this has been bugging be since birth as well: does the sun have any effect (increase/decrease/fluctuate) on the Earths rotation speed at the moment? Let's ignore the moon for this one. Dark matter, dark energy... aren't they concepts that make sense only in mathematical models? As far as I understand, space is "expanding" due to the momentum that large objects (galaxies, etc) gained when the Big Bang happened, am I right? Btw I'm no expert, I'm just wondering. But there must be some size boundary line, above which space is expanding and below which space is not expanding The analogy I heard was pennies taped to a balloon that you are blowing up. In the case of continents, there's an identifiable reason why it happens this way, and we can identify specific locations which undergo more or less expansion. It isn't a matter of scale, it's a matter of location. Ya it was an oversimplified example. I was just trying to help illustrate movement of sections without growth of said sections. The picture that you have of all the stuff in the universe being placed on an ever-expanding background is incorrect. It is far more dynamical than that. Spacetime everywhere bends and contracts in exactly the way Einstein's equations tell it to. At large scales the universe is homogeneous (every point is equivalent) and isotropic (every direction looks the same). Under these conditions, and with the right amount of matter, radiation, and dark energy, Einstein's equations tell spacetime to expand. At small scales the matter distribution looks *completely different* and Einstein's equations tell spacetime to behave *completely differently*. The spacetime around your does not care about what is happening &gt;100 Megaparsecs away. The presence of your body, the presence of the Earth and even the presence of the air are far more important than the distribution of far-away galaxies in the observable universe. What spacetime is doing between galaxies tell us nothing about what is going on down here. Wouldn't it be more correct to say that einsteins equations predict how space expands and contracts, rather than to say they do so according to his equations, it's kind of like saying his equations came first, which they definatily didn't he just observed the universe (as all scientists do in truth), and came up with a model which, A. described it, and B. predicted it. Oooh. That makes sense. Maybe.

My impression was that, thanks to the Big Bang, all of space was forever expanding, and not likely to ever stop (i.e. no Big Crunch). However I didn't consider the effect of Masses on space? It's just areas moving away from each other. Earth's orbit around the sun doesn't increase, our sun's orbit in the milky way neither, but galaxies move away from each other, as are clusters of galaxies Is this because the expansion is so miniscule that it has no effect on the galactic scale but in the intergalactic scale, it adds up, causing a detectable expansion?

So, nearing the heat death of the universe, supposing a galaxy still exists, the night sky will only be filled with the galaxy the viewer's occupying and and no other sky objects?
 No, it's because effectively the expansion adds an extra force to the equations that govern these orbits, but this merely causes the equilibrium point of the orbit to shift a tiny amount, (proportional to the radius of the orbit). It does not destabilize the orbit; the Earth and the Sun will still remain at the same distance indefinitly. Only for objects that are extremely far away, this extra force becomes destabilizing. as far as I know, there is no minuscule expansion. It's not the atoms themselves that are expanding. The galaxies are actually moving away from each other. Solar systems are still under influence of gravity of the galaxy &gt; Solar systems are still under influence of gravity of the galaxy

Yes, but if the expansion is so slight that it can't compete against gravitational attraction on mere interstellar scales, that doesn't mean that the expansion isn't still taking place.

In the "expanding balloon" metaphor, gravity is like a piece of scotch tape holding a small area of the balloon in the same absolute size, despite that area moving away from other similarly taped areas. Galaxies aren't moving away from each other, space itself is expanding. Think of it like drawing a number of points on a deflated balloon then slowly blowing it up Thanks. Do we know how fast the universe is expanding? Is it anywhere near light speed? Why not to what? Me too. I don get how this can be the most voted answer. He doesn't answer the question at all...at all. The rate of expansion of space is quite small. It adds up (exponentially) with distance, making it noticeable at intergalactic scales of distance, but on the scales of distances familiar to us Earthlings, various attractive forces (such as gravity of course, but also the much stronger forces involves in atomic nuclei) overcome that expansion of space. In essence, space might be expanding even within the nucleus of an atom, but the particles just "snap" right back together.

Sort of like if you had a very gentle breeze flowing outward from the center of a wiffle ball. The breeze might be blowing, but it's not nearly strong enough to blast the plastic of the ball apart. Err, why not?  Wouldn't it be that local space *is* expanding, but just not fast enough to overcome Earth's/Solar System's/Milky Way's own gravitational binding?  The Hubble Constant of 67 km/s per megaparsec translates to 27 picometers/s across Earth's diameter, or 4.8 nanometers/s across 1 AU, or 30.6 m/s across the width of the entire galaxy.  On those scales, other forces dominate. Because any expansion so minor is compensated by the other forces, which maintain the exact same distances that are based on the other forces and the laws of physics. The earth doesn't grow by a meter every 3 millenia, because the gravitational force that affects the mass of the earth, pulls it back down... (basically) Precisely my point.  But that doesn't mean that the expansion isn't still at work between any two points, no matter how close.

You mean 85 cm per 3 millennia? :) Well, I estimated the 3 millenia from my head, so I'm not ashamed that I didn't get the precise amount of years it'd take per meter... 

I should say that I am not physicist. I did not study this matter so this is only my understanding of it from the available sources and the other explanations. Also, my previous comment was perhaps a bit too hasty and not exactly correct.

But to your point - no, the graviational force is exactly the reason why the expansion does not take place at all. 

Imagine a cluster of balls - now create a small explosion in their center - the balls expand with some velocity from the center and at the same time, they get slightly scatched by the explosion. Now, if there was no friction and no outside gravity, the balls would never stop (that's newton's first law), but the force that scatched the balls is gone, it was compensated by the molecular bonds that hold the ball together - it does not constantly get more and more deformed, because the effect of that force has already ended and there is no new force that would change this state. The inertia affects the ball as a whole, not as a sum of its components. The force CAUSING expansion is still there however, it's just not strong enough to overcome gravity. That's what I thought.  Though it sounds as if other people are implying that the force just isn't there at small scales....which to means seemed strange and would imply the underlying mechanism had some sort of piece-wise definition. Expansion of space is what happens when there is a homogeneous, isotropic matter/radiation/dark energy distribution and there is just the right amount of each. ([FLRW metric](http://en.wikipedia.org/wiki/Friedmann%E2%80%93Lema%C3%AEtre%E2%80%93Robertson%E2%80%93Walker_metric)) This descibes the universe on scales larger than about 100 megaparsecs. Our local environment looks *nothing* like this, so there is no reason to believe the expansion occurs on small scales *at all*. It may instead be contracting, or it may be doing nothing (I don't know enough GR to say what will happen, just that properties of the cosmological metric have nothing to say about what happens locally). Whatever vacuum energy (cosmological constant) is present, it is so minuscule compared to the energy density of our surroundings that it has no effect on what happens to spacetime at all. There's not a very good physical reason to apply Hubble's constant to the solar system at all. In other words, if you constructed the equations describing how matter moves in the solar system, you wouldn't find any terms saying "add expansion at a rate of 67 km/s/Mpc."

In fact, in the very simplest model of structure formation (galaxy cluster formation), in which a spherically-symmetric dense region collapses, the Hubble constant doesn't appear *anywhere* in the equations for how matter behaves. Is that really the case? I think I understand what you're saying - that we assume the universe is homogenous to derive Hubble's Law, and so it shouldn't apply at all at small scales, e.g. it's not that Hubble expansion is negligible at small scales, it's that it's not correct at all.

But that doesn't seem right to me, because Hubble's Law still seems to work on moderate scales where the universe is still very inhomogenous. You can see the Hubble Law on distances as short as from here to the Virgo Cluster, and on that scale the structure of galaxies is not homogenous at all - it's clumpy and filamentary. But we can still see expansion on scales as small as 10 Mpc, and on that scale the universe is not really any less homogenous than our solar system is. That's right. The expansion certainly doesn't disappear the second we depart slightly from homogeneity and isotropy. But what's no longer quite the case is that the expansion between two points is H_0 * distance.

Now, when you get to scales where things aren't moving away from each other at all, there's absolutely no way to measure expansion. Just try to conceive of an observation you could make which would tell you whether there's some component of their motion which expands them away from each other as H_0 * distance.

(One thing you could do is drop two point masses at some distance apart from each other, and they *definitely* wouldn't start expanding apart.)

One way we can think about this theoretically is with a simple model of structure formation that I've modelled elsewhere, which is to take an expanding FRW universe and carve out a spherical region slightly denser than average. Due to spherical symmetry and Birkhoff's theorem, that region will not be sensitive at all to the outside universe (the same way that the gravitational field inside a spherical shell knows nothing about said shell), so it'll evolve as its own FRW universe with a different Hubble rate, and eventually collapse. That region has no idea, in the slightest, what the outside Hubble rate is. &gt; Wouldn't it be that local space is expanding, but just not fast enough to overcome Earth's[...] own gravitational binding?

Well, yes and no... The expansion or rather thing that makes space expand on large scales is also present on small scales but it doesn't amount to any expansion at all because it gets completely negated by any of the attractive forces. Instead, the only minuscule effect that is left from the "expansion" is that all those other forces get weakened a tiny bit. That's exactly what I was getting at.  You can't say that expansion isn't happening on smaller scales; it is, it's just other forces compensate to keep stuff the same size.

If you had a piece of string a megaparsec long, it had better have a tensile strength high enough to withstand the opposite ends pulling away from each other at 67 km/s or the expansion really will rip it apart into pieces small enough to stay together. Thank you for asking all the exact questions and clarification I was wondering.  Since the gravitational attraction is infinite and exists independently of the distance of 2 objects, which is the distance this 2 objects need to be from one another so that attraction becomes irrelevant and they can start drifting apart? is there a fixed distance? Correct me if I'm wrong, but wasn't it proven that the expansion was accelerating? Which means that it's only true on very large scales **for now**, but not an inherent property of expansion.  

In trillions of years, even atoms would be ripped apart, no? http://en.wikipedia.org/wiki/Big_Rip I think it means,  that due to the effects of the electro force and gravity,  that even if space itself is uniformly expanding,  the regular forces make up this distance to remain in equilibrium , so there is no observable effect,  unless you look at very large scale, where the cumulative expanding exceeds the weak coupling of galaxies to each other A lot of people seem to use "gravity" as the thing that is binding everything.  
  
Would a lone atom in the void between galaxies, not bound to them by gravity, still not be torn apart because of the other fundamental forces? Atoms are held together by the other 3 fundamental forces (2 really, with the electroweak theory): electromagnetic force, strong nuclear force, and weak nuclear force.  These are much much much stronger than gravity or the small force /u/adamsolomon discusses.  On a reasonable time scale, these forces will continue to hold that intergalactic atom together.

EDIT: Thanks for the gold! I.e., the space in between the component atoms of a water molecule is expanding, but at such a low rate that the forces holding the molecule together have no trouble holding their own against it.

The [Big Rip](http://en.wikipedia.org/wiki/Big_Rip) hypothesis revolves around the idea that the cosmic expansion is accelerating and will eventually become fast enough to overcome these other forces. All of these comments similar to this make it sound like there's some unknown universal force pulling everything apart. Is this necessarily true? Couldn't it just be an ongoing balance of pressure differential? IE: The universe has mass; beyond the theoretical edge of the universe does not. Pressure differential of any mass to a vacuum causes expansion into the vacuum. This reminded me of one of my favorite science fiction short stories ever: **Exhalation** (by Ted Chiang). It won the 2009 Hugo for its category.

It's a letter to us, the reader and explorer of its dead world, by a being from a world which is governed by pressure differentials, everything is moved and created by air pressure differentials (potential) even life and thought itself.

But there is a problem, their world is dying, the pressure is slowly equalizing through their universe and at some point in the future there will be nothing left for life and though to exist, and it might be sooner than they thought.

You can read the story here: http://www.lightspeedmagazine.com/fiction/exhalation/

I cannot recommend this enough, it's a true magnificent piece of writing, and very bittersweet I might add, it's just perfect. It's a magnificent story. I've never seen anything provide a better metaphor for entropy. Finally I know what this story is called! I heard it on Escape Pod years ago and loved it but then forgot what it was called. To anyone that's not heard or read it I strongly recommend it. Thank you Pyrelord. &gt;Thank you Pyrelord.

For the night is dark, and full of terrors. 

 Ooh, it's on Escape Pod? I will definitely give it a listen! They do some really fantastic readings.  This was a great short story! On par with Asimov's "The Last Question" and "The Last Answer".

EDIT: What story by Ted Chiang would you recommend for me to read next?  Assume you mean Ted Chiang not Asimov. Story of your life and the related short story collection) are fantastic.  Desperately want to see him get after some full length works.  