I ran a simulation using java for 100,000 trials each. The average time for both people moving is half that of only one person moving. Here is a histogram of the data: http://i.imgur.com/5mYnGiT.png

Details of the simulation:

People are assumed to be on a 100x100 grid. If they are on the same spot, they can find each other. At t=0, they are placed on a random location in the grid. Each time step, anyone that's moving will randomly move north, south, east, or west. They can't move out of the 100x100 grid, so if they pick a direction not allowed, they'll pick again. I did a simulation as well.

I simulated each test on grids of increasing size: 20x20, 40x40, 80x80, 160x160, and 320x320. I gave the seeker a vision of 10 units, and counted the number of loop iterations until the seeker found the other person. I only ran 100 trials for each grid size.

Median iterations for one person standing still: 0, 547, 9215, 32892, 188207

Median iterations for both people wandering randomly: 4, 380, 3208, 17359, 95125

The std. deviation was also much larger when one person was standing still.

This more or less confirms u/GemOfEvan's data.

Great question, OP. It might also be more accurate to limit the random direction choices to not include moving backwards, as realistically neither party would spend 25% of their time backtracking. Yep. There's lots of ways to model the idea of "moving randomly". A more accurate simulation might have the seeker wander in a random direction, and only occasionally change direction. Adding obstacles would help too, except OP kind of ruled those out.

I might do a better version tonight if I have a chance. It's an interesting question. Also doing a more calculated sweep of the area would be more realistic. If I am looking for my wife in the store, I'll likely walk the path that leads around the outer edge of it before journeying in. Careful there.  At some point you're going to end up running simulations comparing different kinds of terrain. Do we check the underground parking lot? What if we're in a family? Do we split up? If so, how long does it take for all five members to find eachother again?

Why do these people not have a "If we find ourselves separated, let's meet at the information booth" protocol in place before entering? What if one person doesn't want to be found?

What if one family member went to wait outside?

What if the park closes? Also what are the sight lines in the park? Any main walkways or natural traffic flow? Is it very crowded on national wear-a-blue-shirt day? What If one party was on a ride when the other walked right by and yet considered that area "searched".  I added a kidnapping routine, the simulation still hasn't ended so I can't give you any meaningful data.  Despite it getting lost in the weeds of ''testing terrain'' a more methodical search method is what will glean more real world applicability, despite introducing some more variables.  My suspicion is the simple test showing two random pathing find each other in half the time would be true for the median in the real world, the real difference should/will show up in the outliers, where two active searchers may come up with search patterns that take significantly longer to intersect than the longest possible result with one stationary person.  That would depend heavily on the park itself, as others have stated. You'll probably also walk faster as the other person is enjoying the activities but you are specifically looking for them. Perhaps more importantly is that a person in such a situation would almost certainly NOT move "randomly" at all... they would probably think things like: "Where do I think the other person is going?", "What are their favorite spots?", "If they're trying to find me too, where do I think they'd look for me?" and so on. 

The more interesting question, to me, is whether such reasoned searching winds up a any better than average ransom? It's fair to assume some of those informed guesses would be wrong, and with two people searching for one another some of them might actually work to keep them from finding each other. So I wonder if it winds up being close to the performance of a random search algorithm anyway. 

I'm certainly not capable of simulating such a thing and I'm not really sure you could without developing proper AI's that model the people involved... seems MUCH harder than modeling any sort of random, but fun if someone could :)  Could you first add random paths around the grid, the people are only allowed to move on paths. When they reach a intersection they can choose any new path but not backwards.  Maybe you can generate a random cycle for each wanderer. If they complete their walk  before finding each other, generate a new random cycle for each. Also the fact that the one being sought out might be stopping to go on rides or the bathroom. The seeker might walk past them without looking to see if they went on a ride. Most amusement parks I've been to are basically a huge circle so if both people moved in the same direction, they'd potentially never meet unless one backtracked.  In this hypothetical question, however, there are no obstacles. Amusement parks also tend to have alternate paths that can be taken, which would allow for backtracking in the grand scheme of things. It was mostly "one step forward two steps back" backtracking which can happen with random direction I was trying to avoid &gt; Amusement parks also tend to have alternate paths that can be taken

7 bridges of Konigsberg problem then? Time to get graph theory in here? Graph theory may be useful if the amusement park were described as a topology of nodes and pipes, but not because this is the bridges problem. Aren't amusement parks exactly that, though? A node (where 'streets' connect) and pipes (the actual 'streets' themselves). Or am I misunderstanding your terminology? You aren't misunderstanding terminology, but the 7 bridges of Konigsberg problem is about path finding (i.e. crossing all the bridges once and only once).

The simulation could model the amusement park as a graph of vertices and edges ("nodes and pipes" as you described it) if you wanted to model the movement of people on paths between various attractions at a specific theme park, but it doesn't help answer OP's original question to restrict that movement so that they use each path only once (i.e. the 7 bridges problem).

The most important part of modeling and simulation is including only relevant things in your model to answer the question you're asking, and to leave out everything else. And if they both stood in the same spot, what are the odds? You're right, if both parties are moving, there is some small chance they will never find each other or take way longer to do so. This is true even if they usually find each other more quickly if both are walking. Good catch. Unless one of the people walked slightly faster than the other one. Then they would eventually come up behind the other person. If I were looking for someone who I knew was just walking around the park, I would probably backtrack a lot, especially if I suspected their location based on prior info.

A perfect example of this situation would be a band trip, where I knew my friends would be there and uninterested in finding me, but I might want to find them and talk about a certain ride or thing that happened. Should I stay where I'm at and wait for them to pass by, should I constantly move forward, or is there a level of backtracking that can improve my ability to find them?

In one of the simulations, the searching party had a range. I wonder if "staying in place" by moving around within their range would help. This would definitely reduce the main issue: sticking to the perimeter. Instead of a 33% chance of escape it'd be 50% Also, might be more accurate to make the detection available in only one direction at a time. Maybe a cone shaped like of site. Well if they don't know the other person is stationary then they might backtrack to see if they wandered over. &gt;backwards

You mean retracing steps? Great point. There's actually a simple explanation for why they meet about twice as quickly for a large grid. Assuming an infinite grid, person A taking a random step is exactly equivalent to person B taking a random step while person A stands still. That's just a change in reference frame. Thus, person A and person B both taking a random step is equivalent to person B taking *two* random steps while person A stays still. So, when both people are moving, we would expect the average meeting time to be cut in half, since it's equivalent to making person B take twice as many steps per unit time.

Of course, that only works if the people never run into the boundaries of the grid (i.e., the grid is effectively infinite). That's why your results don't quite match my prediction for the smaller grid, but they do seem to for the bigger grids.

Edit: I should point out that I've tacitly assumed here that a person on an infinite grid would, on average, find their friend in a *finite* amount of time. I realize now that that may not be correct. To fix that, I would need to assume that there are boundaries, so that a person will find their friend eventually, but also assume that those boundaries are far enough away that my argument above is mostly valid.

The point is, two people moving randomly at each time step can be viewed as one person making two independent random steps at each time step. Adding boundaries just makes the probability of moving in a given direction more complicated. So if a person is going to find their friend eventually, they'll find them faster if both people are moving. For large grids, they'll find them roughly twice as fast. Yes, in other words if one person walks twice as fast while the other stand still that is the same as if they both walk.  Which is intuitive. That was my thinking as well, except the parameters of the person moving randomly would suggests that the double movements would tend to cancel each other out, thus cancelling the acceleration to a solution.
 I replicated something similar to your setup. But, I added a bit of a movement model.

I tried to pick something reasonably simple that modeled each player wandering around with some intent, moving to a location they haven't been to in a while. The seeker because they're looking in a "stale" location for their friend. The tourist because they want to see something new.

In this case, for a moving player (either seeker or tourist), they pick a destination and move with determination to it. The destination is randomly selected from the lowest 10% least recently seen grid squares. Players then move in nearly a straight line until they reach their target destination, at which point they pick a new random destination using the same strategy. Each tick, players move in one of four directions. If the destination requires movement in both x and y, the player randomly picks one of those two directions each turn. Each movement marks the vision radius (10) around the current grid square as recently seen.

I ran 1000 trials for each grid size and seeker strategy (wanders or stands). The seeker finds the tourist if they're within 10 grid squares. The results:

       World   Seeker    2%ile   10%ile   25%ile   50%ile   75%ile   90%ile   98%ile
    -------- -------- -------- -------- -------- -------- -------- -------- --------
       20x20   stands        0        0        0        0        5       14       32
       20x20  wanders        0        0        0        0        3        7       18
       40x40   stands        0        0        5       29       74      123      203
       40x40  wanders        0        0        4       16       36       66      188
       80x80   stands        0       16       71      192      396      605      911
       80x80  wanders        0       11       36      104      222      404      766
     160x160   stands       17      117      342      891     1672     2395     3943
     160x160  wanders        7       64      172      464     1020     1834     3119
     320x320   stands       84      541     1516     3821     6919    10562    18815
     320x320  wanders       69      251      732     2024     4213     6908    12974

This agrees with previous results. On average (median) it's 2x faster for a seeker to wander than stand. In the 90th percentile, it's about 3x faster. In the 98th percentile, it's about 4x faster.

This is maybe a little surprising for this movement model because you'd think even with the bit of randomness the tourist still might visit the whole map more quickly, thus finding a standing seeker sooner. Apparently not -- I'd suppose even in this case the randomness trumps the intent. (Or there's a bug in my simulation.)

**Edit:** Ah! It's worthwhile to consider how many moves it would take if one player stands and the other player takes an optimal route that covers the map.

With this setup with a visibility radius of 10, an optimal route to cover the 320x320 world from an optimal starting point requires somewhere around 5100 steps, the median being half that at around 2500 steps.

In this simulation, a wandering seeker found the tourist in a median of about 2000 steps. This means that **it is on average better for the seeker to wander than stand still, even if the tourist happens to be optimally seeking the seeker.**

**Edit:** Fixed bias in marking a region viewed -- primarily affects the 75-, 90-, and 98%iles. Signficantly less bad for standing in the worst case (for a 320x320 world, 48433 steps became 18815 steps) -- slightly worse for standing in the worst case (for a 320x320 world, 10197 steps became 12974 steps). Updated the table. Does it make any difference if the stander - i.e. you - stand in the optimal position? I.e. is there a big difference between standing in the middle or a corner?  

Plus OP does mention field of vision. So are these models based on literally bumping into each other? In reality even in a busy park you can scan a certain amount and therefore not have to venture completely into the corners.  Why is it common advice that if you're lost, you should stay put? Different situation... For one thing, searchers don't do a random walk, and a list person probably wouldn't, either. "Stay put when lost" assumes people are going to come looking for you, and will start with where they knew you were going to be. If you are lost, and wandering, you are likely to get farther and farther from where people will start looking for you, which means it will take them longer to find you.

If the search uses a spiral search pattern, being twice as far away from the start point means the searchers have to cover four times as much ground before they find you. When searching for people on the ground or from air a spiral pattern is almost never used. That said- the main issue with the search object moving (other than not being where first expected as a last known position) is that it's possible for them to accidentally move from an unsearched area into a searched one. For a multi-day search this could mean you move from an unsearched section while everyone is home sleeping from darkness into an area they searched during the day. The next morning they will skip your new section, obviously. The other factor is that almost no searches have 100% probability of detection so it's hard enough to get spotted as is. I'd subsequent searches are conducted then there is a good chance they will start with areas you more likely should be and with good probability of detection. You don't want to wander out of those areas accidentally.  There is a very good book about lost person behavior which is utilized by the more experienced search organizations to predict the movements of everyone from children to mentally handicapped adults. Why a book on lost person behavior? Because people rarely stay put!!

Source: I'm a SAR subject matter expert and have coordinated many searches and trained many organizations on search theory.  &gt; here is a very good book about lost person behavior which is utilized by the more experienced search organizations to predict the movements of everyone from children to mentally handicapped adults. 

Title? I am very interested in SAR. What would you say is the best thing to do to get seen in these situations? What about if you didn't have flairs or a burning fire? Where are you?  In the woods?  Probably, since a lot of wilderness is woods.  You can start by creating a large area of disturbance, evidence to searchers from the ground and possibly air, that someone has been nearby recently.  Break branches, pile leaves and sticks, make markings on the ground, etc.  Anything that looks out of the ordinary and catches a searcher's eye if only for a second. That's most likely where I would get lost, or on the backside of a snowy mountain. What kind of disturbance is noticeable from the air? Walk out a huge arrow in the snow in the direction you were headed, or put rocks on the snow. 

Arrow for direction, X just to show you are. 
Anything is better than nothing

A fire with smoke is of course good, a flare etc. Bring something if you know you might get lost on a mountain. &gt; Bring something if you know you might get lost on a mountain.

I'd recommend a satellite phone and a GPS over a flare, but that's just me. If I was completely and totally lost, like knocked unconscious and dumped in the wilderness lost, I probably wouldn't assume someone was going to find me in time. I'd head downhill until I find a stream or river, and follow the river downstream until I find civilization.  If I knew vaguely where I was, well, I can figure out which way is which, and I probably know which direction the nearest major road is, so that's what I'd aim for. Is either of these strategies going to significantly harm my chances of survival? Downhill is very common, and following water is always a top likelihood.  Even small children and autistic individuals tend to follow water.  When building a search plan using local topographical maps, moving water is very important because so many groups of people tend to follow it. Thanks. Now I'm curious what kinds of people don't follow moving water.  I'd have to dig back through (lots of data and it's been a while) but I think, off the top of my head, that people with dementia are some of the worst cases of not following standardized patterns like this.  Small children are also tough because they like to hide for security, and often hide too well or become stuck somewhere. Isnt the issue with following the water that you are unable to hear the rescuers. If the water is too loud you wont hear their calls and thus could make the rescue effort take longer.
I an no expert just something someone once told me. Great breakdown! 

Thank you :D Ask the people that get lost in the catacombs. I bet 100% of them wish they would have stayed put. If A stays put and B searches the whole area, there's a 100% chance B will find A.  

If both are moving, the average time may be shorter, but there's a non-zero chance that A and B will never meet.

Most people would prefer wasting two minutes as a general rule to prevent the possibility of exponentially longer searches. No boundaries. In somewhere with no boundaries it is totally different then an amusement part of set size. I once competed in a computer science competition where we had to navigate a maze to find a treasure and avoid a dragon.  We didn't manage to finish our code in time so we handed in a program that would always stay still.  Everyone else tried to navigate the maze and got eaten by the randomly wandering dragon. We came in third.

I'm glad to see our experience was confirmed. Ops question sort of (in a way) mirrors a question I'd always had about the lottery: Are you more likely to win the lottery if you always pick the name numbers or if you always pick a new set of numbers? Same probability.

You can test yourself pretty simply. Roll two dice twenty times each. Count how many times the same number comes up on both. Roll one die twenty times. Count how many times a 6 comes up. 

It should be about the same. It's more likely to be the same if you do it two hundred times instead of 20, but I assume you're a busy person.  (You and another redditor said the same thing, so I'm going to copy this to them, as well)

That's the conclusion I intuitively came up with as well. It doesn't matter whether the match is being made to a random number or to an arbitrary number.

However, again intuitively, Op's problem and mine seem nearly the same. The big difference is that Op's problem allows for the searching party to see the target at any range with an unobstructed view. And, as an aside, wouldn't that mean that both parties are essentially on a 2D plane and always in sight of each other? Couldn't the searching party simply do a 360 and find who they're looking for almost instantly?

So, assuming that both parties are on the same plane with a limited range of view, in both cases (mine and Op's) each side is "wandering" trying to make a match. In my case, the wandering is a random number in a linear set. In Op's case it's, basically a random point on a 2D plane.

So our question becomes the same: is the search party more likely to find the target if they move about or if they stay in the same spot? My scenario gives a 1D line with a visual range of essentially zero, whereas Op gives a scenario of a 2D plane with an unspecified range.

What are the simulations doing that such a disparity between methods manifest whereas my scenario stays the same? I don't think your problems are the same. With numbers on a die, there's complete unconditional randomness. Your problems would be identical if the searcher and searchee randomly teleported each round, but they don't. They can only move to adjacent points and they bounce off the edges, so their current location is conditional on their previous location.  Same probability.

You *can* change your expected winnings depending on what numbers you choose. Numbers over 31 are less commonly chosen. The less commonly chosen your numbers, the less probability of having to split the prize with someone else. So avoid low numbers and obvious patterns (don't pick 34, 35, 36, 37, 38). If this were ProjectEuler, we'd want those as averages out to nine decimals. Would it be possible to apply this sort of simulation to figure out whether it's better to roam around looking for an empty parking space, or 'camp'? Can I ask why you were giving medians? Are the results of trials not distributed normally I imagined sugar in a cup of tea.

You stir it, and the movement causes it to dissolve quicker as collisions occur more frequently.

Having both persons moving, increases the chance *2.

Can you run some simulations for 3 people - how long until 2 meet, how long until those 2 find the other 1. How does having 1 or 2 people stood still affect the time for them to meet? This is a cool simulation, but I'm fairly certain the size of the grid will significantly affect the outcome, assuming the grid is small enough (and I think your grid is small enough that it will affect the outcome).

The average time until collision is large enough that I'm willing to bet they both end up on the perimeter at some point in many of your simulations (avg = ~1000 steps, but they're only a max of 50 steps from the perimeter at any given moment), given reasonable variation in their movement. At that point, they're much more likely to remain on the perimeter than leave, and so they're much more likely to collide (once you're on the perimeter, but not on a corner, you're twice as likely to remain on the perimeter on any given move as compared to leave it; in the corner, it's even a 100% guarantee that you'll remain on it). I'd be curious what the results are like on a much larger grid - 1000x1000 will be closer to an 'infinite' plane than 100x100. This got me thinking, and it turns into a more interesting problem than I thought it would.

Imagine a 4x4 grid. This consists of three different types of points: corners (4 of them) edges (8 of them) and middles (4 of them). So, initial state you have a 1/4 chance of being in a corner, 1/2 chance of being on an edge, 1/4 chance of being in the middle.

If you're on a middle piece, you have even chance of moving in any direction: two of those directions put you back on a middle piece and two put you on an edge.

If you're on an edge you have 1/3 chance of moving to a middle, 1/3 chance of moving to the other edge, and 1/3 chance of moving to a corner.

If you're in a corner, you have a 100% chance of moving to an edge.

So, the odds of your second position being a middle space are (1/4)x(1/2)+(1/2)x(1/3) +(1/4)x(0) = 7/24.

The odds of your second position being an edge are (1/4)x(1/2)+(1/2)x(1/3)+(1/4)x(1) = 13/24

The odds of your second position being a corner are (1/4)x(0)+(1/2)x(1/3)+(1/4)x(0)=1/6 or 4/24.

In fact, I bet as we continue we could make a Markov chain of this. We can make it into a matrix and find the eigenvector for steady state. We'll actually get three eigenvectors, but two of them will have negative values which won't make sense. ~~Lo and behold... the eigenvector with equal probability of being in a corner/edge/middle gives us the eigenvector.~~

~~This means that you *will* have an equal chance of being in a corner as on an edge as on a middle... but there are twice as many edges as middles and corners... so any particular edge piece is actually half as likely to contain a person as a non-edge piece.~~

~~Edit: I tried it with a 5x5 and also found equal chance of being in an state type, but since the middle middle is unique and the EdgeNextToACorner has 8, then those will be the most and least likely places to find them (by a factor of 4 and 1/2 respectively)? Now I'm beginning to doubt my method.~~

~~Edit2: I definitely see why it will always give me a solution of equal odds in every state... and makes me think the Eigenvector-&gt;Steady State assumption has a flaw.~~

**Edit3**: I wrote my matrix the wrong way. Transposed it and for the 4x4 case now I get a steady state solution of 1/3 middle, 1/2 edge and 1/6 corner, which actually puts any middle square as more likely than any edge (since there are twice as many edges), which is more likely than a corner.

Edit4: 5x5 case yields results of 1/20 chance of being in the very middle square, 1/5 chance of being in an "interior edge" (there are four of them, so 1/20 each), 1/5 chance of being in an interior corner (there are four of them, so 1/20 also), 3/20 chance of being in an exterior middle edge (there are four of them, so 3/80), 3/10 chance of being in an exterior secondary edge (there are 8 of them so 3/80) and 1/10 chance of being in a corner (there are four of them so 1/40). Or, 4/80 to be in any specific interior square, 3/80 for an exterior edge square and 2/80 for a corner.
 Hmm. I think you are on to something. Not sure about the eigenvector part but to some extent we must be able to model this using Markov Chains. I'm going to look into this to see if I can add anything but that is a job for Friday/weekend - Algebra exam tomorrow must take priority unfortunately!  Not sure if this is what you meant, but one Markov chain representation would be to consider the state transitions "from middle to middle", "from middle to edge", "from middle to corner", ..., "from corner to edge", "from corner to corner"

If what it is you intended to capture in a (first-order) Markov chain was the probability of transition from one state (M, E, or C) to another, your transition matrix would look like:

[1/2, 1/2, 0

1/3, 1/3, 1/3

0, 1, 0]

With Rows 1,2,3  defined as "from M, E, C", and Cols 1,2,3 defined as "to M, E, C" respectively.

... In the 4x4 case, I should clarify. That's exactly what I meant, yes. And when I worked out those matrices and found the eigenvector (which would be the state of densities that would return itself) I found it more likely to be in the middle than in the edges, and more likely in the edges than the corners. So the question now is whether there is a way to write a rule for the generalized nxn grid. &gt; I'd be curious what the results are like on a much larger grid - 1000x1000 will be closer to an 'infinite' plane than 100x100.

I made a javascript version so you can test for yourself: http://jsfiddle.net/7723nwnm/2/

edit: with multiple runs and averages: http://jsfiddle.net/7723nwnm/6/ So using your tool, a grid of 1001x1001, both wandering is faster, however, after increasing the grid to 2001x2001, It's actually faster for one party to stay still.  Even more so the larger the grid.
[Pic of data runs](http://i.imgur.com/BmUlS7x.png) You have to run more than one simulation per grid size...

* 125627	* 52086	* 2.41	* 250
* 14512	* 484520	* 0.03	* 250
* 110945	* 962	* 115.33	* 250 Ah...  that's better...  So here's 10 runs of a 3k grid... which does favor both roaming.  
 

Both moving mean|One moving mean|Ratio mean
---------------------|--------------------|-------------
35308004|47160010|0.75
  
Trial|Both moving|One moving|Ratio|Grid size
-----|--------------|-------------|------|----------
1|47237450|6306059|7.49|3000
2|54306855|21160083|2.57|3000
3|14248444|4509425|3.16|3000
4|17483318|16708454|1.05|3000
5|11326723|50938117|0.22|3000
6|69064804|35546672|1.94|3000
7|11926114|39828612|0.3|3000
8|38258501|6400663|5.98|3000
9|29479137|196773054|0.15|3000
10|59748694|93428962|0.64|3000
  
 
 Do you think diagonal motion being allowed would help too? I think that would help significantly with getting off of the perimeter, but I might be overlooking something. I tried this in my implementation, http://www.reddit.com/r/askscience/comments/35uljq/if_i_wanted_to_randomly_find_someone_in_an/cr89r0o I wonder...this assumes the searcher is searching randomly.  But how would a systematic search affect things?  A systematic searcher is _guaranteed_ to find a stationary person within the time it takes to search all cells (in your example, perhaps walking to the nearest corner and then covering the space row-by-row).  But for a mobile target there's no guarantee of success.  

Any chance you could see how a systematic searcher stacks up in both situations? I wrote a copy as well, and given that a systematic search of 100 squares would take 99 steps at most, and the mean of the both moving (which is better) was 134, compared to 228 (one static), I think systematic will come out ahead given the assumptions.

http://www.reddit.com/r/askscience/comments/35uljq/if_i_wanted_to_randomly_find_someone_in_an/cr89r0o But the question remains, given systematic searching, is it better for one party to remain stationary than for both to search systematically? 

Also, isn't it awesome that we're finally at a point where we can math/sim this out - right as it's becoming less and less relevant due to the increasing likelihood of both parties having cell phones? ;)  quatch answered the question - according to his data, random searching takes (on average) 134 steps before the people find each other. If one of them sat still and the other searched systematically, the maximum number of steps is 99 (less than 134). So, if one person is static, systematic is faster than random, but that requires some level of cooperation.  
  
Also, they can't *both* search systematically unless there was some communication ahead of time to determine what search system to use (which would defeat the point of the question). For example, take one search method: "Go to the edge, spiral around until you get to the center, then start again." If they both did that, they'd never find each other - unless they'd agreed that one should go clockwise and the other should go counterclockwise.  
If they can discuss a strategy ahead of time, the fastest way would be to agree to meet at the center, which is a boring solution. I don't know about systematic search patterns, but you're starting to touch on the idea of what's know as a Schelling Point.

[Wikipedia](http://en.wikipedia.org/wiki/Focal_point_%28game_theory%29) gives a breakdown of how they work in theory, and there have been numerous trials that have shown that people do rely on Schelling points when they are unable to communicate. To put it into your question, the optimal search pattern may be one that A) focuses toward the most popular ride, B) focuses towards the talles landmark, or C) focuses on the entrance. &gt; A systematic searcher is guaranteed to find a stationary person within the time it takes to search all cells

Just an aside, but a random walker in the plane (2 spatial dimensions) is also *guaranteed* to eventually find a stationary "target" (under certain conditions, like isotropy), because the fractal dimension =2. what if the other person moves to an area that the searcher has already been?  That's kind of my point. It seems from the simulations that a random searcher finds a random mover faster than a stationary one, but I suspect that won't be the case for a systematic searcher, for the reason you mention. Simple proof of the fact that (for an infinite grid) it will take on average half the time when both are moving:

If the lost person does NOT move, then the question is how long it takes a random walk to get back to a fixed point. We will reduce the situation where both people move to this situation. Just observe that two people taking moves simultaneously is the same as alternating between moves (instead of A and B moving simultaneously, let A move then B move, then A again and then B again, etc.).

Now we can see that when B moves, that's the same thing as A moving in the *opposite direction* (at least on an infinite grid). But there was a random chance of B moving in any direction, so we might as well have B never move and have A move in a random direction *twice* each round, once for itself and once for B's movement.

So now we're back to one person standing still and the other moving, *but* we've now got the first person moving twice as often. So whatever the (average) time it took with one person standing still, it will now take half that.

Neat! Fun question.

Edit: And I should add that it's known that even on an infinite grid, a random walk like this will eventually "return to where it started", that is, it will eventually find the stationary person. However, this is only true in 2 (or 1) dimensions! In three dimensions, a "drunken walk" can get you hopelessly lost. Luckily most park goers are confined to a measly two dimensional surface. This also justifies why it's okay for me to say that the average will be halved when they are both moving - in three dimensions we don't even have an 'average' to talk about but in two dimensions we do. A and B moving simultaneously is not the same as alternating between moves in the way most of the people here are interpreting things.

One major example is if A and B are adjacent and both move in the same direction simultaneously. Most people here consider that to be a miss.

A different case that is less clear cut is when they're adjacent and swap places. People here seem to allow that to be counted as a miss, but I could see a good argument for counting that as a hit. I really like this line of thinking, it's very creative - but I'm unsure of the conclusion.

Can you detail a bit why you think the average time is halved?  My gut (often wrong) seems to think that the average time will be the same, but the deviation will be doubled?  Once we double the speed of 'B', don't we double the probability that 'B' will get farther away from 'A' equally as much that 'B' will get closer to 'A'? **Edit**: After running it again, with 10x more samples (below) the results converged.

hey, you beat me to it. I also used a 100x100 grid, but only 10k replicates (discarding co-start), and with Queen's movement.

    &gt; summary(dataA) #only one moving
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
        1.0    46.0   120.0   193.7   256.0  2657.0 
    &gt; sd(dataA)
    [1] 228.633

    &gt; summary(dataAB) #Both moving
       Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
       1.00   37.75   92.00  134.10  187.00 1304.00 
    &gt; sd(dataAB)
    [1] 134.1485

code: http://pastebin.com/PMqDqquw  (in R)

Edit: Ok reran everything with 100k simulations, but also saved stats on how many times each square was walked through.

DataA:  print(summary(dataA));print(sd(dataA$steps))  #A:Random, B:Static    
    
         steps             min               q1               md        
     Min.   :   1.0   Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  
     1st Qu.:  38.0   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 2.000  
     Median :  93.0   Median : 1.000   Median : 1.000   Median : 2.000  
     Mean   : 134.6   Mean   : 1.025   Mean   : 1.908   Mean   : 3.095  
     3rd Qu.: 187.0   3rd Qu.: 1.000   3rd Qu.: 2.000   3rd Qu.: 4.000  
     Max.   :2086.0   Max.   :10.000   Max.   :29.750   Max.   :43.000  
           me               q3              max       
    
     Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  
     1st Qu.: 2.000   1st Qu.: 2.500   1st Qu.: 5.00  
     Median : 2.857   Median : 4.000   Median : 9.00  
     Mean   : 3.553   Mean   : 4.695   Mean   :10.04  
     3rd Qu.: 4.344   3rd Qu.: 6.000   3rd Qu.:13.00  
     Max.   :41.720   Max.   :52.000   Max.   :68.00  
    [1] 135.3912 #Stdev: Steps

dataAB:  &gt; print(summary(dataAB));print(sd(dataAB$steps))   #A:Random, B:Random   

          steps             min               q1               md        
      Min.   :   1.0   Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  
      1st Qu.:  38.0   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 2.000  
      Median :  93.0   Median : 1.000   Median : 1.000   Median : 2.000  
      Mean   : 135.1   Mean   : 1.026   Mean   : 1.912   Mean   : 3.099  
      3rd Qu.: 188.0   3rd Qu.: 1.000   3rd Qu.: 2.000   3rd Qu.: 4.000  
      Max.   :1598.0   Max.   :10.000   Max.   :23.750   Max.   :33.000  
            me               q3              max       
      Min.   : 1.000   Min.   : 1.000   Min.   : 1.00  
      1st Qu.: 2.000   1st Qu.: 2.500   1st Qu.: 5.00  
      Median : 2.857   Median : 4.000   Median : 9.00  
      Mean   : 3.560   Mean   : 4.707   Mean   :10.05  
      3rd Qu.: 4.348   3rd Qu.: 6.000   3rd Qu.:13.00  
      Max.   :31.960   Max.   :38.000   Max.   :69.00
      [1] 136.0619    #Stdev: Steps

which should be read as the aggregated statistics (in columns) for all of the runs. Eg. the min column is "the minimum number of times a square was walked through (discarding zeros)", and has rows describing the distribution of that over all 100k runs. "steps" is how long it took for them to meet (as in the orig. data). *Reading the mean or median row is probably what you want.*

updated code: http://pastebin.com/0MiLTf1g

**More Edit: Systematic Search**

DataAgB:  &gt; print(summary(dataAgB));print(sd(dataAgB$steps)) #A:Systematic, B:Random

          steps             min               q1               md        
      Min.   :   1.0   Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  
      1st Qu.:  36.0   1st Qu.: 1.000   1st Qu.: 1.000   1st Qu.: 1.000  
      Median :  86.0   Median : 1.000   Median : 1.000   Median : 1.000  
      Mean   : 122.6   Mean   : 1.065   Mean   : 1.818   Mean   : 2.388  
      3rd Qu.: 170.0   3rd Qu.: 1.000   3rd Qu.: 2.000   3rd Qu.: 3.000  
      Max.   :1745.0   Max.   :10.000   Max.   :31.000   Max.   :36.000  
            me               q3              max        
      Min.   : 1.000   Min.   : 1.000   Min.   : 1.000  
      1st Qu.: 1.526   1st Qu.: 2.000   1st Qu.: 4.000  
      Median : 2.000   Median : 2.250   Median : 7.000  
      Mean   : 2.890   Mean   : 3.557   Mean   : 8.181  
      3rd Qu.: 3.511   3rd Qu.: 4.250   3rd Qu.:11.000  
      Max.   :34.900   Max.   :40.250   Max.   :52.000  
     [1] 121.3984 #Stdev: Steps


Updated Code: http://pastebin.com/fUrkHp7M
 Does it change if the looker progresses through the grid orderly and only visits each square once before starting over? That's a good question.  Assume one person is methodically searching.  If the other person is standing still, you'd expect, on average, to encounter them after searching roughly half of the park.  However, if they are moving in a way that is unaware of your movement, I don't think there's any reason you'd be more likely to find them.  At every time point, their location would be random and you'd have a 1/x chance of finding them (for x 'locations').  However, you could search through the whole park and miss them in this scenario as they could move around you to a spot you already visited.

I think it's like the difference between trying to draw the Ace of Spades out of a card deck with and without replacement.  Would be interested to see a simulation with this constraint, though. I feel like the average moves would be the same between methodical and random searching, but methodical searching might have less deviation from the average. But most people here aren't modeling this as a park you get around by teleporting from one location to another, so it's not so much like drawing cards from a deck. Ah, that's a good point.  The position of the other player isn't totally random, just the direction of the change in position. It very well could. The simplest example is if the the entire park laid on a line, in which case moving from one end to the other is definitely better than reversing course prematurely. I bet many other topologies result in there being strategies much better than a random walk.

Related: this [fox hole puzzle](http://gurmeet.net/puzzles/fox-in-a-hole/). The problem with this simulation is that not many places are laid out like a grid. Amusement parks are constructed as a continuous path, very few dead ends or corners. Rather than hitting the "edge" of a grid, you simply continue in a looping path (ala Pacman)

Instead of modelling a grid, if you model a racetrack or railway with many different intersecting paths, I'd hazard a guess that both people moving would have worse odds, since it introduces the possibility that they move in the same direction and never meet.

In this "track" system, most likely one person standing on the intersection of the greatest number of paths while the other moves is the most effective method. Of course not. In an actual amusement park there are actually a lot more variables than what were brought up in this entire thread. But OP posted a very interesting question to initiate thinking. Like he said,
&gt;the theme park is just used to personify a general statistics problem IMO its a more interesting problem to assume intersections and loops than just to assume its a massive grid where people move in random directions.
 Anyone who has raised children knows this is the most practical approach. 

An amusement park, a mall, downtown area, etc have crowd-flow corridors, not discrete points or squares.  If we are going to make it more realistic and utilize tracks instead of grids, we should factor in the possibility of both nodes choosing to follow the same approach of staying in one spot as well, in which chances of reunification are null. 

P= Can I get an /r/explainitlikeimfive answer to this?  Comment is about simulation person wrote that shows its faster for both people to move than for one to stay in one place. In fact, on average, its twice as fast for both people to move around.

The simulation was run on a 100x100 square grid. At the start of the simulation, two people are placed on random squares. From there, they move to one of the squares next to them at random. If they end up at the same square, they have found each other. They are not allowed to go off the board. They also could not pick an invalid move like choosing to go off the board. 

The graph's x axis is the time a simulation took (pick an arbitrary time unit like minutes, so less is better), and the y axis is the number of simulations that took around that time. So for the 500 time bucket, of the simulations where only one person moves, ~40k of those took around 500 [minutes] and of the simulations where two people moved,  ~55k of those took around 500 [minutes]

The excel graph is pretty much self-explanatory. Those results are interesting. In a more real-world scenario I'd anticipate the moving search to have an even greater advantage, as the simulation does not take into account variable velocity. In the example given, a person wandering the theme park will alternate between walking and stopping/looking at things. This would further amplify the advantage of the moving while searching approach, as when the target stops, the stationary searcher's chance to find the target would drop to zero. Interesting approach. Of course, in a real amusement park there will likely be a bottleneck or major intersection of some sort, and the best strategy will be to stand still at that point.  this is not sound. moving randomly is not the way someone looks.

aka in your simulation someone might move left and right repeatedly or overlap. they also get stuck to the edge.


what would be closer to a real simulation is someone will move randomly but weighted in a manner to discourage backtracking.

there are different movement strategies, like what if you moved randomly but only in 1/2 of the park? 1/4 of it?

the math is simple make  1x5 grid and put people at 1,2 and 1,4

25% of the time they'll meet in 1 move if both move towards each other.
0% of the time they'll meet in 1 move if one stays still

if they both move, they'll meet 2 out of 5 times for second move
if only one moves, 33% of the 2nd moves 

they'll meet much higher if you deprioritize backtracking.


that is, analyzing the 1x5 grid they'll move towards each other by default if they prioritize the paths that in n moves have the least number of redundant visits



to answer the op, the odds are the same. imagine shaking a ball around in a bucket. the odds of it hitting an X on the wall of the bucket are the same if the X is moving or not. this is not the same as your problem statement, of course, because you have the cases where people "randomly" move and spaz out... a ball bouncing around in a bucket has more meaningful, or predictable movement. But if that X was moving around the odds do not decrease or increase of the ball meeting it. Even if the ball was magically randomly moving, it wouldn't be the case.

 Half as long makes sense to me. In the both move case, motion of a person relative to the other person is twice that of the stand still case. It's as if the second person is taking twice as many moves per time step. This is ignoring boundary effects. Just want to go ahead and say that I love computers. You were just nonchalantly able to say you ran 100k trials like its no big deal. Oh the world we live in! What happens if one person moves quicker than the other person? I am slightly disabled so whoever looking for me would generally move twice my speed. So A would move twice the speed of B. In this scenario, how much difference would it make between B moving and B staying still? I don't think this is right.  Assuming your random walk rules, where each walker moves randomly to either the north, south, east, or west, we consider the simplest lattice, a 2x2 grid.  There are essentially two starting conditions for this lattice:

* the walkers sharing a diagonal, i.e., on opposite corners
* the walkers sharing an edge, i.e., on a single side.

In the first case, the probability the walkers meet for the first time on their nth move is 1/2^n.  This is seen by noting that the walkers either meet, with probability 1/2, on their first move, or are in an equivalent arrangement to their initial condition, i.e., on opposite corners.  This process repeats until they meet.

However, if the walkers share an edge they will never meet.  Any move leads them directly back to their initial condition in which they share an edge.  This is because the only two composite moves available to the walkers are an exchange or a move to one of the three other edges.  In larger grids, similar sets of initial conditions always exist; they are whenever the difference between initial conditions in one dimension is an odd number of sites and the other is even.

Of course, the simple result described above relied on your particular set of rules for the random walk.  Different rule systems, for example, the inclusion of a 'stay' option or the incorporation of a 'viewing range', would clearly complicate this simple analysis.  However, I think that rule systems which eliminate the above difficulty will tend to lead to average identical times because you can map the two moving-particle system to a one moving-particle system by fixing one of the particles.  This is only simple in periodic lattices, but for a big enough closed space a periodic approximation may be appropriate.

I believe your result, in which both walkers moving leads to them meeting in half the time is a quirk of your numerical code.  My guess is that you check to see if the walkers are on the same spot after each move of individual walkers but count steps after both walkers have moved.

Interestingly, the answer to this question is never in continuous space (well at least for simple diffusion in a periodic space, though I believe this is a dimensional issue and will hold for all point interactions in dimensions greater than one).  The issue arises due to the non-existence of the Laplace transform on functions going as 1/t at early times. Where was the non-moving person standing?
Is there any difference in location (e.g center of park vs. corner)?
I would assume the center has the highest chance of collisions Isn't picking a random direction not the way a human would act though? If you were recently in an area you would probably assume that the other person is not there so you wouldn't return there for X amount of time. Would it be possible to simulate this? Would it be correct to think of this problem sort of like flowing water in a stream? Let's say the paths are the creek bed, and the people are the water. Now this ignores the fact that people don't necessarily flow like current (they can go any direction on the path they wish), but I'm curious if this is the driving principle behind your results. Moving around increases the number of people you come into contact with. I don't think the movement should be completely random, you should place increased weight on moving straight forward and to a block you haven't been to or left/right, and even less on going back or to a place you have already been. I think we should also assume the two will start relatively close to each-other but also out of their field of vision. Usually you start looking for someone fairly soon after you lose them. &gt; anyone that's moving will randomly move north, south, east, or west.

That doesn't seem like a very realistic representation of a person moving through a park, or really anything for that matter. Surely they would decide on continuous paths to follow. Why is it common advice that if you're lost, you should stay put? It's advice for people in wilderness where the boundaries are less well defined. In a confined space, the parameters change. Depends on if your last location is known, and if your environment has boundaries. If you're lost in a shopping mall, feel free to go looking, but stay in the mall. You can't really get more lost. But if you're in an unknown forest, you're just as likely to worsen your situation and make things harder for anyone searching for you.  That assumes that others will think you lost as well and come looking for you. You are probably in a location that is part of the other person's travelled path or close to it so person b can just backtrack and look around to find you quite fast without searching the full park.   
If a is not true (meeting someone) you are probably better off going to some highly visible spot if available.  
If none are available and you do not share known locations the simulation result might be best :)
 Could you post your code, or how you did it?   &gt; They can't move out of the 100x100 grid

I wonder how the simulation would play out if movement were unrestricted and the people could go out one side and come back in the other.

What's the optimal strategy for an amusement park built on a 2-torus? I wonder if there are any real world statistics and how they would correlate with this question. Surely there are plenty of people who loose someone at parks, shows, malls, and other densely packed events.  Just using logic, when you are moving a round you see more people per unit time so will generally run into the person you are looking for faster.

in real life we have some system to the way we walk not a random walk so the situation becomes more confusing, it really depends on how the two people decide to walk. Would you mind sharing your code on Github or Pastebin? Is there any value to people in this being a true gaussian random walk versus a grid world?  I coded this up in a circular area with radius 100. and step-size 1., but it's in python and running pretty slow at about 3 experiments/second (an experiment is over when the two people are within distance 10. of each other).  I'm happy to run them, but don't know if there's anything here you can't get from a gridworld. I run a company that does simulation analysis, including pedestrian traffic studies. We've done pedestrian flow analysis for clients ranging from theme parks to the federal government. Here are my thoughts:

* I agree with the idea that on AVERAGE you will have a shorter search time with both parties moving. However, if both parties are moving you will have a much longer tail on your search times. There will be circumstances where due to random behavior, both parties move in such a way that they don't find each other for a substantial amount of time. So, one party remaining stationary will take longer on average, but the search time will be more consistent. 
* Random movement does not account for "high traffic" and "low traffic" areas, let alone areas that a person will necessarily move past at some point (like the exit).
* I disagree with both the grid approach and the 100/1 ratio of search space to detection. 
 - I just did a quick measure of Epcot's world showcase, and the main path is a loop approximately 1.6 km long. There are another 2+ km of paths in other parts of the park. If there is heavy crowding, 3m would a good approximate for 95% detection. If there's light crowding, perhaps as far as 30m. 
 - Many of the paths are linear (including the 1.6 km one mentioned above), meaning that the movement isn't completely random - even if the destination is the person will be following the path
* None of these analyses consider the target being inside a building / on a ride. You can black-box this that the person simply can't be found when they're inside an attraction and only search main pathways, or you can program in logic such as searching the shop / camping near the ride exit for a specific period of time. Regardless, someone being in a queue + ride for an hour or more (and the majority of their time at such a park) is a reality that must be considered.

TL;DR you've got the right general idea, but a lot of the details that your model abstracts can have significant impact on the results. [deleted] Does this include the moving seeker LOS? Or just randomly bumping into one another? I imagine if it includes an individual actually seeking someone then it might be even faster. The Simulation is biased.  the foot traffic is not equal like the assumption states.  So the walkers will be in the areas more likely for walkers to be and that is why you got the results.  If a stander accounts for traffic then they stand in the most traffic dense region they will be more likely to find the person than walking around.   Is this still true when directionality is not limited to cardinal directions? I.e. they are free to roam in an arbitrary direction? This doesnt really reflect the problem at hand. Most theme parks aren't 100100 grids. A more accurate simulation would be to take a map of a park and create a graph with nodes as intersections and edges as paths between intersections. The length of the path being the wieght for that edge. Finding a person would be if two agents cross a path in opposite directions or if agents land on the same node.

If you take the matrix of this graph, you can calculate the most connected node and just find how likely a single agent traversing the map randomly would enter that node in a given number timesteps. 

You could make it a much harder problem to solve and add a secondary weight to the edge dependent on traffic on the path to catch some probability that you miss the person. Or you could look at long horizons maybe by examining the errogodic nature of the matrix, maybe even build a Markov process, and simulate different search heuristics. This is the basis for why sperm are motile and eggs are not.  It has evolved because it is more successful than the alternative. I think you replied to the wrong comment because the simulation provides evidence making it slower for one to stand still while the other moves. I think your comment is more relevant to the explanation given to why everyone says to stay still when people are searching for you. Which is so they have an idea of where to look.    

Perhaps though you were noting the evidence of the top reply that in smaller grids staying still is favored. For those interested in investigating these kind of phenomena, this is usually studied with "Agent Based Modeling/Simulation". One of the most prominent applications to develop these kind of simulations is [NetLogo](https://www.youtube.com/watch?v=D9iD72cuh98).  I used it a lot to teach ABM and Simualtion to PhD students who were in non-computer related fields (Social Sci, Agriculture, Rural Dev, etc). 

 May I please see your code? 

Also, what kind of dev environment do you use? I don't personally know any Java devs who use Windows.  If you are moving then there are more collisions (e.g. brownian motion) with others. If the people (or objects) are truly moving randomly then if both people are moving there is a greater chance of collision than if only one is moving. 

Source: I am using the analogy of enzymatic efficiency: there is greater successful (desired) collision when both molecules are in motion. &gt; If the people (or objects) are truly moving randomly then if both people are moving there is a greater chance of collision than if only one is moving.

How can that be? Even if one is stationary they're moving with respect to each other. If you have an idealized 2-particle universe, it is not possible that the chance of a collision is affected by whether one or both particles are in random motion. Can you provide a link, please? In an idealized 2-particle universe, the energy of the universe would increase if both particles are in random motion. Presumably the chance of a collision increases with energy, but it's been so long since I looked at statistical thermodynamics that I can't remember the exact equation, and it's possible this isn't quite right.

A bit of googling leads me to a calculation of the mean free path, which is associated with particle collisions: http://hyperphysics.phy-astr.gsu.edu/hbase/kinetic/menfre.html#c5

Based on this, the average relative velocity increases if both particles are moving, which will lead to an increase in particle collisions. 

Edit: I might have it backwards. In an ideal gas, the frequency of collisions actually decreases as the temperature increases. Of course, this doesn't exactly model the system of 2 particles in a constrained box, but I may have been too quick to dismiss the naive statistical approach: http://hyperphysics.phy-astr.gsu.edu/hbase/kinetic/frecol.html

Edit2: Another resource suggests the exact opposite: http://chemwiki.ucdavis.edu/Physical_Chemistry/Kinetics/Modeling_Reaction_Kinetics/Collision_Theory/Collision_Frequency

Intuitively, you'd expect collision frequency to increase as temperature rises.

Edit3: My second link doesn't automatically raise the pressure as you raise the temperature. If you use the ideal gas law you'd get an increase in pressure along with an increase in temperature, which accounts for my confusion. SAR-Paradox is correct. This is correct. In layman's terms, the more kinetic energy, the increased frequency of collisions. Mean free path is the way to go about this. Figure out how much ground each is covering per time, and as each particle covers more ground, its odds of running into the other particle's location increases with it. It doesn't feel right to use those calculations without assuming some kind of uniform average particle density, and we are at an opposite extreme of 2 randomly moving particles. Of course: 

[Collision Theory](http://en.wikipedia.org/wiki/Collision_theory)

[Collision Frequency](http://chemwiki.ucdavis.edu/Physical_Chemistry/Kinetics/Modeling_Reaction_Kinetics/Collision_Theory/Collision_Frequency)

Mind you i am using molecular collision theories as an analogy so the physical kinetics only remain true if we assume that the two people looking for each other are moving completely randomly.

At an abstract level: the frequency of collision increases when the total energy (kinetic) in both molecules (people) increases. So if both are moving then the total energy is higher and thus they are more likely to find (collide with) each other if they move completely randomly. 
It is also worth noting that this analogy does not account for the mentioned "vantage points" or "lines of site" throughout the park.  If they're both moving, then the relative velocity between them will be higher than if only one is. And if they are moving in the same direction, the relative velocity between them will be lower. If they're moving randomly, their movements will be uncorrelated. If you imagine the different directions the vectors could be pointing and add them up, then 2/3 of the time the sum will have greater magnitude and 1/3 of the time it will have less (assuming the two things are moving the same speed). How could that be true? If I am standing in a room with someone half the directions I can walk are away from them and half are towards them.
 Half are away and half are toward, but we're comparing vectors to vectors, not rays to points. So once we pick a velocity, we want to compare ours to theirs. So, suppose we have our random unit vector in the plane, picked uniformly. Let's look at the arc of the unit circle, centred on the end of our vector (assuming our vector starts at origin), and bounded on either side by the furthest points on the circle reachable via a straight line segment of length 1 from the end of our vector. This forms, extending to the disk, a sector 2/3 radians "wide." Any vector inside this sector, when subtracted from our chosen vector, produces a difference of magnitude at most 1. This is exactly 1/3 of the circle, and thus of possible random unit vectors possible for the other velocity; and since our vector was chosen randomly from the uniform distribution, we have the result. It holds for a similar reason on the sphere, albeit a bit more of a pain having to use cones.

(I may have skipped several steps, but I'm trusting the idea makes sense. As for why it's 2/3 radians, our vector, the vector to either endpoint of the arc, and the vector connecting the end of our vector to the end of the arc all have length 1, forming an equilateral triangle.)

*edited for spelling* Lets reduce the problem to a simpler one- two points in a 1 dimensional world. At each point in time the points can move one step to the right (+1) or one step to the left (-1) or not move at all (0). Let's assume that each of these options has equal (1/3) probability.

First lets consider the situation where one of the point is held stationary, and the other point can move. In any step in time, the point can move either towards or away from the other point, but given enough time, it will randomly move back and forth until it will intersect the other point.

Now lets see what happens when we let both points move. As was mentioned earlier in the thread, this is equivalent to having one point move but we have to properly add the motions of the two points. The possibilities are -2 (1/9 probability) -1 (2/9 probability) 0 (3/9 probability) +1 (2/9 probability) +2 (1/9 probability). So it's still stopped 1/3 of the time, but when it moves, it has the possibility of moving further. This means that it's going to have bigger swings back and forth and will therefore intersect quicker. One way to think of it is, set the origin at one particle.  The roll your die for each particle, move them, and also move the origin as necessary.  

One particle never moves, but the other particle moves twice.  The motions may cancel, but all-in-all it'll cover twice as much ground.  If you'd expect it to, say, have a 50% of crossing a line in 5 minutes, now it should do it in 2:30.

(I think). That's an excellent explanation. Thanks! Add to that a psychological aspect, both parties will have some targeted areas to look in also, which will increase that chance a lot more than anything else would EDIT TL;DR It depends on how the park is designed. If you stand still in a spot that's unlikely to be visited, like some offshoot of the park, it will take longer than if you walked around, but if you stand in the middle of a * - shaped park, it's better than walking around.

If we model this as a (lazy) random walk on a graph, expected time for you two to find each other in the situation where both of you are walking is known as the *meeting time*. In the case where only one of you is walking, this is the *hitting time*. Let *M* denote the meeting time in the worst starting position, and *H* the worst hitting time. We want to compare H and M.

It turns out that the inequality

M &lt; K H

holds for some constant K (and apparently it's possible that K is as small as 1/2). [Details and a complete answer here](http://www.stat.berkeley.edu/~aldous/Papers/me38.pdf). The inequality appears as Proposition 1. It thus seems that the answer (as of that paper) is unknown for general graphs (i.e. general layouts of the amusement park), and depends on whether this K can be brought down to less than 1 or not.

IMO the other answers so far don't model the situation as well. Amusement parks are not generally arranged as grids, and they're not translationally invariant (so looking at the other person's movement as an origin shift is inaccurate), and I suspect that whether M&gt;H or M&lt;H depends on the underlying graph, i.e. the way the theme park is laid out.

EDIT: In fact, I think I do have an example of a graph where M&gt;H and another where M&lt;H for specific starting positions. The first is a star graph, with one person standing in the middle, and the second is a large clique with one extra vertex connected to the clique by one edge, where one person starts at the extra vertex.  /u/GemOfEvan and others have given a monte-carlo solution with the tally converging to half the time if both are moving as opposed to one standing still. However the reason it is half the time can be easily understood using a transformation of reference frame. If the seeker changes from not moving to moving at a velocity v, then in his instantaneous rest frame this looks like the person he is seeking changes his velocity from v to 2v. From this point of view, it is clear that the person he is searching for will inevitably cross his path twice as soon if he is moving twice as fast. This can be worked out cleanly using only Galilean transformations for those that want to see an actual mathematical proof and is left as an exercise to the reader. Why do the velocities add up? If both move in the same direction, the relative velocity is zero. Side note:  in real life, you always move.

First, for whatever reason, you can't know that they aren't standing still themselves sometimes- random motion doesn't have to mean continuous motion.  They could be on a ferris wheel with a near stationary position relative to the park size.

Second, given the geography of the place, you can always optimize your search- he's moving randomly, you're not.  Orbit the center of the place, check the extrema on occasion, etc.

Thirdly, standing stock still in an amusement park for up to infinity hours is just depressing.  Take a walk, get an ice cream. It depends where and in what situation you stand. If you stand at the exit and cause the park to be evacuated, it's most efficient, but I suggest you get your ice cream first, just in case they won't let you in afterwards. It's simple. We free the slingshot ride from its constraints and wait for the panicked crowd to either disperse to the perimiter or exit. Assuming you came together, they're either in the car waiting for you or around the edges of the park. Or they're desperately trying to flee from you because you're a dangerous psychopath, killing random people on his way - maybe that's the reason the other person didn't want to be found in the first place... Actually it's both.  You walk to the security office and get them to put out a call for the person you want.  Then you wait for them to come to you. You can't just throw out the assumptions of the question.  That is exactly NOT answering the question. Imagine that both people are standing still: the chance of you two colliding is zero if you don't start in the same spot.

Next, imagine one person is moving very slowly: it will *probably* take a long time for you two to collide.

Now, what if one person is staying still, and the other person is moving really quickly: the *expected* amount of time to collide goes down, because the moving person is going to cover ground faster.

**What if both people are moving?**
This is almost exactly the same as if one person is completely still, and the other person is moving as fast as both people combined! &gt; What if both people are moving? This is almost exactly the same as if one person is completely still, and the other person is moving as fast as both people combined!

I think this is the hard part to grasp, because the immediate thing that I (and presumably most) people think is that with both people moving, there is a chance that they could never meet and yet both fully cover the whole park, whereas this is not a possibility with one person staying still (and the other fully covering the whole park), so it doesn't feel "almost exactly the same" This brings up a point for a more real-world example of this problem. In reality the other person will not be moving completely randomly, but will be less likely to backtrack and more likely to explore new areas. (Although they might return to a few of their favorite rides, we can ignore that for now).  

If the other person was moving randomly, but with a preference for unexplored terrain, what would be your optimal strategy? Should you still move randomly or should you also attempt to explore the entire park? Explore the entire park in reverse flow of normal traffic at high speed. This is what a panicked mother does without even thinking about it. The other advantage is this exposes you to the maximum number of different people, so the odds that one of those people flowing past you the other way is your child also looking for you is increased. Statistics are rarely ever intuitive. That's what makes the field so valuable. The fault in logic here is that a random walk will fully cover the whole park. A true random walk would involve randomly picking a direction (maybe by rolling dice), then walking a distance in that direction (could be a fixed distance every time or a random one), then stop and repeat. To find a random walker, it's better to random walk yourself than it is to stay still. 

A different and interesting question is, is there a BETTER way search for a random walker than this? Without any additional info about the geometry of the park, my intuition says that a random walk is the best you'll get. &gt;  What if both people are moving? This is almost exactly the same as if one person is completely still, and the other person is moving as fast as both people combined!

Qualitatively right but quantitatively I don't think that's correct... since the directions of motion are independent and random, the relative speed (that is, speed that one person sees the other one moving at) is not going to be 2 on average.  A quick mathematica calculation (below in case it's wrong) shows that the average relative speed assuming the two people are both moving at velocity v with a random orientation with respect to each other is 4/ \* v, or about 1.27 v.
It's the right conceptual way to look at it though.


    (*relative velocity of person B from person A's reference frame, 
    assuming A and B are both moving with speed 1 and person A is moving 
    at angle theta=pi. *)
    velocity[theta_] := {1, 0} + {Cos[theta], Sin[theta]};
    (*speed of person B relative to person A*)
    speed[theta_] := Sqrt[Dot[velocity[theta], velocity[theta]]]
    (*Integrate over all angles from 0 to 2pi linearly (due to assumption 
    their directions are set randomly and independently), then divide by 
    2pi to get the average speed over all angles *)
    Integrate[speed[x], {x, 0, 2*Pi}]/(2*Pi) // N
    (*output: 1.27 (or 4/Pi exactly)*) the reason it's correct is you can consider one person to be a reference frame. all of their movements could be considered negative additional movements on the second person. sure a person might move away from the second person in one move, then toward them, but that's also the case if they are the only one moving. the key thing is twice as much random movement is occuring. I think the average time of finding someone by standing still would be more consistent, for example someone wandering around might pass through there every hour. 

If you're wandering around too, then the mean time-to-find is probably the same but with a higher deviation, for instance you may run into them in 3 minutes or you could be just missing each other for hours.  I see what you're saying, but couldn't your second point also be true when standing still? The person could randomly walk into you in 3 minutes, or they could randomly wander everywhere but your location for hours [deleted] You also have to take into consideration that people in general are methodical and not random. If they've checked one area of a theme park they're less likely to check there again.  This is why if you are actually lost, you should not move around because you will be more likely to be evading your rescuers than moving towards them. This absolutely applies in a wilderness setting. If you are truly hopelessly lost, stop moving. Set up camp and stay put. 

You should always tell people who are staying in civilization where you will be and what your plans are so when you don't turn up, someone can raise alarm. 

If you just go wonder off thinking you're going somewhere though, it's just making things harder on your rescuers. 

Source: Eagle Scout before everyone had a cell phone.  But now we have conflicting practical answers. In a real park, assuming the other person is probably looking for you but also semi-randomly wandering while enjoying the park, what should you do? Is the other person just roaming or are they actually looking for you? They might reasonably start off roaming but eventually decide to start looking for you, in which case they would probably avoid places they have already been. I would imagine that as long as you stay still, they would find you with some consistency (provided they are looking for you) But there's an assumption that you've made that you're walking randomly which isn't actually true. If you're looking for someone, you'll look in places you haven't looked yet. You won't actually move randomly... [deleted] **TLDR**: if you know your target will always be moving, it doesn't matter; the odds will be the same. If, however, they might also stand still from time to time, then moving is strictly better than standing still.


**Code**: I wrote up the graph walks over at https://github.com/Pomax/AmusementParkProblem with a run-in-the-browser page for it over on http://pomax.github.io/AmusementParkProblem


**An explanation**


Let's model the amusement park as a graph, with "places to be" as nodes, "paths to walk from place to place" as edges, and "finding someone" either being on in the same place or walking in opposite directions on the same path, so you bump into each other (or at least see each other as you pass by). I'm also going to assume you don't start both in the same place, for obvious reasons.


For any graph with 'n' nodes, we can set up all possible "who is where" configurations, and then see what the odds are of finding each other in a single step. We'll either find each other, or we'll end up in a starting configuration, so if we don't find each other on step one, the odds of finding each other on the next step follow the same model.


You also stipulated that the person you're looking for HAS to move, but this seems silly. They're not looking for you, so they could very well be standing still, too. That gives us two problems to look at: which of the "I stand still" vs "I move around" tactics wins when (a) my target *must* move, and (b) my target *can* move.


**Let's begin!**


The simplest amusement park has an entrance, a ride, and a way to get from one to the other. Boring, but let's look at it anyway. There is only one possible starting position:


1. (you)---(target)


If we follow your rules, and say our target *must* move, then:

- if we don't move, and our target moves, we'll meet on the left.

- if we do move, and our target moves, we'll meet on the way.

Odds of meeting as nomove:move = 1:1


If we follow the slightly more realistic rules where our target *may* move, then:

- if we don't move, and our target moves, we'll meet on the left.

- if they don't move, we won't meet.

- if we do move, and our target moves, we'll meet in the middle, and

- if they don't move, we'll meet on the right.

Odds of meeting as nomove:move = 0.5:1


In this very boring park, depending on what our target's policy is, "moving" is as good as, or better than, "not moving".


So let's look at the three node case. We're assuming no dead ends so we're looking at a ring with three nodes, and two possible starting configurations:


1. (you)--(target)--(   )--(you), and

2. (you)--(   )--(target)--(you).


That looks like four nodes, but the last node is the first node, used to show the ring being closed. Both we and our target have two directions we can walk in, left or right.


If we follow your rules, and say our target *must* move, then:

- if we don't move, and our target moves left, we'll meet if we start from 1. and won't meet from 2.

- if we don't move, and our target moves right, we won't meet if we start from 1. and will from 2.

- if we move left, and our target moves left, we won't meet form either start.

- if we move left, and our target moves right, we'll meet from 1. and cross paths from 2.

- if we move right, and our target moves left, we'll cross paths from 1. and meet from 2.

- if we move right, and our target moves right, we won't meet from either start.

Odds of meeting as nomove:move = (2 out of 4):(4 out of 8) = 1/2:1/2

If we follow the slightly more realistic rules where our target *may* move, then:

- if we don't move, and our target doesn't move, we won't meet.

- if we don't move, and our target moves left, we'll meet if we start from 1. and won't meet from 2.

- if we don't move, and our target moves right, we won't meet if we start from 1. and will from 2.

- if we move left, and our target moves left, we won't meet form either start.

- if we move left, and our target doesn't move, we'll only meet starting from 2.

- if we move left, and our target moves right, we'll meet from 1. and cross paths from 2.

- if we move right, and our target doesn't move, we'll only meet starting from 1.

- if we move right, and our target moves left, we'll cross paths from 1. and meet from 2.

- if we move right, and our target moves right, we won't meet from either start.

Odds of meeting as nomove:move = (2 out of 6):(6 out of 12) = 1/3:1/2


Again we see that depending on what our target's policy is, "moving" is either as good as, or better than, "not moving".


For a four node graph things get more complicated because the graph complexity can now range from "a ring with four nodes" to "a fully connected graph" (where each of the four nodes is connected to the other three). At this point, typing becomes bothersome, but the procedure for testing remains the same: we generate all possible starting configurations, and then see what the odds of meeting are in a single step for each. If we run them, then we still see that if our target is not allowed to stand still, "nomove" vs. "move" is still equal odds, but if they *are* allowed to stand still, "move" is the winning strategy (ring result: 2/6:4/12 = 1/3:1/3 vs. 2/9:6/18 = 2/9:3/9, fully connected result: 3/9:3/9=1/3:1/3 vs. 3/12:12/48=2/16:3/16)


Taking that to its conclusion: if you don't know what the target's policy is, just walk around, because you'll always either perform on par with, or better than, standing still in the hopes that you spot them as they walk by. However, it's worth noting that the more complex the amusement park graph becomes, the smaller the difference in odds becomes between "stay where you are" and "look around for them". 


Of course, in real life, you've simply agreed before hand to meet back at the concession stand if you can't find each other for more than 10 minutes. But that's less fun.

*On a final note*: the odds of meeting are only 100% given infinite time if the park has a flat, 2D graph, thanks to the fact that a 2D random walk is guaranteed to through its starting point given infinite time. However, if there are any bridges or tunnels, with up/down stair cases to connect to other paths (say there's a high traffic overpass in the park, for instance), then that turns our graph into a 3D space, and all bets are off: a random walk in 3d may never pass through its starting point, even given infinite time, and so the chances of finding our target will never become 100%. Standing still...at the exit. If you are both moving then it is possible that you will keep missing each other indefinitely.

By standing at the exit you exploit the main limiting factor - time. The park has to close at some point. Alternatively, if we know both people plan to stay at the park until close, the exit might be the last place a person would *naturally* go.  UNLESS... there are more than one exit. Then you have 1/x chance this way, with X being number of exits.  I would think that if you moved against the prevailing traffic flow, you'd be much more likely to find someone than moving with the prevailing flow of traffic through the park. If everyone is moving in random directions (not realistic at all), it would still make sense to walk around as you would encounter more people as you are essentially doubling the rate of change for people that you pass by. If the theme park is of infinite size and 2-dimensional, you will always find each other with infinite time, as you stated. However, this is not true if it is 3-dimensional. A drunk man will always find his way home, a drunk bird may never.

See http://en.wikipedia.org/wiki/Random_walk#Lattice_random_walk
 This is actually in my homeowork problem, see [problem 1 here!](http://web.stanford.edu/class/cme305/hw/hw3.pdf). Although the question is slightly different.

The trick here is this: instead of two independent randomly walks on a graph G, think of it as one random walk on (G, G). The terminal condition that two random walk visit the same node v at the same time becomes hitting (v, v) for some v in G under this new random walk.  Isn't there a chance where neither would move, either the seeker thinks that it would be better if he does move, or the one being seeked is tired so he has stopped.

That alone would make it better if the seeker to start moving. of course, I am not doing the maths like some of our redditors here. Kudos to them  **TLDR: Given the setting, it depends on the randomness.**

This is highly related to my work as a math PhD student (Kinetric equations, Lattice Boltzmann Equations,..) and I would like to point out one more interesting fact.

Even if we assume a random search pattern, it is not directly clear which "type of randomness" we have to deal with.

Consider the following (eventually unrealistic) simplification. Assume, that you are hunting for food (food = the person you are looking for) and you can be in exactly two states. Either you are looking around for your food, or you are moving. This means, that while you are moving, you won't notice the food around you. I know, this is somehow unrealisitc for this scenario, but my point is a different one.

The standard theory for [Random Walks](http://en.wikipedia.org/wiki/Random_walk) and  [Brownian motion](http://en.wikipedia.org/wiki/Brownian_motion) most of the time assumes, that your steplength is sampled from a [Gaussian distribution](http://en.wikipedia.org/wiki/Normal_distribution). This means, that it is highly unlikely to perform a long step and rather likely to perform a small step (there is a justification for this, namely the fact that your steplength corresponds to the distance to collision with a background media which is likely to be small). 

However, it has beend observed, that the optimal search pattern for foraging is to sample steps from a different distribution, namely one that is algebraically decaying (and not exponentially, like Gaussian). This means, that large jumps are still less likely than small jumps, but more likely than in the Gaussian case and the mean jump length is actually inifinity. In the given context, this is considered an optimal strategy for foraging.
There is even the [Levy flight foraging hypothesis](http://en.wikipedia.org/wiki/L%C3%A9vy_flight_foraging_hypothesis): 

*Since Lvy flights and walks can optimize search efficiencies, therefore natural selection should have led to adaptations for Lvy flight foraging.*

And this has actually been observed. There is an [article in Nature](http://www.nature.com/nature/journal/v381/n6581/abs/381413a0.html) by Viswanathan et al. that shows, that the flight pattern of an albatross is exactly of the above mentioned form. 

So to summarize: If you would know, that the person you are looking for and  under the assumption, that you can only walk or look exclusively, it might be a good idea to consider the type of random motion.

Personal opinion: I'm not sure, that this assumption on walking XOR looking is mandatory. The important part are the assumptions on the target. In the foraging setting this means: Target does not move (or relatively slow compared to own movement) and more importantly, there is some correlation between food at position X and food around position X. The albatross basically searches randomely in a small area and tha performs a larger jump to get away from that area, since there is probably no food left. Ok, here is how I would prove that moving is always better.  Here are the assumptions of my model:

1. The 2 walkers are modelled by Brownian motion with equal scalar diffusion coefficients D.  The larger D the faster the 2 walkers move.  The positions of the walkers at time t is denoted by A(t) and B(t), respectively.
2.  Assume their field of vision is a ball around them of radius r.  The simulation will stop when they spot each other,  i.e. |A-B| &lt; r. 
3. Assume they start their search from points A(0) and B(0) on the plane.  
4. Assume that the walkers cannot go further than R away from each other,  i.e. |A(t) - B(t)| &lt;  R at all times (i.e the fun park has finite size).


Noting that X(t) = A(t) - B(t) is also a Brownian motion with diffusion coefficient 2D.   We wish to measure the MEAN FIRST HITTING TIME for the process X(t) to the ball of radius r around the origin.

Solving the equation for mean first passage time in spherical coordinates, we get that the mean first passage time is T2(|A0-B0|) where
&gt;T2(s) = (f(s) - f(r))/(2*D),  
for f(s) = -0.25s^2 + 0.5*R^2 log(s),

and where |A(0) - B(0)| is the distance between the walkers at the start.  On the other hand, if only one guy was walking, the mean first passage time would be twice that, since  the equation would be:
&gt; T1(s) = (f(s)-f(r))/D.

That is,  T1 = 2*T2.   This is consistent with the simulations done by  /u/GemOfEvan.  Treat all this with suspicion,  I'm on a bus. This has been commonly referred to as The Rendezvous Problem or Telephone Problem, and is considered to be a largely unsolved mathematical problem. The Anderson-Weber strategy is thought to be one of the best solutions. 

Here's the mathematical explanation From Cambridge U Statslab website (NOT ME): hthttp://www.statslab.cam.ac.uk/~rrw1/research/rendezvous.html

" A reasonable strategy has been proposed by Anderson-Weber. This is one in which, in each block of n-1 successive steps a person either stays put at his present location (with probability p), or tours the other n-1 locations in random order (with probability 1-p), repeating this until meeting occurs. When n is large, the best choice of p is about 0.2475, and the expected time to meet is about 0.8289n steps. There might be a better strategy - no one knows. The principal results that are now known are
1. The Anderson-Weber strategy is optimal for n=2, with p=1/2. The expected meeting time is 2. Proved in 1990.
2. The Anderson-Weber strategy is optimal for n=3, with p=1/3. The expected meeting time is 5/2. Proved in 2006."
This is from my previous answer to the same question on Quora. As long as they aren't wearing a diaper, or they're a camel/cheapass who only takes sips of the nasty fountain water when absolutely needed on a cool day, you can camp out the restroom facilities.

That is, if they don't pee while riding Splashderp Mountain D: I thought about it like this:
Instead of messing with 3 dimensions, lets work with two. So both parties can either move left or right. The only options are: you move left, friend moves left (no change in distance). You move left, friend moves right (distance increase, assuming you started on left). You move right, friend moves left (closer!). You move right, friend moves right  (no change in distance). In only one of those situations did you get closer, so by my maths... carry the two.... if you're both moving you have only a 25% chance of running into them. 
If you weren't moving there would only be two things to happen: move closer or farther. 50% .
I don't see how adding more dimensions would change anything. There are just more directions, but the odds would stay essentially the same.
All that being said- I don't do math and I sure as heck don't show my work when I do.
Tl;dl 
Stay still, I can't prove it with a simulation. What if the park is circular-ish? If you both walk in the same direction (for instance counter-clockwise) at a similar pace it could take hours before you run into each other. If you know the other person is moving, by standing still at a bottleneck you would be guaranteed to find them much faster then if you are both walking in same direction. In general,  this can be simplified down to a random walk of one object encountering a specified point on a bounded grid,  vs the same object moving twice as actively/rapidly encountering the same point.  Obviously,  the more rapid the motion, the faster the object will encounter the point.  Should be T/2, roughly.  Grid size will impact the time reduction somewhat. 

This works because one object can be seen as fixed,  with the grid moving randomly around it,  while the other object moves relative to the grid. 

Of course,  a more accurate model might incorporate FOV,  resistance to backtracking,  obstacles,  etc,  but with both objects exhibiting identical properties in all cases, I would expect that  T/2 would hold. 

Tl/dr motion is relative.  Late to the party, but here's a simple explanation. Let's model the system as a random walk. Over time, a single random walk will fan out by the normal distribution. The standard deviation will will be a function of time and walking speed. We switch our frame of reference to one of the people. Now, the other person will have be doing a random walk at 2x time. Thus, the standard deviation of the normal distribution will be 2x (might be sqrt of 2 as I need to verify math) greater. The greater the std dev,  the more likely to hit far out points. This is one of the best threads of its kind I have ever read, but there is one thing that these simulations are not taking into account. When someone is lost in a forest, for instance, the assumption should also be included that when the searcher had searched a sector, that sector is that not searched again. One of the biggest pieces of advice that they give people that are ever lost in the forest, for instance, is that when you know you are lost, do not move. It is very natural for searchers to assume that an area that they have searched it is no longer searchable.

I wonder what these simulations would look like with that fact taken into account.

I would like to ask the simulators to program their simulators to do this, and see how many sims actually complete (with all sectors searched) with the person not found at all. This is a common game theory problem. Basically you want to do the opposite of why the other person is doing. If they're standing still, you would want to walk around. If they're waking around, you would wan to stay put. It's all about that imperfect information :-/ This is actually semi-related to something I study in Economics called game theory. It is the study of strategy. An experiment actually occurred where people were let loose in NYC in an attempt to find others who were also  looking for them with no other hints provided. ABC did a special on this called Mission Impossible: search for strangers in NYC. All teams were successful in finding each other but their strategies relied on finding landmarks mainly. I realize this is only partially related to your question.  I can't even find people where we're supposed to meet up.  But it seems if two people were looking for each other, given no other location, landmarks would be a pretty good idea.

It seems that if at least one person is moving, and one person just waits near Union Sq, eventually the other person will find them in a reasonable amount of time, since it's a high traffic area to meet people.

What does game-theory actually say about this? But you can't know if the other person will be moving or standing still.  If you both stand still you will never meet, but if you both move you can still meet. This makes it optimal for you to move. The size of the park will largely impact your outcome. You could also develop strategies (re: algorithms) to improve your chances of finding them based on park structure. A BFS style search on an open grid would probably give you quickest results assuming both objects are moving at the same speed. Feel free to correct me if I've overlooked something since I just glanced this over.

edit: on second thought, you're not an agent in the matrix so you can't be everywhere at once. BFS wouldn't do anything except find the shortest path to the object once located. Given your "spherical cow" restraints your question basically boils down to the following:

Consider 2 points inside a 2-dimensional area.
Point 2 is performing a 2-dimensional random walk.
Your goal is for point 2 to come within x units of point 1.
Is this more likely to happen if point 1 is stationary or also performing a 2-dimensional random walk.

Let's call 'P' the probability that point 2 is within x units of point 1.

P = (pi * x^2 )/(area of park)

As long as point 1 is more than x units away from the walls of the park, P will always be the same. P will only decrease if point 1 gets closer to a wall than x units.
If point 1 is also performing a 2-dimensional random walk then there will be times when point 1 gets too close to a wall and P gets smaller, thus reducing the probability that it gets close to point 2.

TLDR:  Staying in one place would have better odds assuming that said place is further away from the edge of the park than you can realistically see. None of the comments I see seem to point out that traffic at theme parks is not "random." For instance, around opening time, the traffic would move towards the rides. Around lunchtime, towards food places. Around closing, towards the exit. If you positioned yourself correctly, walking *against* where a crowd would be would allow you to scan more area. &gt; Assumptions:
&gt; The other person is constantly and randomly roaming
&gt; ...
&gt; Bottom line: the theme park is just used to personify a general statistics problem. So things like popular rides, central locations, and crowds can be overlooked.

The problem requires this assumption, which is why these are overlooked. Tacking on a question to this thread:

If me and a friend flip a coin 4x until we both get the same sequence is it better for me to keep my original 4x flips or for both of us to keep flipping a new 4x flip.

Example:

I flip THTH and now wait for him to flip THTH or we can both keep flipping. Which methodology arrives at an answer quicker? Think about it this way:

If one person were moving randomly, each step would randomly either move him *closer* or *further* from the other person, linearly.  Since it's random, the only way he is going to reach the other person is by a series of favorable random direction choices.

Therefore if he were to be moving twice as fast, or took 2 random steps for every one, he would statistically find the other person twice as fast.  More "rolls of the dice," if you will.

Alternatively, the other person could move at the same speed, rather than him moving twice as fast.  It would give the same result.  Twice as many random movements per time period that either bring them closer or further.  Twice as many "rolls of the dice." [deleted] Your dice example does not work, because you assumed that you can get from one place to another instantly. You have to add the constraint of movement. Your dice examples are a classic example of events that create a binomial distribution, where n is the number of times you roll the dice and p is the probability of a success, the mean is given by np and the variance by np(1-p)

In this case, for the same n, the variances of both the 1 dice and 2 dice versions are identical, as the probabilities are identical. You can look at http://www.enigmaathome.net/ to see some actual working examples.  They decrypted 3 previously unknown Enigma messages and it took the equivalent of 7748 years, 303 days, 14 hours of PC time based on a single Athlon 3500+ PC.  This was basically a brute force effort, using all the known weaknesses of the Enigma machines.

For a generic example, Wikipedia says "If the wiring is secret, the total number of possible configurations has been calculated to be around 10^114 (approximately 380 bits); with known wiring and other operational constraints, this is reduced to around 10^23 (76 bits)."

At 100 GFLOPS (decent modern processor), this would be about 3.17x10^94 years for the more complex case (longer than the universe has existed).  For the limited case where we assume we've captured an Enigma machine and know the wiring &amp; limitations of the system, it's about 3,169 years on average to brute force it.  This jives fairly closely with the practical enigmaathome results above. This should be used as an example when teaching about the importance of a right algorithm ! (And knowledge of hardware.) And human intelligence. Don't spend forever brute forcing something if you can glean information another way.  Step 1 when considering the defense of a system should ALWAYS be physical (i.e. Personnel) security  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Yup. Kevin Mitnick (insane hacker who ended up flipping for the FBI when he was caught) has a great book on social engineering. He actually has several great books.  The Art of Deception, the Art of Intrusion, Ghost in the Wires Really cool book. It's crazy how much social "hacking" can be accomplished in a friendly phone call or two. [deleted] Well, "rubber hose" cryptanalysis does use brute force - you find someone who knows the secret password or whatever and then "brute force" their face with a rubber hose until they give it up. It's funny that you mention that cause one of my early CS professors did!

Edit: *because And for good reason. It certainly helped the IT security section of my CS course that I was dabbling in the Enigma Machine as a hobby. Many principles carried over well, as they're basic algorithmic security principles related to encryption. [deleted] Could you explain why that is good please? My guess is that it's because semi primes are hard to guess intelligently. 

The use of that, I would guess, would be to make it difficult to guess without a brute force attack. 

The fifteen digits would make it difficult to guess *with* a brute force attack. 

Just a guess. [deleted] I think you may be confusing password strength and the crypto-key derived from the password.  Ideally, you'll use a standard algorithm such as [PBKDF2](http://en.wikipedia.org/wiki/PBKDF2) - Password based key derivation function 2.  Even if the distinction is clear in your head, it isn't coming across in your words. But passwords are usually encrypted and the plaintext (your password) bears little relationship to the ciphertext. The dificulty of breaking a password using brute force is dependent on the length of your password, and the variety of characters used. It is not dependent on the ordering of those characters. Ruff216 will be just as easy to crack as ufRf162. PhD student in CS here, studying Information Security. I'm not really sure what you're trying to convey there.

Passwords are generally encrypted using a one-way hash, which acts as a "mathematical ratchet." It generates data that is negligibly distinguishable from random and that has a very slim chance of being produced from any other password. It doesn't matter whether your password has prime numbers in it or not. In fact, it shouldn't matter: If you could show a given hash output was derived from a password containing primes (or really, any specific data) the hash would be provably insecure, because you should not be able to draw *any* inference about the password used based on looking at its hash.

Semiprimes are used in some exponential ciphers that exploit discrete logarithm hardness (i.e. it is not known how to easily compute y from x^y mod n for very large numbers). Consider a large prime number *p*. The totient function of p, phi(p) which is the number of coprimes to p less or equal to p is obviously p-1, since p is prime. By Euler's theorem, we know that any x^phi(p) = 1 mod p. Now think up some exponent k having gcd(k,phi(p)) = 1. We can compute its modular inverse k' easily using extended Euclid.

Now, you could encrypt a message M by taking C = M^k mod p. Because a discrete log is hard to compute, an adversary could not (easily) figure out M from C by itself. However, if you want a friend to be able to decrypt C, they need *k'* and *p*. Furthermore, phi(p) is easy to compute and thus if you know *k* and *p*, or *k'* and *p*, you can find the other *k*.

However, if you have a different modulus *m* instead of *p* where *m* is a semiprime consisting of the product of two primes *p* and *q*, it is much more difficult to compute phi(*p*) without knowing *p* and *q*. Then we can generate a *sk*, *pk* pair from which it is very difficult (again, as far as we know) to derive the other *sk* from *pk* and vice -versa. RSA exploits this property and I suspect it is what you were thinking of. The example in the second and third paragraphs are the basis of the Pohlig-Hellman cipher.

Edit: No need to delete your post, just clarify. It's not like this stuff is easy. We're all learning. "...11 and 13 which equals 143, 143 is not a prime number, and has more options to which its divisible..."

Those options are still only 1, 11, 13 and 143. There are no extra "options" created from multiplying. I think what khublakhanguest means is that with some random semi prime number, 143 just being the example, a hacker doesn't necessarily know what primes are hidden in it, and so they have to use a brute force search to discover them, and that part takes 1000 lifetimes. By introducing the extra variable of a second prime in encryption, it's harder to look through all possibilities. So how was the Enigma code broken in the 40s when they didn't have today's computing power? As others have answered there were operational failings - when encoding a message the sender had to enter the Kenngruppen, basically pick a few random letters, many operators would use their initials, those of a girlfriend or some other memorable collection of letters. This had an impact because the people at the Y-Stations who listened for enigma messages and then sent them to the codebreakers got to recognise the signature/style of the morse code that the operators sent, therefore a guess could be made as to what the Kenngruppen was, which aided the decoding of the message.

The enigma also had an inherent weakness in that it was impossible to see the same letter encoded as the same thing if they were next to each other, e.g. "hello" would never be encoded to "ethhn". Also, a letter would never be encoded as itself (e.g. "hello" would never become "hcrtk" or "xeghy"). This was a huge help when trying to see if a crib (clear text) could possibly match the message.

Also, do keep in mind that the English Government Code &amp; Cipher School (the organisation responsible for code breaking) was also fed information from the Polish cipher bureau, who had been working on the Enigma for some time during the 1930s (Enigma started as a commercial venture for banks etc to send secure messages). The Poles had made some nroads in to prewar enigmas and understood some elements of how the machine worked - Henryk Zygalski, Marian Rejewski and Jerzy Rycki did much of the early work to defeat enigma, indeed Rejewski devised the initial design for the bombe machine that Alan Turing later improved on before GC&amp;CS made the machine(s) that helped significantly in the decoding effort.
Zygalski created his sheets - you can find examples on the internet but they were sheets with perforated holes in, by placing the sheets over each other in the right order some of the enigma settings could be determined. An almost identical method was devised by Gordon Welchman at Bletchley Park (he hadn't been told they existed..), the sheets were used extensively during the war.

Do note that the enigma changed many times before and during the war, there was a lot of hard work done during the war to get on top of Enigma and keep up with the changes. Whilst Alan Turing is the best known of the codebreakers there were many more - Dilly Knox, Gordon Welchman, Bill Tutte to name but a few. There were thousands of people working at Bletchley at one point.

If you are interested I can fully recommend Hugh Sebag-Montefiore's "Engima - The battle for the code" which is a superb book that covers the breaking of the Enigma and Bletchley Park, also take a look at "The hut six story" that Gordon Welchman himself wrote, quite technical but very interesting.
  Also, The Germans were for the longest time using the same opening sentence on all their messages. Having a known text in message at a known spot was a huge mistake on their part. though "The Germans..." is a bit over-simplifying. Different branches were less or more strict about following the protocols. IIRC the Air Force messages were easier to crack because of lapses like what you describe, while Army mid-level officers were better at drilling the enlisted folk to follow the rules properly, and so it was much rarer to ever decrypt infantry messages.

(I don't remember *which* branches were better/worse, though.) The German Navy were super stringent. They actually even had a different variation of the cipher which was more difficult to crack.

This being a huge problem, as they were destroying the ships coming and going from America to Britain. Was this a big obstacle? At what point did the code breakers realize the Navy was using a different cipher? If you're familiar with how an Enigma machine works, the Kriegsmarine were using one more rotor than other branches of the German Military. Basically, each rotor is a randomization device and the navy was using one extra randomization device. This increased the possible number of configurations to astronomical levels, multiplying British processing time by 50. (a message that used to take 1 hour would take 50).

The British code breakers were actually aware of the fourth rotor before the Germans even built it. They had intercepted data that indicated the Kriegsmarine was building the new Enigma. The fourth rotor's wiring was figured out before the Germans had actually sent a message on it. The British knew they could defeat it, the problem was time. Their 3 rotor bombe machines were capable of decrypting Navy enigma, but it would take too long for the information to be valuable. They were unable to defeat four rotor enigmas for months because they couldn't afford to build new bombe machines. Eventually the Germans lax encryption protocol allowed the British to decrypt most four rotor messages.  I'm afraid I can't remember off hand -- the book I got the information from is _The Code Book_ by Simon Singh Notably too, finding these messages from less strict branches was the key, because for much of the war, as I understand it, all branches would be using the same key on the same day.  So, if you knew one place that that had lax practices, you could more reliably crack them, then use the key from that to help crack other messages sent that day. Is a C.S. degree a prereq for enjoying those books?  No way! You might end up wanting to study CS after though. :-) So basically the idea is that the weakest link in any encryption is the human. Yes, but the encryption had weaknesses too. Modern day crypto guys will tell you any system designed to allow decryption of a message is inherently insecure. 

Probably the biggest downfall of Enigma was the Germans refused to believe it could be compromised. I don't have a direct source but it was discussed in the Nazi hierarchy and they dismissed it. They believed that spies and lapses in security were a more likely source of intelligence.

The Allies were acutely aware that by using information gleaned from decrypts it might become obvious, in some cases they sat on information rather than using it to remain covert.

Admiral Donitz refused point blank to believe Enigma had been broken, even after the war when he was shown (no doubt, limited) evidence of code breaking. If I recall correctly he went to his grave in 1980, still believing Engima had been secure.
 Is it possible to have a computer design a code that is unbreakable?  That depends what you mean by unbreakable. But an unbreakable algorithm was first developed over a hundred years ago and is quite simple. Basically, you need a string of random characters as long as your message and you add together the characters in corresponding position from the key and message to produce the character for the ciphertext. As long as only the intended recipient has the key and that key is never used again and the key is actually completely random , the code is unbreakable. This is terribly inconvenient in practice.  Just to add to this, I believe it's called a 'One-time-pad' (OTP), for anyone interested.
 That's pretty much it. Creating unbreakable code is quite easy, using it not so much. Still, the code has to be as good as long the information it carries has to remain secret.

The easiest 'unbreakable' codes are simple phrases. Saying "Three Pigs" might carry enough information to start an invasion, assuming both sender and recipient understand the code, and the code is used correctly (as in: you don't tell your lover the "Three Pigs" means the invasion will happen on 8th of May according to 3rd plan variant).  The term used in cryptanalysis is "Perfectly Secret."

Formally, by Shannon's theorem, a cipher is "perfectly secret" if for any message, key, and cipher space M, C, K, |K| = |C| = |P|. The cardinality of the first two can also be larger, but it suffices to make them equal. Also, each key must be used with equal probability.

The proof is very simple and uses Bayes' theorem. The one-time pad where you have a message-length key and xor your message with it was probably the most widely used and best perfectly secret cipher out there. It was also highly unwieldy. The NSA successfully attacked Russian ciphers based on occasional key reuse. I don't doubt similar mistakes were made on our side.

In the movie *Tinker, Tailor, Solider Spy* there is a brief scene where they show a one-time pad being used, but it isn't explained. Just follow the 15th century Voynich Manuscript which still to this day is unsolved. Why someone encrypted a botany text also is unknown. Is it actually encrypted or is it just a weird made up language? There are indicators of it containing ciphers so I would lean toward encryption. 

 It is almost certainly a [hoax](http://archive.wired.com/wired/archive/12.09/rugg.html), not a cipher. Tom Clancy had a book where the Catholic Church used a version of the Bible (in Latin, possibly with errors) as their source for a one time pad, and they used the daily lectionary reading for the day to point to the starting point.  That way, any message could be decrypted based on a one time pad, and the source was something that did not seem unusual for them to possess so it did not scream out espionage.

cool trick.


Chemists might use a version of the CRC handbook
 Both of these are very bad ideas, because the key is widely published.

It doesn't take long to brute-force through all the books on someone's shelf, these days.

A better key would be a well-shuffled deck of cards, of which a duplicate in the same order can be made. So long as the cards are re-shuffled just after the text is encoded, there's no longer a record of what the key had been on the sender's side.

Once the recipient decrypts the message, they can similarly shuffle their deck.

No one raises an eyebrow when a person owns cards, or pays much attention to what order said cards are arranged in. I believe the Navajo ["Wind Talkers"](http://en.wikipedia.org/wiki/Code_talker) never suffered a decoded message.  Navajo is most definitely not computer encryption however. It was more so security through obscurity.  At the time, there were some thing like less than 50 non native speakers of the language, and it was also quite different and unintelligible to even the other languages closest to it. Well, it's not really accurate to say the code was broken. Codes changed daily, and some days the code might simply not be broken.

In the same vein, reuse of codes also gave Bletchley Park a lot more sample ciphertext to work with, so some of the comparative ease was also down to lazy radio operators.

Also in WW2 Nazi messages used standard snippets of text (known as "cribs") which could be quickly searched for in decrypted text to indicate a successful break. 

One such crib which sticks in my mind was a quantity of Z characters at the beginning of the message denoting how important it was (more Zs == more important). Other things which were often included were phrases used to report weather conditions.
 
Also worth noting is that to this day, there are secret and top secret techniques for decoding encrypted messages. I'm guessing these didn't make it into the software mentioned elsewhere in this thread. 

Edit : worth noting, not nothing.  The software mentioned elsewhere wasn't really trying to be particularly clever. If every nazi had followed safety protocol to a T, it would have never been broken, but many of them skipped protocol and slowly leaked enough secrets to the Allies for them to break it.  Modern computers were pretty much the result of inventing tech to break Enigma.  [Alan Turing came up with the design for a logic machine called the Bombe](http://en.wikipedia.org/wiki/Bombe) which was the power-house behind decoding stuff.   &gt; slowly leaked enough secrets to the Allies for them to break it.

This isn't exactly true..   They had a working German enigma machine at Bletchley Park, the trick was that the rotor positions were changed daily, so they only had 24 hours to brute force the code before they changed again.  

The decoder was no where near powerful enough todo this, the breakthrough came when they realised that the Germans would transmit a weather report every morning, so they would get an encrypted message they they knew would start with the same characters. 

This allowed them to us the Bombe to calculate the enigma rotor positions and in turn allow them to decrypt all the German messages for that day.  Thanks for clarifying that. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] They had as long as they liked to decode the messages, though, and the more decrypts they had, the more they could build up a pattern of guessed plaintexts (cribs) and knowledge of various German systems (like grid-referencing, codenames, callsigns etc) Basically all the messages were being intercepted and stored, so once the setting for a day was determined, even if that day was in the past, they could read everything from that day on that network.

In addition, if they decrypted the Army enigma saying "we will make an offensive next week!" a day late, this was still operationally useful. Or, besides the weather report, they'd get go out and mine a specific grid position somewhere in the North Sea or Atlantic that the germans would then diligently report using their naval grid system.  Knowing that the grid coordinates (specific letters and numbers) were in the message, they could work backwards using the same principles.  They called it ["gardening"](http://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma#Crib-based_decryption) when they planted such messages, and the general term for a bit of known text was a "crib". The thing is different (and a lot of) methods were used for reducing the search space (number of possibilities) by Turing and the polish cryptanalysts before him, the weather thing was just one of them. 

The wikipedia article is pretty good:

http://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma


 It's good that you mentioned the Polish. Many (most?) people don't seem to be aware that the Polish made enormous strides in breaking Enigma before the British even started. Exactly, it was really sad that *The Imitation Game* didn't give them any credit at all either. It was on the whole a pretty badly researched movie, in my opinion. They actually did give the Polish credit, just not much. It's only one line of dialogue and it's pretty easy to miss. Its been some time, so I don't remember it that well, but wasn't it more like "The polish obtained the enigma machine" and not "they successfully cracked some enigma messages" ? Two lines. One is "Polish intelligence smuggled [an Enigma machine] out of Berlin." The other is "[Turing's device] is inspired by an old Polish code machine." The word "old" is what's bothersome, to me, since Turing started his work in 1939 when the Polish bomba was less than a year old. Otherwise, it's an accurate statement. The Poles did crack some Enigma messages, but Germany almost immediately increased the complexity of Enigma to the point where the Polish machine was uselessly slow. Two lines. One is "Polish intelligence smuggled [an Enigma machine] out of Berlin." The other is "[Turing's device] is inspired by an old Polish code machine." The word "old" is what's bothersome, to me, since Turing started his work in 1939 when the Polish bomba was less than a year old. Otherwise, it's an accurate statement. The Poles did crack some Enigma messages, but Germany almost immediately increased the complexity of Enigma to the point where the Polish machine was uselessly slow. To be fair, changes to the naval enigma machine itself and to the signalling procedures made the Polish work largely useless quite early in the war. There are quite a lot of credit given at Bletchley Park, which I visited few months ago. The almost all guides there start with "We owe the Polish a lot and couldnt have done this without them" Thanks, but I never found how they got to know about the daily weather report format. Surely that was leaked by a spy?  I believe there were a few times where they were able to obtain code books which gave the daily configuration. Daily configuration yes, but knowing that the 'x'  message in the morning is about weather?  The message was transmitted at the same time each day from a particular station. You don't need to know the content of the message to know that it's probably the weather report.

This is a good illustration of why leaking _any_ information in a cryptographic system can usually be exploited for possibly-catastrophic improvements in bruteforce running time. To be hyperbolic about it, the simple act of being able to assume that a particular message contains a weather report is enough to win World War II. And once you've decoded it once it would surely be easier to identify it every day even coded? With realistic encryption (i.e., not ROT13) even a small deviation can cause a wildly different output. Suppose my super-secret encryption algorithm was MD5 hash:

    Input: "test1"
    Output: 5a105e8b9d40e1329780d62ea2265d8a

whereas

    Input: "test2"
    Output: ad0234829205b9033196ba818f7a872b

Here's a visual representation of the Enigma machine: http://public.tableau.com/profile/nsalvate#!/vizhome/Visual_Enigma/VisualEnigma

Decoding a message once will give you no help for decoding the message a second time when the rotor settings have been changed. First transmission from a given station. Messages were sent by morse and key operators have discernible differences in key stroke patterns.  There were also situations where some german stations would accidentally transmit the message with the same code wheel positions as the day before, and then when others noticed, the same station would *re*transmit the identical message with the code wheels fixed to the new day's settings.  Duh.  Some basic failure to understand encryption there. Nice. Thanks!  They also used known words at the end of messages like the Nazi salute. They knew certain weather station sent message in a certain format, like the salutation in the beginning or the end.  I've heard of that and in this case I always wonder - why encrypt the weather report?  I get where the troops are, where they should go, but weather is of no significance isn't it?  

Not hind sight bias, just doesn't seem worth the effort. In June 1944 German meteorologists predicted that stormy weather over the English Channel would continue until mid-June.  Their counterparts on the allied side predicted that a high pressure system would deflect the storm and provide calm conditions.

The German high command left their defences for war games in the belief that the weather would make an invasion impossible.  The largest amphibious invasion in history went ahead.

http://www.history.com/news/the-weather-forecast-that-saved-d-day


 No need to give your weather forecast to your enemies.  Weather tech was not the commodity it is today. Even more than giving your enemies info, letting your enemies know when your info differs from theirs is the easiest was to lose. Weather was a major factor in many battles in World War 2. For example, the Battle of the Bulge was planned around   A storm that prevented allied air dominance from playing a role.  This would be impossible without accurate weather reports. Just recently, a German weather station was discovered in Greenland, placed there by a U-boat. There are german weather stations on the Labrador coast as well. Eastern Canada.  Weather is very important. Knowing where it would be clear would be a great help to bombers, for example. Aside from what has already been said, it also provides a "safe" message for you to acclimatise to the day's new codes on.

You can, for instance, spend an hour or so getting things right whilst decoding the unimportant weather message, which in turn shows you that you've correctly lined up the code. It's a bit like saying "testing, testing, 123." Except that you aren't saying the same thing every morning, which could then be used as a key to decode the rest. It also serves more of a purpose than simply saying "testing" because it also tells you the weather.

If you then receive a message telling you to be ready to fire AA guns in five minutes, you then know that your lines of communication are definitely clear and you don't need to sit and say: "well, a new message just came in. We should set up our enigma machine for today... Ah, wait, this isn't right. The code wheels can't be in the right position because this message came out all gibberish. Hmm. What's going on here... Oh, I see what it is. Seigfreid made a mistake here as always. Let me just fix that. Oh, apparently the allies are about to bomb us and we have five minutes to prepare our air defences before they arrive. When did this message come through? Five minutes ago? And that sound like aeroplanes... That's our fighters right? They're here to shoot down the allied bombers? No? Schisse." Weather reports were relatively easy to get, every ground station in the Reich received and deciphered one every morning. After they knew the format they just listened to the german broadcast.  They could decode single messages, but it could take longer than a day just for someone to guess a sentence.
 Bigger than that, honestly, was the fact that a letter could never be "encrypted" as itself. This meant that, as long as you guessed correctly that even a single, decent-length word was there, you could begin the guessing pretty quickly. The allies later made a version without this flaw that has, as far as anyone knows, not been cracked to this day. Didn't they figure that out because one position that would relay the weather signal did a double touch on some digits? So instead of a message starting 'dave' it was 'ddaavvee' and the doubling of the digits allowed them a further tweek on rotor positions. Remember watching a doc on bletchley and some old english guy describing how nice it was that this one position helped them so much whilst gently chuckling (could have misunderstood though). Don't forget that at first they didn't allow letters to ever represent themselves.

So an A could never be an A. So when  you go through and see each letter, you can rule out them, which made decryption faster. &gt; Modern computers were pretty much the result of inventing tech to break Enigma.

Not so much, actually.  The Enigma project was shut down and heavily classified after the war - it didn't become known until the 90s.  All the technology that went into computers had to be invented separately.

In addition, the equipment they designed was not a computer in the sense we understand it.  It was a machine designed to do one job as quickly as possible.  In that sense it was closer to Babbage's Difference Engine than a modern (Turing complete) computer.  

It's instructive to note though how powerful a dedicated piece of hardware is when you compare what the Bombe could achieve with the computer power you need to do a similar job in a similar time. That is why I referred to it as a logic machine, but I guess I was under the impression that Turing's involvement on this project was instrumental in the government allowing him to go about his other works as well.  [His technical report 'Proposed Electronic Calculator', dating from the end of 1945 and containing his design for the Automatic Computing Engine (ACE), was the first relatively complete specification of an electronic stored-program digital computer.](http://www.rutherfordjournal.org/article040101.html) People don't realize that Germany cracked British Navy codes as well. Churchill said their own lack of security cost a lot of sailors lives. But breaking Enigma is a cooler story so that's why it's known more Yes: the real triumph of Bletchley was organisational. They were able to file information and use it to make informed decisions. In general the Germans were not. A similar story applies to radar - both sides had it, but the UK had effective Fighter Command control of their resources, which they used to put their planes where they needed to be. Turing's Bombe was actually based on the Bomba designed earlier in Poland by Marian Rejewski.  Turing's bombe operated on a completely different principle. The linking idea was of using a machine, which itself possessed components simulating the enigma, to automatically check possibilities for the key. But the main point of the Turing-Welchman bombe was to find the plugboard settings, whilst the Poles' bombe in fact could *not* work with the plugboard - you had to hope that the letters it operated on were among those not changed by the plugboard. At the start of the war, only 6 letters were swapped by the plugboard, but by the end most of them were. Turing's Bombe would have been impossible without Rejewski's.  The British were nowhere near breaking Enigma whereas the Poles had been reading messages for years and only shortly before the war did the Germans move to a five rotor Enigma changing the number of possible sequences  from 6 to 60.  The method still worked it just required ten times more machines and manpower.  Due to the likelihood of war, the Poles shared their breakthrough with the British. Turing, as you say, created a machine that checks for keys automatically, but his machine was operating entirely on the Polish concept. Well besides their own codebreaking efforts (which showed the utility of using a machine to break the cipher) the Poles also figured out the wiring of the rotors which existed at that time, which was of immense value to the British effort. But the British bombe operated on a very different premise. Modern computers were the result of a bunch of things, but the Bombe was not really it. The Colossus, built for decoding a different German cipher, was a programmable computer (although it used punched cards for the programs.) Modern computers descended from efforts at Manchester University (where Turing ended up working) and owe a lot to Turing's theoretical work before the war, but since the Colossus was classified, it couldn't influence later designs directly. Off-topic: there was a new movie about Alan Turing released recently. Called "The Imitation Game", well worth a watch. But it definitely isn't a science lesson, or any kind of remotely detailed account of the interesting stuff that happened at Bletchley. Entertaining as a film, but not an accurate historical recount.

I'd recommend some books but I'm mobile (on less than 3G) and can't fully remember the titles. Simon Singh - The Code Book

would be my #1 recommendation for people interested in the stuff. It's basically a short history of cryptography but with detail to many techniques. He doesn't do the lazy "There were flaws that could be exploited." but actually goes into the mathematics and shows how the hacks worked.

IMO this doesn't happen often enough in non-fiction: actually trying to teach the reader something instead of just wanting to tell a story. There was a weaker machine for large portions of time. 5 wheels instead of 7 I think. So, substantially less powerful encryption. Couple that with grabbing one intact and possibly grabbing some of the relevant unencrypted text and you can start working some of the setups backwards.

I believe the Wikipedia article on them is actually pretty solid on this subject. It's certainly going to be more a crate than my vague recollection of the subject.  Enigma original had 3 wheels, later amended to 4.

Here's a three rotor machine, with the steckerboard exposed : http://www.rutherfordjournal.org/images/030108-11.jpg

4 rotor machine : http://upload.wikimedia.org/wikipedia/commons/4/49/Enigma-G.jpg
 There were some sendings like weather reports that has the same words in the same place every day. The big weakness of the enigma was that a letter cannot be swapped with itself. So you start trying things out and if any of the letters were the same as the message you expected you know you are wrong and have to try the next position. Not quite as forward as looking at the message because letters were swapped around, though. But since only two letters could be swapped with each other you could look for a letter that was swapped with two others and continue to the next combination. Then you don't have to try out all settings for each position in the message. 

That got slightly more problematic When encryption got harder, especially for navy stuff. There is some pretty good stuff on numberphile on the enigma. Because humans are creatures of habit. For instance a weather report would be sent something like 8a.m every Tuesday. This would give a slight insight into how certain characters were coded. There were little hints left by the machine, for example a letter would never be repeated (enigma would never type aa),  and no letter can be encoded as its self so a would never code as an a.

Along with this other clues were scattered about.  The nazis seemed as obsessed with the weather as the English.  So the first report of the day was temperature cloud cover wind etc.  this could be measured by the allies as well as the nazis.  So if it was ten degrees you cold look for "ten" to be in the code.

Many soldiers were loyal nazis and signed their emails Heil Hitler, or even better HH (remember HH would never come out as Two consecutive letters)

There were many cases of particular operators starting the day with a test signal.  One used to send something like aaa and would get back zzz this was perfect for giving the codes for the day.  

All these little clues left breadcrumbs for the coders.  Once "in" they could decode all the messages on that system for the whole day. How long would it take the world's fastest super computer?
 A LOT less time. The fastest supercomputer does over 33 Petaflops, so if 100GFlops is 3169 years, the supercomputer would be 330,000 times faster. 

It'd be roughly 3.5 days. Mild correction (excuse the pedantry) but the 'flops' in petaflops already means 'floating point operations *per second*'. [deleted] No worries, I for one appreciate you saving me from making the same mistake in the future. So does that mean that if the enigma was still in used today and everything about it is a secret, that it would be impossible to crack even by computers designed to crack codes? Breaking a decent cipher with no hints is extremely difficult. A brute force attack, or one in which all keys are tried, is the worst case attack. A cryptanalyst will utilize all available shortcuts to avoid having to resort to brute force. So if the GCHQ had to break Enigma again, they would utilize mostly the same tactics they used back in WW2. They would find the patterns in the German key usage and plaintext. They would also attempt to reduce the Enigma complexity as much as possible--notice the lack of fixed points (no letter encrypts to itself) in Enigma, eliminate plugboard settings, etc.

Enigma was adequate *given that the key was random and nothing was known about the message*. The environment in which modern ciphers are used is very different. For instance, if you were to use Enigma to encrypt your wireless connection (instead of WPA), this would be hideously insecure. That's because your network might broadcast tens of thousands of very similar packets every second, each encrypted with the same key. This would enable a known-plaintext attack which is what GCHQ used back in WW2, except now they have millions or even billions of hints instead of just one or two. Cracking your wifi would be trivial.

If you were to use Enigma to encrypt a single unique message, using a random key, none of the known cryptanalysis methods would be effective. In that sense, Enigma is still secure.

Enigma is not designed to protect against a known-plaintext attack which is a common scenario in modern cipher usage. The attacker often knows what is being encrypted and might then attempt to recover the key being used. For that reason, modern ciphers utilize diffusion which spreads the statistical properties of the plaintext throughout the whole ciphertext. The result is that if you use a modern cipher like AES to encrypt "May 24, 2015" the ciphertext will be quite different than if you were to encrypt "May 25, 2015" with the same key. Further, modern ciphers utilize confusion, which disrupts any linear relationship between the ciphertext and the key. Thus encrypting "A" with the key "123" will yield something entirely different than if you encrypted "A" with the key "124".

So in most practical cases Enigma is not secure. &gt;GFLOPS

This is entirely integer-based. Cryptography does not use floating point arithmetic very much. If this EnigmaAtHome really does make extensive use of floating point arithmetic, it is doing something very badly wrong.

Please stop using FLOPS as a universal metric of computing power. It isn't even a decent metric of *floating point* performance, let alone the integer performance we care about here. And, as you can see elsewhere in this thread, it leads to confusion. People are comparing GPUs to CPUs based on floating point performance and precision, all of which is *completely* irrelevant.

EDIT: I just looked through the source. Practically all integer, as expected. *Thank you!*

Good lord, this reminds me of a story.

Do you know what one of my first tasks was when I got hired at IBM back when the BlueGene/L was important? I was supposed to measure the performance of a genetic sequence alignment code on the Bluegene, compare it to other IBM systems, and provide proof that the Bluegene was the best system to do sequence alignment and therefore help motivate IBM's investment in the platform. Big Problem: the Bluegene was designed for floating point operations, and the bulk of sequence alignment is fixed-point operations on chars. Among the systems I tested, the Bluegene had the *worst* performance per dollar. Guess who got a stern talking-to when I mentioned these results at a meeting with bosses a couple of management levels up?

 So, how long would it take a modern computer with code breaking softwear to crack the German enigma code from WW2? &gt; They decrypted 3 previously unknown Enigma messages and it took the equivalent of 7748 years, 303 days, 14 hours of PC time based on a single Athlon 3500+ PC.

~~~~I could be wrong, but my understanding is they *have* decrypted one, and are working on three more. The [server status page](http://www.enigmaathome.net/server_status) for Enigma At Home shows three work units in progress, average turnaround time of 21.66 hours, with 45,552,000 or 91,104,000 work units per message, depending upon the type.~~~~

~~~~91,104,000 work units * 21.66 hours = 1973312640 hours, or 225,115 years to complete all possibilities. Average of half that works out to about 112,500 years for a 50/50 chance, or about 56,000 years for a 50/50 chance of solving the "other" type of work unit with about 45 million combinations.~~~~

Nope. I was wrong; see below. The part you were missing was the "single Athlon 3500+ PC." part.

We can setup computers into things called [Beowulf clusters](http://en.wikipedia.org/wiki/Beowulf_cluster) that have significantly more computing power than a single Athlon 3500+ PC. [deleted] The home page hasn't been updated in a while.  If you look in the forums, they've cracked all three they were working on.  They are working on a fourth that was discovered later but the 3 original have all been finished. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Then how did Turing's Bombes decrypt so many messages in under 24h? The Bombes used a known or "guessed plaintext" attack. This meant that they either knew what a particular message contained, or could guess.

The bombes contained wiring simulating the enigma's, and connected up many such "simulated enigmas" in such a way that an incorrect guess about the enigma's settings would lead to electricity flowing in the bombe in a characterisable way. Such a situation would be discarded, and the next possibility checked. Whenever this didn't occur, the machine stopped and someone checked whether the resulting settings gave a sensible output. Given this technique, how long would it take on average to find the setting? It depended on the "network" being cracked, since there were multiple systems for using the enigma (in particular the Naval enigma added a fourth rotor which made it a lot slower to crack.)

Famously though, on the easier networks, when Bletchley was fully up and running, the day's settings would have been determined by breakfast. Nowadays a computer can perform the same calculation in under a minute. Maths. They weren't trying to brute force every possible combination, they eliminated a lot of the possibilities first, and then brute forced through the rest. Not by brute force - they knew the first message of the day would be a 6am weather report, all the machine had to do was fill in the gaps. &gt; At 100 GFLOPS (decent modern processor), this would be about 3.17x10^94 years for the more complex case (longer than the universe has existed).


The 'longer than the universe existed" doesn't really demonstrate the time scale. It's bit is like someone talking about penis size saying "my penis is smaller than a galaxy".

This is how many more times longer than the universe has existed that number of years is, based on the univers being 13.8bn years old.  
2,297,101,449,275,362,318,840,579,710,144,927,536,231,884,057,971,014,492,753,623,188,405,797,101,449,275,362,318 &gt;  3.17x10^94 years, (longer than the universe has existed)

Talk about the biggest understatement of all time. The universe hasn't even been here for 10^18 _seconds_

10^94 is trillions and trillions and trillions and trillions and trillions and trillions TIMES that. [deleted] How did a bunch of people with pen and paper do 10^94 years worth of modern computer work? They weren't relying on brute forcing it.  
Known patterns of German messages were exploited and this vastly reduced the time needed, and they did have computers to calculate for them.  Not only were they not brute-forcing the solution but exploiting operational and cryptographic weaknesses, they weren't using pen and paper. The built machines to automatically test thousands of possible enigma settings and eliminate them in a short space of time. What's PC time? It's like 'man-hours'. Amount of time the PCs are running, multiplied by the number of PCs. That would be the time it would take a computer to do something, in this case an Athlon 3500+ which is an 11 year-old processor. [deleted] Its effective against brute force attacks, not well designed algorithms exploiting flaws in its design. Interesting. What made the computers that solved the enigma back then different? Or rather, what made their approach different from a brute force? Can you briefly define "brute force" please? brute force = just go through all combinations 1 by 1, without using any shortcuts. I'll try to break your password by brute force: I'll try "a", then "b", then "c"....  "z", "aa", "ab"....
 Honestly, when you get down to it, the impressive thing is how well Enigma holds up. I wonder how long it would take if the ps4 had an app the crowdsourced all the attempts. Just like the ps3 did with the app folding at home. The answer depends on whether you're trying to brute-force the answer, or trying to use the weaknesses of the Enigma and its usage protocol to break it the same way the allies did in WW2.

The top comment tells you about the brute-force case: this would still take a very long time, because there are many possibilities to check. But the problem in the war was that many possibilities could be eliminated by clever logic. Using this method with a simulated Bombe, enigma messages can be decrypted in a few seconds on a home computer. A few seconds vs a few thousand years is quite a difference!  Why does anyone care about the method that takes centuries? The method you are referring to is known as 'Brute Force'. It works like this. Say a combination to a lock is 4 digits. The brute force method would call for trying every single possible combination until you get it correct (0001 to 9999). However, say you know that the lock your trying to decode belongs to a very simple minded person that always used their date of birth as a combination. You've narrowed down the choices to just 1 combination and saved time. You wouldn't have a good measure of how much time you've really saved without the context of brute force. It's basically a standard used to answer this question.  When we moved into our new house there was a key safe but we didn't know the code. 

1-9 keys. 0001. 0002. 0003. 0004. It would've took forever. 

So I used logic. Aha! Each key can only be pressed once, and it *doesn't* matter in which order. Then the person we got the house from was somewhere in his 50s... I guessed it'd be a birthday. 1951. 1952. 1953. 

It took less than 10 tries! I felt like Alan Turing for days.  And what was in the safe? Of course OP, bring up a safe and withhold the contents like everyone else Ha!  I'll set my combination to 0000.  Your brute force machine will never get it! The 'simple-minded' person attack is also known as the dictionary attack, where the most common passwords in reality are stored in it.  Some dictionaries have billions or even trillions of combinations (for long passwords and such, not 4 digit numbers). It's useful as a measure of the strength of the code. No, no one would actually be trying to break the code this way.  The method that takes years is called brute forcing. The computer runs through every combination until it finds one that works. With the nature of the enigma machine known, so using certain exploits, this process would take thousands of years to simply guess the right answer. The other option is using every exploit known, for each exploit drastically reduces the number of possible combinations. This is an important lesson in explaining how cryptography works as it shows why brute forcing is not a viable means for most cracks. [deleted] What about using graphics cards to run parallel processing?  I messed around using my old 8800gfx video card cracking wifi wpa codes using rainbow tables and was shocked at how many combinations per second I could get.   The example in the top comment assumed a processor with ~100 GFLOPS of computing power. A single Titan X has 6600 GFLOPS of single precision compute power, so you can assume that, theoretically, it would be able to do it nearly 66x faster. Double precision compute performance is a good deal less, but not necessary for this application I don't think. Depending on the kind of hashing used, AMD might be a better choice. Remember when Newegg was selling MSRP $550 R9 290Xs for $900 during the height of the mining craze? Bitcoin and Litecoin and whatnot use some kind of hashing - I am not sure what to be honest - that AMD GPUs seem to be better at. Fiji, releasing in June, is supposed to have 4096 sahder cores, or 1280 more than the 290X or exactly twice the flagship card before that, the 7970 (rebranded as the 280X).

Anyway. Yeah. CPUs are really bad at floating-point. If you get an eight-socket Haswell-EX system with flagship CPUs, you have 8x18 cores capable of 32 single-precision FLOP per cycle (FLOPC?). At 2.5GHz, the system nets 11.5TFLOPS, or two Titan Xes. It costs close to $50 000 however, while a Titan X can be slapped into a sub-$100 embedded system (Intel Atom or AMD AM1) for much less. Maybe you spring for a larger motherboard that can accomodate two Titan Xes. Cool. That's a whopping &lt;$2500 for the whole thing. FYI, litecoin (along with dogecoin and other scryptcoins) use an algorithm that is specifically memory intensive, rather than processor intensive. Which means that a graphics card is not actually hugely great at mining it, because it can't be parallelized very well. This was done to help the problem that Bitcoin now faces, of only being able to make money mining with the absolute top of the line equipment, and even then for only a month or two.  Even then, you're paying more in electricity than earning in Magic Internet Money.

By memory-intensive, do you mean bandwidth or total RAM? &gt; ut using graphics cards to run parallel processing? I messed around using my old 8800gfx video card cracking wifi wpa codes using rainbow tables and was shocked at how many combinations per second I could g

Using parallelism with a CUDA-enabled GPU would make it definitely faster, considering brute-force can be easily serialized  Uhm, serialized? ;) It took one guy two weeks break the T52 (Enigmas big brother, used by the German embassies and navy) using a pen and paper.

[Arne Beurling](http://en.wikipedia.org/wiki/Arne_Beurling)

Not really relevant to the question, but this guy always comes to mind when the Enigma is mentioned on reddit. I have a question.

My understanding of codebreaking is that once you have a key, translating the message is basically a lookup table. 

From watching the movie "The Imitation Game", it seemed as if the real break-through was when they realized that certain messages had the same phrase repeated daily.

Once this was done, was the computer even needed to decipher the messages anymore? The computer was still required. The trouble was they didn't know exactly what the messages were, they only knew enough to narrow down the possibilities. This helped speed up the process of breaking the daily key a lot but still required the computer. The key flaw in the Enigma code that let us crack it was that no letter could be encrypted as itself. So we didn't know what that F was, but we knew it *wasn't* an F. Capturing a machine (thanks, Britain!) helped immensely. IIRC that helped but the real weakness was that we could perform a known-plaintext attack using their weather report and other such things. 

It's mentioned in the Wikipedia article that sometimes, when they didn't have the day's code, they would initiate military action somewhere unusual, because then they could know that the place and details would be mentioned, giving them enough known plaintext to make their job a lot easier.  Erm, the Polish people helped. A lot more than Britain or Hollywood would let you think.  The polish reverse engineered it, then gave it to British intelligence when they thought an invasion was imminent. A) The code changed every day, but was encoded using the same machine that had the same basic mechanisms, so each day required a re-breaking of the code.

B) they knew what *some* words were, so the machine tried out translations until it came to a possible 'correct' message, then humans would double check it. ~~For small sets of words, more than one code could possibly translate the same way apparently.~~ Edit: A correct code would have certain electrical characteristics, but occasionally an incorrect code would have the same characteristics but not decode the message. IF the full message was not decrypted, the humans would un-pause the machine and set it to continue from where it was.  Depends on the cipher mode. In some modes, a cipher just translates a block to another block, and the same block always gets translated the same way. This is "Electronic CodeBook" mode.  This mode basically works like a substitution cipher. Translate a block, and then everywhere you see it, you can substitute your translation.  

There are modes where that isn't true though, where the same plaintext *doesn't* always encrypt to the same ciphertext. For example, in "Cipher Block Chaining" mode, each block of plaintext is xor'd with the previous block of ciphertext before being encrypted. This means that each block can have an entirely different output, even on repeating inputs.  A known block of plaintext (like "the file is a PNG, and has a header shared with every PNG") doesn't get you anything else in the message.  On a side note Bletchley park was owned by the UK national telephone company and I did residential courses there in the 80's, parts of the computers were lying on the floor in various unlocked rooms, the lecturers told us they were used in the war for cracking codes....they played it right down and it was amazing to find their real significance, I picked a few bits up and dropped them again on the floor. Do you think the lecturers even knew? I've noticed there is a lot of misconception about who people think broke the Enigma Code. It was not in fact solely the British as most people think but it was the Polish effort that enabled Britst to decode Enigma messages.

&gt;German military messages enciphered on the Enigma machine were first broken by the Polish Cipher Bureau, beginning in December 1932. This success was a result of efforts by three Polish cryptologists, Marian Rejewski, Jerzy Rycki and Henryk Zygalski, working for Polish military intelligence.

&gt;From 1938 onwards, additional complexity was repeatedly added to the Enigma machines, making decryption more difficult and requiring further equipment and personnelmore than the Poles could readily produce.

&gt;On 25 July 1939, in Warsaw, the Poles initiated French and British military intelligence representatives into their Enigma-decryption techniques and equipment, including Zygalski sheets and the cryptologic bomb, and promised each delegation a Polish-reconstructed Enigma. The demonstration represented a vital basis for the later British continuation and effort.[3] During the war, British cryptologists decrypted a vast number of messages enciphered on Enigma. The intelligence gleaned from this source, codenamed "Ultra" by the British, was a substantial aid to the Allied war effort.

EDIT: http://news.bbc.co.uk/1/hi/world/europe/8158782.stm BBC article [deleted] http://www.reddit.com/r/askscience/comments/2qoksb/with_modern_technology_how_long_would_it_have/ Finally my degree (Molecular Genetics) can be useful! 

It's all about protein gradients. It's part of why life is mostly symmetrical or radial. You have a point of origin, let's say a shoulder area, producing a particular protein during development. As the cells near it replicate to form an arm, the protein made at the origin spreads into them. The further the cells are from the origin, the less protein they have. Eventually, the cells are far enough away that the lack of that protein signals that the new cells being formed should be hand cells. Those hand cells then function as a new point of origin for a different protein radiating outward, which when present on its own forms finger cells and when mixed with the original shoulder protein forms wrist cells. At about a 50/50 mix of hand/shoulder proteins, elbow cells form. 

This is a very simplified explanation, as the truth involves the interaction of countless protein gradients and combinations from tons of origin points, but it's the general way that your body forms and differentiates. 

So the cells on the tip of your nose are far enough from the point where your nose meets your face and have little enough of one or, more likely, five thousand nose proteins that they know they should be tip of nose cells as opposed to anything else. They're obviously not getting "please become feet" proteins because the origin cells for those are much too far away. 

Hope that helps. 

[Edit]: Thanks for the gold! And thank all of you for such a friendly response. I'm glad you guys found my explanation so interesting. 

If you haven't looked yet, check out some of the wall-of-text comments below. Other users have added a ton of great information to this conversation. Specifically in regards to extracellular matrices, asymmetric cell division, and protein sinks.  Thanks for the response, that makes a lot of sense. How about on the micro scale? It seems like there would be a lot of 'blur'. So rather than an exact map of where every cell should be, it is more of a 'close enough' system? It's stupid complex. You've got so many origins and proteins interacting with all the processes in the cell that it is a pretty perfect map as long as it's working correctly. Some proteins will enter the nuclei and interact directly with the DNA, activating, promoting, or deactivating different regions. Some will react with other proteins in the cell directly. Some will serve as signals that are read by the membrane proteins of the cells. Some will modify how RNA is transcribed. It's the most complicated machine you can imagine.  Let's assume, hypothetically, that I'm biotroll in year 2101. 

Could it be possible to have set of proteins that  tweak the gene expression in some point of body into a origin point of some other part. For example, I stick needle into the forehead of someone I don't like and that becomes origin point for genitalia.  Sort of. If you also threw the right stem cells in the mix, you could do that. We're doing similar things now to help restore cut off fingers and such. The forehead cells are already differentiated though, so just showing them dick proteins wouldn't make them turn into a dick.  That's probably a good thing otherwise adult entertainers would have very short careers.

That aside, this explanation makes it seem very simple to grow organs: just get some stem cells, sprinkle the right mix of proteins on them, and watch them differentiate. But it can't be that easy, can it? Well, nuclear fusion is *just* smashing some atoms together and harvesting energy.  That doesn't make it easy.You have *thousands* of proteins that all need to be dropped in at the right times, in the right ways, from the right places, at the right mixes.  And we have no idea what most of them are. Not to mention, the cell has to know how to handle them. Like /u/Morgensengel said, showing dick proteins to your forehead won't just cause them to make a dick
 Can't we just measure them then? e.g. look at the protein mix at the tip of the nose, and record that as "tip of the nose" mix? I'd imagine you would have to measure them during the formation of the nose, which happens in a fetus. And also be non-disruptive enough to ensure nothing goes wrong as a result of the measuring tools being there - as I imagine "bumping" or interfering with the cells might create skewed results.

A potential solution would be to somehow inject a 'tracker' in the cells, which spreads to other cells as they are made. Relay that back to a computer and you can track the distances between any other cells.  Here's my expertise as an biomaterials scientist working on molecular diagnostics. In short, we don't even KNOW the full human proteome, let alone of materials or methods to measure exact quantities of all of the important factors in the tissue.
 Scientists are working on this but the number of proteins is very high and it is very hard to study.  You have to somehow measure these things inside of a growing embryo and then figure out which specific proteins from the multitude are the important ones. Not an easy task. We do, in fact, do that. Look up 2d gel electrophoresis. It can be used to characterize tissues and cancers.

However, there are many other factors in cell behavior and development including epigenetics (dna methylation, histone modification), protein modification, age, etc. kind of, but thats way too simplistic. For it to form into a nose it had to have the right amount of the right proteins **at the right time** during the developmental cycle. Also, when you look at proteins you have to know what you are looking for. Practically there arent good ways to check all the proteins, and you cant do it easily over time, which makes it hard. You cannot do 25,000 western blots. If you could, you cant get antibodies for all proteins anyway. You could check all the mRNA with nextgen sequencing instead (sequence the transcriptome), and then you could get a snapshot of all the mRNA produced in the cell at a given time point, but you still wont know how much of that mRNA will ultimately get translated into protein, and how this goes over time during the development of a baby. So in the end you still dont know whats going on. Even if you could do that successfully it still doesnt really make sense..  That was a very good way to describe it, in a minimal way.

This is a fascinating topic, despite the dick. [deleted] You obviously haven't reached your 400 level classes yet, or you'd know the appropriate response is,  "imagine a frictionless star in a vacuum...." in short "it might be" - you just have to come up with exactly which proteins you need, get hold of the right kind of stem cells (the stem cells in grown humans are not exactly the same as embryonic stem cells), get them in an environment where every cell can get the right signals while differentiating, etc. Biology is incredibly weird at the base level, and we very often only have probabilities telling us what each part is most likely to do - no real proof of what it does, or how. Once it's figured out how - this could be incredibly simple... or not. It isn't easy, since the right proteins and the right amounts are a big challenge. Also the quality of stem cells. stemm cells =/= stem cells. There are different kinds of them. For example, every human has stem cells in his bonemarrow responsible for all our blood cells. They are, by definition, stem cells, but they aren't omnipotent stem cells. This means you can make different blood cells with your bone marrow, but you can't make neurons with it (for an example). Your skin stem cells on the other hand can make new skin cells, but only skin cells. [So there are different levels of potency dividing the stem cells into different kinds](http://en.wikipedia.org/wiki/Stem_cell#Potency_definition).

Then there are "induced" stem cells. Herfore you can take skin cells I guess, or other kinds of stem cells, treat them with a known mixture of chemical and proteins, and you will turn them into more potent stem cells (meaning you can now make more kinds of tissue cells than before).

And this potency separation is what is a major issue. You want your stem cells to divide you you can get a huge chunk of them while keeping their potency, but what stem cells naturally do is to divide and differentiate to less potent cells (this ensures that they can't do a huge mess and focus on their own task, bone marrow cells won't make skin cells by accident and skin stem cells won't make blood cells by accident). So you have to find a way to produce stem cells without loosing their potency, but then again you do not want them to lose their ability to differentiate. Because once you inject them somewhere, you wnat the stem cells to build the tissue/organ you want and once the job is done to stop. In the example above, after you injected the mixture and male genitals are fully grown on the forhead of you dickhead ;) landlord/boss, you want the cells to stop dividing, also, in order to grow the genitalia in the first place the cells have to differntiate and become specialised cells.

you see, it doable because we can observe it happen naturally, but it is anything except easy &gt; just get some stem cells, sprinkle the right mix of proteins on them, and watch them differentiate. But it can't be that easy, can it?

Yes, it's [that easy](https://xkcd.com/1425/). :P

The "hard" part is hidden behind "get some stem cells", "sprinkle" and "right mix". Getting the good kind of stem cells that will work on a patient is a hard problem. Putting them in the right place is a surgery-level problem (call that "easy" relative to the rest here). Figuring out the right mix of proteins is a Hard++ Challenger-Mode problem, on par with analyzing the effects of a strand of DNA with no simulations allowed. As for sprinkling, well, we're not that far ahead with our injection vectors yet. Putting arbitrary "stuff" in arbitrary locations in the body (or even a disembodied organ) is still pretty hard.  That is perhaps the single weirdest method of getting a traumatic brain injury I have ever heard in my life.  That right there is the difference between simple and easy. Getting to the moon is simple. Nuclear explosions are simple. That doesn't make them easy to accomplish, just means that you can explain how they work in a few short sentences.  The key missing point here is that it's not just a specific set of proteins ( the most important of which are called transcription factors, as they in turn regulate many other genes) but also a specific order of the presence and absence of these proteins. We are just now delving into an ocean of data to understand how the cell changes in response to a signal and how that sets up the reaction to the next signal So, asking for a friend: some stem cells and dick proteins could actually give me a longer penis? You'll have to shred it or cut it in half to facilitate growth. Plus then cancer.    I laughed maniacally at a human sized forehead cell being introduced and shaking hands with a human sized dick protein.

"Just call me Richard." You can reprogram one differentiate cell to another, even from a different germ layer, using the correct transcription factors.  [Here](http://evolution.berkeley.edu/evolibrary/article/evodevo_05) are fruit flies growing legs from their head thanks to a "biotroll" :) Scientists are already doing this with non-humans, notably fruit flies. It's part of how we're starting to understand how this stuff works. By screwing around with a set of genes called [Hox genes](https://en.wikipedia.org/wiki/Hox_gene), scientists have messed with the fly body plan done stuff like "[make legs grow where antennae are supposed to be](https://en.wikipedia.org/wiki/Antennapedia)" or "grow 2 full sets of wings instead of 1". 

Bug stuff: a notable trait of flies is only having one set of wings (hence the name of their order, Diptera, which is Greek for "two-wings") while most other insects with wings have two sets. In flies, the second, rear set of wings have been reduced to little stubs called *halteres*, used as sensory appendages to basically provide gyroscopic information to the fly. They're why most flies are very, very good at maneuvering so damn quickly in the air. Tweaking some genes called the **https://en.wikipedia.org/wiki/Bithorax_complex** results in the halteres actually becoming full wings by turning the 3rd thoracic segment of the fly, where they normally reside, into a duplicate of the 2nd segment, where the forward wings live.


Some bonus sources: 
http://learn.genetics.utah.edu/content/variation/hoxgenes/
http://www.exploratorium.edu/exhibits/mutant_flies/mutant_flies.html
also, a BS with a minor in Insect Biology. :)


 This is random, but figured I'd ask. I'm a physics student with a moderate interest in math and I notice these tiny flies outside on my balcony all the time. I don't have a picture, but they have quite narrow bodies and often times just like to perch on the flowers I have hanging in the balcony. 

What really interests me is that these flies (which I've dubbed as orbital battling flies) have very peculiar orbits during flight. In fact, it's almost a perfect representation of the Lorenz system. I'm curious if these flies are known and studied and if anyone had noticed what I noticed.

edit: For the record I live in Western PA. I'm actually working on a project like this, where in a nematode we can force one of its organs to turn into something else.

The original reply is describing morphogen gradients where signals act at a distance, but there are many other ways for cells to figure out what they should be doing, like more direct cell-cell interactions or cell intrinsic gene regulation. The cells in someone's forehead (be that skin cells, bone cells underneath, or whatever) are made not from the other functioning forehead-cells but from stem cells in the tissue. These are not the kind of stem cells you're probably thinking of, they are not pluripotent stem cells like the ones that come from an embryo (cells that have the ability to become any cell in the body), they have lesser potency. They would be called multipotent, oligopotent or unipotent, and it means that they can only create one or very few types of cell.

An easy example, skin. Your skin is built up by layers upon layers of skin cells, called keratinocytes. Under all this is a single (one cell thick) layer of skin stem cells, that are replicating (splitting) at a more or less fixed rate. Every time a stem cell split into two it results in one new stem cell to keep up that work, and one new keratinocyte. And of course, the topmost layer of keratinocytes are constantly rubbed off, so every layer is constantly pushed upwards.

What I'm trying to say here is that I don't think you can induce genitals in an adult's forehead, but what you're suggesting sounds like it could work on an embryo! So in biology there's the concept of a "stem cell" - you may have heard of them. Basically, they're cells that haven't yet received a signal on what to become. They're technically called undifferentiated cells.

Well, anyway, stem cells turns into genitalia when they get the right signals - that's the proteins, cell to cell communication, etc - so if you could somehow replicate those signals exactly, you could turn a stem cell into a penis. And the best part is, once a cell has become differentiated, it stays that way. The penis would remain a penis forever.

The issue is that once you've progressed beyond an embryo, you don't have many stem cells left. I think they've managed to coax bone marrow into stem cells, I might be making that up. If you recall stem-cell-bans because some people likened it to performing genetic experiments on fetuses, this is why. You only get the stem cell from a brand new fetus, so to put genitalia on someone's forehead you would need to get some of their stem cells first, and then implant them into the person, while providing the signals for genital and simultaneously preventing the "I'm a forehead" signals from getting through. It's comforting to know that my penis will not spontaneously change into an ear. All the cells that are differentiated have dip switches (methylation groups) on genes that determines the running code from the dormant code.  You would need to reset some cells to a point in the build where they were not yet differentiated - then start them on the path to run the code for genitalia.   Yes, it's possible to grow additional limbs in chicken using regulatory proteins- [1](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1571061/), [2](http://dev.biologists.org/content/124/11/2235.full.pdf)  (KFC definitely should use it.). Actually yes. As a project for a thesis a friend of mine was working on, they had to show proof of concept that a less complex part could be made to form in a place on a fruit fly. They had it express legs along its back. The ultimate these revolved around nerve endings, and tho they were not able to completely run nerve endings to it, they were able to make an functional eye form on the back of the fly. So one day mothers really might have eyes on the back of their head. There are real life examples of this. Kartageners syndrome is a problem with proteins controlling cilia movement. Cilia are like little hairs that can move and form a current. In the syndrome there is a problem with cilia creating a current that stops certain "bags" of these proteins from being properly circulated. The result is you have these bags of proteins that control directionality where certain organs develop in the body build up in the wrong area so you have something called situs inversus, which can make your heart develop in the right side of your chest and not the left. where cells/organs develop is dependent on these protein gradients so this is an example how messing with those gradients screw up development.  This has been going on in vitro for years. Even I have reprogrammed fibroblasts to motor neurons. 2012 Nobel Prize: Yamanaka for figuring out how to turn fibroblasts into stem cells. In other words, he figured out what proteins need to be on the tip of that needle to do that.  This is really really fascinating - thank you! Now let's try to figure out how the brain works. Should be a cake walk. Then what determines what protiens are released?  Is that the instucctions on the DNA? Yep. The DNA in any cell is able to express any protein. Based on its methylation (little sticky buddies that hang out on the DNA), it will want to produce some and not others. Other proteins present in the cell or interacting from nearby cells will also modify which proteins it makes and how much of each. Some proteins will also just straight up bind and inactivate or destroy certain proteins upon their production. Lots of ways to promote and regulate protein expression.  It's gobsmackingly fascinating, but too much for my small brain to comprehend.  &gt;.&lt;  Can these interactions be represented mathematically? Yes, and they have been. One great example is Alan Turing's model. Here is some more info about it: https://phylogenous.wordpress.com/2010/12/01/alan-turings-reaction-diffusion-model-simplification-of-the-complex/ Could this be modeled using finite element analysis?
 Wow, this is amazing. Reading this makes me sort of religious, not in the sense that I'd believe in Intelligent Design, but I'm in awe of evolution right now, and humbled by the mathematical complexity of it all. I read somewhere that ABO antigens are important in fetal development and act as embryonic markers for the same purpose. Is this true to your knowledge?  Wait. Then how does the origin point know it's the origin point, and to gather all the protein to begin with? Is it just in the species's DNA?  Cells are capable of signaling other cells in the immediate vicinity to alter their gene expressions so that they differentiate into functionally appropriate cells for the tissue. One pathway that I know of that might interest you is the Notch pathway, which actually mediates such signaling between adjacent cells, particularly in nervous tissue (thus ensuring that cells around neurons tend to differentiate into glia, for example). In case you're interested in slightly more information:

What I find fascinating is that these signaling compounds don't have to be proteins. Small molecules (organic compounds, e.g. retinoic acid) as well as mRNA (the instructions for protein construction, although this is complicated, since an mRNA gradient essentially results in a protein gradient) can also form these gradients. And, early on in development, a lot of these signals are actually defined by compounds that the mother put into the egg.

Also, gradients aren't the only thing acting. Amongst other things, asymmetric cell division also plays a role. If you start with one cell with determinants in it that can specify fate A and fate B, it can sequester those factors such that one of its daughter cells gets the A factor (and will become an A cell) and the other daughter gets the B factor (and will become a B cell).

This underlines a large topic in development: cells can either "know" what they are supposed to turn into without cues from other cells (autonomous), or cells can require instruction from other cells in order to turn into what they are supposed to (non autonomous).  Different organisms use different combinations of these developmental strategies (mosaic vs. regulative development).

Thanks for asking developmental questions, definitely got my mind churning this morning! Very early on, cells differentiated into inside, outside, and middle (endoderm, ectoderm, and mesoderm) (skin, GI tract, and bones) -- these are called germ layers.  These cell lines don't subsequently cross over, so as the arm is forming, there isn't a risk that a skin cell gets confused and thinks it's a muscle cell.

So as the arm grows, the skin cells grow to be arm skin, the muscle cells grow to be arm muscle, and the bone cells grow to be arm bones.  In the meantime, blood vessels and nerves are growing into the arm under their own algorithms.

Does that help explain why there isn't blur? Yes that helps a lot, thanks. Would it be reasonable to say that as a cell becomes more differentiated it acquires new signally proteins/mechanisms to talk to child specializations but also retains the signaling mechanisms to communicate with more general (parent) ancestors? Also, remember many of the things that make tissues work (like shape, or size) are independent from the cells that compose them and more or less follow a predetermined map laid down by OTHER cells to work. For example, skeletal muscle shape is very dynamics dependant, as is bone shape, and "bone" cells don't account for that but "cartilage" cells, which lay down the form that bone cells will later pick up (of course this is gross generalization and osteocytes do follow stress lines in bone). 

Most cells on the tip of your nose actually "know" nothing of their position, but more of their tissue. They aren't "tip of the nose" but "facial skin, hairless", many of the properties we associate with the place instead given by underlying tissue (vascular properties of the danger triangle, tensile properties from the underlying cartilage, the fact that you can't wrinkle the nose because there is almost no muscle fibers), and it's this locational UNawareness that lets things like muscle or skin transplant be possible. If we had a foot liver, we could transplant it into our abdomen liver with no issue because it would know it's a liver, not a foot liver, if that makes any sense.   That would be reasonable. 

It's a bit more complex. There are waves of development, hundreds of genes modulated, stages that flow in certain processes like a symphony rising and falling over time. 

 If you've ever programmed, think of spaghetti code.  Code that got written over the course of a few years.  People came in and out, wrote in extra programs and functionality, abandoned certain functionalities that stopped working when they edited some of the main program, then used the non-functional parts of code to do something entirely different from what it was originally meant to do...

The body's programming is like that.  So what you say isn't unreasonable, but it's not as linear as children cells listening to ancestor cells -- for one thing, the ancestor cells are going away.  A newly-differentiated skin cell might develop pathways that enable it to detect which direction the subdermal cells are in, so it knows to face the outside, so to speak.  A new muscle cell learns to sense the orientation of the limb it's growing in. Everything in this level is blurry and stochastic.  Luckily it does not matter because millions of these guys are all interacting in the same way.  They average out to be a nose or a foot because all their neighbors are participating in the self organization.  

A rain drop does not know it is part of a thunderstorm or a hurricane.  But the hurricane's structure is the emergent effect of the interactions of countless particles and currents of energy.  Any one local part of the system is just following local physical law.  The emergent aspects can be much more than the sum of its parts.
 Well not only this but we have a very incomplete picture. For example most of the discussion here is concerning genetic expression of stem cells during development. What about mechanotransduction in adult cells? Cells are *extremely* sensitive to their physical (as opposed to just chemical) surroundings and will act accordingly.  Actually, [some creatures do have a perfect, exact map](http://en.wikipedia.org/wiki/Eutely). One of my favorites is *C. elegans*. Provided everything goes properly during development, the critter will [ALWAYS end up with 1031 cells](http://en.wikipedia.org/wiki/Caenorhabditis_elegans#Reproduction_and_development) when it's grown up.   Nurse here (NOT a geneticist!). 

Just wanted to chime in and say that my limited knowledge tells me that it involves HOX genes in part. Those help direct the body "plan" of the organism in question. In short, it informs the organism when to branch off into appendages during early development. 

http://en.wikipedia.org/wiki/Hox_gene

Somebody correct me if I'm wrong, all of this is vastly over my head. Hox genes absolutely do play a part! However, hox genes know where to be expressed based on the interactions of protein gradients. :) So we'd say that early embryonic patterning via the interaction of protein gradients is *upstream* of Hox genes. it helps that most organ and tissue development happens within the first few weeks of a pregnancy- there are much fewer cells to deal with. Another factor is that cells are influenced by the other cells they are touching. One cell gets a signal and can propagate it to its neighbors. Pretty soon, the edges of your organ or tissue are defined, and the interiors can be filled in later. (Vast oversimplification) Absolutely never simply "close enough." The way organisms make highly precise cellular identities is through using a set of morphogen gradients, making control extremely precise.  So, the cells in, for example, bones...are they influenced by combinations of certain concentrations of proteins from skin, muscle, etc? Or is the ulna influenced by combination of proteins from carpals and the humerus? So, to make that clearer, does the cell's formation and behavior depend on only similarly formed and behaving cells, or is it a combination of everything surrounding it? 

As well, do these proteins travel through the cells themselves until a near-equal concentration is reached sort of osmotically (I'm thinking concentration differential as seen in stuff like Na+, K+, and Cl- in neurons, but without the ionic forces or active protein channels...I just can't remember the right word), or are they transported via other transport proteins (or some other vehicle)?
 To give you a sucky answer, yes. 

Cells are influenced by the proteins and extracellular structure of everything around them. And if you consider that a protein gradient is potentially originating from many cells away and just spreading trough the nearby cells, then they're being influenced by cells far away from them as well. 

You're right that osmosis is part of it, but it won't be just 1:1. Cells touch other cells or liquid-filled spaces on all sides, so the osmotic pressures aren't going to be straightforward. One center cell touched by 12 surrounding cells might have 12 times the concentration of a particular protein than any of the surrounding cells. But even the it wouldn't be that simple, as each of those surrounding cells have other cells they're touching. 

Then you have to add the fact that proteins aren't tiny permeable ions, so active and passive transportation channels and protein interactions are going to affect how proteins move between cells. You were right to consider that as part of it as well. 

Some days I think it'd be fun to get a graduate degree and work on building computer models of all of this. The complexity is intriguing and it hurts my brain. 

[Edit]: I realized I didn't directly answer your first questions. Other bone cells probably have more influence  in terms of number of proteins interacting just due to similarity in structure and protein productions, but they're definitely influenced by muscle, skin, blood, and everything else around them. That being said, a super-expressed protein in a muscle cell that directly targets and modifies the function of bone cells near it could be said to have "more" of an effect. I'm thinking ligament production.  Thank you! That was far from a sucky answer. I feel so edified. I understand cellular interaction*only* within the realm of neuroscience, so it was really fascinating to see that "communication" happens in all cells, and even helps to form them.

I absolutely agree with you, there. If any schools nearby offered it,I'd totally go for a graduate degree in neuroscience as well, building computer models and even doing histology stuff. Money is also a factor.

You mention ligament production; so, a muscle cell does this "super-expression" thing which produces a very strongly influential protein, which in turn causes that bone cell to start forming ligaments? Is this, then, how ligaments are actually fused to bone and muscle? They're all just grown out of/into one another? So I assume it is then a similar process for any time you have a sort of "tissue gradient" going on (for example, areas of different kinds of skin cells such as simple squamous to cuboidal or columnar)? Thanks. Neuroscience is fascinating as well. 

I used the super-expression and ligament examples hypothetically. The former isn't an official term or any sort and the latter was just my guess at how it could work. I don't know for sure how ligaments form. 

But I can tell you that the cells for it do form from the cells next to them. All cells form from nearby cells, and you can see tissue gradients of the type you described during development. Usually though, as development continues, the far ends of any gradient like that will express different proteins that meet in the middle and create a more definite boundary. So while you may have had an odd muscle/ligament hybrid cell during development, it could have turned into just a ligament cell or just a muscle cell the next time it replicated due to a sort of consolidation of each gradient.  Oh, I see! Thanks so much for all of your answers. You explain things very well.  Thanks. Always happy to help.  &gt;Cells touch other cells or liquid-filled spaces on all sides, so the osmotic pressures aren't going to be straightforward. One center cell touched by 12 surrounding cells might have 12 times the concentration of a particular protein than any of the surrounding cells.

This sounds fractal? I'd say you could definitely describe the radial development of some sea critters' shells as fractal.  The Self-Made Tapestry: Pattern Formation in Nature

If you or anyone else in this thread like to learn about patterns of growth, you should read that book. Thanks this sounds great and I'll look in to it. With all these over-my-head answers, it would be great to see some sort of generalized model that might depict some abstract order to this chaos. So your bone cells come from various stem cells. Those stem cells are induced to differentiate (decide on which cell type to become) based on specific chemical signals in addition to cell-cell interactions. In fact, a big part of how cells orient themselves is based off of rubbing against and grabbing onto each other (such as in Notch) or protein gradients like Wnt/beta-catenin signaling.

In fact, the latter signaling pathway (Wnt/beta-catenin) is a very early indicator for directionality of cell populations (it keeps your organs from being placed in a reversed direction like in situs inversus) as well as which cells should migrate to the front (ventrally) versus the back (dorsally).

On top of that, many signals are derived from what's been mentioned (such as protein gradients, where the proteins in the proximal end of your ulna or radius are sending the most signal to the nearest cells at the more distal end of the bone or the most distal part of the humerus). That said, skin signals are pretty negligible for most bone cells since there's layers and layers of various cell types beneath. For the signal to reach, it would have to go through fibroblasts, skin stem cells, fat cells, muscle cells, immune cells, and many others first (where by then, the proteins are probably already broken down). There's some major exceptions to this (like how growth hormone from your pituitary affects organs all over the place as far as growth ) but then we have to decide if we're talking about paracrine signals (where cells influence cells in their near facility ) or endocrine signals (where signals are far reaching to cells on complete other ends of the body or near them simultaneously via blood distribution) or autocrine (where the signals released influence themselves! This is a big issue in cancer). A lot of development of an organism regards paracrine signalling and a lot of endocrine regards homeostasis in a much more developed organism, but there's of course exceptions. 

On top of that, your ulna has an incredibly diverse population of cells (from osteoblasts and osteoclasts that are directly involved with bone remodeling to immune cell and blood precursors that are just stored inside). But this makes the conversation more complicated but all relates to cell cell interaction dictating them where to go. The fundamental aspect I'm getting at here is that these directions and influences occur at the cellular level and not at the larger bone level (the hip bone doesn't influence the leg bone, but rather the microscopic cell colonies on the edge of each influence each other). 

Your final question, the answer is basically yes. During development, everything stems from the first fusion of the egg and sperm, leading to the first cell. When it divides several times over, certain cells take precedence on dictating development in certain areas. Now, I'm only a med student, but we've been told that how those signals originate are somewhat murky and probably have to do with epigenetic changes that affect the cells protein expression early on.

I hope that answers part of your questions   *slow clap*

That was awesome. Thank you. It answered it and then some. 

I did know that we were talking the cellular level, so, as you said, nothing from the hip is going to be reaching the arm or anything like that.

The differentiation you mentioned; is that how labs are able to turn a skin stem cell into a bone cell or neuron by placing the cell onto a special plate with differently textured and pressured bumps and stuff? 

As well, I heard that Turing even did some work on an equation (or something) that would be able to determine (or predict) how a cell could differentiate. Did I mishear, or is that true? If it is, do you know anything about it?

Finally, can you talk more on autocrine signals?? That sounds fascinating.  &gt;The differentiation you mentioned; is that how labs are able to turn a skin stem cell into a bone cell or neuron by placing the cell onto a special plate with differently textured and pressured bumps and stuff?

Now that is some interesting research! I'll have to go on a search because I remembered reading about it some point. Basically, you have two major types of stem cells (pluripotent and totipotent). The former have a very defined end-game (like skin stem cells are destined to become skin cells) while you have many more pluripotent stem cells in babies and fetuses (since they need to make a lot of cell types, including nerves that don't have a specific stem cell population). I'll have to get back to you on this, but some research is designed to take pluripotent stem cells and revert them to totipotent stem cells so they can then induce those stem cells to form anything. Which is exciting because then they could make, let's say, an organ based off your own skin stem cells (which are easily obtainable) and you would be hard-pressed to reject the organ when transplanted since it's your own DNA! That said [the transformation to totipotency is not fully understood and highly complex](http://en.wikipedia.org/wiki/Cell_potency)

I've never heard of this equation that Turing worked on. There's a lot of mythos surrounding Turing that I won't even touch, but I can't imagine how an equation would do justice to the protein signals that a cell gets to differentiate. It would have to account for every environmental change (if, say, there was a laceration that cut some of your muscle fibers and your satellite cells replenished them, they get signals from proteins in other cells, cell cell interactions, and cell lysis, not to mention the inflammatory response that would occur due to the injury). You'd have to defer this question to someone who's heard about Turing's equation.

Autocrine signals. Oh boy, that's a hot topic in cancer. There's a myriad ways that its involved and many are [elaborated in this Wikipedia article](http://en.wikipedia.org/wiki/Autocrine_signalling#Autocrine_Signaling_and_Cancer). Basically, autocrine signals are a way for a cell to induce itself to do something. There needs to be proliferation without any regulation to be a successful cancer. One way is for cancer cells to produce protein signals that bind its own receptors that protect it from destruction via the immune system as well as stimulate it to keep dividing. Many cells in the body proliferate, undergoing mitosis and cytokinesis, under cell cycle regulation (where extracellular signals can prompt proteins to be made the pushes the cell through the cell cycle). A cell can also produce its own signals (which is autocrine signaling) to make those proteins as well as produce its own signals that allow it to stop making regulatory proteins for the cell cycle. Unchecked cell cycle progression is a cancerous malady as well. 

Autocrine signaling in cancer is an enormous topic, but basically it's how cancers can get themselves to keep growing. A colleague of mine when I was doing cancer research talked about how cancer cells are kind of like parasites: they feed off the resources of the human body, they don't contribute anything, and they spend most of their time trying to survive against the body's immune system.

If you find cancer an interesting topic, there was a great PBS documentary called *Cancer: Emperor of All Maladies* that was produced by Ken Burns and is an amazing descriptor of the history and state of cancer research. Thank you! I will look into the articles and documentary as soon as I get a chance. 

I hadn't heard the terms pluripotent and totipotent before, so now researching on my own will be a bit easier. Thanks! 

As for Turing, I should have mentioned that it was *only* for very early stages of development, like, zygote to fetus, so it was about differentiation and positioning of very early stem cells, so a lot of those other factors could be ignored. It also may not have been an equation, but my mind is thinking equation because it is Turing. I hit up google and found this, so, yeah...no equation, but he did do work on [the chemical basis of morphogenesis](http://en.m.wikipedia.org/wiki/The_Chemical_Basis_of_Morphogenesis). 

This is all so fascinating to me. I wish I had the time and money to pursue it all further. I'm currently reading through The Principles of Neural Science, as that arena is more my forte, and even just neurons interact in such amazing ways; even how they sustain themselves is incredible. To be able to learn about other types of cells (or anything, really) in such a depth would be amazing. 

Thanks so much for your time!  Thank you for your interest! This is a totally fun way for me to review (since I'm completely procrastinating from studying for my medical school classes at the moment). 

I'm checking out that Turing work in just a moment, but thanks for looking into that.

Neuro is such a complicated field though! We had it as a stand alone course in medical school and I barely can comprehend some of the stuff going on. I'm glad you're handling all that neuroscience because I know I sure couldn't! 

Anyways, keep asking the good questions. It never fails to astound me how there is always someone with the relevant qualifications around to answer even the most obscure questions. That's what I love the most about this place. To be fair, the question ties into morphogenesis, cellular differentiation, and regulation of gene expression, important areas of biology and molecular biology.

Asking about cells on the nosetip and getting all this is like asking about the beak size/shape of some obscure finches and ending up with a lecture on evolution. True. This question is not very obscure. Anyone who knows about stem cell research can answer this question in its entirety. This is common knowledge bio that thousands of people know by heart in great detail. I actually had exam questions about this stuff back in my undergrad.  The proteins act as signals that initiate chain reactions in the cells to coil up irrelevant sections of DNA and expand relevant sections of DNA. Then in these cells, the relevant DNA is loosely packed and easy to read, and therefore those genes are expressed; while the irrelevant DNA is packed up tight and difficult to read, and therefore not expressed. Correct? That's one of the many ways they can influence the development of a cell, yes. They'll often be in direct competition with another protein trying to do the opposite, so whichever is in higher concentration will win out and have its function (turning expression on or off) performed more.  It's also self-reinforcing often, where turning on a gene will generate more of the protein that turns it on.  It's not all about protein concentrations. A great deal of recent work ([here's one paper](http://www.ncbi.nlm.nih.gov/pubmed/21397942)) has shown that the elastic modulus, microstructural porosity, and surface chemistry of the substrate cells adsorb onto determines what they become. It's a big deal for bone replacements, since they want to encourage new bone cells to grow on/into the implant. Is all of that relevant during initial development as well? I'm not very knowledgable when it comes to post-developmental differentiation. Which is unfortunate, as it's much more important for medicine.  Most of this work is done with stem cells, so I would be surprised if it wasn't. Even minor elastic modulus differences resulted (in one study) in cells becoming brain vs muscle tissue. It's worth noting that these factors are not 100% controlling, but likely work alongside (or augmenting) protein/growthFactor concentrations. This! When I first stopped in here, this is one of the things I wanted to add. Elastic modulus in particular is a pretty big deal. So, if cells were radiating from my torso how would some know to becomes arms and others legs? They all have the same set of "instructions", they just move down the list as the proteins run out, right? DNA-wise, yes, they have the same instructions. If you consider methylation of DNA, part of epigenetics, you could say they could have different instructions. But essentially methylating DNA is the same as activating or deactivating it with a protein, so they're the same thing to us here. 

Let's say the center most cell of your torso is generating protein A, which is spreading into nearby cells. Very early in development, your cells receive orientation information from the womb (proteins from the wall of the uterus and surrounding liquid), so the cells on either side of that first cell know their orientation. One is more in the leg direction and one is more in the head and arm direction. Leg direction cells start producing protein B once they get far enough from the origin cell (once the concentration of protein A gets low enough). Protein B starts making more leg-like structures at that point. Same goes for arm/head direction cells and a protein C. 

In the real world, it's like hundreds or thousands times that many proteins interacting. But essentially, that's what's happening.  So the proteins originate from some point and indicate what structure should be built. Since DNA is just the list of instructions for proteins, does that mean these signal proteins are a result of [Hox genes](https://en.wikipedia.org/wiki/Hox_gene)? Or are those a totally different thing? Bingo. Hox genes are central to this whole system. They react to and produce the proteins that specify developmental structure. The DNA has the code for everything, but the proteins tell it which instructions to execute.  Was a bio major in college. Took a class on evolutionary developmental genetics (affectionately known as EvoDevo). OP should look up a book called Endless Forms Most Beautiful. Gives an educational and entertaining look at this field that I think is easily enjoyed by a variety of educational levels.  So would it be possible to somehow strengthen the protein "signal" to make an organ which is under-developed grow larger? Since then the more distant cells would receive a stronger signal and "think" they're closer to the source. Definitely. This (and situations where the proteins that say stop are never expressed) is the cause of genetic mutations where people grow an extra limb or way too much bone somewhere. The problem with doing it intentionally as a treatment is figuring out exactly what proteins to promote or quash without messing everything else up.  Or as I stated in a previous comment, "messing up" doesn't always lead to pathological issues. Some people get situs inversus(organs laid out in a mirror fashion with the liver on the left for example and the spleen on the right) from improper signaling, which is totally compatible with normal life until a doctor sees you and is all turned around!  So what happens when a baby is born with a(hypothetical) non functional arms sticking out of their head or any sort of extra body part deformity? Is it that at some point a cell was accidentally made on the head that has a protein for an arm? Pretty much, yes. At some point, the cells up there started expressing arm protein incorrectly. Why do cells not do this when a finger or a limb is lost?  I'm not as well versed in the post-development world, so hopefully someone else can help out here. But my guess is that is has to do with the fact that the cells are fully differentiated. We're no longer developing stem cells that can become anything. So we can replicate the same skin cells there to close over a wound and repair a muscle, but the cells a few cm away would be too different to make without stem cells.  Interestingly, this does happen in some animals! For example, zebrafish are capable of regenerating their fins (limbs) and even their hearts. Salamanders can regenerate limbs and tails. Neonatal mice can regenerate fingers! 

But unfortunately, that regenerative capacity is lost very, very quickly in mice and in humans. The cells that gave rise to the fingers or limb are lost during development and replaced with actual finger or limb cells (stem cells vs. differentiated cells). Thank you both. That's cool about the regenerating critters.  I just want to add one or two things. The origin cells are different from the cells they "direct" the way /u/morgensengel explained. For example, if you take a not origin cell from the heart (during development) and place it somewhere in the liver, the heart cell will become a liver cell. If you take a heart origin cell, then there will be a heart growing ion the liver.

There is also a thing called "asymmetrical cell proliferation". This basically means that  especially in the very early stages of development, the protein mix in the cell isn't divided homogenously. Some cells at some stage do split the protein mix equally, meaning they all get the same shar of protien x, y, and so on. Other cells at certain stages divide asymetrically, meaning one cell hass all the x proteins, while the other has all the y proteins. If I remember correctly, this is how origin cells are made, correct me if I am wrong /u/Morgensengel . So a cell can become more specialized based on protein (or other) signally. How about when that cell divides? You get two cells with the same level of differentiation? Then each of those cells can aquire independent unique specializations (depending on signally) and as they divide there becomes a new branch of specialization?

Sorry for the horrible wording. If I understood you correctly, yes. You start with one cell which has all the genes necessary to build all the proteins and all the tissue you need to build your whole body. Bones, organs, neurons, skin, nails, hair, everything. Now the cells divide and the assymetirc cell division I mentioned determines the "orientation" of the following two daughter cells. http://www.nature.com/nrm/journal/v9/n5/images/nrm2388-f2.jpg Posterior and anterior can be looked at as "up" and "down". One of the two daughter cells will be responsible for the upper body, while the other is responsible for the the bottom. But I think I forgot to mention that asymetrical and symetrical cell division are alternating. So the cells divide asymetrical, then symetrical and so on. Some divide asymetrical while other divide symetrical, depending on the developmental stage they are in.

I studied biology with a focus on genetics an microbiology, but I did not focus on developmental biology. maybe /u/Morgensengel can give you more infromation. 

As an additional info for the cell origin stuff, I want to mention the [HOX genes](http://en.wikipedia.org/wiki/Hox_gene). These are basically the genes responsible for the proteins mentioned above (origin cells and stuff). http://upload.wikimedia.org/wikipedia/commons/d/da/Hoxgenesoffruitfly.svg

You see that each gene is expressed in certain body parts. During the development these Proteins, which are mainly gene regulators, activate the genes necessary to build that one body part while simultaneously inactivating the genes needed to build other body parts. And since these regulator proteins are more abundant in the near proximity of the origin cell, they do their job efficiently. The further you go from one origin cell, the closer you are to another one meaning that a differen gene regulator is now abundant. So if you graft skin from elsewhere to a new location, does it retain its original protein gradient, or does it eventually "starve" itself and "feed" itself the new protein profile of the new location? Axis patterning is one of the most amazing things in metazoan biology. And all this happens, correctly (almost always) despite the fact that ALL of our somatic cells have the exact same genome (yeah yeah except B and T cells).

One very important point I have to add, which is sometimes missed even by biologists, is that protein gradients only exist because of protein sinks - specific proteins are degraded in specific poles or along specific axes of cells, and that is what generates the gradient. Without a sink, the protein reaches equilibrium (equal concentration throughout) and no gradient can be maintained. This equilibrium occurs because the steady-state (stable) level of a protein is achieved at the precise time at which its rate of creation, or translation, matches its rate of degradation. At that point the concentration is equal throughout the whole cell. So the purpose of a protein sink is to actually create *local* changes in the rate of protein translation or degradation within a single cell, which people often think of as a homogeneous soup with a nucleus and cytoskeleton (I assure you it's much more). I believe it has been shown that it's primarily RNA interference that locally lowers rates of translation. Pretty amazing that these mind-numbingly complex processes all evolved spontaneously.

Great question OP, and great answer /u/Morgensengel. Thank you for adding this! That helps the explanation so much.  Woah, woah. What about those B and T cells? Could you elaborate on their differing genomes? (Also, what other types of cells are besides somatic?)

Also, how dense is a cell? How can ribosomes for example find the right stuff to build from just by diffusion? Sorry I brought that up...I'll never forget it because way back in grad school, we were asked a question in class about whether all somatic cell genomes are identical. We all said yes except one smartass, who brought up VDJ recombination, which technically *is* an exception. Very briefly, B and T cells have a few gene loci that encode immunoglobulins (antibodies). Our immune system's ability to respond to infection is dependent on having a huge library of antibodies which can recognize virtually any possible piece of a protein (an *epitope*, which is a 6-8 amino acid stretch of a protein). To achieve this, the loci encoding antibodies rearrange during development to create the huge library of antibodies our B and T cells express. Hope this makes some sort of sense...pretty cool exception to the rule if you ask me. Without it we wouldn't survive very long...

As to your first question, somatic cells are all the non germ-line cells, and all divide my mitosis to ensure fidelity of replication - the only changes in the genomes of somatic cells are due to random mutation, which occurs once every billion bases or so per generation. So pretty much all cells are somatic except sperm and eggs, which divide by meiosis and, because their genetic makeup ends up being derived randomly from pieces of the sequence of *both* copies of each chromosome, are unique. Thank you very much. 
And thanks to you, OP. Neuroscience MSc. here. Let's not forget about the interaction of these gradients as things change over time. As these gradients interact with each other at various locations (cells, networks), they cause modifications of the cell which can involve many functions (differentiation, etc) including the production of new gradients. So these things are vastly complex, and also temporally dynamic. This leads to a more distinct system (as opposed to a close enough system) because the system is refined and changed over time. Sorry for being a bit vague, but I figured that's better than absurd technicality. Sonic the hedgehog, innit? The Sonic Hedgehog gene is one of them, yep. Along with all the other Hedgehog genes.  Does this have anything to do with possible [Morphogenetic Fields](http://en.wikipedia.org/wiki/Morphogenetic_field)? I don't know much about it, other than that my friend did his master's thesis on it. Seems to be a pretty cool topic. You had your moment to shine, and you really knocked it out of the park. 


I'd always wondered about this, but never had anyone lay it out in a simple, straight forward, high-level way that made sense to me. 


Thanks for that.  Do you know of an animated video that explains this? I learn best by seeing.  Best I can do on mobile: https://m.youtube.com/watch?v=FujT2tdHv8s

It gets pretty technical, but basically this is a fruit fly embryo, and it's showing how the protein DPP establishes a gradient where most of it ends up on one side of the embryo. It talks about how dorsal (top of body) structures form when the amount of DPP is high. 

 How does something like this evolve? I mean I'm not some ID proponent or creationist. But then I'm faced with something that seems so clever and fragile at the same time that it boggles the mind that it actually works and doesn't produce massive deformities 99% of the time. 

The way that works reminds me of recursive functions in programming. Nature can be pretty amazing!
 You start with a ridiculously simple version that just differentiates a body into two layers - guts on the inside, skin on the outside. That's (more or less) enough to make a primitive version of a worm or a jellyfish or the like. Then refinements are added gradually. Very early on in evolution, we developed genes that create proteins that make sure that genes replicate correctly during cell division. That was kind of a prerequisite to anything truly complicated coming about. 

As to how it started, you can look at single-called organisms. They'll have feeder bits on one end and flagellum on the other. The proteins produced near the feeder bits prevent the proteins that form flagellum from making anything near the feeder end and vise versa. 

We do the same thing, just across cells instead of within them.  How long has this knowledge been around?? I remember being told as little as 4 or 5 years ago in highschool that we still didn't know how cells knew how to differenciate.  Keep in mind that often teachers (even good ones, sometimes) will say something like that instead of "I don't know" in order to maintain authority and respect in class.  The knowledge /u/Morgensengel is talking about seems pretty deep into a specialized field so it's pretty unlikely that anyone studying to become a high school teacher is studying that topic (and that's okay, because it's definitely not a topic being taught at the high school level). I'm pretty sure it was course material as part of an actual unit with a textbook chapter and everything. To be fair I'm finding a lot of stuff in university that I was told the knowledge of didn't exist. Also of note is that textbooks can become outdated rather quickly. (Hence crazy prices in college/university for the new editions being released all the time.)

What someone is teaching you in high school may be outdated by at least some degree. Science doesn't stay static on all topics forever! (Certain things yes though) Yes there are some concepts that remain "stable", but new work and new discoveries are made often.  As /u/mewhaku said, things get outdated quickly! This is especially true in some fields of biology (like stem cell research and immunology) where the research coming out on a year to year basis are totally changing the game.

Also, from my experience, a lot of what I learned in high school was a gross oversimplification that borders on the edge of being invalid. When teaching biology at a basic level, lots of generalizations are made which do disservice to the highly complicated interactions in the body and I found I had to unlearn lots of generalizations when talking about biology. Genetic biologist here.  There are some things we didn't know, but cell differentiation, particular from development has been study for a very very long time and has not exactly been some mystery.  We've known about protein gradients, and compartmentalization of pre-made Transcription Factors within the zygote which leads to the beginnings of differentiation for quite some time.

But, it is an extraordinarily complex thing, so either the teacher gave you the "I don't know, so no one knows" answer, or the teacher just couldn't be bothers to explain the complexities behind it.  There ARE still some aspects of it that are little understood, but it is not a big mystery anymore how it happens.  Lots of research has been done in this field.  You typically won't learn about it until higher level courses in college though because you need a strong foundation in basic biology to not get overwhelmed. So when someone has an extra thumb is this because the process has gone wrong?  Yes. The digits are set up by a gradient of proteins that originates from the posterior portion of the limb bud, called the ZPA. In some classical experiments, that ZPA was transplanted toward the anterior part of the limb bud and it resulted in extra digits that formed in a mirror-image to the normal digits!

(For this example, posterior = armpit, anterior = shoulder) how close are we to a shot that can regrow limbs? Further than we'd be if we could do more stem cell research. I don't honk we're remotely close, but someone else could answer that better. 

I'd have to imagine a vat filled with stem cells that you put your bloody stump in for quite a long time. It'd help if we had proteins in it that accelerated growth, but cancer would be a big concern. You could have a fancy liquid filled cast that your new limb grows in though. That'd be neat.  Do you think limb regeneration could be accomplished with stem cells and 3-D printing? 

What if we had different vats of stem cells, and a 3-D printer could use them like ink, printing layer after layer until a limb is complete? "Bone cell goes here, muscle cell here, skin cell here". An MRI of the opposite limb could be used to form a basis for the printer model. Once the whole thing's printed, it can be surgically attached, with some stem cell "glue" at the end to get the ends to attach to one another. 

One caveat is this is a completely artificial method and not the way a limb naturally develops... there could be a problem with long, linear structures like muscle fibers and nerves, where the limb elongation process is central to their development.  Seems like it'd be tricky to keep it alive the whole time, but I could see that working. I don't think the cells would care much that they were developed in that manner instead of natural replication.  Ok, so I more or less knew this part, but I always wondered where the actual protein gradient originates from. Wouldn't we already need a differentiated cell expressing the specific protein first?

Sorry if this was already asked / if I'm expressing my question poorly. If I had to provide an example, let's say you have an embryo of just a few undifferentiated cells. What's making the protein gradient happen at this point / how's the process starting off? There are two mechanisms I know of. One is external surroundings (wall of the uterus, parts of an egg, the sea floor, etc.) touching some cells and not others and telling them they're one side of the body. The other is asymmetrical splitting and explained by u/tischlampe in this thread.  Excellent question! The gradient is set up by factors that are already present in the egg before fertilization occurs. This is most well studied in the frog (Xenopus). The egg has a bunch of signaling molecules attached to the cell membrane in just one spot. When fertilization occurs, these signaling molecules detach from the membrane and start doing their thing. (It's partly mRNA that gets translated and partly protein that starts binding to other proteins.) As the first few cell divisions take place, the gradient is established that controls early embryonic patterning and gastrulation. Amazing! Does that mean, taller people had more protein that was produced from the origin cell and hence longer limbs? That or their DNA has a different set point for determining it's time to stop growing. "I make leg until protein x drops to a 1:3 ratio with protein y" vs. "I make leg until protein x drops to a 1:7 ratio with protein y."  Second person would be taller.  No. Height happens much later--childhood/puberty. This stuff happens during the first few weeks of pregnancy. What's the disorder involved with protein gradients? How does it present itself physically?  If an embryo had serious abnormalities in the gradients of embryonic signaling proteins, it would die very very early in development. Thank you for this, it's a fantastic answer. I got the idea that there would be chemical signals based on proximity, but "protein gradients" makes WAY more sense. With enough origins and gradients, you would have SUPER-fine control of shape/function/composition. Fascinating! hey man, that was exceedingly interesting. I never knew any of that and I am a super cool smart handsome guy! 

Just wanted to say thanks!  I can't even begin to fathom the incredible complexity of the biological machine that is the body. It's absolutely mind numbing.  Okay, purely theoretical as I'm aware as to how unethical this is, but...  

Assuming you had a way, does that mean you could disrupt these protein gradients to modify the body structure of an embryo? Say, modify the shoulders to have extra arms, or disrupt the feet to prevent toe growth or something? Absolutely. You can even take the origin cells from one area and put them in another to grow the former structure there instead of or in addition to what was growing there. It's been done in the lab with animals.  Thanks for the very informative response.

 Wow this was totally something new that I hadn't heard before! Thanks for the fantastic explanation. this is how your degree is finally useful? What about parts learning new functions? Like taking nerves from your chest and inserting them to your hand (to restore destroyed ones, thus getting it to move) -  for the first few months the hand will move with breathing (the nerves planted from the chest are doing chest wall movement) but it dissipates over time. Do the nerves just learn that "hey! I shouldnt move anymore like I used to!" Reading your description of  how this work my mind imagined it and made a comparison of what you were describing to a "seed" (DNA) and flowering plants. How a human grows from it. And it just blew my mind the entire time. 

it was truly phenomenal, and thank you for this response.  I thought that cell function was largely controlled by the stromal matrix--that proteins laid down with specific glycosylation patterns would effect the differentiation and polarity of cells to grow up in that matrix... I don't mean to disagree, I just thought that the extracellular protein domains (of cadherins, etc) of cells they were adjacent too and other contact dependent effects were very important. So the proteins act like coordinates for the cell to let it know where it is and how to work? Interesting.  Has anyone tried to make a computer program to replicate this specific behavior, to evolve computer animals? TL-DR: Cells be complicated!

People have, but it turns out it's a very complicated process. 

[Here](http://www.the-dodo-diet.com/wp-content/uploads/2013/11/Biochem-jpeg.jpg) is an example map of most of the 'known' chemical processes that govern. That is to say, the ones that we have been able to track to specific functions. However, while this map is certainly complex (which is really the message it is trying to convey, rather than being useful), it's still by no means a complete picture, as there are still many unknown chemical processes, and not all of the interactions between the various processes listed on this chart are complete. Additionally, you couple this with the fact that there are more types of signal input that just chemical (for instance mechanical and electrical signals are known to play a role), and you end up with a very confusing picture, where it's not clear how all of the 'circuits' should line up.

To add even another layer, [we are just beginning to understand](http://www.pnas.org/content/109/21/8346.abstract) the types of circuits that cells use to regulate themselves. While the first charted showed many of the interactions, it turns out there there is a big temporal component to cell regulation, and we are just beginning to understand how that component plays out in a real system. 

Taken together, this means that accurately modeling such a system is VERY difficult, and while some interesting work has been done on it, we are a long way off from completing a fully realized 'in-silico' or electronic version of a cell, or something that really represents life on the cellular level. 

  Wow, that's really pretty.  I'm going to have to make a poster of that :=)

I didn't mean simulate the human body though.  Have you seen the bike evolution apps, for example?  http://rednuht.org/genetic_cars_2/

In this app, the gene directly describes the car.  Instead, you could have the gene describe the chemical given off, and how the 'cells' react to that chemical.  Thus building up much more biological shapes.

Make sense? There's something about your description that really got to me.  It's one thing to consider, say, your eyeball to be an amazing piece of "engineering."  But after reading your post I can't help but view even the most utilitarian parts of my body as the cumulative result of countless processes that all managed to go right.  Thank you for sharing.   Is it possible to somehow 'hack' this process in order to control things such as length of limbs? Yes, but it's messy. For example, you can treat embryos with a drug that will make their limbs stop growing resulting in little nubs. But that drug will have effects on the entire body as well as just the limbs, and obviously no one wants little nubs for arms/legs anyway.  How does the separation between eg bone cells and muscle cell work then? Is it also a gradual difference with the same process? Or does that work differently? What about gene expression? Doesn't that play into this somewhere? That's really interesting.  Has anyone managed to do a complete protein map of the human body? That's quite a feat to attempt! I imagine that would require thousands of researchers to even start. Many people have mapped out protein gradients at certain times in development or during homeostasis in certain parts of the body, but there's so much we don't know that it may be a wild-goose chase to start trying to map out proteins of the human body when we don't even know what they do! In fact, this is one aspect of applications of the human genome project that had the same issues. Although we've labeled every gene in the human genome, many of them have no known function and could very well have strong importance in some body function (and I'm talking about thousands of genes)! Do cells generate those gradients by emitting chemicals in different directions from the membrane? How do they know in which direction to emit them? Not that I've heard of. u/tischlampe gave a good example of asymmetrical splitting in this thread, and that's definitely part of it. The cell generates it evenly within itself, but it may split unevenly, resulting in more protein in one daughter cell than the other, thereby establishing orientation.  [deleted] After development, which a lot of the really good answers are focused on, your cells know to *stay* the correct type of cell by modifying their genomes to only express the right subset of genes in the right dosage at the right time. This is possible because the genome is more than just its constituent DNA - it's wrapped up in proteins called histones, which can be chemically modified to control which DNA can be accessed and when. Your DNA itself can also be modified - methylation of certain sequences of DNA (CpG dinucleotides most prominently) is known to suppress gene expression.

So it turns out the way your chromatin (the DNA + histones) is wrapped up and 3-dimensionally organized dictates which genes are expressed when and in what cell types.

An important point to add is that epigenetics/epigenomics and chromatin biology are VERY active fields of study. Beyond what I've stated here, there's not a whole lot accepted as absolute fact; for example, how the histones are modified (by what proteins, under what conditions, etc) and why that serves to open up DNA is still under investigation. As is why certain cells are more or less amenable to being "reprogrammed" as different cell types, or how it even happens. Every answer in biology generates 3 more questions! Most of the responses here describe developmentally how a cell knows what kind of cell it should turn into, and they're excellent responses.  I will add one thing - all somatic cells in your body have the exact same genes, so cellular identity is determined epigenetically by chemical modifications to the chromatin that turn certain genes on and other genes off.  So extracellular signal gradients tell the cell what it should be, and it then establishes its identity via epigenetic mechanisms. Nitpick. Mature red blood cells contain to genes because no nucleus. More interestingly, mature B and T cells, due to receptor gene splicing, have unique genes.  Oh yes thank you. nitpick. DNA is not spliced. it is recombined.  B+T cells undergo V/D/J recombination of immunglobulin genes. their genes are not unique, they are just uniquely recombined. Hmm. Since intervening DNA is lost, I've always considered it splicing. Since sequences are lost and new joins created, isn't DNA unique (at least to each founder cell's lineage)? I know vocabulary is precise, so you well may be right. Not my area of expertise. I'd say yes and no. Epigenetics has an influence on whats expressed but the expression of the genes themselves depend on things like transcription factors and other proteins.  Yes, but where do the transcription factors and other proteins come from?  Genes!  So if their genes are epigenetically silenced, they will not exert any influence.  They certainly play a role in dynamic transcription during a cell's lifetime, but I think epigenetics is more fundamental in providing binary on/off switches for determining *cellular identity* in the first place. Well, as /u/neeblue said, it's kind of a chicken and egg statement, but if you look at signal transduction, often those activate transcription factors that bind DNA to activate protein transcription. Many times, those genes are constitutively activated and are not epigenetically controlled. Other times they are.

Epigenetics is highly important, but I wouldn't say the most fundamental. The epigenetic control is based off of proteins that were induced by signals that were created by genes that may have been epigenetically controlled or not. It's all kind of a circular argument. But not all silenced genes are done so through epigenetics. I'm sure you're aware transcription factors can act as activators as well as repressors of the expression of gene x, and methylation does not necessarily play a role for the regulation of every gene in the genome. Also considering that methylation does not play a role in the regulation of c elegans, drosophila, yeast, and many many other organisms, I don't think methylation has such a fundamental role in cell development as your posts make it seem It's a matter of interpretation - you interpret how fundamental something is based on its evolutionary conservation.  In my line of work, I tend to weigh things on criteria of human-centric biology and health.  So, if something is evolutionarily conserved, it's probably important for *all* life.  But there's no denying that epigenetics is crucial in *human* development - [here](http://www.nature.com/nrg/journal/v6/n8/full/nrg1655.html) is an old review on DNA methylation and human disease.  So I'm not saying that epigenetics (more than just DNA methylation) is crucial to all cells being able to develop and live, but in fate determination in complex organisms. You're right, and it's no question that epigenetics is vital in development (I got to do a lit review of the IGF2/H19 locus in my senior year). I'm by no means an expert in epigenetics and don't have broad knowledge of the subject, I just had a bit of a knee-jerk reaction to the comment of epigenetics being a binary on/off switch, when transcription factors are also on/off switches themselves. Transcriptional networks of course make it more complex than a transcription factor being exclusively an activator or repressor, but so does the vast epigenetic network of methylation, histone modifications, boundary elements that surround individual loci. transcription factors very much do not all act as a simple binary switch. the hill function describes transcriptional output given a particular TF input (concentration). a hill coefficient of 1 reflects binary TF activation, 4 reflects graded activation you could not be more wrong. epigenetics is not comprised solely of DNA methylation, which it seems is what you might think. you've entirely ignored histone post-translational modifications, for some reason... Look up histone acetylation and methylation as well as gene silencing through nucleotide methylation. Another thought: stem cells undergo unique methylation patterns that 'code' them to be used in different areas throughout the body. This is one of the major problems with a pure DNA view. Methylation of DNA as well as methylation and acetylation of histones can affect gene expression. I know this is maybe a little off topic, but I hope it helps! Not off topic at all!  It's a critical step in the determination of cell fate.  To illustrate in an overly simple way:

**Extra-cellular developmental signals --&gt; Epigenetic changes in new cell --&gt; Cellular identity** Methylation of DNA is one thing, but [histones can be methylated as well and I believe that's what you're referencing.](http://www.ncbi.nlm.nih.gov/pubmed/12110177) Histones are also acetylated at lysine residues(positive)  negating its interaction with the phosphate backbone(negative)  allowing the chromatin to unwind and be transcribed. There are many correct ways to answer this question -[ here's a lecture](http://sitn.hms.harvard.edu/seminars/2014/secret-life-rna/) I gave that explains it simply in terms of RNA (10:00 through 24:00). The lecture is for Harvard Science In The News, it is meant to be easily understandable by general audiences.

"DNA contains the information your cells need to perform their functions but if every cell in your body contains identical DNA, how can one cell become a blood cell, another a muscle cell, and even another a brain cell?! The answer lies in RNA, the dynamic messenger of DNAs information."

 Thanks, I really liked your lecture :) I've only watched your part but I would say that the most relevant sections to cell differentiation are between 27:00 and and 30:30. Do you know of any other resources (hopefully not too technical) relating to cell differentiation? If it exists it would be great to have some sort of high level abstract model depicting the cell differentiation process. A kid in my 9th grade biology class asked a really good similar question. We had a classmate who was having surgery because one leg was shorter than the other, which was damaging his spine. So someone else wondered "How does my right leg know to stop growing at the same time as my left leg?" Cellular induction happens by many pathways. These can include: 

-Adjacent cellular surface proteins

-Cytokinetic chemicals

-Genetic expression stimulation from adjacent cells(not totally sure on the mechanism of action on this one). **Short answer:** Yes. Flatulence would propel an astronaut forward very slowly, but if you used the gas as fuel for a combustion reaction the astronaut could get going much faster.

**Longer answer:** Gas diffusing will carry a small amount of momentum backwards, so it must exert a force on the person, pushing them forward. Essentially, farts are rocket fuel. So let's figure out how much and how fast a person farts, to figure out how fast an astronaut can get moving in space.

Anyway, [this paper abstract gives us a good idea of the average volume of gas produced by a person in a day.](http://www.ncbi.nlm.nih.gov/pubmed/1648028) They give it somewhere between 476 to 1491 mL, and [another paper](http://www.ncbi.nlm.nih.gov/pubmed/9176210) gives the composition as a mixture of methane, nitrogen gas, hydrogen gas, and carbon dioxide. Let's say the average person produces 1 L of gas each day and we'll [guess that this gas mixture is about 0.5 grams/Liter, which is not entirely unreasonable given the known masses of the gasses in the mixture.](http://www.wolframalpha.com/input/?i=1+mole%2F22.4+liters+*+1+liter+*+%2810+grams%2Fmole%29) That comes out to 0.5 g of flatulence every day for a normal person. 

Now, let's guess that a fart leaves the butthole at about 1 m/s - again, not entirely unreasonable. So putting all this together, we can find that a day's worth of farts carries backwards momentum equal to

    (1 m/s)(0.5 grams) = 0.0005 kg m/s

so for momentum to be conserved, the astronaut will now be traveling [7.7x10^-6](http://www.wolframalpha.com/input/?i=0.5+g+m%2Fs++%2F+65+kg) m/s forward, [which is only about 1000x faster than hair grows.](http://en.wikipedia.org/wiki/Orders_of_magnitude_%28speed%29) If an astronaut in space farted every day, it would take 10,000 years for him to get up to a normal highway speed. 

This is incredibly inefficient, but luckily, there's a better way. The gasses I listed above are combustible - specifically methane. Just spewing the gas backwards to get a push forward would be like putting your SUV in neutral and trying to propel it forward with a supersoaker that sprays gasoline backwards. Instead of *throwing* it backwards, you can *explode it* backwards to generate thrust, like a real rocket. After all, every 14 year old knows you can light a fart on fire, but if the astronaut did this the gas behind him would expand in all directions, not giving him much of a push. Instead, we need to harness this energy for a jetpack, so that all the exhaust goes backward.

If we take the methane to be about 1% of our flatulence, and the energy of combustion to be 890 kJ/mole, then we find that the [chemical potential energy of the gas is about 100 million times greater than the kinetic energy backwards.](http://www.wolframalpha.com/input/?i=%280.01+Liters%29+*+%2822.4+moles%2FLiter%29++++%28890+kJ%2Fmole%29). If we had one of those fancy [gas backpacks that they put on cows](http://www.springwise.com/img/uploads/2014/05/cowbackpacks.png) to harvest the methane from their farts and a jetpack to burn it, then [this gas would be enough to get a particularly flatulent astronaut up to highway speed in a day.](http://www.wolframalpha.com/input/?i=%282*%280.01+Liters%29+*+%281%2F22.4+moles%2FLiter%29++++%28890+kJ%2Fmole%29+%2F%2865+kg%29%29^%281%2F2%29) 

(Edit: /u/throwaway_MZ3Ji8yc offers a good discussion of the practicality of such a rocket in the [comments](http://www.reddit.com/r/askscience/comments/3569v1/if_you_farted_hard_enough_in_space_could_you_move/cr1mnpp) below.)
 &gt; If an astronaut in space farted every day, it would take 10,000 years for him to get up to a normal highway speed.

But he would have to be naked or at least have an opening for his butt, right? you could build a device in the suit to intake the fart and then expel it at the same speed using only the pressure of the fart, without any butt-vacuum contact. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Yeah, but a real device necessarily would carry some coefficient of fart drag, which would decrease efficiency.  [deleted] [deleted] [deleted] Do we get an induced fart drag component as well? It might be small enough to practically ignore since induced drag is about wingtip vortices. With this being a vacuum I don't think that enough would curve around the astronaut from the butthole for it to be important. I was referring to the well known phenomenon of buttcheek vortices. The fart flows under and around your butt cheeks, diverting your fart downward and adding a fart drag component. You have to revisit "High Speed Aerothermodynamics of Farts" by Dr. P.E. Yue.  Sadly I am only in college right now and we have not gotten that far. I shall purchase the book to get ahead though. It might be required reqding later anyway. Yes but the discovery of friction-less surfaces means this problem is solved. Why not have a funnel so it compresses the fart down before expulsion.  Wouldn't that give a stronger boost? Compressing the gas would make it flow faster, but also over a narrower area. The total amount of thrust is not changed. 

A funnel could help direct to create more efficient/accurate thrust. But I think that /u/VeryLittle is already assuming that you are farting with laser accuracy. The cross-sectional area of the fart has nothing to do with its momentum. Serious question here: Does that mean an astronaut with an exceptionally large anus would accelerate just as quickly as astronauts with average, and small anuses (flatulis paribus)? Or they would at least end up at the same velocity once the gasses are released?

That seems counter-intuitive, but then again I'm not very educated in physics and many things seem counter-intuitive to me. Imagine you have a metal weight sitting on your hand. It's heavy, but not bad. You could hold it for a few minutes without pain. 

Now instead, we balance that weight on a needle on your hand. It will hurt, right? Why? Because all the force is in one place, and the way we're built, we feel that more. 

It's the same thing - in one case, the big anus releases the air over a large area, which we may not even feel. In the other, it's a concentrated burst we can feel because it's in a small area. But both are the same amount of force.  This relation between force and area is pressure where P=F/A. It's the reason why the needle hurts, the same amount of force on a smaller area results in a higher pressure. The force would be equivalent to the fart mass multiplied by it's velocity and in the direction of the fart. If size affects the initial direction then that would be important. It is also important to take the coefficient of fart drag as mentioned elsewhere. &gt; Serious question here: Does that mean an astronaut with an exceptionally large anus would accelerate just as quickly as astronauts with average, and small anuses (flatulis paribus)? Or they would at least end up at the same velocity once the gasses are released?

This is correct, due to conservation of momentum.  If both astronauts are identical weight, expel the same amount of gas at the same speed, the mass(fart) and mass(astronaut) in both instances move away from the system centre of mass at the same rate.

The pressure of the fart on the astronaut with the narrow anus is exerted over a smaller area, so the astronaut will likely feel more of a push at that point. But if both astronauts expel the same amount of gas, at the same speed, doesnt that mean they have anuses of the same size? 

If not, what variable am I missing? The variable is the diameter of the anus, but that won't affect the amount of force. The amount of time to expel the gas - The astronaut with the larger anus may be able to expel the full amount of gas in one second, the smaller may expel 1/10th the gas per second, and take 10 seconds to do so. Only if the largeness of one's anus effects how hard they push when they fart. &gt;Compressing the gas would make it flow faster, but also over a narrower area. The total amount of thrust is not changed. 

This is incorrect. The acceleration of the gases is what gives the rocket engine its thrust. Accelerating the same amount of matter to a higher speed will give the engine more thrust.

This is why when you hold a garden hose it produces no thrust, but when you place a nozzle on the end of the hose you produce some thrust. Won't you need more energy to expel the fart then? Yes, so you'll feel a bit bloaty before you manage enough butt pressure to overcome the thrust barrier. [deleted] You would probably need to have a seal around the rectum right? Like a butt plug or something similar. Were still talking scientifically right? Yes. There would have to be a sealed post-combustion chamber to create linear force. Consider a rocket bolted to the underside of your chair, how it's shape would focus energy in one direction, then shove said projectile right in your browneye. This is a very important distinction.  The real answer to this question is the astronaut would just end up with a smelly spacesuit and no extra momentum. This got me thinking... do current space suits account for astronaut farts or do they just have to smell it the whole time?
 There was actually a post I saw just today that said that astronaut diets are specifically tailored for minimal flatulence. &gt;...then [this gas would be enough to get our astronaut up to highway speed in a day.](http://www.wolframalpha.com/input/?i=%282*%280.01+Liters%29+*+%2822.4+moles%2FLiter%29++++%28890+kJ%2Fmole%29+%2F%2865+kg%29%29%5E%281%2F2%29)

This is a few orders of magnitude off: you need to consider conservation of momentum as well as KE. Even if there's enough chemical energy, there's not nearly enough reaction mass. An efficient methane engine might have an [effective exhaust velocity](https://en.wikipedia.org/wiki/Liquid_rocket_propellant#Bipropellants) of ~3.6 km/s, at an oxidizer : fuel mass ratio of 2.6. So with 7 mg (10 mL) of CH4, this would give you a V of just (3.6 km/s * (2.6 + 1) * 7 mg / 65 kg) = [0.0014 m/s](https://www.google.com/search?q=(3.6+km%2Fs+*+(2.6+%2B+1%29+*+7+milligrams+%2F+65+kg%29).

(There's an unrelated error in your [Wolfram link](http://www.wolframalpha.com/input/?i=%282*%280.01+Liters%29+*+%2822.4+moles%2FLiter%29++++%28890+kJ%2Fmole%29+%2F%2865+kg%29%29%5E%281%2F2%29): "22.4 moles/liter" should be "1 mole / 22.4 liters").

In one interpretation, this maneuver is extremely inefficient at converting chemical energy into kinetic energy. The propellant stream is very fast (v ~ 3 km/s), and the rocket is slow (the total V is very small), so, most of the KE (~ v^2 ) goes into the propellant instead. For energy efficiency, you'd need the velocities to be of similar magnitude, so you'd need a propellant mass comparable to the rocket mass. (see ["propulsive efficiency"](https://en.wikipedia.org/wiki/Rocket#Energy_efficiency))

Since in this concept there's much more "inert" mass (nitrogen) than fuel, I think it'd be more effective to separate the combustion from the propulsion. For example, burn CH4/O2 in a fuel cell, and use the electricity to power a small [resistojet thruster](http://www.lr.tudelft.nl/?id=26232&amp;L=1), using the inert gas as working fluid. Then you could get a lower exhaust velocity (maybe 700 m/s) over a larger mass, for a V of around 0.005 m/s. At least in theory.

*edited, because my math stinks* &gt; V of just (3.6 km/s * (2.6 + 1) * 7 mg / 65 kg) = 0.0014 m/s[3] .

Can you run through this with me a little more explicitly? I'm not an aerospace engineer so my training has left me equipped only to deal with pure kinematics - I don't fully understand the 1+2.6 and your meaning of 'fuel to mass' ratio.

&gt; (There's an unrelated error in your Wolfram link[4] : "22.4 moles/liter" should be "1 mole / 22.4 liters").

Good catch, that's why I link to those things. These are all great caveats and I'll edit my post to include a link to yours.  Oxidizer/fuel ratio: just means 2.6x more oxygen than methane, on a mass basis. If you have 7 mg methane to burn (per your assumptions), you'd balance it with 2.6*7 = 18 mg of oxygen, for a total exhaust mass of 25 mg. ^what ^is ^this ^a ^rocket ^for ^ants

The (effective) speed of the exhaust is 3.6 km/s, so its momentum is (3.6 km/s * 25 mg), and the velocity change (V) of the human is that divided by 65 kg.

Nothing but kinematics. Okay, I get it now. You're right, and now I understand your original comment better - conservation of momentum would tell you that most of the KE goes into the exhaust. So your first post was suggesting adding some inert gas (i.e. nitrogen) to the mixture to increase the exhaust mass so that more of the energy ends up transferred to the astronaut?  I was thinking about your idea that most of the fart mass was inert (1% methane, balance nitrogen?), so yeah, to make use of that.

0.5 grams is still hardly anything. I looked up what the [astronaut MMU's](https://en.wikipedia.org/wiki/Manned_Maneuvering_Unit#Overview) carry: it's 5.9 kg of compressed nitrogen, expelled at probably around 600 m/s (not stated). [deleted] [deleted] If Randall Monroe reads /r/askscience, and I'm guessing he does, then hopefully he reads this suggestion: if ever you need a guest contributor for What If, hit up /u/VeryLittle. 

Seriously man, you're awesome. Even just skimming through your history it's clear you put a lot of effort into answering questions in this sub in a light-hearted and undaunting way. Thank you, this is how we bring science to the masses. Combine fart jokes and math.  I'm glad you enjoyed it :D There is a reason I have you tagged as " Randall Monroe but shitty drawing " 

Seriously, if you ever wanted to do something like he does, you would be amazing at it. Why not. 

Paging /u/xkcd :

Hi Randall, I've noticed you've put What If updates on hold until July. If you're interested in having guest columns fill the next two months I'd be happy to contribute a few essays. [A portfolio of my writing can be found in my comment history.](http://www.reddit.com/user/VeryLittle/gilded/) Have a nice day.  Guest columns on What If has to make it sound like the best publication I will ever enjoy with all the money I can throw at my screen. Like I would pay for a subscription or something of the What If periodical. [deleted] [deleted] [deleted] Well, it's not extremely plausible. But! If I was an abandoned astronaut that just happened to have a bottle attached to my spacesuit that could collect my farts and then detach without creating a vacuum and a light that worked in space to light the gas, just maybe I'd have a chance at getting home.  You'd probably do better throwing the bottle in the opposite direction you want to travel fart in the bottle, light the gas, take the boost, *then* throw the bottle Out of context this is a strangely hilarious statement, but in regards to maximizing your V, this is absolutely the correct answer So really you should carry several progressively larger bottles, spend enough time farting to fill them all, ignite the farts in the largest one first, then throw it away when it's expended and grab the next largest... [Which is coincidentally, the entire concept behind a multi-stage rocket, like the Saturn V.](http://vintagespace.files.wordpress.com/2011/04/saturn-v-artists-con.jpg) [deleted] You wouldn't go anywhere.  Your giggles would counteract the fart force. [deleted] [deleted] [deleted] " If an astronaut in space farted every day, it would take 10,000 years for him to get up to a normal highway speed."

so could the guy fart himself to the speed of light in 4.28x10^10 years?

 No. The consequences of special relativity require increasingly more energy to speed up the same amount as the speed of an object increases and that nothing with mass can travel the speed of light. 

So not only would he never reach the speed of light, it would take him longer than 4.28 x 10^10 years to reach a speed very close to the speed of light.  If my back of the envelope math is right he'd have to fart more mass than the observable universe. Am I off-base, or do we need anti-farts? Of course this is assuming the butthole is a perfect nozzle only ejecting the jet in one direction. And that the fart provides its own oxygen.

fun fact, your flatulence would actually have shockwaves. Can... can your butthole fart in multiple directions at once? Well see, when we're talking about a jet of gas expanding into a vacuum. It expands a lot, and a lot of the energy will expand in a radial direction, not so much in the direction of discharge.


.... really glad I've spent a decade of graduate work to analyze the what-if of farting in space. You know, if you want to make practical use of this thought experiment, you could always apply it to something like Enceladus, where we see jets of what we're pretty sure is water ice/vapor shooting out from the surface, more or less directly into the vacuum.  Well, really, you've spent a decade of graduate work to contribute to the peer review of a thought experiment on the what-if of farting in space. After all, this will be recorded forever in the annals of Reddit history. I *know* there has to be a citation format for this to go under. Not a correction, but a remark:

&gt; the energy of combustion to be 890 kJ/mole

This is really not meaningful since rockets don't transform *all* thermal energy into kinetic energy. /u/throwaway_MZ3Ji8yc is right to take the usual exhaust velocity of CH4 rockets as a parameter as well as the oxidizer-to-fuel ratio.

The remark I wanted to contribute with is that this is a supersonic exhaust, so it can only be achieved with a convergent-divergent nozzle. It will also require a certain pressure and temperature in the combustion chamber - not really pleasant if its made of meat. &gt; The gasses I listed above are combustible - specifically methane. Just spewing the gas backwards to get a push forward would be like putting your SUV in neutral and trying to propel it forward with a supersoaker that sprays gasoline backwards. Instead of throwing it backwards, you can explode it backwards to generate thrust, like a real rocket.

This is probably not recommended since the inside of your butthole would have to be burning gas, in order for the rocket farts to work. 

It's the superinflation of the heated gas that increases the thrust. If you just burn the gas once its outside of your butthole, it's not really helping much. Although, granted it would help a little bit since the gas expanding behind you would still propel you a bit. However, this would still singe your buttocks, which would not be ideal.  So one would need to install a heat-isolated combustion chamber just inside the rectal opening.  &gt; the rectal opening 

Also known as anus, butthole, funhole, crack, cracker, farter, pooper, shitter, pooter, crapper. I love engineers/physicists, digging straight into the math. Did you forget about the space suit?

The astronaut wouldn't move because the gas diffusion wouldn't leave the suit, which is connected to the astronaut. Let's suppose the astronaut is floating on the ISS, no suit needed indoors.  This was actually a real concern on the US space station Skylab (in the 1970s). Because it was so huge inside (made out of an empty Saturn V rocket stage) you couldn't just reach out and grab a wall to propel yourself. You could get stranded in the middle of a room and not be able to reach anything. IIRC they ran a cable or a grab rope or something down the middle like an elevator shaft cable to fix this problem. Why not attach a one-way-valve to the suit that would flap open with the pressure? This wouldn't exactly work. The physics wouldn't be dominated by the flatulence in that case, but since the suit is pressurized, you'd have gas diffusing out of the suit, which would have different kinematics than the what I described in my post.  Ignore the suit, just a tiny airlock over the sphincter to protect it from space. I can draw you a diagram Can I see the diagram? Floating in a pressurized environment with no clothing to dampen the expulsion, then yes a person could gain momentum. The station itself wouldn't move of course  Well that just raises another question. How many farts would it take to move the station? It can be assumed that there's a nozzle of some sort to let it out. Otherwise lighting it on fire would be rather dangerous.  Now what we we need is to incorporate this new discovery into space suits. There are actually a number of compelling reasons why we don't want space suits to be able to produce large amounts of thrust on their own.  I agree but maybe I should have been more specific I meant as a plan B in case of being stuck outside the ship floating around...i.e. the movie gravity haha I'm always amazed at how simple questions, like this one, are able to be throughoutly put into theorethical terms and analyzed just from random internet sources. Surely without resorting to combustion, the specific impulse could be increased by ensuring a narrow opening (nozzle-like) with the anus, which increases the speed of expelled gas? To increase the speed you would have to increase the force expelling it. Also, you've already got it going through a narrow opening (I hope)  Rocket nozzles increase the speed of particles by restricting flow.

http://en.wikipedia.org/wiki/Rocket_engine_nozzle Which harnesses more net force. You aren't harnessing combustion here, you're using muscles that have a force limit  I'm sure that, with proper training, an ass-tronaut could fart with a more puckered butthole producing greater thrust and with superior directional control.  Would there be an increase in thrust if we let out only short, controlled bursts versus one long and sustained burn?  Maybe burn isn't the right term here.  Gust? You should publish this as a leaflet to be distributed to elementary schools, to encourage the youngest generation the value of science, via the channel of demonstrating its applicability to a topic near and dear to their hearts. Farts.

The only way this could be a better introduction to science, is if it were to be upgraded to a paper on the propulsive capacity of dinosaur farts. This is everything that is beautiful about the internet. Someone asks something as ridiculous as "Can you get around in space by farting?" and gets a proper scientific answer. What a wonderful world we live in.  It makes me laugh that this is the most interesting thing I'll read all week.  I checked out one of the references and don't see a mention of O2 as a gas released, and it actually wouldn't make any sense for O2 to leave your body that way. It bothers me quite a lot that you mentioned combustion of methane and hydrogen in the absence of oxygen.  &gt; I checked out one of the references and don't see a mention of O2 as a gas released, and it actually wouldn't make any sense for O2 to leave your body that way.

You're right. You'd have to pipe some oxygen from the suit or an extra tank of oxygen to use in the jetpack.  If you are lucky and by chance have a lighter just fire it up and you can achive way faster speeds :p [deleted] [deleted] You forgot that hydrogen gas (also present in farts) is also combustible. I'm pretty sure there's also enough air mixed into our flatulences to provide enough oxygen both for the methane and hydrogen gas. How many days would you have to fart into your fancy jetpack to have the dV to get into orbit? So a lot of rockets use liquid oxygen and liquid hydrogen combustion to generate the upward thrust to get into space. This simply takes *a lot* of fuel, because you need to be able to exert an upward force greater than the downward force of gravity in order to get going and stay going up. 

Normal rockets need thousands of pounds of fuel just to get a rocket to space, so I imagine if the energy considerations are comparable for combusting liquid methane and liquid oxygen, you'll need a few tons of methane. At less than a gram a day, this would take a long time to amass.  Methalox rocket has a projected ISP of 380. Let's say the crude fart-powered one has one of 260. 

If you weigh 100kg with all your equipment, you'd need 3500 tons of fart-gas, which would take you 1900 person/years to collect. What if you tried to light your fart on fire? (Given that you could in this situation) Would there be a change in force?  The problem is, the astronaut will have to expose his/her butt, and not only become seriously injured in the process due to butt-vacuum contact, but will also end up on the sex offender's registry for life.

The solution, is to install this device in the butt position in the space suit and fart into it:
http://emdrive.com/images/emdrive.jpg For those unawares, you're looking at a picture of the hypothetical "EM Drive" I don't think its hypothetical anymore. While everyone agrees the prototype has been built, most physicists are extremely skeptical about it and attribute the small amounts of thrust generate (0.0001 N) to originate from other sources (heat, charge build-up, measurement error (interference from the device), etc).  

None of the results have been published in a peer-reviewed journal.  Physicists don't buy the results for the same reason you don't accept people who claim to have built perpetual motion machines -- when someone claims to violate a fundamental law (conservation of momentum or 2nd law of thermodynamics) you need to see very very strong experimental evidence of it (preferably with theoretic underpinning) and even then you'll still be skeptical. &gt;but will also end up on the sex offender's registry for life.

WHO PUTS A PLAYGROUND THAT CLOSE TO A SPACE STATION?! IT'S ENTRAPMENT!
 Yes, but it would be much more effective if you could pipe in a bit of oxygen and an igniter.  This would increase the propulsion by at least a factor of five.  It would also require some explaining for your proctologist so be sure you have a good story put together before trying it. The combustion chamber is probably sub-optimal but the variable-diameter nozzle would definitely make things interesting. Like...a sphincter? I made [a playable version of this exact question](http://www.surrealix.com/reddit/astronaut/) last time it came up!

In [his AMA](http://www.reddit.com/r/IAmA/comments/1s4l7v/i_am_col_chris_hadfield_retired_astronaut/cdtupcd), Chris Hadfield said

&gt; We all tried it - too muffled, not the right type of propulsive nozzle :)

So while theoretically possible, it seems in practice it's not a viable method of navigating the space station. This might sound like a joke, but it is a serious question: what are the health implications of temporarily exposing your butt hole to the vacuum of outer space?

We design a special spacesuit that harnesses farts as a propellant. Inside the suit, there is a special sealed compartment surrounding the butt hole. Just before a fart is expelled, the compartment quickly opens, the fart propellant is ejected into space, the compartment closes again, and air pressure inside the compartment is quickly restored. The rest of the suit is unaffected and is otherwise like a regular space suit. Experiments done say that brief exposure to a vacuum is incredibly unpleasant but survivable.

For more specific information, [here's the results of the tests on some animals in the 60's](http://www.scientificamerican.com/article/survival-in-space-unprotected-possible/). But don't these experiments assume that the entire body is equally exposed? In this scenario, only one end of the digestive tract is being exposed, which would create a huge pressure difference between our vacuum-exposed butt and our presumably pressurized helmet. I suppose you could also install a device that would seal off your mouth and nose, but wouldn't there still be some pressure left in the digestive tract? Would it blow out the--

... wait, that's just a fart, isn't it. Neil de Grasse Tyson talks about this in one of his Star Talk episodes. There was apparently an actual test in the ISS by a russian cosmonaut that concluded it to not work. However his ass was not bare apparently so it's been deemed inconclusive. 

NDT confirmed what /u/VeryLittle says but ommited the ignition part of the answer! [deleted] If a fart does set you in motion in space, we should put bananas in space at equal calculated distances. Astronauts would stop at these pitstops, eat a banana, wait for the fart, then swing forward. Nice and cheap idea for space travel, eh ?

Question: How many bananas does it take for a astronaut to reach Mars ?  [deleted] Beans, brussel sprouts, soda, cauliflower, broccoli, cabbage, and other such carbohydrates can induce flatus. Combine that with a localized muscle relaxant near the colon, and you have excessive flatulence! 

http://image.sciencenet.cn/olddata/kexue.com.cn/upload/blog/file/2010/1/2010123203248875447.pdf Yep, any amount of force expelled through your flatulence can provide thrust for traveling through a frictionless environment. You could throw marshmallows at a perfectly still titanic in space and it will cause it to vector ever so slightly. This article isn't completely an answer, but introduces the problem with farts in space:

http://www.themarysue.com/space-farts/

referenced article:
http://blogs.discovermagazine.com/seriouslyscience/2014/03/14/flashback-friday-farts-underappreciated-threat-astronauts/
 [deleted] Your skin provides an osmotic barrier, keeping the concentration of fluids in your body at homeostatic levels. You're not going to absorb water through the skin and even if you were able to, it wouldn't rehydrate you.

Additionally, the effects of water pressure and submersion during the onset of dehydration would [contribute to hypothermia](http://www.klemmerhead.com/vitalyte/hydration-101/science-articles/hypothermia-and-dehydration/) and bodily wear (i.e. trenchfoot) which would take their toll over time anyways, over that of the person who remains on land. After a time, prolonged exposure to moisture would also cause the bonds between epithelial cells in the skin to weaken leading to maceration of the epidermis which would eventually leave the person open to infection as well. One notable example is the [David Blaine stunt](http://en.wikipedia.org/wiki/David_Blaine#cite_note-40) in which he was submerged in an isotonic solution for 7 days and emerged with skin breakdown on the hands and feet. Humans aren't designed to survive indefinitely in water. 

Assuming other factors are held constant, the submerged person would consume more energy and water due to the body needing to adapt to indefinite submersion and thus dehydrate sooner.

Edit: 

The 'tub' is implied to be more like a pool/large tank as the test subject is submerged up to the neck, thus pressure is assumed to be a factor. 

Also the notion that one can 'drink' through the anus has been brought up repeatedly. While it's true that a person can bypass the digestive tract and rehydrate this way, barring an enema, it's not physically possible for the average human being to do so.
 This guy knows. The hydrostatic pressure from the water increases your blood pressure which in turn inhibits the release of Anti Diuretic Hormone into your blood. Less ADH means more urine output so you would become dehydrated faster if you were submerged in water.

Edit: Question-"Is this why swimming makes you feel like you have to urinate?" Answer-It is part of the reason. This is a phenomenon called immersion diuresis which has two factors: 1) hydrostatic pressure of water directly raises blood pressure causing ADH inhibition and 2) cold water will cause vasoconstriction which increases blood pressure and thus indirectly inhibits ADH. Also, I have read that there is a psychological piece to it as well. Something about being in water, thinking about water makes you have to urinate. I don't know the science behind that piece of it [but there is a great article which explains the other two factors in detail.](http://en.m.wikipedia.org/wiki/Immersion_diuresis#Immersion_diuresis) Inhibition of ADH is also why you pee so much when you drink alcohol.  Less Anti Diuretic Hormone is produced when alcohol is present, and therefore, your kidneys are under the assumption that they need to dump water from the body.  


I love the pituitary gland.  So much going on in such a tiny space.   Is there anything thing readily consumable that increases ADH? salt. by increasing the solute concentration of your blood, you'll secrete more ADH, which will have the net effect of  conserving water. Increased sodium intake also activates the renin-aldosterone-angiotensin-system, which causes excess sodium to be excreted in the urine.

https://mcb.berkeley.edu/courses/mcb135e/kidneyfluid.html Quick correction, ADH acts by increasing permeability of the collecting ducts to water.  This has the effect of conserving water, yes, but does NOT act through modifying sodium re-absorption.  You may be thinking of aldosterone.  I think he means the hypothalamus detects the increase conc Na+ in the blood causing the posterior pituitary gland releases more ADH. right. via the RAAS system.

Ive edited my original post, thanks for reminding me. An easy way to remember the function of each hormone cascade is to know that renin-angiotensin-aldosterone system regulates **blood volume** via sodium/potassium exchange and ADH/vasopressin regulates **blood salt concentration (osmolarity)**  via water reuptake. That's the easy way?? 
I read it three times. I'll never be a biologist/doctor/smarty pants :( [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] On a related question; why is it that salt water produced such vastly negative effects compared to normal water? Human blood needs a well regulated concentration of electrolytes (salts such as sodium, potassium and others).
A funtioning human kidney has the capability of regulating your water/salt ratio to a certain degree.

If you drink water with slighly less or more salt than your blood needs the kidney will able to concentrate or dilute your blood salt and have you piss the rest.

Now sea water has way too much salt in it. while diluting it down to normal blood levels the kidney has to secrete a lot of salt with even more water, resulting in you pissing the salt water you just drank on top of water needed to dilute it in your body.

So drinking sea water while dehydrated, no matter how good of an idea it seems at the time, will dehydrate you even further. [deleted] On that note, is there an explanation for 'breaking the seal', that is when drinking the time it takes to have to pee decrease after the first piss? Is it just in our heads? Or does peeing tell the kidneys to go on and give the bladder more it can take it? Oh I know this one! I'm going to keep this simple; a little more detail can be found [in this Mental Floss](http://mentalfloss.com/article/31408/science-breaking-seal) article.

Your brain carefully regulates ADH so that you have the correct amount of salt and water in your bloodstream at all times. Alcohol interrupts the brain's ability to make ADH effectively, but when you start drinking, there are two factors that keep your bladder from instantly filling up at maximum speed:

1) The ADH that was in your bloodstream before you started drinking takes a while before it's used up. If you were to instantly stop all ADH production in your brain, then every 20 minutes or so the kidneys would use up half of whatever is left in your bloodstream.

2) You have less alcohol in your bloodstream when you first start drinking, so ADH production isn't all the way shut down yet. So between residual ADH still chilling in your bloodstream and ADH still being produced decently at the start of drinking, it takes your kidneys a fair while before the lack of ADH really hits them.

By the time you finally have to pee, usually it's been a couple hours and more than a couple drinks. By this point, the alcohol has dramatically interrupted ADH formation, and your kidneys have used up all the ADH in your bloodstream plus whatever meager output your brain can still manage. Without ADH, you kidneys can't reabsorb all the water they filter, and so they end up full-tilt urine production mode.

It is almost a little bit sad: all the while your brain can still sense that there's no need to be peeing so much, but it can't tell the kidneys no matter how much it tries.

So next time you drink, make sure to drink lots* of water. Your kidneys are going full-tilt urine production anyways; might as well replace what you're losing.

^^*don't ^^[water_intoxicate](http://mentalfloss.com/article/31408/science-breaking-seal) ^^yourself ^^dog Everyone needs to read the original article as this post omits a key statement; 

"So, theres really no seal to break, no dam to crack open. If anything, the damage was done when you took your first drink and started suppressing your ADH, not when you took your first pee."

This is just a commonly occurring coincidence that's a result of the fourth dimension. [deleted] [deleted] [deleted] [deleted] [deleted] My impression is that your ADH was normal before you began drinking, so once the alcohol affects that, your bladder begins to fill. Whether you pee or not does not affect the ADH effect on your kidneys, they will still want to dump water from your body. 

Also, if you physically did not pee, your kidneys would be trying to produce more urine but be backed up. This can actually kill you. (Like that lady who did the "hold your wee for a wii") If it is the same one I am recalling, she died from water intoxication.  It was a brain malfunction as a result of the body chemistry dilution and not some sort of damage to her kidneys. You're right. If you start drinking water while keeping yourself from urinating, hyponatremia (water intoxication) will kill you before urine trouble from not peeing.  My understanding is that "breaking the seal" is more or less just an illusion. As you drink more and more, your body will have to pee more. So the act of urinating in and of itself isn't causing you to have to urinate more later on, but rather it's just that the alcohol you drank is being digested. [deleted] [deleted] But when you're drinking the effect of ADH inhibition, while present, is not the major cause. The major cause is that you drink a lot more fluid over a short amount of time than you ever normally would. And it's why you don't pee when using MDMA. MDMA increases the output of ADH, aka vasopresin. [deleted] [deleted] [deleted] I was trying to find a source on this, and this was the best I could find.  http://www.ncbi.nlm.nih.gov/pubmed/10751106  It seems to say that immersion in water dramatically increases urine production despite the fact that it actually *lowers* blood pressure.  

edit:  Well, that seems if you are in feet first.  It increases blood pressure if you are head first.  http://www.ncbi.nlm.nih.gov/pubmed/3631667.  I can't help thinking there would be bigger problems if you were immersed head first in a bath tub. [deleted] MDMA releases ADH; do you know whether it's just because it raises blood pressure, or is it a more direct result of the release serotonin and/or norepinephrine? Might sound a but wierd, but could you possibly pull water into your rectum and absorb it? [deleted] [deleted]  Our bloodstream readily absorbs salt and other minerals from the GI tract, just (hopefully) not bacteria. It would be like drinking salt water. [deleted] [deleted] Yes. The anus is very good at absorbing things put into it,  Suppositories exist for this very reason. When you need to bypass the kidneys, and liver, and need medicine fast, that's when you would be given a suppository. If you mean specifically if as the OP suggested in his scenario, I doubt you could pull your anus open far enough to do the trick.  Would a person in a humid environment survive longer (technically) than a person in a non-humid environment, when it comes to dying of dehydration? It would depend on the temperature: if it were hot and the person needed to sweat to cool down, the one in the dry would probably last longer, if not, the one in the humid conditions would lose less water through breathing. I think that a person in a humid environment (assuming warm enough to be room temperature) would probably keep sweating slightly more because his sweat would take longer to evaporate from the skin thus not allowing the body to cool properly as needed.

Therefore the more you sweat the faster you lose water and probably dehydrate quicker.

This is just an "educated" guess on my part though and I'm in no way qualified to answer this. Could be way off. What if you were to take in water through the rectum while being submerged?  That will work if you can take in a sufficient amount of water. Some people clearly can pull air in their butt, so it should be easier in water since there is more pressure pushing against the muscle. [deleted] [deleted] [deleted] If you are considerably dehydrated, and you step into a steamy hot shower, do you (minutely) rehydrate? That would be a bad idea: if you are dehydrted, your blood volume is lower than normal, meaning blood vessels have to constrict to keep the pressure up. If you are heated up, blood vessels near the skin dilate, moving blood to your extremities to keep you cool. This means it takes it away from internal organs and your blood pressure will drop. This will mean you don't have enough pressure to get blood up to your brain and you will faint, probably within the first couple of minutes if you are badly dehydrated.  
Added to this you will start to sweat which will dehydrate you further. &gt; The submerged person would consume more energy

*(disclaimer- this is not my field)* 

I believe two more mechanisms would increase energy consumption. First, heat lost to the surrounding medium would increase due to conduction (vs. convection in air). Second, if I understand the literature correctly, metabolic rate would increase due to the greater heat loss in water.

There is a growing body of evidence suggesting the existence of "brown fat" in human adults which can become metabolically active at lower temperatures. [\[1\]](http://www.ncbi.nlm.nih.gov/pubmed/19357405?dopt=Abstract) [\[2\]](http://www.ncbi.nlm.nih.gov/pubmed/19357407?dopt=Abstract) [\[3\]](http://www.ncbi.nlm.nih.gov/pubmed/22202013) Submersion in cool water has been shown to increase metabolism in this fashion.

The [Wired magazine article](http://www.wired.com/2013/02/ff-cold-weight-loss/) about Ray Cronise and cold therapy states the following:

&gt; Studies have shown that the same thermogenic mechanism used by BAT also occurs in skeletal muscles during cold exposure. Before you shiver, your muscles produce heat [...]

but I haven't been able to find any recent published research on the topic. well, that all depends on the water temperature, no? Not trying to be pedantic, but when submerged, are you still considered in contact with atmosphere?

I was confused by your post because atmosphere usually refer to air.  I agree that was confusing, I meant heat lost to the surrounding medium. Depending on where the tub was, the guy in the tub might live lots longer because his rate of water loss is much lower. 

In the tub, you'd have essentially no water loss through the skin, and maybe some water gain. (Although note that wrinkly fingers are NOT due to water uptake into your fingers; they are actually a neurally-controlled response thought to improve your grip under wet conditions: http://www.nature.com/news/science-gets-a-grip-on-wrinkly-fingers-1.12175)

Since the tub full of water would humidify your environment, you'd also lose less water via the lungs. Normally you lose a lot of water by breathing because the air in your lungs is at 37C and 100% humidity. Therefore it is holding a lot of water, which you lose when you breath that air out. That's the 'steam' you see when it is cold outside and the water from your breath condenses to form a small cloud. Imagine losing all that water every breath. It's a lot! But if you were doing the experiment in a tropical rainforest, the tub wouldn't make much difference and the guy not in the tub wouldn't lose much more water than the guy in the tub.

As mentioned above, increased blood pressure increases the amount you pee (your body dumps water to reduce blood volume; a lot of older blood pressure medications work by making people pee). But I don't think being submerged in a foot of water substantially increases blood pressure, and that increase in blood pressure wouldn't last long anyway because within seconds your body would open capillaries. In fact, the person in the tub would most likely have *lower* blood pressure just from the warm tub water causing surface blood vessel dilation. And that would make them pee less.

Frogs actually drink water through their butt. Many amphibians 'drink' through their skin. We're not quite amphibians (we're adapted for prevention of water loss like most land animals), but the same environmental biophysics and physiology rules apply.

A much more interesting question is whether the person would live longer if the tub were full of hyperosmotic water (saltier than blood, like seawater). In this case, there would be water loss through the skin, but still a humid environment. I honestly don't know the answer to that one.

Source: PhD in biophysics, and I teach physiology to pre-med and med students. But try the experiment anyway.
 What about in a solution with the same tonicity as human bodily fluids, like in an isolation chamber? Why does my skin shrivel up when exposed to water for long periods of time then? 

Is it not because it absorbs some water?  It's actually a very common misconception that our fingers get wrinkly due to water absorption; they actually become wrinkly simple because it is beneficial to our grip and dexterity. 

Research has found that people with nerve damage in their fingers do not get "prune fingers," suggesting that the response is actually controlled by our nervous system rather than a physical reaction of the epidermis or dermis layers, aka outer/inner skin.

Pretty cool actually. We developed it so that we could grip wet or submerged objects, which may not seem like a huge deal in modern times, but it's one of those little evolutionary attributes that could have possibly made the difference between your ancestor living or dying at some point and you not being here right now. Ya never know. We developed everything for a reason. 

Except make nipples. Never needed 'em. Don't think we ever will. Those can disappear, but I guess that would leave the world feeling kinda lopsided. And trans-gender operations would have one more aspect to them. But, so long as the ratio of patients remains even for each gender, we could take the female-&gt;male nipples and give them to the male-&gt;fender patients. Then we avoid the whole "making a nipple fiasco and people get a nice variety to choose from. 

Yes, that should do nicely.. Wait. What thread am I in again? What were we talking about?.. Ahh yes, pruney skin - well, nipples are still kinda on topic with the prune-looking aspect.. Carry on.  being evolutionarily beneficial and absorbing water into dead skin aren't mutually exclusive explanations.  
One is "how" the other is "why". I have heard both explanations, with some more detail but I was lazy and didn't check sources.  
e.g. Why do we salivate when thinking of food? "Cephalic phase of digestion, parasympathetic ennervation of the salivary glands etc". is correct (as far as I can remember). As is "so we are prepared to chew food and lubricate and partially digest it with saliva".  
I'm not saying you're wrong, because that would take effort finding out sources, just that your logic is flawed.   I've seen conflicting articles saying that there is no indication of additional grip or touch sensitivity whilst the fingers are waterlogged.

https://www.mdc-berlin.de/42518188/en/news/archive/2014/20140109-better_grip_with_wrinkly_fingers__mdc-rese &gt;"To begin with, the participants had to bathe both hands in warm water (40 C) for half an hour to induce fingertip wrinkling. The subjects were then asked to transfer 52 dry or wet objects  glass marbles, rubber balls, plastic dice and brass weights  from one container to another via a small 5 cm diameter hole in walled partition. The subjects repeated the task with dry, unwrinkled fingertips."

There's a pretty blatant flaw in this study. They are comparing wet, wrinkled finger tips to dry, unwrinkled finger tips. If wrinkling provided an advantage while our fingers were dry, we would expect to have permanently wrinkled fingers. **What they needed to compare was wet, wrinkled finger tips with wet, unwrinkled finger tips.** People with certain nerve damage have finger tips that do not wrinkle when wet. They should have compared their wet grip to wrinkled wet grips. Since we know that wetness generally causes things to be more slippery, the result that:
 &gt;"In both experiments dexterity was the same and there was no influence on touch sensitivity" 

indicates to me that wrinkled, wet fingers are able to operate as well as dry fingers, which means they add a benefit to offset the wetness.

Also, none of the items they tested with (marbles, balls, dice, brass weights) would have been around during the time in our evolution when we gained wrinkly fingertips. Naturally forming items like wet rocks, moss, sticks, etc. would make more sense.  [deleted] There was a study done that said it was our way of being able to grip things better submerged in water.  I don't think it was 100% "that's why" but a study none the less

[Article on study](http://news.sciencemag.org/plants-animals/2013/01/wrinkles-help-fingers-get-grip)
 Could you absorb the water if you had a few deep wounds?  Thanks to blood pressure the mass transfer of liquids through deep wounds is predominantly one-way, at least until your heart stops... which would be very soon. You may incidentally absorb some small amount of water against the body's effort to maintain homeostasis, but note that absorption isn't the same as hydration. If you're thinking of IV hydration that's done differently and in a [highly controlled manner.](http://www.healthline.com/health/intravenous-rehydration#Overview2) If they were that deep, wouldn't you bleed out as much as you "absorbed" in? And unless the water was maintained at body temperature they would die of hypothermia. What about through the anus, though? Couldn't you absorb water there? Wouldn't the body also burn too much energy keeping all that water warm? (transfer of energy) [deleted] Slightly off topic but you seem knowledgeable so I want to ask about something I once read but not sure if true. Skydivers in free fall don't need to breathe as oxygen is forced into the skin from the rushing air and enters the blood stream that way. Also that's why it's not smart to free fall through clouds as the moisture prevents that and experienced skydivers often forget to breathe as it's usually unnecessary so they can pass out due to lack of oxygen. Am I the victim of false info or is this something that could be true?  It is completely false that:

* Skydivers in free fall don't need to breathe
* Oxygen is forced into the skin from the rushing air on skydivers in free fall
* Oxygen enters the bloodstream from being forced into the skin
* Moisture prevents oxygen from being forced into the skin
* Skydivers  often forget to breathe
* It's unnecessary for skydivers to breathe

Skydivers, like all people, breathe normally during free fall. I suggest you find your nearest skydiving club, maybe taking a dive once. They will answer all relevant questions.

EDIT &amp; PS: Skydiving is awesome. You really should try it at least once! Thanks for the info!! Thank you. I've been wondering about this question off-and-on for what feels like most of my life (randomly shows up once in a while during a shower). I had figured you would indeed die of dehydration even if you were surrounded by water as long as you weren't able to drink it, but definitely didn't expect that it would cause you to dehydrate even faster. Tl:dr you would die faster in a tub then? Random guy here (don't know much about phisiology or anything), what about the possible hydration through enema?

Wouldn't anyone possibly in this situation try to get hydrated at all cost? Is trench foot the same as when your hands and feet get wrinkly in the bath? No. There's two stages, immersion foot and trench foot, it takes about a week to get trench foot and the skin breaks and has open sores. I've had immersion foot before and it hurts like hell, like walking on glass. You have to dry out at least once a day to keep from getting nasty feet.   Though if the submerged person peed enough in the tub the water level would rise to the point where they could drink. Do you have a source for skin being an osmotic barrier? I'd like to read on this. Shouldn't water be absorbed through the anus? What if your anus was held open? AFAIK your hart rate slows when you are submerged in water.

I am not at all convinced you would use more energy in water than out. &gt; Additionally, the effects of water pressure and solute concentration would cause dehydration

How? Osmosis causes flow of water from a lower concentration of solutes to a higher concentration of solutes. Why would water leave the body? I like visuals, so here are some. 

[This](https://www.flickr.com/photos/tomas-/17070402826/in/datetaken-public/) is human skin. You can see the outer edge is all thin layers. The round cyan blobs underneath are cell nuclei. Those cells in your epidermis are all constantly being renewed, and they head out to the outer edge and as they go they lose their nuclei and turn into little balls of fat. They also secrete some proteins that 'tie' each cell to it's neighnbour. This creates an 'Epidermal barrier', which stops water going out of your body, and also obviously stops water coming in. 


[Here](https://www.flickr.com/photos/tomas-/16971478384/in/dateposted-public/) is a picture of an epidermal barrier function being 'tested', something (purple) has been injected into the dermis, and this substance is trying to get out from the skin, but you can see that the epidermal barrier (blue) stops it. 

If you lay in a bath tub the water is just soaking into the very very top flattened layer of your skin (the out part of picture 1), and that part of your skin is just the thin, flattened keratinised chitinous skin flakes that are your 'wear and tear' armour. The water doesn't get past your epidermal barrier and can't help you. 

Having said that, you can drink water, and if you don't swallow it you can still absorb it readily in your mouth. The same lack of epidermal barrier function in your mouth is also in your ass, so you can just try and suck some water up your [ass](http://www.google.com). One small nit to pick. The cells don't turn into fat on the outer surface. The cells that make up the epidermis (keratinocytes) are rich in a waxy substance called keratin. When the cells die at the outer surface, the leftover keratin forms a barrier (stratum corneum) that keeps water in or out. That is one part of it, I was referring to the lamellar bodies. There are a lot of lipids there. Although they are secreted as well as being in the lamellar bodies. The Stratum corneum is actually outside the tight junctions, so it's not really the waterproof barrier. 

One nice way to think of it is to see the keratinised layer as a framework for the lipids, [here](http://www.nature.com/jid/journal/v121/n2/full/5601872a.html) is a nice review on it. Right you are! That will teach me to argue with a biochemist...

I guess I was mostly objecting to use of the term fat because it doesn't make sense in a histopathologic context. Calling them lipids makes way more sense to me. From a biochemical standpoint, what is the difference between fat and lipid? that was kind of what i was thinking. would an enema allow enough water to be absorbed, or would you just be uncomfortable for no reason? While skin is fairly waterproof, there are some fairly accessible mucous membranes which could do a decent job. If you pried your anus open or inserted a cloth up there while pulling your foreskin back to expose the head of your penis (or insert a cloth into your vulva if you're a woman) you might be able to absorb a significant amount of water over time through these membranes. [deleted] This is really interesting idea, would it really work?  You should also consider effect of temperature. At the same temperature, water will transfer heat much much more rapidly. If too cold, water will hasten you freezing to death. If too warm, water will hasten your death by dehydration.

If the ambient air is very warm but the body of water is pleasantly cool, being submerged would be protective as you would not have sweat as much to stay cool. If you *really* want to go down that road, you might as well just complain about drowning. I'm still surprised nobody thought of this actually. The submerged person would clearly drown before the unsubmerged person died of dehydration.  &gt;would be up to their **neck** in fresh water

Does no one read the post text? Yah but if you were head first then the drowning would still apply - agreeing with /u/cyrusm I'm pretty sure these kinds of overly simplistic considerations are excluded from the hypothetical premise presented in the question. Maybe the person trapped underwater in the question is equipped with an oxygen mask with a ridiculous amount of oxygen. At any rate, I assume the OP knows a person trapped underwater for any significant period of time would drown (or freeze if the water is too cold, or suffer heat stroke if the "air" is too hot, or whatever). At least, I hope the OP realizes these things. :P I see expertise here so I will ask a long awaited question
Why, when I pee, I feel like I have totally relaxed my urethral sphincter and my bladder is totally empty, do I sometimes feel a strong need to pee 5 minutes later. Does this happen to everybody, or just old people?

Thanks for your response. There is still some left in the "U-bend" of the urethra, so you'll get a dire need to pee but it'll be a rather small volume of urine. Couple things can cause this, but probably it is a leftover response from saturation of your sensory receptors responsible for telling you "GO PEE".  Those receptors are so filled with their activators, that they just become reactivated after you've already done the deed. So the general consensus is that the guy in the tub would due 1st yes? We can all agree on that? 

But.. What if the guy in the tub, Spread his cheeks and unpuckered his sphincter to let water in.... 

He wouldn't be "drinking" the water. But he'd be able to hydrate himself, yes?  Unless the water is heated to 80+ you'd probably die of hypothermia in 12 hours or less, depending on how tough you are. 

Normal room temp of 70-78 should be lethal to most people after several hours. 

So.. it's not de-hydration you need to be worried about unless the air/tub water temps are over 80, in which case you should be able to stay in the water indefintely as far as body temp goes. Though it would drain the 'energy' out of you faster as your body is trying to basically heat that water up to body temp constantly. 

If you could figure out how to suck water into your butthole, you might actually be able to hydrate like that. I think some people can suck air in their butt by relaxing their butthole, so it should be possible. I'm going to go ahead and say I'm the first person to ever have thought of this solution to this problem.

If you are every dying of de-hydration submerged in 80+ degree water but unable to drink it... go ahead and relax your butthole and try to suck water into it. If the water is colder than 80, you don't want to do this as it will lower your core temp a bit faster and that will kill you long before de-hydration.

Link for hypothermia by water temp:
http://www.pfdma.org/choosing/hypothermia.aspx Submersion in "normal room temp of 70-78" water is not "lethal to most people after several hours". If that were the case, public beaches and pools would be littered with corpses. Many people love to stay in water, particularly the ocean, for very long periods of time and many distance swims, sometimes in colder water (&lt;70), take 3+ hours to complete. No they would survive the same amount of time. The skin is pretty waterproof and doesn't allow water to cross into the body. Now if it was dehydration due to heat the tub may survive longer due to being more cool and sweating less.  Perhaps they could hydrate through... other orifices? In case people think he's kidding ["rectal hydration"](http://www.ibtimes.com/what-are-rectal-feeding-rectal-hydration-doctors-call-cia-tactics-torture-1751952) is sometimes used. Yeah if the water was fresh water you could keep shoving water in your rectum.   I thought the water didn't have to be fresh. I recall a story where a family stayed alive, lost at sea, because the nurse mother gave them salt water enemas. If I recall correctly it wasn't salt water, it was fluid from fish entrails. DIrty but not as salty as seawater thanks to the action of fish kidneys. Why wouldn't they just drink it?  Too foul to ingest, and full of nasty contaminants. The rectum is very good at extracting water from foul materials full of nasty contaminants (i.e. feces).  According to this, it was water collected at the bottom of their dinghy which contained various things including rain water and turtle blood/offal:

http://www.theguardian.com/lifeandstyle/2009/aug/22/shipwreck-lucette-sailing I remember Bear Grylls mentioning that story, on an episode where he maybe gave himself an enema? Didn't he use turtle blood? [deleted] If you're using microbial dense "dirty water" or sea water you would dehydrate worse.  The salt concentration would pull water out of the blood lining the colon.  Osmotic gradient.  Fresh water would give you a bit of a boost in hydration, but not significantly.  You may outlast your dry suffering counterpart.  I'm speculating, but wouldn't the body soak up salt nearly as much as if the water had been ingested? Why would the colon only take in the water and not the salt content? Abstract of this paper: http://gut.bmj.com/content/43/2/294.full

"The past 20 years have seen many advances in all aspects of colonic physiology, and the unrelenting appearance of new information is daunting to clinicians and scientists alike. Nevertheless, we should not lose sight of the fact that the main function of the human colon is to absorb about 90% of the 1.52 litres of ileal effluent which passes daily through the ileocaecal valve.1 2 In mammalian species, the key determinant of colonic water absorption is the rate of Na+ absorption. We now know that Na+ transport processes are not distributed uniformly throughout the human colon, a concept which has important clinical implications. This review provides an update on the basic mechanisms underlying salt and water transport in the human colon in health and disease, and highlights several interesting areas for future research." How about someone in a humid environment vs a dry environment?  Does breathing in moist air supplement for drinking water? Saturated air would reduce the *loss* of fluids through respiration compared to dry air, but the water would have to condense in the lungs and be absorbed into the body to supplement drinking water. 

To condense in the lungs would require a [dew point](http://en.wikipedia.org/wiki/Dew_point) significantly above body temperature. In such an environment, heat stroke, severe respiratory distress, and/or drowning would be more immediate concerns than dehydration.  &gt; The skin is pretty waterproof and doesn't allow water to cross into the body.

For short periods of time - but if you're talking about the days it would take a person to die of dehydration a good portion of the skin would have failed. The way I understand it, a good portion of water is lost through the skin. Wouldn't the tub-soaked person's skin being submerged stop or at least mitigate water loss through the skin, allowing him to retain water? The only real "water lost through the skin" is sweat. People still sweat normally underwater, to the point that swimmers are at serious risk of dehydration. Not alcohol proof though. That lady died of alcohol poisoning when SARS was all the rage. She filled a bathtub full of alcohol and sat in it. [deleted] [deleted] Wouldnt the added pressure cause more problems? If it is a bathtub, and assuming a submersion of 6 inches, the increased pressure would be about 0.22 psi, or about a 1.5% change in pressure compared to atmospheric.  Which is approximately equivalent to the difference between being at sea level versus being 500 ft in elevation, approximately the average elevation of Alabama.  So, think of it this way: would a person acclimated to the mean elevation of Alabama have complications due to only to elevation changes caused by living on the shore?

Short answer: no.   The jellyfish *Turritopsis nutricula* is biologically immortal and could, under ideal conditions, live for 1000s of years. After sexually reproducing, this jellyfish can revert back to the immature polyp stage (back into a child). The jellyfish can still die due to predation, but aging is not a problem for it. The exact mechanism for this is not yet well understood. [Article on aging and the immortal jellyfish]( http://www.sciencepub.net/stem/stem0504/007_A00288stem050414_49_53.pdf)

**EDIT:** More credible sources, as the first one I posted is a bit sketchy, as pointed out by /u/SirT6 below.

[Reversing the Life Cycle: Medusae Transforming into Polyps and Cell Transdifferentiation in Turritopsis nutricula (Cnidaria, Hydrozoa)](http://www.jstor.org/stable/1543022?origin=crossref&amp;seq=1#page_scan_tab_contents)

[A silent invasion](http://link.springer.com/article/10.1007/s10530-008-9296-0/fulltext.html)

Note: The last article uses *Turritopsis nutricula* instead of *Turritopsis dohrnii* but it's now thought that the two species names [may refer to a single species](http://onlinelibrary.wiley.com/doi/10.1111/j.1439-0469.2006.00379.x/abstract;jsessionid=E51AAF9938A2B0E2FF223A0324D85A89.f01t03). That is incredible. Is this the only species that can revert back to its child state like this? Can you ELI5, what the process for that is and why would the jellyfish start to do this instead of just aging and dying?  This species of jellyfish is the only animal known to be able to revert to an immature state after reaching sexual maturity. To begin well need a quick understanding of the jellyfish lifecycle. They start as a free-swimming larva and then develop into a sessile polyp (similar to a sea anemone). Polyps are colonial and can asexually produce medusa (asexual reproduction results in a clone). Most medusa (the stage that looks like the jellyfish you picture in your head) die after releasing sperm/egg, but *Turritopsis nutricula* can return to the polyp state after producing sperm/egg through a process called transdifferentiation.
Transdifferentiation is a change of well-differentiated cells (cells with specific jobs) to other cell types (different jobs) by returning to a state of undifferentiation (cells with no job). Stem cells are a kind of undifferentiated cells, but it is unclear if they are involved in the transdifferentiation of *Turritopsis nutricula*. Transdifferentiation is usually only seen in regeneration, but this jellyfish has managed to use it to revert to an earlier form of life.
[(source 1)]( http://www.researchgate.net/profile/Ferdinando_Boero/publication/230806599_Reversing_the_Life_Cycle_Medusae_Transforming_into_Polyps_and_Cell_Transdifferentiation_in_Turritopsis_nutricula_(Cnidaria_Hydrozoa\)/links/09e415049c1ffe92d6000000.pdf) [(source 2)]( http://www.sciencepub.net/nature/ns0802/03_1279_hongbao_turritopsis_ns0802_15_20.pdf)

While *Turritopsis nutricula* is the only known animal to revert to an immature state, there are other examples of biological immortality. To be clear biological immortality means that likelihood of death does not increase with age. [Wiki page on biological immortality]( http://en.wikipedia.org/wiki/Biological_immortality#Organisms)
 Wouldn't this kind of thing be a huge evolutionary drawback? I can't fathom how such a thing could evolve and stay competitive. Won't these really old individuals with their "outdated" dna be competing against their offspring for resources? There's no guarantee that your offspring will be fitter than you. To a first approximation, they'll be less fit on average. Competing with your offspring doesn't hurt that much because there are a thousand others competing with them. In that case why aren't there more immortal species? I thought death of ageing was basically a selected-for trait because it benefits your genetic heritage in the long term. That's how people have always been explaining it to me.  Mortal species have failed these two fundamental steps to achieve immortality:

1) Mutate to become immortal; 2) Pass along the immortality genes enough that the random deaths of the few immortal specimens do not end that genetic line.

Remember, natural selection is about being the least worst at surviving, not about being the best. Well, you probably wouldn't mutate immortality just like that. I imagine it would be a long process of adaptation that would require a selective pressure to push it.  Not necessarily. A very common form of adaptation (and thus selection and evolution) is when a phenotypic feature that developed under one selective regime then increases fitness under a completely different regime. This is fairly common in invasive species (which end up being terribly well adapted to an entirely novel selective regime). 

[Exaptation](http://evolution.berkeley.edu/evosite/evo101/IIIE5cExaptations.shtml) is the currently accepted term for a feature which was *not* selected for its current function, although it may serve a new, different, or unknown function. Basically, traits aren't *heading somewhere,* and are often co-opted to a new function under a different selective regime (which are, after all, constantly changing). So, it's quite possible that whatever feature allows *T. nutricula* to be functionally immortal was selected for unrelated reasons and just *happens* to confer 'biological immortality.' People often forget that evolution doesn't have a goal and that it is just the logical consequence of variability and inheritance in dynamic environments. Good point, thanks.  Definitely, but I have no idea what the correct sequence of mutations would be, so I truncated it into the "Be immortal" step.
 [deleted] [deleted] We are too complicated, now, to become immortal by any accident.  
Too many of our body-parts have evolved to be "good enough" to get us through the few decades we are able to reproduce, and then we start to break. 

But a tiny jellyfish is simple enough. Well, our nearest relatives (chimps) do live a fairly long time (40-50 years), but we can live for much longer (the record for humans is 122!).  So we could certainly evolve in that direction, if there were selective pressure to do so. &gt; I thought death of ageing was basically a selected-for trait because it benefits your genetic heritage in the long term.

No, it's just that survival past reproduction hasn't been selected for. If each generation reproduced later than the previous one, you'd most certainly select against senescence. Hmh.. this made me think. Could this be why humans live longer than most species? I mean, the fact that we take SO long to mature should add a selective pressure for longer lifespan (until the lifespan is long enough)? [Bigger species tend to live longer.](http://www.npr.org/templates/story/story.php?storyId=12877984)

"Human beings used to fit into this pattern, but now that we have learned to drink safe water, wash and bathe and create medicines, we last longer than our size would predict."

We're tricksy that way.

 The reason old age has been "selected for" in humans is that having elders in a group provides sources of information which can increase the odds of survival for the entire group. This is a common question in evolution.  Longer life lets you spread your genes for a longer period of time, so it is *always* helpful to live longer.  So then why do rats (insert any animal really) only live two (or however many) years?  

One explanation is that they're just not likely to live past two years even with immortal genes.  Accidents, disease, and predation are far more likely, so not many rats actually die of old age.  Which means that rats with genes that let them live past two don't have any reproductive advantage (they're not more likely to pass their genes than a rat with crap longevity) because they'll probably get eaten before those genes kick in.  Immortal cells are typically called 'tumors'. Basically the war against cancer was won already and the cure is senescence. 
 That is very weird because it seems obviously untrue. If it was true you'd expect all mammals to age at roughly the same rate because we all mutate at roughly the same rate. Instead we have things like mice that only live for a few years, compared to closely related bats that live decades.

The way I've heard it is you have an extrinsic lifespan, how long can you expect to live if accident or disease or predation kills you. It isn't worth the effort to make your intrinsic lifespan too much longer than your extrinsic one. So bats, which have a lot fewer predators than mice, live a lot longer than mice. I wouldn't expect all mammals to age at roughly the same rate. I would however expect them to age at roughly the same rate in relation to how long it takes them to mature (with exceptions made for outliers since I'm sure there are also other factors at work). I have no idea whether they do or not. 

The idea is that you are useful to your offspring while they mature and once they reach adulthood you are competing for precious resources and they can take care of themselves. So their chances of survival increase if you die off a while later. That's a good point. Still, I don't think competing with your offspring provides much selection pressure, because they have a lot of competitors that aren't you. Aren't there more factors involved? I should think that the wear and tear on a cellular level differs based on such myriad things as (not exclusively): habitual diet/specific enzymes used, size (and inverse cube law, surface area to volume ratio, etc.), method of reproduction, and leftover genetic adaptations to no longer extant external stimuli. I'm not an expert by any means, I'm still in my second year of biochem, so take that with a grain of salt, though. Evolution isn't really about getting "better" or survival of the "fittest". It's more about being good enough. Horseshoe crabs have existed in the same form for almost half a billion years. Evolution also isn't conscious, it's a name given to identify an observed process of genotypic/phenotypic change to a species over time due to elimination by environmental pressures. I wrote a thesis on the possibility that DNA is in fact the main unit of life; yes it codes, but to build an organism to survive in. Just as a builder would draw up blueprints before building his own house. We currently tend to view DNA as the blueprint but I suggest maybe thinking of DNA as the builder who will construct then reside in the structure. So long as DNA continues on, DNA wins and it doesn't matter if it changes or not. It's actually a researched theory with some interesting support but I don't know how to do links =\ How does this differ from the selfish gene described by Dawkins?  "Evolution also isn't conscious" 
I know it's not, but the way scientists mention it, many people assume as though it is conscious. Like "some of the plants evolved to have poisonous leafs so animals wouldn't eat them" and then, for the animal who needs to eat that plant "they evolved to have immunity against the poison." I'm not sure if I made my point, but I want to know more about the actual process. I've read several books, and watched many documentaries but this aspect is still confusing.  Evolution is not conscious, no.  Let's go through your two examples:

"Some of the plants evolved to have poisonous leaves so animals wouldn't eat them."  
"They evolved to have immunity against the poison."

Here's how that actually works:

* There is a valley with some plants, and some deer.
* The plants are the primary food source for the deer.
* Even so, the plants are abundant enough that some survive to flower and seed.
* Each flower has slightly different genetic information from combining the flower's DNA with DNA from pollen from a nearby plant.  These slight genetic differences are the key to evolution.
* These flowers become seeds and are scattered over the landscape.  
* A bunch of random mutations happen in the plants over time (thicker stem, more water absorption, etc).
* After several generations, one happens to get a random genetic mutation that makes them create a mildly poisonous chemical.
* Deer start to avoid the slightly poisonous plants. Their leaves don't get eaten as much, so they do much better than all the non-toxic plants.
* This makes it HARDER for the non-toxic plants to survive, because if 1/8 of the plants are toxic, the food supply's gone down by 1/8.  This means more of the non-toxic plants get eaten.
* Because the toxic plants are not getting eaten at all, and the deer are eating the competition, the new slightly toxic plants do very well and their population continues growing.
* After several more generations the toxic plants are doing SO well that they completely take over the non-toxic plants.  The completely non-toxic plants go extinct.
* At this point, the desperate deer at this point are going after the slightly toxic plants.  Some of the deer die to it, but some don't.
* The deer that can best tolerate eating the slightly toxic plants will have more food available, which means more babies, each with slightly varying DNA.
* Random mutations occur along the generations that make the toxin more potent, and likewise, that make the deer more resistant to toxins.  Toxic plants might get pollinated by less toxic plants, but those babies get quickly eaten by the deer that are tolerating the slightly toxic plants, and only the toxic+toxic plants do well.
* Because the deer that survive the poison are the ones that are reproducing, it becomes less of an advantage to have only weak toxin.
* Likewise, if any of the baby deer have an even better way of tolerating the toxin, they'll have a more ample food source than the deer that can eat only slightly toxic plants.  Those toxin-tolerant deer are able to have more babies, and crowd out their competition as the plants grow more and more toxic.
* Soon only deer that can tolerate eating toxic plants are left.  The rest are either dead from poison or have moved on to a different area.
* Likewise, the non-toxic plants are all gone.  Only plants that are toxic are left.

Now, if the plants didn't have the deer eating them all the time, the toxin wouldn't have been a particularly beneficial trait.  Maybe a few of them would have remained toxic, but since toxins take an organism energy to create and have no other benefit, it's unlikely that the toxin would stick around, since energy dedicated to making toxin is energy that's not making offspring.  Likewise, the deer very likely would not have become resistant to the toxins without trying to eat the toxic plants.  It may pop up randomly as a mutation, but it doesn't overly help a deer to survive, so the trait doesn't help them out-compete their fellow deer.

Edit: for clarification something like this happened with humans and milk, didn't it? Yes, being able to drink milk into adulthood is a genetic mutation.  So are blue eyes. Dont forget its not as cut and dry as randomly obtain beneficial trait. Some traits get linked to a negative trait. eg. More toxic, lower fecundity (less progeny and children to pass on the trait).

So a weird little equilibrium eventually gets set up where the plants are toxic enough to deter most predators (not all!) but not toxic enough to essentially end their germ line by being sterile. When you get several traits linked together, thats when things get interesting. Life history trade offs. The classic example is r vs K where r is many young, fast growth rate, relative low parental care (rabbits) compared to K slow growth rate (I should have clarified this was to sexual maturity, the only age that matters), low litter size, high parental care (humans). There are obvious benefits that apply to both, there are obvious costs that apply to both.

There are costs to producing toxins, to having the large number of proteins needed to regulate and maintain these poison molecules in the plants. Life is all about trade offs, cost to benefit analysis that no organism does, but every organism lives by. You're correct.  As I mentioned, toxin is biologically expensive.  It's also important to note that if that random mutation for slight toxicity never happened, both the deer and the plants likely would've carried on as before and both would have gotten along fine.  Or if some other trait had happened like spiky leaves, the deer might have evolved tougher lips instead.  Or if the deer and plants had split off into two groups, one with toxin+immunity vs tough lips+spikes, they could both coexist in the same ecosystem since neither is competing with the other.  Eventually they stop breeding with each other and become different species.

There's also random/disaster selection, where a trait may not be beneficial at all or even detrimental, but some random event happens.  Like say half the deer are nocturnal, while half aren't.  A flash flood wipes out the valley during the day while the nocturnal ones are up in the hills sleeping, leaving only nocturnal deer.  And also sexual selection, where a trait has no purpose except to attract a mate (see: peacock).

If we're getting into K vs r, I like to mention insects, which tend to have an absolutely HUGE r rate.  They breed by the thousands, and have tiny lifespans.  This is why there are around 950,000 species of insect and only 30,000 species of fish, even though fish came first.  Also why you get so many freaking weird looking bugs.

Edit: A note on fish, while fish usually have a large number of offspring at once, only a few make it to breeding age, and they tend to have much longer lives than insects do. The individual doesn't evolve, but it may already be highly suited to a wide variety of possible changes in a relatively stable environment. Think about how some species are called *living fossils* because their general body plans and life history strategies have remained viable for millions of years. Although molecular-scale changes will occur, the progenitors of such a stable lineage might well compete effectively today. If they've had enough children that they're competing with them, they've done very well from an evolutionary point of view. I don't really see how this would slow down useful evolutions, as they are still reproducing and can still compete. I think the idea is that once you have a "stable" population in an area, unless the new ones are born extremely fit, the adults will have an advantage since they are mature and not necessarily because they are evolutionarily advantaged; therefore less adaptable / less traits which is definitely a negative for surviving new stresses.

An idea worth exploring may be that since these jellyfish occupy such different niches during different life stages they are less "inconvenienced" by their offspring and therefore more likely to develop immortality. Yea, if anything it gives them an opportunity to produce more offspring and benefit evolution more than simply dying after reproduction.  They aren't really immortal. They still die because of predation and sickness; they just don't die of old age, but from evolutionary perspective that makes no difference.

They still have a limited average lifespan even though they don't have a maximum lifespan. How long do they live on average? &gt; I can't fathom how such a thing could evolve and stay competitive. Won't these really old individuals with their "outdated" dna be competing against their offspring for resources?      
       
There is a concept called [negative selection](http://www.nature.com/scitable/topicpage/negative-selection-1136) (sometimes also called purifying selection) that, as an example, explains so-called living fossils (species that have remained unchanged for many thousands of generations and resemble their fossil ancestors). The idea is that individuals in these species are well suited to their environment and any changes are deleterious. As long as the environment doesn't change over great periods, offspring that differ far from their parents are selected against so the selective force is to stabilize the traits that are present.      
(Edit: Changed words.)
 &gt;biological immortality means that likelihood of death does not increase with age

I'm curious about this aspect - are they more or less "immune" to genetic mutations and cancers?  Does this undifferentiation effectively buffer against this?  Might the stem cell aspect play into the equation this way (so to speak)?

Interesting, seems [transdifferentiation](http://en.wikipedia.org/wiki/Transdifferentiation) is a relatively young concept, and a brief ctrl+f "cancer" found no hits on the page..  I'm more intrigued now. If they were immune to genetic mutation, that would suggest the species can't and hasn't evolved in a long time. I can't see evolution selecting foe that trait (if even physically possible).Also cancer commonly happens because the more our cells replicate the ends of our DNA becomes sorta "frayed" and at some age cells do not have sufficient data to make a new copy cell. That is why old people are more likely to have cancer, and I assume becoming young again would "refresh" the DNA, making cancer less likely.  Aren't lobsters supposedly "immortal" as well?  They don't revert in quite the same way, but they are capable of dealing with telomere issues due to something within their biology.  They continue to grow in size, so they find it more and more difficult to hide and avoid being eaten; so it isn't quite like the mentioned jellyfish.  But 

I just remember this because one of my top rated comments was about using the science behind the telomere "fix" in lobsters to extend human life, and having to compete with my great-great-great-grandchildren for potential mates due to nobody ever dying.

Edit:  Scrolled down and more or less got my answer.  They die because of predation, but also because they lack the ability (eventually) to sustain the energy levels required to keep up with their size.  So, they eventually do get too big and will eventually die no matter what.  However, I would be interested to find out if there have ever been mutations in lobsters that create "dwarf" lobsters that are unable to increase in size beyond a certain point, thus never having to deal with the size issue, and because their genetics are not an issue, they would be theoretically capable of existing for a very, very long time. Even if those size limited mutants existed, the avg fitness (in terms of offspring produced over lifetime) would have to outpace the fitness advantage that large size presumably confers to the wildtype lobsters for the mutation to become fixed within a population. If a lobster could survive endlessly due to a mutation that limited its size, would it not have more opportunities to pass on its mutation? 

I realize that the lobsters who occupy and compete for resources would continue to reproduce, but repeated reentry of the mutation to the local population would increase the likelihood that it would take hold. 

This is, of course, assuming that the lobster would not be at a disadvantage due to its smaller size. So it is likely that the mutation would need to stop growth at a point optimal to its defense and attractiveness. Any lobster better would potentially prevent mating and decrease the chances of it passing. 

The chances of the stars aligning perfectly is unlikely. And so I don't expect it, it was more of a what if it did happen.  I heard Lobster are biologically immortal also...any word on this?
 Lobsters can live indefinitely, but they die to predation, and if that doesn't happen, their size becomes so large that their metabolism/physiology can't keep up with the size and they die.  So they sort of do die of old age, but it's a different flavor. But what if we provide the food necessary to sustain the large lobster.. could we create godzilla-lobster? No, Eventually the Square Cubed law would catch up with it and it would die. Essentially the Gills underneath the lobster wouldn't be able to support the large mass above them. (Since a cube grows in area slower than its volume). If it somehow overcame that another problem I'd imagine would be the exoskeleton not being able to support the body.  What if we changed the square cubed law? Sir, your ideas are intriguing to me and I wish to subscribe to your newsletter. In humans isn't the primary achilles heel the oxidants and telomeres? Not necessarily for the telomeres. They are a limitation to how many times your cells can divide but it seems like your brain will go before that really starts be an issue for most of your other organs. Neurons(with a handful of exceptions) are no longer in the cell cycle and never replicate, so telomeres aren't a problem (that said, it is the oxidant thing to a certain degree).  This seems like a semantics question along the lines of the Theseus Ship paradox.  Why is that polyp considered to be the same individual if it discards most of the cells that used to comprise it?  If we considered a female's egg to be the same individual, could we say this about any animal? A female's egg is haploid until fertilization, at which point it combines with the DNA of another individual.  The jellyfish's DNA doesn't change. Ah, the DNA is a good way to sort that out.  Thank you. Like you said, it's really a matter of semantics, as well as a bit of sensationalism. I had to do a presentation on this jelly a few months ago and there is a post on [MITs science journalism page](https://ksj.mit.edu/tracker/2012/11/first-we-get-proof-heaven-now-secret-imm/) about this organism with references to a paper. One of the paper's authors showed up and specifically says that they did not mention immortality. It's more of a clone than anything else.  After I responded it made me think about animals that clone themselves and haven't changed in thousands of years.  By the definition of same DNA = same individual, that would be an extremely old individual. Don't organisms that reproduce asexually (such as bacteria) gradually change over a number of generations just due to random mutation anyway? Yeah, and there's horizontal gene transfer, when scraps of foreign DNA from other bacteria end up accidentally permeating the cell wall and being incorporated into their genetic code. It's a pretty scary thing actually, and a big reason why bacteria can become resistant to antibiotics rather quickly. They can literally pick up new traits within a single generation, which is crazy. if DNA not changing is the requirement for immortality does that make some crops (apples, potatoes, bannanas.....) artificially immortal because of the way they are grown from part of the original plant which keeps them genetically identical? Haas avacados are all just trimmings from one random tree from California. A post man was a amateur gardener, and found this weird looking, young avacado plant. He was going to dump it but a friend urged him to give it a shot to see how it's fruit would turn out.

The rest is history. Haas avacados account for something like 90% of all avacado production.

The original tree finally died in the 1990's. If some of your cells were used to make a clone, but you died and the clone lived on, would you consider that immortality?  There are still expression differences that arise due to gene x environment interactions throughout the lifecycle of the clones that make them epigenetically and phenotypically distinct.  I'm not sure what the answer to this one is. No, but if my brain survived and the rest of me regrew, I would consider that immortality. Bananas don't have a central nervous system, so something like that doesn't work as well. If someone cuts off my toe, and I grow back from that, and I never had a brain, does that count as me? I'm inclined to say yes. There is an 80000 years old forest which is considered one individual: http://en.wikipedia.org/wiki/Pando_%28tree%29 I agree that it's like the ship of Theseus.  

The problem is really what is the definition of an individual, and is it biologically relevant? I mean, when we think of immortality, we care about it because we care about continuity of our consciousness.  First of all, the neural net of a jellyfish is pretty limited, they don't really have a consciousness to begin with. Secondly, many of its memories are going to be encoded in parts of the body that die off and be lost when it reverts. 

Genetically, I don't think it's that important either.  I mean now we could theoretically take stem cells from a woman, put them into her own egg, implant them in her own uterus, and have her give birth to her own clone.   If she could do that without genetic errors she could genetically live forever, but our assumption of identity would say that she would be different than her children, even though they grew entirely from her. 

I think the difference is in the mind, and how our minds are interconnected with themselves allowing for fast communication internally through neurons, and slow communication through other methods.  We split off identity based on the speed of communication.  Two parts of your brain are part of the same individual because they communicate between eachother quickly through electrical impulses, despite the fact that two parts of your brain might manifest different desires or opinions.  Two people communicate slowly through speech and other senses. So we consider them different individuals.

On the other hand, you have someone like identical twins, which start out as the same cell, but divide and then develop separate nervous systems.  They are distinct individuals.  Or you have something like conjoined twins which even share some neural activity but maybe not in the brains, which we still mostly consider distinct.  And then you have something like people with chimaerism, which really messes with people, but you have two genetically different plans making up a single individual. 

I think what really constitutes immortality in a practical sense is the amount of experience that gets preserved. With the jellyfish, very little is preserved as it reverts to a polyp, and it's practically similar to reproducing.  On the other hand, humans are better at preserving that experience through communication despite the fact that their offspring are genetically different. 
 We also have the problem of Theseus Ship.  As I understand it, our cells completely renew over the years. We end up as new people a few times in 'our' lives. Which should lead one to the conclusion that our identity is not tied to the specific atoms which constitute our body, but the temporally stable pattern they form (also from physics: it's not clear that particles even have specific identites *at all*, e.g. not electron #83597538534, but: stable pattern of energy in this region of space time which can be approximated as a specific object, but isn't) Many cnidarians including anemones and corals also don't senesce and are thought to be biologically immortal. It's difficult to prove though, because unlike trees or turtles, there are no rings to count, so there's no way to date them effectively.  &gt; Article on aging and the immortal jellyfish

That is a sketchy looking journal you linked to. Chinese press, gmail contact address, relatively unknown editorial board, a website that causes eye cancer...

Research on the organism seems pretty scant. Here is the [best paper](http://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/179209/1/Biogeography_13_101.pdf) (PDF) -- also pretty weak -- that I could find. I would say the jury is still out on the "immonrtality" of this species. You're right. The article I first posted isn't the most credible. I should be more attentive to my during-breakfasts posts. I found a more credible source from [Biological Invasions](http://link.springer.com/article/10.1007/s10530-008-9296-0/fulltext.html). I'll edit it into my previous post. They use a different sentience name but they are [considered synonymous](http://onlinelibrary.wiley.com/doi/10.1111/j.1439-0469.2006.00379.x/abstract;jsessionid=E51AAF9938A2B0E2FF223A0324D85A89.f01t03). This seems to be the [earliest report](http://www.jstor.org/stable/1543022?origin=crossref&amp;seq=1#page_scan_tab_contents) of the reversion to an immature state, which was cited in [Cell](http://www.sciencedirect.com/science/article/pii/S0092867414002827). So I would say this is well documented. However, you were absolutely correct to question my original source. Do those papers actually discuss the "immortality" of the species, though? It looks like they are mostly interested in questions about phylogeny. The *Cell* review also only mentions the jellyfish in regards to reverting back to a developmental stage -- there is no indication how many times this process can be repeated, or if their is loss of fitness with each reprogramming. It seems like a pretty big leap to go from developmental plasticity to immortality. I could only find the one study probing the longevity question more deeply, and it isn't a great one. I made one of my links wrong. Sorry. [This is the most substantial paper](http://www.jstor.org/stable/1543022?origin=crossref&amp;seq=1#page_scan_tab_contents), which seems to lay the groundwork for the claims of immortality.

The biological invasions paper refers the "The potential immortality of Turritopsis dorhnii" twice. Yes it does say 'potential', which is quite reasonable. We are not completely anticancer that they can revert indefinitely. Cinachyra antarctica (Antarctic sponge) grows very slow and one is estimated to be ~1500 years old. Does this species have "memories"? And if so, can they remember past events after reverting? Jellyfish do not have a brain - instead they have something called a nerve net, which verges on a central nervous system but is not quite. It would be difficult to say what a memory might look like in such a network. As far as I know studies have not been conducted on these species, since their nervous systems are so primitive.  There have been studies done on the "persistence of memory" from caterpillars that metamorphose into butterflies, and sense memories (I think it was association of a bad stimulus to an odorant) DID persist.  This is especially interesting because if you cut open a chrysalis, you don't find a caterpillar or a butterfly, you find a soupy goo. Apparently some small remnants of the caterpillar stay intact within this soup, and somehow the memories remain. Physiologist here, my dissertation is on the physiology of aging (specifically telomeres) in a long-lived bird species.

I think another way to think about the question is: *Why do organisms age?* - from an evolutionary perspective. This helps explain why 1000yo eukaryotes aren't prolific. Others have covered the biologically immortal species, so I won't talk about those...but also look up hydra, which don't age if they reproduce asexually, but once they start reproducing sexually they do! 

Darwin (1859) suggested that lifespan, like other species traits, should be affected by selective pressures. Three major evolutionary theories of why aging exists: 1) the theory of programmed death, 2), the antagonistic pleiotropy theory of aging, and 3) the mutation accumulation theory of aging. These theories are not necessarily mutually exclusive, and it is likely that the reality of aging that we observe in nature is an aggregate of two or more of these theories (Kirkwood and Austad 2000).

The programmed death theory states aging (and death) evolved to replace less fit individuals in a population with younger ones with more reproductive potential (Weismann 1891). There is, however, limited evidence of senescence directly linked to population mortality in the wild, and natural mortality is likely linked to extrinsic factors like predation, infection or environmental
hazards (Kirkwood and Austad 2000). There are no known evolutionary mechanisms that could yield such a result, so though the theory was foundation for later hypotheses, it could likely be "relegated to the dustbin of old ideas."

The power of natural selection declines with age once reproduction begins (Medawar 1952). Therefore, genes that results in a loss of fitness early in life, particularly before reproduction, are under strong negative natural selection and genes that have negative effects later in life face little selective pressure.  Genes can be both adaptive at early age and hazardous at older ages, or pleiotropic genes. Rose and 
Charlesworth (1980) demonstrated the presence of these genes in *D. melanogaster.*

The programmed death theory was elaborated as the Disposable Soma theory by Kirkwood, where individuals must balance the allocation of resources between germ and somatic cell lines. Aging occurs as a result of the accumulation of damage during life, and though maintenance and repair mechanisms have evolved, they cannot mitigate the damage, resulting in aging (Kirkwood and Austad 2000). This theory also suggests that the variation of lifespan for individuals within a species could be a result of variable maintenance systems. Under the accumulation theory of aging, the free-radical theory of aging, proposes that reactive oxygen species (ROS), produced in stress and metabolism lead to damage in both DNA and cellular material. The mitochondrial theory and telomere theory of aging also exist under the umbrella of the accumulation theory.

edit: formatting What do you think about a theory that delayed childbirth or never having a child increases a lifespan for a female as the body detects lack of pregnancy and turns on life-extension mechanisms to make sure that this individual will have a chance to reproduce later.  Good question. There is considerable evidence that increased reproduction (number, attempts, and effort) shortens telomeres and may impact survival (Bauch et al. 2013, Voillemot et al 2012, Kotrschal et al 2007). I think it is likely, however, that there is cost of reproduction, and less so that longevity enhancing mechanisms are 'turned on.' This is supported by the literature thus far. 

There is some evidence for this in other animals, that delaying reproduction delays senescence. I referenced it earlier, Steve Austad's work explored the phenomena that hydra do not senesce if they reproduce asexually, but begin senescence once they are triggered to reproduce sexually (don't have a citation, was at a personal meeting). Also, Hunt et al. (2006) showed that the selection for increased longevity leads to decreased reproductive effort - Quote from Abstract: 

&gt; "...we selected directly on adult longevity of male field crickets *Teleogryllus commodus* and measured the correlated responses of age- dependent male reproductive effort, female lifetime fecundity, and several other life-history traits."

edit: spp name [deleted] Love that paper! Such a cool study and a cool mechanism (since telomerase is active in gonads, sperm are acted on by telomerase throughout life and pass on longer telomeres). 

I've chatted with Dan Eisenberg (1st Author) a number of times, great guy, and really cool study.  His work explores lots of these cool comparisons!

&gt; (I have as well so my daughter and grandchildren can thank me later!).

Haha, they owed you from day one!

Another really cool study came out in Science this year, showing chronic malaria infection shortening telomeres, survival and fitness. Implications for chronic diseases that we often think of as relatively benign (Herpes SV 1) - 

http://www.sciencemag.org/content/347/6220/436.abstract Aw sweet, I always wanted to do telomere research but I'm just not a chemist/biologist (robots ftw!) However for the better part of a decade I've had this idea: Synthetic kidney to synthesize telamerase and introduce it directly to the blood stream. People live with one kidney, kidneys synthesize hormones and cycle blood, it's the ideal candidate for a switch-out for different chemicals to make you stop aging. If one could grow such a kidney, is this idea viable? Robots are awesome! I use robots to help with the accuracy/precision of pipetting reagents in my lab work on telomeres, so thanks for your work!

Thats a cool idea, however, a little dangerous in practice since we don't fully understand how telomerase works in cells and affects longevity. Without going into extreme detail, when telomeres shorten substantially that they cannot be rolled and capped, this is seen as DNA damage and triggers a pathway called the p53 apoptosis pathway. This is a tumor suppression pathway and results most likely in the death of the cell. If enough telomeres in a tissue or system shorten and trigger this pathway, the death of the aggregate number of cells causes a decrease in the function of the system (we term this as system senescence).

Telomerase can elongate telomeres. However, up-regulation of telomerase is implicated in about 85% of cancer cases. Telomerase is only active in human stem and germ cell lines, however other species appear to tolerate increased telomerase activity in other cell lines. Up-regulation of telomerase by itself can carry considerable risks, as it puts in jeopardy the telomere shortening branch of the p53 tumor suppression pathway. Should tumorgenesis occur, this p53 suppression pathway could be 'blocked' by the increased telomerase activity, when a normal, telomerase-deficient cell would proceed towards apoptosis.

Telomerase deficient mice have shown recovery of organ activity and physiological 'health,' but the study was only a brief telomerase addition (Jaskelioff et al 2011). While this did not promote carcinogenesis, the author explicitly said that increase telomerase for longer periods of time, especially longer in life would like lead to carcinogenesis. There are some species of bird, however, that can withstand higher levels of telomerase in somatic cells.v

Pro re nata administration of telomerase to healthy somatic cells currently leads to carcinogenesis in all studies I am aware of.

An interesting paper on the topic: Haussmann, M. F., D. W. Winkler, C. E. Huntington, I. C. T. Nisbet, and C. M. Vleck. 2007. Telomerase activity is maintained throughout the lifespan of long-lived birds. Exp Gerontol 42:610-618.

(copied some lines from previous comments of mine) If we had a sure-fire way to identify cancer cells (in essence, a general cure for cancer), and had that going in our body more-or-less continuously, and we also had an ongoing administration of telomerase, how close would that get us to arresting aging? &gt; If we had a sure-fire way to identify cancer cells (in essence, a general cure for cancer), and had that going in our body more-or-less continuously, and we also had an ongoing administration of telomerase, how close would that get us to arresting aging?

Very good question, and an interesting topic. Some speculation: If we could withstand high levels of telomerase, cell lines wouldn't stop dividing, or cells triggered to die. Therefore, systems would not degrade with age, for instance your acquired and innate immune systems would both be robust throughout life and there is some evidence that telomere shortening could be a component of cardiovascular disease. So there would be some benefit there. There would be a number of drawbacks though, cells would have a limited p53 pathway (triggers cell death), so cells that are malignant wouldn't have telomeres that are shortening and triggering this demise. Telomeres, in some sense, prevent malfunctioning cells from having too long a life that they negatively affect the system over lifespan. The number of times a cell can divide is called the Hayflick Limit and is governed in some way by telomere length. Telomere theory is just one of the many components that affect aging at a cellular and greater organ system level. There might be some longevity increase, but perhaps even more important a increase in system health. 

Many of us who study aging are more concerned with increasing 'health-span' or living healthier for longer. If we could extend lifespan from 90 to 120 years, but you had to live those 30 years like you were 95yo, that might not be the best experience. But, if we could extend your health span, say you now live until your 100, but with the physiology of a 40yo until your 90, that would be better IMO. I think there is a potential for a bit of both.

(quoted myself)

 The simple answer is that this is not a good thing for natural selection.  A species that lives for 1000 years fails to evolve for 1000 years while everything around it is slowly becoming better adapted to its environment.  Since we cannot significantly change our genes during life, death and aging are a necessary part of the development of life historically.

If there was, for some reason, a strong selective advantage to a long life you would see it evolve.  In fact our unusual life spans probably are a result of natural selection. After we developed language, cultural knowledge became an important survival factor, and only the old can remember things that don't happen very often.  Older women who are no longer reproducing are great at raising the children of others.  This is almost certainly the explanation for menopause.

But living for ages and ages?  It just has no selective advantages at all.  in fact it is counterproductive from the perspective of a gene.  It's actually a great example of how evolution cares primarily about *genes* and not the happiness or well-being of the individual organisms that transmit those genes from one generation to the next.  A couple of problems with how you framed this.

The main problem is that longevity can be adaptive if an animal is fertile throughout its lifespan (and many are). Just by living longer, animals can have more offspring, and by definition a greater fitness.

The reason we don't see more long-lived animals is tied to the rate a which animals die. Every animal is subject to death by accident or predation. This is its extrinsic mortality. Genes which would confer lifespan beyond the expected age of extrinsic mortality are not selected for because the animals die before the gene can confer any advantage.

In fact, the animals that do evolve longer lifespans tend to do so because they have found a way to lower their extrinsic mortality rate (evolving flight, growing larger, evolving to live underground etc.). Now, under these new conditions, there is selective pressure for genes which confer some longevity advantage. This answer surprised me.

Your argument is consistent, but is there any direct proof for this?

We are only talking about lifespans on the order of 1000's of years, whereas evolutionary time scales are much much longer, no? OP has his/her theory a bit backwards. There are plenty of examples of species which evolved longer lives in response to selective pressures. Any time a species finds a way to reduce its extrinsic mortality (the rate at which accidents and predation kill the animal), it faces selective pressure to live longer.

The correct answer to the original question is that extrinsic mortality limits longevity, and therefore genes which would confer a lifespan advantage never have a chance to undergo natural selection. the speed of evolution is related to lifespan. under a certain selective pressure, two animals might take the same number of generations to adapt to it. If one reached maturity after two weeks and the other after two years, the one that takes two years will take fifty times longer to adapt.

This is why mammals survived the extinction of the dinosaurs, we were small and bread fast. They had too long a lifespan to adapt to the huge climate changes. How long were the dinosaurs lifespans? I looked it up and the T Rex might live for 30 years but most die within 6 years of reaching full maturity. Basically dinosaurs (the big kind) grew super fast and died pretty quickly. Probably like 20 years was a lifespan of the big ones we think of when saying dinosaurs How do we know this? But it's not like things choose how they evolve. If a thousand-year-living animal happened to come into being, natural selection itself would be the only way to kill it off (for the reason that it doesn't favor [good] natural selection). Seems paradoxical.  if something with a thousand year long lifespan came into being, the adaptations required to keep it alive that long would likely make it less survivable than its short lived brothers. And lets be honest, how often does a wolf die of old age? it's an extra burden on the animal that will rarely give any advantage at all.

giving a plane a slower, more fuel efficient engine wont help it in a dogfight. In Evolutionary Computing there is plenty of research showing that performance can be improved with limiting or preventing solutions from a previous generation from participating in the next generation. This might be true in many (if not most) circumstances, but it can't be the full answer to why animals cannot live millennia. If living a very long life were that detrimental, you wouldn't see any organisms with those life spans; however, plenty of trees have incredibly long life spans compared to animals, and they are subject to the exact same evolutionary processes we are.  &gt;they are subject to the exact same evolutionary processes we are.

Well, yes and no. Trees will be subject to alot of similar evolutionary pressures but the major difference is that once they establish themselves they have far less competition for resources than an animal would have. They collect their energy from sunlight, which actually becomes easier the older and larger they become. This is why in the rainforests trees become so tall and once they reach the canopy and establish themselves they will outcompete any new trees trying to grow beneath them by blocking out the sunlight. A similar thing can be said for their root system, once it is established they are able to drain the resources from a much larger area and outcompete new trees attempting to grow there. Things can evolve without any advantage or even evolve with a disadvantage provided said evolution does not stop them from reproducing. As for your theory on humans growing older, it is baseless, as evolution is not an actual physical thing, it can't decide anything. People weren't forced to have babies at an older age so there is nothing forcing that selection. &gt; does not stop them from reproducing

In this case, though, they're competing for resources with the younger generation. So having that feature has a cost to it as well. Is natural selection being selected for? That's sort of like saying a rock is influencing the way the wind comes at it. Maybe that's not a fair analogy. Maybe that's not even what you meant either. If Im a thousand year old oak, for example, are my acorns obsolete? I, grand oak that I am, would not thinks so. Anyway, somebody further down in the comments said it was about the energy being used to sustain cells. At some point it is more cost effective to let a cell die than it is to repair it. The need to reproduce is definitely selected for so the species in this way has covered it own behind. If the individual could reproduce forever, it would. It is just unable to. Reproductive longevity is probably selected for. I can't imagine how it wouldn't. There is of course a strain on the mother and maybe that's why we don't see reproductive old age being selected for. I don't know. There is most certainly diverse species that select for things that others just can't.  [deleted] [deleted] [deleted] Several things going on here:

First, some animals _can_ live thousands of years.  In particular, there's the famous immortal jellyfish, and some corals and sponges are thought to live thousands of years.   

Second, we don't really have a clue how long many species live.  I would not be the least bit surprised to find that some other marine invertebrates, for example, could live thousands of years.  We know many can live hundreds of years. For example, the [ming clam](http://en.wikipedia.org/wiki/Ming_%28clam%29) was 500 years old, and [sea urchins](http://fishbull.noaa.gov/1014/19ebertf.pdf) can exceed 100 - 200 years old.   But for most animals we'd never know it unless we actually stuck one in an aquarium and watched it for a thousand years, because most animals don't come with handy tree rings for dating.  Lobsters can also likely live more than a hundred years, and may live longer than that.  I rather suspect there are plenty of species out there that could live indefinitely.

This brings us back around to the question of "why doesn't everything just live forever".  The answer is that most things get killed by something or other.  If you look at species known to have long lifespans, they are all usually pretty likely to live to old age in the first place, provided they make it to adulthood.  Tortoises and clams have hard shells, animals in deep or cold waters have few predators, whales are _huge_, big lobsters are too big to be eaten by most fish, etc.  Adaptations allowing older age actually benefit these creatures, because they are likely to live long enough to get to use those adaptations in the first place.  Contrast this with mice and insects and little fish, and things like that.  These animals have a pretty much 100% chance of getting eaten by something or dying for some other reason before they make it to a few years old.  There's no selection pressure for adaptations allowing them to live longer, because none would ever live long enough to use those adaptations.  So they live fast and die young.  

I'd argue that, on the whole, animals are a whole lot easier to kill than trees, and that's why they tend to have shorter lifespans. [deleted] Why has no one put lobsters in sealed, ideal, conditions for decades to see the results?

This sounds crazy to me and if it's true I don't understand why I haven't heard about 20 foot long lobsters that have been growing in labs for the past 100 years.  This is because they can't live forever. This is a common misconception. While they won't die of old age, they will sooner or later be so big that thwy are unable to sustain the energy needed to molt. In which case they will either die from exhaustion while attempting to molt, or they just won't molt and they will die when their existing carapace deteriorates to the point where they contract an infection or parasite and die. This was the answer I was looking for.

I knew if what OP said was really true- there'd be a monster lobster in a lab somewhere.  That and probably a giant lobster running around the globe eating everything (or evidence of said lobster).  Given the fact that there are millions, and lots of sea, there could have been one mutant lobster that managed to grow large enough in an area with a small enough threat to overcome all predators and eventually be kind of the world. There WAS one giant lobster ruling the seas. But then it tried to attack Japan and Godzilla defended the land, smashing the lobster into thousands of small lobsters. And that's where baby lobsters come from.  Could you somehow help them molt so that it doesn't make them get exhausted? Or is that something only they can do? [deleted] How much do you charge?  I imagine, yes, you could, but you could also put a mouse on life support and give it organ transplants when needed and it might live forever too. We're talking about an animal that can naturally live for thousands of years. What if you provided them with enough energy/food? 

Please give an answer or I'm going to buy a lobster at some point  Maybe they can't eat enough even if there is plenty of food laying around. Maybe if you fed them with a tube they could grow. And Grow! **AND GROW!** Unless they couldn't digest enough food fast enough. Then you'd have to inject them with like simplest straight up nutrients directly into their tissues.  We could infuse those nutrients with butter for the tastiest lobster ever! Could you purposefully stunt them? I know calorie restriction has showed promise with mammals, but it is known to cause stunting. Or possibly keep it in a small container? Maybe not ethical, but might still be interesting. Their internal organs would continue to grow. Happens with fish that are kept in containers that are too small.  How big are they at this point? And why can they no sustain the energy? But in ideal conditions they wouldn't be able to contract an infection or parasite. Let's make a world-sized lobster. Even in a sterile environment you have to understand that an arthropod's carapace (I.e exoskeleton) is literally the only thing holding it together, much like your endoskeleton is what is holding you together. You can't repair an exoskeleton the way you can repair bones, and also an exoskeleton, which has to hold all of the lobster inside, can't expand. And a lobster, like most arthropods, doesn't really stop growing if it has food and space. At some point, no matter what the outside conditions are, it HAS to molt if it wants to get bigger. Once it gets big enough, it will not be able to store enough energy to complete this process, and it will die.  

This isn't even counting for the cube square law. Even if the buoyancy of the water kept a gigantic lobster from collapsing under its own weight, the inertial mass of its limbs would eventually mean that it would be unable to move, so it would starve. Would it be possible to try to develop a specialised diet to give the lobster more energy to help it molt? [It seems](http://www.lobsters.org/tlcbio/biology3.html) that the respiratory system is affected during molting --- would it be possible to increase the oxygen content of the water? To minimise the duration of the molting process, during which the lobster is vulnerable couldn't they maybe help it get its shell off? So could a lobster with stunted growth theoretically live forever? How big is a lobster that cannot molt? Why do we only ever see them around the size of afoot at the grocery store? Seems like there should be a lobster the size of a bus.  You just don't go to the right grocery stores: http://www.telegraph.co.uk/news/newsvideo/viral-video/11270184/Giant-lobster-age-70-caught-off-Californian-coast.html who is going to pay for this, red lobster? Funding, man.  So much primary research is not done because there is nobody to foot the bill for it. [deleted] Seriously. How expensive could it be to keep a few lobsters in a cage for a few years? Seems like a cheap and easily cared for 'pet' that would offer some insight into anti aging Well, a few years isn't the problem, but we are talking about an experiment that would have to take place for 50 or 100 years before any real research on lobster aging  could begin. 

Not many agencies are super happy to give money for an experiment that *might* produce results about lobsters in a century.  But honestly how expensive is lobster upkeep? It's probably cheaper than owning a dog. I have absolutely nothing to back this up it just seems like an animal that is easily cared for. Like owning goldfish or something Surprisingly expensive, seawater systems are expensive to maintain, corrosion destroys pumps, filters etc. We keep some lobsters in my lab regularly for few months and just keeping that small lab running costs thousands annually   If you could guarantee that, in doing this experiment, we would unlock the secrets of telemorase and extend human life indefinitely, then you would get funding instantly. 

But it's cost-benefit, and right now that experiment isn't top priority. Even that little money it takes to raise a lobster would instead go to a shorter-term experiment that is more likely to produce usable results. 

Unfortunately, in the US, the government is super stingy worth what money goes to the sciences and how it gets used; they think of research as a business, which isn't really conducive to "research for research's sake". I know right, I feel like this is the kind of project that even unemployed old me could comfortably fund. To you and /u/randomdude45678 , the cost is extraordinary when you think about about taking this idea from concept to results.

First you'd need a facility, one that is not likely to be altered or destroyed in the next 200 years.  Once you've paid for a building, custom tank, support, food system, etc, you need employees, an organization to oversee this project that will not scrap it after you've invested 105 years of property tax, maintenance, upgrades, emergency repairs, salaries, insurance payments, lobster medical care, etc.

You are basically creating something that will be a monitored time capsule, passed down for generations.  To tell you the truth, I can't think of much of anywhere this would even be feasible outside of something like the Royal Society, and I don't think Lobster Husbandry is high on their hobby list.

There are plenty of 80 year old lobsters out there to research, you'd have to keep one around for an extremely long time, and if it were just paid for by some generous and curious man, he'd have to allocate a fund to pay for it in perpetuity, and support a financial manager to oversee this project and replace himself over years and years.


If you think you can get away with just leaving one in an aquarium somewhere, keep in mind that my local aquarium is a treasure of the state, and we just lost 60% of all living things in it because someone at a chemical factory put the wrong label on a bottle. You make it seem so expensive, but every long term study has high costs associated with it- no one is disputing this. 

Say it costs 10million over a 100 year period- that is a ridiculous bargain if we made inroads in extending lives. 

My point is it's cost relative to other studies that would not be as impactful. 


I'm speaking in hypotheticals and generalities here, considering this wouldn't be possible anyways unless we could get around the molting issue.  Yeah the molting thing has killed the lobster idea.  But the problem is, while 10million is a good bargain for humanity, some individual human owns that 10 million, and he would literally get nothing out of it except warm fuzzies.

Someone has to sacrifice so that there is support for people to sit around and think up new math puzzles, experiment with ideas that end up being a total waste, and poking things to see what they do.  But there is so much curiosity and so much potential, it becomes a tough decision to figure out what to spend your excessive wealth on.  Most of the time, they end up investing in medical research, or ways of improving techonology(I.E. electronics and petrochemical research), because medicine hits you right in the feels and technology is everywhere, and probably a big part of what made them wealthy to begin with.

The amount of stupid things we don't know should boggle your mind.  Did you know that saltwater crocodiles head out to sea, and nobody knows what they do out there?  Nobody's ever just followed the dang thing to find out.  There are tons of animals we've never seen breed, basic phenomena that happen despite being seemingly impossible, and social problems that are killing people off by the millions with no solution forthcoming.

Basic research IS worth it, but someone's got to just give generously to get the ball rolling.  The world is full of balls waiting to be rolled. Have you ever had a saltwater aquarium? Those things are crazy expensive to upkeep. You have to do water quality tests, keep the chemical balance just right, replace the filter regularly, so on. It's not like a hamster where you just throw old newspapers at it periodically. I'd estimate that it would be between $100-$300 a month to upkeep and feed a lobster in those conditions, and that's not counting the cost of paying the staff to take care of it, the cost of the initial set up, and the cost of any monitoring equipment. That is peanuts when it comes to scientific research. Plenty of people spend that much on in home aquariums.  I'm sure the government would love to fund a project like that.

Not to mention, who wants to be stuck with a decade spanning project taking care of a lobster? I'm sure that could be delegated to multiple people- even first year grad students.

All you have to do is keep the thing alive day to day- over years and decades qualified researchers could come in periodically and analyze the data collected by the tedious work of grad students.  You *really* don't wanna be the 1st year student that kills the 600 year-old lobster.  Most PhD students get tuition payed for and a stipend (in the US anyway) so that time used caring for the lobster could be used teaching labs or small courses. So technically they are still paying those students for their time.  That cost will exist regardless of what they spend their time doing so I don't see how it's relevant. 

I.E- that cost exists for all research with work done by grad students who have their tuition paid for in addition to a stipend.  Actually, understanding how elderly lobsters genes change or not could be a very interesting study. If we could determine say, how their daf-2 gene regenerates, or if Lobsters manages to survive without such a gene, we could make huge in-roads to understanding how to lengthen human life spans. In fact, I'd be shocked if some similar study hasn't been undertaken already. &gt; Not to mention, who wants to be stuck with a decade spanning project taking care of a lobster?

Lots more upkeep in the lobster case, but the [pitch drop experiments](http://en.wikipedia.org/wiki/Pitch_drop_experiment) suggest that there's always somebody willing to become caretaker for a decent long-term experiment. Also there aren't very many marine biology labs that have been focused on lobster work since 1915 After the lobster reaches radically large proportions it won't be able to move, and will die. In addition the moltting becomes more and more stressful each time, which can cause the lobsters death.  They are immortal, but call prey to their own flawed designs. Its kinda poingant. Could you site some sources for this? I can't seem to find any that blatantly state that lobster's don't age. Sounds like a neat concept but I'd assume there would be gigantic lobsters running amock somewhere.. If only for the financial benefit - I guarantee people would pay for a "giant" lobster. (something slightly sad about eating a creature that old)

Here's an example of an, allegedly, 140 year old one

http://www.telegraph.co.uk/news/worldnews/northamerica/usa/4213315/George-the-140-year-old-lobster-to-be-released-by-New-York-restaurant.html It's likely part of the word 'ideal' but the larger an organism becomes the more energy is required to sustain it, so the larger it grew the more at risk (sensitive) it would be to food supply changes... vs something that stayed the same size, or could revert/shrink.

Definitely interested in any links you can provide that discuss this. Thanks! crustaceans cant simply grow larger and larger, there *is* an upper limit to their size. the time, energy, and resources all increase drastically with size. at some point, even in ideal conditions, the lobster will not be able to attain enough energy or resources, even with shell resportion, to keep on increasing its size indefinitely.

iirc the protection the shell offers also goes down with size because it becomes easier to breach or something. im not too sure. but regardless, a lobster couldnt just get arbitrarily large.  This is true for crocs and alligators too. After sexual maturation, they don't age, only grow until external forces kill them or their food supply and environment can't support them anymore. How long do they actually live in the wild on average? I couldn't find any information on what the average lifespan is, but I think a [Tardigrade (AKA water bear)](http://www.eoearth.org/view/article/156414/) is an animal that could theoretically live for 1,000 years. Apparently they can enter a latent state where they cease to physically age; The website I linked to has said that one was revived after 120 years of being in a latent state. Hopefully someone more educated on the topic than me can shed some light on the feasibility of such a long lifespan for this creature Unfortunately the Tardigrades that were revived after their 100+ year rest died within a few minutes. The oldest known living animal (actually the oldest known life form at all) is [a sponge](http://genomics.senescence.info/species/entry.php?species=Scolymastra_joubini) in the Ross Sea in the Antarctic. its roughly estimated to be approx 15,000 years old. though according to its growth its size is in line with 23,000 years. its hard to know because of the fluctuations in sea level though. How hasn't anyone mentioned cancer yet? To be brief (mostly out of my own ignorance) DNA replication isn't a perfect process. Wikipedia says that DNA polymerase and its associated proofreading factors can add nucleotides at an error rate of less than one mistake per 10^9 nucleotides. Much of this DNA is *practically* irrelevant introns that can have mistakes for the most part, as they don't code for any proteins. But, over time, mistakes get made in the coding exons, the parts that get translated into proteins. If this coding causes unchecked division of a cell, you get cancer. Most malignant cells are caught by the immune system, but its really just a game of probability.

Even longer story short, most eukaryotic organisms will die of cancer if given enough time. The factors that screen for malignancies become less effective over time while the prevalence of mutated genes that code for unchecked cell growth grows exponentially as these errors get magnified over time. 1000 years is too long for most complex organisms, especially mammals. If they had the ability to otherwise live that long, they'd die of cancer.

Edit: a sentence and word. &gt; DNA replication isn't a perfect process. Wikipedia says that DNA polymerase and its associated proofreading factors can add nucleotides at an error rate of less than one mistake per 109 nucleotides.

This makes me wonder if people who have children later in life are more likely to have kids with more random mutations in their DNA.  I know there is higher occurrence of major abnormalities like down syndrome (trisomy 21), but it hadn't occurred to me that there could also be small random mutations in their DNA. Good question. With DNA sequencing becoming cheaper, we may know the answer to that in a decade, if it becomes useful/trendy to DNA sequence you and your baby. Forgive my ignorance, is cancer prevalent in species that aren't mammals? It happens in invertebrates and vertebrates. I don't know about microorganisms specifically but as /u/glorkcakes said any multicellular organism could probably have similar unchecked or abnormal cell growth.  Turritopsis dohrnii, the immortal jellyfish, is a species of small, biologically immortal jellyfish found in the Mediterranean Sea and in the waters of Japan. [read more](http://en.m.wikipedia.org/wiki/Turritopsis_dohrnii) 

Note: i linked it via mobile sorry if it doesn't open just search it on Google.  Because death has its advantages.

In multicellular organisms, every time a cell divides (mitosis), there's a risk of something going wrong. Not every cell in your body actually has the same DNA. This is why freckles exist - some of our skin cells are mutated and produce too much melanin.

This is also why cancer becomes more likely as you grow older - the mutations stack up and inevitably one of your cells will mutate to grow uncontrollably, creating a tumor.

Reproduction sort of resets this. Its a way of making the line reset to a single copy of DNA, and testing it to make sure it's still good. If the organism survives to reproduce, the DNA is likely good. If it's bad and a mutated organism is birthed, the line ends there (assuming the mutation is bad).

Death is a mechanic that developed with multicellular organisms. Single-celled organisms, to my knowledge, don't naturally die.

I have a suspicion that the reason we're seeing more cancer nowadays than ever before is that we're circumventing the death mechanic with our improved health system. People with more mutated copies of DNA are surviving to reproduction more often, and so more of us are starting out life with increasingly mutated DNA, so cancer and other mutations hit us earlier than they would normally (even accounting for the fact that we're living longer). Given that some Bow Head whales based upon age of antique harpoons and other indicators are believed to be over 200, maybe the Jean Calment of this species live 3 or even 4 centuries. That is, maybe a Bow Head was born well before Newton or Leibniz or Washington or Franklin and is still around. This to me is more exciting than old jelly fish since it is possible that these whales are not just long-lived but sentient. A nematode called *Platyhelminthes*, or more commonly known as "Flatworm", is considered to be immortal. It never ages, as it stays forever young. It can even re-grow its' own head if decapitated, and will also regain its' memories.

[Source](http://www.zmescience.com/research/studies/immortal-worm-never-ages-forever-young-043294/). Wildlife biologist here. There are a lot of wrong answers here. It doesn't have to do with evolution. It's about the energetic cost of body maintenance. Think about my car. Every year I drive my car it gets worn out, dents, scratches, the brakes wear a bit, the belts fatigue. I spend money fixing things, replacing parts. I could replace those and spend money at the mechanic forever. I could drive a forty year old car if I put enough money into maintenance.  Or I could save my money for a new car. At some point out become more affordable to junk my old car and buy a new one. So too for animals. The important thing is their genes. The genes could try to maintain a single animals body forever, constantly doing chaloricly expensivemaintenance. Or they could let the animal die and spend energy reproducing and making new, young bodys that require less upkeep. Wait, but why is maintenance not *cheaper* than reproducing? Babies and children are known for their appetite. To use your analogy - a car would 'die' if the tires tear down. You could buy a new car, but then all the good-to-go parts of the old one go to waste. It makes sense to just get new tires. Of course the rest would still be worn out, but usable at the least. The only reason to get a new car is if it is technically more advanced which is basically evolution and you say that's not the case, although it makes sense to me. Right, so you change the tires.  But then you need an oil change.  Then one day you hit a bump and need a new muffler. And so on and so forth until one day, the whole transmission needs to be scrapped.

The same thing with the body. Grow a little bit of new skin on a child? No problem. Heal a broken bone on a teenager? Not easy but doable.  Regrow a damaged liver on a middle aged man? Getting harder, but still can be done, especially with medical treatment.  Repair the damaged brain of an elderly person? Now you're getting into nearly impossible mode.

Over time, it becomes more and more expensive to repair the body.  Just like with a car. Where this analogy fails is that your body's ability to heal itself isn't intelligent at all: it is a stimulus/response mechanism that developed entirely by trial and error. GM and other car makers increased the price on replacement parts in recent years to stimulate new vehicle sales, because so many at-home mechanics were able to cost-effectively keep cars and pickup trucks from the 60s, 70s, and 80s going forever. So it is theoretically with your body: if we had an intelligent mechanism for healing the body you could theoretically keep it going indefinitely at the same energy cost as building a new human every 30 years. It's not just cars, it's everything.  Everything becomes more difficult to repair over time, after all entropy is always increasing.  In the car example, eventually the body starts to rust even. Yes, there are cars with millions of miles on them, but they're on a third or fourth transmission sometimes.  Every good in life, short of diamonds or something, has a shelf-life.

Speaking of rust, the main thing that causes aging is free radicals, which are basically oxygen molecules that are spit out by the mitochondria whenever you burn energy.  Those molecules mess up your DNA, and while there are processes that repair the damage, over decades the body starts to break down. 



 You can replace the rusty body on a car. You can strip the parts off an old frame and reattach them to a new one. The only thing getting in the way of this is you're not in control of the supply of parts (like a new frame). But if you are, and you've got the tools &amp; knowledge, you can keep that car going indefinitely. Theoretically you could do this with the body too - it's only a question of mastering the technology and producing the material necessary. The math of replacement vs. building new is not a barrier if you're equally good at both. Is it the same car if there are none of the original parts left? Since the car in this situation is an analogy to a living thing, I'm going with yes.  I still consider myself the same "person" I was 10 years ago, even though those cells are probably all gone by now. However with humans the cells only have a limited life cycle before they can't replicate any further. As well brain cells are not able to replicate so as those die they can no longer be replaced.  I guess it's not actually an animal, but the [HeLa cell line](http://en.wikipedia.org/wiki/HeLa) is technically immortal. The cells were taken from a cancerous tumor in 1951 and have been continuously regrown since then.  I'm a biologist, and I recently had a similar conversation with a number of scientist friends.  We were discussing death from both an ecological and cellular integrity/metabolic activity/functional replicator perspective, and trying to answer two questions - what is death, and why are organisms mortal?

To a biologist, the definition of death is contextual; a neuroscientist, an MD PhD studying cancer, a microbiologist studying the molecular mechanisms of antibiotics, and a herpes virologist will have very different definitions of death, each suitable for their needs.  None of them will be able to tell you with 100% certainty at exactly what point a cell or an organism has died, nor exactly what irrevocable step equates to death, although they may have some metric by which they measure life and death.

Your question, however, is "why isn't there an animal that could live for thousands of years."  As people have pointed out, some animals can live indefinitely, and certainly some other organisms have indefinite lifetimes.  Consider any single-celled organism that reproduces by dividing  every daughter cell is, in some very real sense, several billion years old.  If you were to look at the organic chemicals within each cell, though, you'd find that they are in another sense much, much younger  no molecule in a living cell is anywhere near that old.  This apparent paradox occurs because material is not sorted between daughter cells with perfect symmetry, so when a cell divides, one of its daughter cells will be built from older material than its sister cell.  As cells continue to divide, some subset of the population is unlucky and inherits the oldest material around.  These cells are more likely to die than their younger sisters, simply because their old material is more likely to fail them.  This enrichment for younger cells tells us that aging is a universal problem confronted by all creatures.  In multicellular organisms (including animals), of course old material also accumulates.  While regeneration is possible, it's important to realize that it comes at some cost, the cost of constantly fighting entropy.  So, the simplest answer to your question is biophysical: "because of entropy."  

However, there is also an evolutionary answer to your question, which is simply immortality doesnt increase fitness.  Evolution produces functional solutions to problems by taking a stochastic walk over fitness landscapes; it flows to solutions like water flows over a surface, generally following the topological path of least resistance, occasionally changing course due to random events.  Immortality is not a feature of organisms because it doesn't increase their fitness - planned obsolescence is a better strategy.  There are many arguments for why this might be true.  It might be simply that it's hard to fight entropy, and so virtually all life must pass through a grand renewal in order for its lineage to be successful.  For most of us here on Earth (bacteria to humans), this means that at some point, we must die.  It also means that to survive, we all must pass through the same beautiful bottleneck - our lineage must be entrusted into a single moment in time; a cell, dividing into two daughter cells.  The act of procreation is not merely one of birth, but also one of rebirth and renewal, at the genetic, biochemical, cellular, and organismal level.

Ultimately, everything an organism does comes at some cost.  This means every "adaptation" is a trade-off.  Regeneration of old material is clearly something that life is capable of achieving, but the problem of aging is apparently solved better by death and rebirth than by repair.  It turns out that for virtually all life, its better to produce more copies and then get out of the way than to try to hold on forever.

(Edited for clarity) Definitely feasible, not useful.

The best way to survive in harsh environments is the shotgun method: have as many progeny as you can, and hope that some of them have the right genes to survive.

Having a very long lifespan means that you do not change much over time, which means that a virus that can kill one of you, will likely kill all of you. Wood frogs only have a lifespan of up to 3 years, but they are the only species that can shut down their entire body and quite literally stop time for them. They survive deadly temperatures below freezing. During this time, they stop breathing and their hearts cease to beat. They produce a special antifreeze substance that prevents ice from freezing within their cells, which would be deadly. Ice does form, however, in the spaces between the cells. When the weather warms, the frogs thaw and begin feeding and mating again. Wood frogs are one of the first frogs to begin the breeding season. Nasa scientists are currently studying these frogs to see if it could be used on humans sent into space. Could give us the key to freezing and preserving ourselves.
 Its probably more successful for a species to have short lifespans than long ones.  Many short lifespans will allow for evolution while forever aging creatures that can't reproduce without growing the population and suffocating the environment won't advance beyond a very simple organism.  Death is probably deeply ingrained biologically in animals. There are.

Sea turtles may live forever if they do not succumb to disease, lobsters, Planarian worms, and some jellyfish are said to be practically immortal. The bowhead whale can live for a very long time too. Land mammals have a specific set of challenges that sea animals do not. Living in the ocean is the same as preserving something in liquid nutrients or something similar for forever. That's not something we can do on land, so most animals don't live as long as many sea animals do. Imagine adapting to the water. Your skin would be infinitely hydrated and in much different shape than it is now.  there are some species of jellyfish, if I recall correcty, that could possibly live forever, as study of their DNA shows it lacking the particular fragments of genetic code responsible of limiting cell division rates, and thus it doesn't have a limit to its aging. Trees.  Trees can live for thousands of years, and evolved from the same common ancestor as all animal/fungi/bacteria/etc after life began.  So in a sense, plants are the animals that you're thinking about that have evolved to live for 1000's of years, with many examples of plants having done so.   What kind of animal is a tree? It's not techinically an animal, but it evolved from the same common ancestor as all animals.  It just went a different direction biologically over the eons, and it found a route that didn't limit it's lifespan to a couple hundred years. Is it fair to say trees won then? Looking at the lumber industry, and humanity's centuries-long-domination and pollution of the natural world, I'm inclined to say no. Judging by the fact that seeds can remain dormant for many years and that trees are almost guaranteed to survive conditions that would ensure our extinction, I'm inclined to say yes. I had this realization while watching the time lapse growth shots in planet earth^^^stoned In general, animals to not live for a thousand years because evolution would not favor such an animal. To keep from over populating its environment, it would have to have a VERY low birth rate, this means it would evolve very slowly and would lose the race to compete with other species. You might be interested in reading [the wikipedia article on biological immortality](https://en.wikipedia.org/wiki/Biological_immortality).

As for your question, suppose there *was* a truly immortal species. As time passed and other species evolved, adapting to the changing environment through mutation and reproduction, this species remains static and unadapted. Wouldn't it make sense for the species to eventually die out from environmental and predatory causes? [deleted] I know this is maybe not really what you are looking for, but some species of sponges (which do belong to the kingdom of animals) like the giant barrel sponge (xestospongia muta) are known to live for thousands of years. It seems everyone is going for multi-cellular types.  What about bacteria or some other single cell critter that would qualify as "animal"?  Do such also suffer from truncated telomeres?  Barring genetic insult and actual demolition, they can replicate forever, can't they? I read somewhere, and I'll try to find  the link later, that applies. Essentially, cancer. Imagine we cure every disease, there are no accidents, etc., etc. Cancer will kill anything that gets too old.

First, lets talk about what cancer is. It's basically cells in your body that are not functioning properly and causing all sorts of damage. Why aren't they functioning? Because the DNA is wrong. Every time a cell replicates, it has to create another set of it, during which it gathers more and more errors. Copy-of-a-copy problem here. These errors randomly happen, can be caused by exposure to chemicals, radiation, you name it, hell sometimes it just happens for no reason.


Now, imagine how many times your cells have copied themselves. Hundreds. Thousands. Probably more. That adds up to a lot of error. The more error, the higher the likelyhood of cancer, inevitably ending in it, followed by death.


I also recognize that there are a few very small creatures (most single-celled, I believe) that seem to be able to copy their DNA perfectly. I have no degree on the topic but one of my theories is when you look at a hard disk drive, it can do the same write/rewrite functions using the same code over and over again. However after a period of time it will eventually corrupt one tiny little part of a file (check out bit flipping), this is still performing its normal function it just slips once in a while.

The computer may still be issuable at this point but if you continue to run or for long enough eventually there will be too much corruption and operating system will not be able to function as it was programmed to do, thus rending it 'dead'.

The human body is obviously much better than a hard drive at fixing said corruptions but eventually cancer and other nasty cell mutations will prevent the organs from doing their programmed job, thus rendering the body 'dead'.

Again this is just one of my shower thoughts but still thought it worth sharing [deleted] Totally not a scientific answer: 

if you consider that all organisms descend from other organisms, then you could argue that all life is merely a single organism perpetuating itself for, not just thousands, but millions of years. 

Unfortunately, this does not hold true for "individuals," all of whom die in the process of perpetuation excepting the examples given in this thread. I think it could be an evolutionary benefit to have shorter life spans, that way as a species as a whole you are more adaptable. As the generations reproduce and die the more suitable for the environment reproduce more and because of the shorter life spans make up more of that species.  If we broaden the question to look at organisms in general, plant type organisms can outlive animals by thousands of years http://www.iflscience.com/plants-and-animals/oldest-known-living-organisms-world. Without being a biologist or anything similar, obvious trends appear even to laymen. The main factors I see is that when comparing plants to animals, or even short lifetime animals to long lifetime ones, are energy use (movement, temp regulation, etc.) and I'd describe it as rate of succumbing to predators/accidental deaths. The latter is fairly obvious, the former seems to operate under the general principle, at the risk of severely oversimplifying it, the more something gets used, the quicker it wares out.

Now to really dive in out of my depth, take everything with a bag of salt here. The cause of aging, may well be a thing called telomeres. Basically they shorten as cells split and age, and as they shorten cells come closer to dying and start having more "health issues". There seems to be some promising research on the topic of increasing telomeres which essentially "turns back the clock" so to speak, which would potentially have huge impacts of the achievable lifespan of humans. Particularly, this might increase the duration of the "prime time" of human life instead of the current trend of drastically increasing end of life when people have the lowest quality of life.    
http://learn.genetics.utah.edu/content/chromosomes/telomeres/   
https://med.stanford.edu/news/all-news/2015/01/telomere-extension-turns-back-aging-clock-in-cultured-cells.html   
 [deleted] Lobsters are in no way immortal, or anything close to it. While their virility continues to grow with age, so does their size. The larger they are in size, the more metabolic energy they expend to molt their exoskeleton. Eventually, the act of molting is too much and they die from exhaustion. Some of the largest, oldest lobsters we've ever found are estimated to be about 70 years old- fairly young compared to some organisms in this world with even greater longevity.  Oh! I didnt know that! Thank you for correcting me Is there any way humans could help the molting process and end up with a super giant lobster? Would they run into problems with the square-cube law like land insects? Or would living in water allow them to get oxygen even at a massive size? So, if a human were to intervene, and assist with the molting process, could you raise an immortal lobster? As mentioned elsewhere in this thread this is a misconception. Eventually lobsters get too large to maintain them selves and either die of exhaustion while molting or so not molt and die when their carapace deteriorates.  They keep growing? If your cup only had bacteria and no broth, most bacteria would look like slime with a yellowish tinge to it. Some are slightly more granular than others. There's a few types that would be a little red, pink, or a little green, others a stark white. There's a couple of types that would likely look crusty (like those in the Mycobacterium tuberculosis Complex), because of cord factor, they tend to look more chunky and waxy.

No idea what a cup of viruses would look like. That would be SO MANY viruses. I work in biomedical engineering lab where we actually have to purify viruses. [Here is what the viruses looks like after I run them through a centrifuge](http://imgur.com/USoiDcZ).

The brown stuff is the supernatant and the white stuff is the virus. Its not quite pure just yet. I still need a few more rounds of centrifugation and resuspension and then I run them on an ultra centrifuge to get the final pure virus.  So what happens if you just drink all of that? Well, the supernatant (the brown stuff) contains a lot of harmful chemicals. I would imagine you would die if you drank that, or at the very least develop significant damage to your body.  Would the average human body be able to survive drinking just the viruses? Depends on what the virus is, obviously. Not all of them interact with human cells. Stupid question then; even if it's a virus that's not really harmful to humans, could the sheer volume of viruses affect the body just by numbers? Or would it truly just be like "sup" when passing through? And even if it couldn't harm you, would your immune system attack it for good measure? It depends on the viral modus operandi of infection, however most common, and uncommon viral strains which interact with human cells can cause infection through gastric pathways.

Short answer is, yes. The sheer volume of something like ICD-10 J00 in a 300ml flask would eat through your cells killing almost all exposed living tissue as it progressed to your blood stream. Your lungs would be bleeding as you coughed up sloughing tissue within a few hours if the virus did not stop your heart first. J00 being the common cold?  Exactly. You can read more about ICD codes [here.](http://www.icd10data.com/ICD10CM/Codes/J00-J99/J00-J06)  My personal favourite is [W220.02xd](http://www.icd10data.com/ICD10CM/Codes/V00-Y99/W20-W49/W22-/W22.02XD) [deleted] [deleted] The virus with the fastest life cycle that i know of is the T4 Phage (Its actually a bacteriophage) its life cycle from the moment it enters a bacterial cell to the moment the bacterial cell burst open is about 30 minutes so yeah you would have 30 minutes in which to thumbs up at the minimum so a really slow terminator style death. Well that's terrifying, and pretty much what I was hoping was the case. Though wait, are you actually talking about a virus that normally can affect us? If so, what about something that's like exclusive to [insert animal]? If it's exclusive to an animal, then I might worry. However, a virus that only infects certain species of bacteria, for example, might pass through unnoticed. I'd need to think to think about the specific virus to make a proper hypothesis, and, even then, would need to perform an experiment to provide a real answer.

The biggest risk would be a massive immune response. Would the viruses taste like anything? That's assuming all of those virus particles are intact and able to infect your cells at that point.  If they have aggregated they might not actually be infectious anymore. So it would essentially eat through you like acid in cartoons would then. That's pretty creepy.  Not necessarily. Some viruses might, but most viruses do not destroy the cell until it has replicated the virus. This can take a couple of minutes, to a couple of hours.

The soft exposed tissue like your lungs would probably show the first signs. Intense coughing fits and internal bleeding would happen fairly quickly. I am pretty sure that your heart would give out before too much of that happened. [deleted] [deleted] Yup, there's definitely the possibility of your body's immune system going apeshit over the sheer quantity of stimulus it encounters. Also, even though it won't actually infect *you*, the virus could possibly infect the microorganisms in your gut and throw your gut microbiota totally out of whack. This is actually a hypothesis behind an environmental cause to Crohn's disease. Your intestines would just give "the nod" and allow the viruses to pass through. The human digestive track can process some of the amino acids in DNA so, you would digest part of it. The viruses are not guaranteed to be homogeneous so the extent of damage is impossible to know but, you will be worse off. [deleted] Ummm. "Just the viruses" I recalled saying?  I wanna say a strong antigenic response of it isn't already pathogenic if it gets in your blood, but most would denature in your pH 2 stomach and you'll get the gainz Also it would depend upon the conditions the virus can survive. Could it survive the stomach acid? Or would it be neutralized before any meaningful infection occurs?  The effects and survivability would depend heavily on the virus' characteristics. That is, of course, ignoring all of the other  nasty stuff in the growth media.  What happens when you drink kombucha? [deleted] What do you do with so many viruses? We chemically modify the viruses for our research. We need a lot of the virus for the study.  How long do they stay "alive" for in that container?  The funny thing about viruses is that they're not really "alive" in most respects. How long does the viral dna remain intact within the nuclear envelope?  depends on the virus and the conditions. Some viruses can last for weeks or months on a normal surface such as a lab bench. Others cannot last long at all. Yeah! I remember that from way back when :P

Just wondering if they... deteriorate or something. I mean they are organic right? They do deteriorate in ways making them non-viable. It depends a lot on the type of virus, which is why some viruses can survive on inanimate surfaces and still be infectious while others like HIV generally have to be transferred directly from one body (or blood product) to another to remain viable. That's probably what was meant to be conveyed by adding the quotation marks - in your sentence using quotation marks doesn't really make sense. How long before they stop working correctly? My understanding is that a virus is pseuo-alive and can sit inactive for a very very long time. Depends on the viruses.

The ones that I use can be ok from a week to a few months in -80 They're not; all a virus is is some DNA or RNA in a handy package that protects the genetic material, is drawn to living cells, and attaches to living cells so as to inject the DNA wad into the cell. That DNA/RNA program will then get inserted into a ribosome, which is the machine inside a cell that assembles proteins, and it'll tell the cell to build copies of the virus. 

Saying a virus is alive is like saying a computer virus (or any computer program) is a computer.

Some of them can sit out longer than others 'cos the armor around them is stronger or weaker and the stuff inside is more or less fragile. Actually, only(?) retroviruses(?) "inject" the DNA. The vast majority of viruses have a protein hull that matches human cell receptors. They connect, and the cell intentionally pulls them through against the osmotic balance expending energy.

Antibodies connect to the same points the virus needs to, temporarily protecting them.


 Great, great, simple explanation for layman. Thanks. Viruses are the only one of the three pathogens that's not really "alive," not an organism as such. How do you modify them? And also, what parts exactly?

If it is top secret, feel free not to tell me! :D Honestly, the idea that someone might be keeping information on viruses "top secret" is scarier than the virus itself.  Interesting picture, the product looks very similar to a DNA extraction, which makes total sense but never thought about it until now What kind of viruses is that?

Retros and lentis make a contact lens shaped pellet with a golden tinge.

For some reason I am almost sure it is just the serum being precipitated with the some of the proteins. I'm going to bet it is a plant virus like CCMV, CPMV, Potato Virus X... maybe. What's the centrifuge run on, like 25000 g's? If they need to use an ultracentrifuge probably somewhere in the hundreds of thousands. The Sorvall my old lab used went up to a max of 600,000g, and that was considered the standard model AFAIK (I think the faster ones go up to 800,000-1,000,000g). I never went nearly that high for membrane proteins, but that's what the manual said was doable.  Interesting fact regarding the colour of viruses, they are so incredibly small that the wavelength of visible light isn't affected by them. This is why they seem to be absent of colour. They can't reflect light!

Edit: I am not nearly as educated on this as /u/pyrotato below. Please refer to his expansion on my comment! This is more on the physics sides of things, a topic I am less knowledgeable in.
 This is perhaps a stupid question coming from an A Level student, but wouldn't that be said for atoms too? Yet atoms reflect light, and apparently viruses do not. I would venture /u/Murmann meant that they reflect light *neutrally*. This means that when we look at them, we distinguish shapes based on things like density and diffraction, but not color, because they don't reflect selectively (i.e. they don't have a color). This would make them look white.

If they reflected no light at all, they would appear perfect black, and if they didn't *affect* light at all, they would be invisible!

About atoms, it's mostly the structure they're organized into that will affect how you see them. Most atoms aren't observable when "single", but fortunately there are [a few which we can actually identify through their color](http://en.wikipedia.org/wiki/Noble_gas#Discharge_color) under certain circumstances! Don't all elements emit unique spectra when the electrons change energy levels, or am I missing something here? that's emission - not absorption - think of sodium, it's emission band is yellow-orange, but a chunk of sodium, a metal, is silver. emission is a property of the element. absorption is a property of the bulk material Viruses do absorb selectively.  The absorbance is very "boring" from a biochemical perspective (absorb short wavelengths), since viruses don't usually contain a lot of the interesting pigments that are required to get long-wavelength absorbance which ends up producing a visible color.

So viruses are basically clear.

They also lack shape, from a visual perspective.  They are (often) smaller than the wavelength of visible light, so it's not possible to "see" their features.  It would be like trying to read standard sized Braille if your fingers were each the diameter of car tires.

But due to their size, which happens to be close to the wavelength of light, viruses do diffract light, and solutions have very pure viruses will cause refraction.  I can't find a really good picture online, but in liquid a viral band like this one can look "pearly":

http://www.nature.com/mt/journal/v9/n4/fig_tab/mt200481f3.html#figure-title

I think the sum of these effects, combined with the fact that viral capsids (and contents) are usually repeating patterns of biomolecules, combines to produce low-intensity structured coloration, although I'm not 100% on optics topics like this: http://en.wikipedia.org/wiki/Structural_coloration  is the virus suspended in a gas? it has a very odd opaqueness...? I am a virus researcher and we lyophilize viruses down. It's a white powder. Nothing cool. We can cross link them with some short oligomer and make a hydrogel kinda like snot though. That's kinda neat.  [deleted] Does being a virus researcher pay well? I assume that the discipline required in order to be practicing in such a field is in the extremes. I would appreciate it if you would answer at your convenience, here or in my personal message box. Thanks for your interesting answer!  It completely depends on a ton of variables and what their actual position is. A "researcher" can be anything from an unpaid undergraduate to a tenured professor.

 Paid techs at my university rarely made more than $13 per hour. Grad student could make a similar amount in some situations. Post doctoral and research associates I've seen make 50k a year or a bit more. Tenured profs 100-200k with all sorts of other opportunities. Contract and private firms pay better but run the risk of going bust quick since operating costs can be astronomical. For virus research specifically a job with the cdc pays well but is very difficult to obtain without renown or connections. There is a huge range of private and university study in viruses, ranging from simple bactireophages to gene therapy, and finding a position in such places requires a wide array of skill level.

You will always run into the publish or perish dilemma if you get a PhD in any research field, and hard work and brains won't always guarantee success. I would never go into it looking to make money, but the potential is there.  Thanks for your reply, I am still in the 10th grade and Microbiology has always been a passion of mine.  Microbiology has a multitude of career paths according to my friend, and he's having a hard time deciding where he wants to go with it because it all interests him. Research is cool, but you aren't limited to it.  I majored in micro! Very cool stuff. I haven't gone to grad school (yet) but I did get a job right out of college, which is great. The only problem with this degree is that R&amp;D jobs (which is what I wanted) typically require at least a Masters degree, but sometimes they'll substitute experience for the degree. 

Beware student loans! They are the devil. Same here, I managed to get a job in pharma after getting my undergrad, but pretty much everyone has at least a master's. But I still see jobs that are welcoming bachelor's degrees.  Do you think your fellow virus researchers would look down on you if they knew you went by the name ShutMyBallsInTheDoor? Have you ever worked in a lab? They would crack up and suggest much worse names. Unless you're lyophilozing in distilled water, most of that color is solutes from whatever the viruses were grown in. ...do they move ? Viruses are just DNA/RNA in a protein coat and maybe a lipid (fatty acid) coat on top, kinda like a box,  only really really small.  No, they dont move on their own. they are like statues or clock puzzle arent they? simply waiting for something which can interact with them. weird. They might metaphorically also be seen as little encapsulated pieces of programming, that are ready at any opportunity to infiltrate large and complex protein factories (cells). When successful, they insert their own programming into some of the machines, and they make more virus (programming + capsule) as ordered. Heh no. Viruses don't have any means of locomotion. They move outlet by diffusion.  [deleted] Actually, I currently culture environmental soil bacteria.  A significant number are actually deep pink, coral, purple, or yellow, with yellow the most common non-white/clear color, and then pink/red.

As for viruses, they are mostly protein on the outside, although some clades have a lipid membrane.  I'm guessing the protein ones would form sort of a jelly like you say, and the lipid membrane ones would be more like a pile of eukaryotic cells, whatever that would be like- probably a slime. &gt;lipid membrane ones would be more like a pile of eukaryotic cells

Somewhat more clear whitish goo.

... very scientifically speaking of course. Most bacteria have a creamy consistency and an off white color. A few are bright red or green. Google 'colony morphology' to see what bulk bacteria look like. [deleted] Would this be consistent with the fact that when I get a sinus or upper respiratory infection, I cough up a bright green to dark green thick slimy substance?  Or is that entire different? Green snot is a sign that your white blood cells (neutrophils) are working.  The green color is caused by iron in the myeloperoxidase enzyme produced by the neutrophil. What you see there is mostly mucus, which is trying to clear the infection. Last stuff I read also suggested most sinus infections were caused by viruses.  You know what I learned when I first started working with E coli in the lab? If you grow a big flask of E coli over night... they grow in a liquid media called broth... the broth turns milky with cells overnight. Then you spin the broth at a really high speed and all the cells form a pellet at the bottom. If you poke around the pellet, it's all snotty and gooey. It's literally like what comes out of your nose when you have a really bad sinus infection. That's a giant mass of bacteria. I was shocked at how similar they looked. It was like I was digging a giant blob of snot out of my bottle, except I know it was 100% pure E coli that had grown in the past 12 hours. Ewww.

It may be made of white blood cells and mucus in addition when it comes out of your nose, but I can tell you bacteria can look exactly the same depending on the variety/growth conditions. [deleted] [deleted] [deleted] All I know is my E. coli are usually white and my cholerae are pinkish. The E. coli smells like wet dog too.   You know what I learned when I first started working with E coli in the lab? If you grow a big flask of E coli over night... they grow in a liquid media called broth... the broth turns milky with cells overnight. Then you spin the broth at a really high speed and all the cells form a pellet at the bottom. If you poke around the pellet, it's all snotty and gooey. It's literally like what comes out of your nose when you have a really bad sinus infection. That's a giant mass of bacteria. I was shocked at how similar they looked. It was like I was digging a giant blob of snot out of my bottle, except I know it was 100% pure E coli that had grown in the past 12 hours. Ewww. I know this is a question that like an eight year old would ask, but I genuinely wonder what would happen if you consumed it. Like, how much bacteria could your body handle? Would it cause an extremely severe infection right off the bat, or would you get diarrhoea/vomiting immediately because your body would detect it faster? I wonder if there's a point of diminishing returns where your body can't absorb any more bacteria at once no matter how big the lump. The bacteria I grow don't have any pathogenic genes. The e coli that make you sick, like food poisoning sick, have specific genes that do things, and my strain lacks all those. They're stripped down chassis for studying and engineering biomolecules.

I think it would flood your gut flora with lots of extra gene-lacking e coli, but after a few days your gut flora would repopulate with the correct balance of regular e coli. Like only so many e coli can live in your gut microbiome habitat, so the population would just drop back down and there's no toxic genes so it wouldn't matter. 

Even if the e coli were carrying a transgenic gene, unless it gave the bacteria a reproductive advantage in the human gut, the rates that genes are dropped is really high because of the fitness cost of maintaining the gene. And since they don't have the pathogenic gene they can't hurt you. 

I bet if you swallowed a cup of e coli carrying [the gene for GFP](https://www.google.com/search?q=gfp&amp;safe=off&amp;es_sm=91&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ei=Ht5iVZr2KsPooATbuYL4AQ&amp;ved=0CAcQ_AUoAQ&amp;biw=1131&amp;bih=576), your poop would only be fluorescent for like, 2 days tops. Cuz the cells would drop the GFP gene since it carries no fitness advantage, and it carries a fitness cost because it costs resources to main GFP.

I would totally drink it, and then take a probiotic pill the next day and I'd be fine.

Now, this is only for [basic laboratory e coli](http://en.wikipedia.org/wiki/List_of_strains_of_Escherichia_coli). If I was working with mammalian cells, like hamster ovary cells or [white blood cells](http://www.theverge.com/2014/3/5/5472596/engineered-white-blood-cells-future-of-hiv-treatment) or [breast cancer cells](http://en.wikipedia.org/wiki/List_of_breast_cancer_cell_lines), or pathogenic bacteria, hell no I would not drink that. 

Actually I would totally take engineered white blood cells if they targeted a disease I have. That shit is the future, man.

http://www.cancer.gov/about-cancer/treatment/research/car-t-cells
http://www.attack-cancer.org/AboutengineeredTcells/
http://limlab.ucsf.edu/papers/pdfs/maf_2013.pdf The joys of lab work... the strain of E. coli I work with are temperamental little buggers. Any small disturbance and they all die. If you ingest mine they'd probably all die, no doubt. Although I still would be inclined not to drink the cells because imagining that texture in my mouth and going down my throat is just too much. Look up bacteria cell pellets on google to get an idea.  They're typically stored at -80 degrees celsius for protein biochemistry labs and go from solid to pretty gloopy. You can try growing them at home; microbes are ubiquitous! Get a disposable plastic container (it won't be fun cleaning this out, which is why I'd recommend sticking to something you'd throw out). Stick a little bit of cooked food (foods with a little moisture at least - rice), or a piece of fruit in it. Cover with a lid, and leave it out; you'll notice stuff growing on it soon enough... 

The fibrous stuff growing on it is usually fungus... You might be able to see bacterial biofilms (all sorts of off-white slime). You can simply throw out the container once you're satisfied :)  [Here is an example of a pellet of bacteria that has been created by compacting them with a centrifuge.](http://openwetware.org/images/c/c2/Tubes.png)  Different bacteria might have variation in apparent color, but due to the color resolving limits of the human eye, it will look some shade of tan or grey without the help of a microscope or stain.

There are SEM images of compacted bacteria on google image search, but I can't find a nice optical microscope image of a slice of a pellet, though I'm sure there are some examples out there somewhere. Pretty much like thick whipped cream. Not all too exciting really.

I've done some large bacterial culture preps in the lab for protein expression and had packed pellets of a few milliliters in size.  We have cups full of phages in our fridge (PhD student in Microbiology) it's mostly clear/the color of the media the bacteria was in before (yellow)
Phage are so small the media still looks clear, while media full of bacteria is turbid.  What's the ratio of phage mass to substrate/medium mass in those cups? 

Also, is it possible to centrifuge or otherwise separate the viruses from the rest of the material in a typical lab setting?  The ratio of phage mass to media mass would be tiny in most lab situations. I've separated bacteria cells from phage by centrifuging the cells down into a pellet and pulling off the media. If you used a strong enough centrifuge, I think you could also pellet down the phage itself to further purify it. &gt;  If you used a strong enough centrifuge, I think you could also pellet down the phage itself to further purify it.

Definitely can be done. Some very good early biochemistry on phages was done this way in the 60s and 70s. It's, in part, how different components of phages that infect E. coli were identified. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Source? I want to read this interesting article [This xkcd](https://what-if.xkcd.com/80/) calculates it to "about a spoonful" and quotes [this paper](http://www.ncbi.nlm.nih.gov/pubmed/23196933) as a source for viral load in blood which he presumably multiplied about by the number of infected people. 

I'm not OP, was all i could find before my personal curiosity gave out.  [deleted] [deleted] [deleted] Viruses in the sea? I had no idea this was a thing.. there are *lots* of viruses in the sea, something like &gt; 10^11 per ml.  They are the major predator of bacteria, which are like 10^6 or higher per ml seawater.

Edit: Although I've heard workers in the field colloquially describe them as 'predators of bacteria', it's not strictly accurate, and phage are actually parasites, or rather parasitoids, since they kill their hosts.  Better to say they are the major mortality source for bacteria. How does that work?  How can there possibly be 5 orders of magnitude more predators than prey? When a virus infects a host it hijacks its DNA to cause it to produce more viruses instead of useful proteins. If one virus infects a bacterium the result is an huge amount of viruses. Viruses are also much smaller than bacteria, one infected cell can produce hundreds or thousands of viruses.

Also as the comment above points out its inaccurate to say these are predators. They are more like parasites since they don't exactly consume the bacteria. well his numbers are off (as I pointed out already) and in any virology publication viruses will be described as an obligate intracellular parasite, not a predator. Regardless, cells can house thousands or more viruses each in some cases. Cells can also release quite a few infectious viruses, as well. It's nothing like a lion and a gazelle. More like a fatass and doritos.  [deleted] They can't be predators, they can't even multiplicate without bacteria. They are parasites.  

EDIT: *multiplicate* almost isn't a word They kill and feed on bacteria.  The analogy to predator/prey is not far off and is common in the field. I can assure you 10^6 /ml is way off. That's about the concentration of E. coli in standard media at the end of log phase growth. It's a lot of bacteria and a glass of sea water would be completely opaque (turbid) at that concentration.

There's just not enough nutrients in water to support that load.  [deleted] [deleted] There are bacteria and viruses covering everything everywhere. Most of them are benign and won't affect humans in any way. Relatively few of them will affect us in good or bad ways. Our bodies require many kinds of bacteria in order to survive. If we eliminated all bacteria from our bodies, we would die. Science has yet to discover most of our bodies' processes that require bacteria. Some have speculated that even the bacteria on the surface of our skin serves a purpose [deleted] Yes. I'd imagine them looking much like a slime mold... as these are essentially just aggregations of cells.  A cup full of virus... basically protein and nucleic acid so might just be a super fine powder?  protein can have a lot of different consistencies it can be rock hard or soft like butta When we concentrate lentivirus I'm pretty sure they make a small white precipitate that you resuspend in another buffer. So, white solid stuff? Yea viruses are little more than a few genes coded in a handful of lines of DNA code. Their existence was questioned for quite some time because of their size making them so illusive. might not the viruses crystallize?  Has anyone actually tried this?  would it be dangerous to handle directly? I work with phages, and we use a nice method for precipitating them out of centrifuged supernatant with acid.  Here's a [side by side comparison](http://imgur.com/gallery/3e7cwZX/new) of some pellets of viruses and bacteria (*E. coli*) from 10 mL cultures (about 1/25 of a cup).  Each set of two from left to right are phage and bacteria from the same infected culture.  You can see that the viruses are a bit whiter and make up a large fraction of the total biomass. Viruses are sometimes described as quasi-crystalline, as they are essentially identical units, but they are truly enormous units by crystal standards, so fail to stack in properly regular patterns when precipitated from a solution. Internally they are RNA or DNA (which are white and gooey in pure form) there external surface is protein, none of which has any use for pigmentation (the proteins role is purely to contain the DNA, attach to host cells and inject that DNA, or evade detection by immune systems), so it too has no specific colour. So a cup of white goo it is.
 So it would look like a cup full of puss? Yes, in the sense that pus is mostly a mass of dead immune cells. So at least some types of bacteria would resemble pus. &gt;  none of which has any use for pigmentation ... so it too has no specific colour.

I might be misunderstanding, but that sounds like you're saying function is required for colour.

Rocks have colour...

Perhaps you mean they wouldn't have a unique colour, and there are so many of them that the light they reflect would sum to white? Large organic molecules generally yield stark white substances unless they are purpose-encoded pigments. Actually many biologically relevant organic compounds are slightly yellow in colour, because the presence of aromatic functionalities in those molecules that typically absorb in the blue-violet to UV region (pi - pi* transitions). It wouldn't be surprising if the bacteria in bulk were yellow or even orange in colour. E. coli tend to be slightly yellow-brown. Mammalian cells (e.g. HeLa or HEK cells) tend to just be whitish and partially translucent.

Personally though, I've never come across a protein that was noticeably yellowish even though I've purified pellets in the 50 uL range (not that what you're saying about UV absorption is wrong.) Biophysical chemist here: dilute protein solutions are usually colorless. Concentrate them high enough (&gt;1 mM in my experience) and you'll start to see the yellow tinge. My lab purifies protein in very high concentrations (~2-5mg/ml) and the lyophilized samples are usually a white powder) our protein has a number of aromatic residues (tyr and a repeating His region [not a tag]) and is still white, and colorless in water/acetonitrile  Yes essentially, that's what I'm saying. There's something qualitatively different about rocks and organic material, in that organic materials are generated in the "pursuit" of the "goal" of ongoing existence (please excuse the number of inverted commas :). whereas rocks just "are" - Ferrous Oxides are just red for e.g. Proteins are made of amino acids which are not pigmented; proteins can house pigmentation systems (e.g. Haemoglobin with Iron, Chlorophyll with Magnesium) but do so at considerable expense in pursuit of "goals" (there I go again) that are specific to more complex organisms - viruses don't have any "goals" that require pigmentation so have not evolved such structures. I still don't see how it follows that organic molecules like proteins and DNA don't each have a color - meaning a wavelength (or balance of wavelengths) at which they predominantly absorb/reflect light. Surely these molecules don't absorb and reflect *all* wavelengths equally (which would make them neutral black/grey/white, depending on relative illumination levels)? Most proteins and DNA do absorb light. However, these wavelengths are outside the visible range, making them colorless without staining. Spectrophotometry, which measures the absorption of light at certain wavelengths, is a common method in biochemistry used to measure protein or DNA concentration.   They do have faint colours but the mix arising from the components of typical virus will be very weakly coloured and outlying components will in all likelihood neutralize each other. My point was that bright organic colours exist because specific structures have value, but they have costs that virus dont need to spend. Certain amino acids have color. Concentrate most proteins enough and it will be yellow/orange. Trytophan is the main culprit. Your use of the word "pigmentation" is incorrect. Proteins have color, quite simply, and it has nothing to do with the more system-based context of pigment. 

Also the crystalline concept of viruses is limited to those viruses which exhibit regular shape. Not all do. 

Not all viruses "inject" DNA or RNA. That's a phage concept. Human viruses enter the cell and uncoat. There's also more functions than you listed. RNA viruses with negative-sense RNA, for example, usually need to bring a polymerase with them. 

Finally, the external surface of all viruses is not protein. Some are never found without a lipid envelope. So the external surface is either protein or lipid.  Does DNA look like sperm? Bacteria can look like this:

http://i.imgur.com/oDvELfS.jpg

http://i.imgur.com/lbvJe7n.jpg

http://i.imgur.com/ANRMIMF.jpg

Pictures from underground tunnel below Helsinki-Vantaa airport. Glycol used to de-ice ice  aircraft created huge bacteria growth underground.  So bubbles of slime are bacteria?

If you poke it, do they move?

And if it is a bubble, why are they stacked on top of each other like an orgy? Bacteria are specialized and there are tons of different kinds of environments of which they can grow on, depending on the amount of resources in the environment (abundance) they can grow under each other and cause that sort of layering effect.   
  
Probably wont move, generally they really adhere to surfaces they colonize in what is called a biofilm.  
  
 Depends the virus and/or bacteria as some are different colors and textures than others.

But this is a bacterial broth, basically a mix of bacteria in a growth media allowing them to grow to a point.

[Bacterial Broth Culture](http://i.imgur.com/TSLSwJB.jpg)



 Broth... I did think about this before and I wonder, how many nutrients would I get out of this if I drank a cup? If you mean how many bacteria they are usually in the 1.0x10*9 Cells before it gets too crowded.

If you mean what nutrients are in them.

Nutrient agar contains 0.5 percent peptone, which is an enzymatic digest of animal protein. Peptone is the principal source of organic nitrogen for the growing bacteria. Nutrient agar also contains 0.3 percent beef extract, which contains water-soluble substances which aid in bacterial growth, such as vitamins, carbohydrates, organic nitrogen compounds and salts. The last component of nutrient agar is 1.5 percent agar, which is the solidifying agent. Is the standard composition.

There are then other things added to make the agar's selective for growing a certain type of bacteria, such as Human blood agar, Skim milk agar etc.

 Do the bacteria change the nutrient composition in a significant way?
My question was a bit unclear, this was actually planned to be about a cup filled to the brim with bacteria and the broth.

I imagine it strongly depends on what kind of bacteria, as some do produce quiet harmful, and in general very different, substances during their metabolic process. Depends the bacteria, Some will produce antibiotics, some will break down releasing toxins etc. some will just grow. 

Also you can grow stuff such as HIV and other nasty things using cell cultures (in specially controlled environments with special suits and rooms) so you certainly wouldn't want to be eating one.


Also drinking a big cup of bacterial growth enhancers i would say would really screw up your stomach even if they were sterile, so i wouldn't recommend it. Actually the broth itself is quite nutritious usually, made of a gel that is rich in protein/amino acids and other important nutrients. You an often eat it, but I wouldn't unless it's classified as food grade and prepared with clean lab equipment.

Now, the bacteria... well some types of bacteria can make you sick, but others are fine (probiotic yogurt is full of bacteria).

If you grow some edible bacteria on food grade agarose gel... it might make a surprisingly healthy breakfast. May not taste so good, though. What if you drank it? It was mentioned as a reply to another thread, but there are things in the broth that would make you very ill/kill you in those quantities. As for the virus/bacteria itself, it is very dependent on what it is. It could range from slow painful death to mild discomfort (ignoring the broth problem for now). I used to work in a biochem lab in college where I would grow up huge amounts of E-coli (which is a bacteria) that I had genetically engineered to produce a certain protein I was studying. This sounds pretty cool but really all I did was insert a plasmid into them, it was pretty simple.

I grew the bacteria in a growth medium called luria broth which had a yellowish tinge but it would become thick, dark and cloudy when the bacteria had used up all of the nutrients and multiplied sufficiently. I actually added an antibiotic into the broth that the bacteria had resistance to due to the plasmid so it was pretty much all my specific variant of E-coli. 

The next step was to take this cloudy broth and spin it down into a "pellet". Basically a clump of bacteria. I would pour the water off and save these concentrated clumps of bacteria for later. It looked like a greyish slime. It was very slippery and slimy and it had a slightly unpleasant odor to it. 

I probably did this would process dozens of times. Anyway I hope that answers your question. I'm not sure that it is even possible to do something like this with viruses because that can't replicate without a host cell. 

*edit: typo &gt; it had a slightly unpleasant odor to it

Ugh. Eww... I would be scared to even be able to smell it and get sick. I am a medical laboratory scientist and its still a regular practise to smell clinical isolates. Some bacteria like Alcaligenes, Pseudomonas, and Eikenella have very distinct smells, (Apple, tortillas, and bleach for these examples.) but after a while you can distinguish a lot of other bacteria by smell alone.

That said, obviously sight and most especially biochemical tests are more important and reliable in diagnosis. When smelling your samples, don't you risk inhaling airborne bacteria? Technically yes, but in general bacteria tend to stick to the agar pretty well. Of course you don't really stick your nose deeply in anything, and there are certain cultures you should avoid smelling, such as anaerobic, fungal, and acid-fast (mycobacteria) cultures. Also if you are using a hot loop to manipulate the plate (a metal wire sterilized in a burner) you have to touch a sterile area of the plate before touching a colony to ensure the wire isn't hot enough to make aerosols and you shouldn't smell a plate after you have been messing with it. 

In general clinical microbiology labs are more lax than one might think, I know as a student I was certainly shocked at first. It's very different than it was in college that's for sure. In other sections of the lab, such as clinical chemistry, you have to wear gloves at all times, but in microbiology most lab techs don't wear gloves. The logic being that that way you will be able to feel if you accidentally touch a sample and wash your hands immediately, but if you are wearing gloves you might not notice a light touch and then spread a sample.  What you can smell are the by-products of the bacteria, since they won't get airborne by themselves.

It also won't harm you to inhale a few bacteria if you can easily fend against them; we are full of bacteria, getting in touch with lots more on a daily basis, and nothing bad happens. Im interested in the smell. Can you describe the odor? It's been some time since I worked with E. Coli in large quantities, but I remember the smell distinctly. It was repugnant... sour and a little fermented.  The kind I worked with came out like a really smelly peanut butter.  Mmm right before lunch... [deleted] I worked teaching a microbiology lab for three years so we grew a lot of bacteria on agar.

Best way to describe what it would look like might be to imagine popping a pimple on your face. You know that white/yellowish puss that comes out, that is pretty similar to the gooey consistency and color of bacteria.

Now imagine a cup full of that and you have your answer. Gross.

But what you should really be thinking about is how badly a cup of bacteria would smell!

Bacteria stink! Like sweaty gym clothes left in sealed car for a week during the hottest days of summer. It may look gross but the smell would probably be obscene.... XKCD did a great "What If" question on this topic a while ago!

[Here is the link.](https://what-if.xkcd.com/80/)

He talks about what would happen if all the viruses in the world appear at one spot and what it would look like/what it would do.

Good read!(dont read it while you're eating though) Dude... excellent link! Just a spoon full of HIV helps the medicine go down!  I've pelleted retroviruses and lentiviruses before. What you get is virus, some water, a little bit of salts and whatnot from the media, and maybe a small amount of cell debris, but I would guess at least 90% of it is pure virus and most of the rest is water. These viruses have envelopes, so in addition to DNA and protein, you have some lipids (fats).
The pellet is light brown, solid, and not reflective or see through. It kind of looks like a piece of chalk. For obvious reasons, I haven't poked it with my finger, but with a pipet, it has a little give, but is more solid than an E coli pellet. I would put the consistency at "slightly undercooked potato." It dissolves in saline fairly easily.
That being said, the largest pellet I've dealt with was smaller than 50uL, so scaling up to a cup (~5000x more) might change things.

I think other people have covered bacteria pretty well, but they are goopier and commonly white or yellow. My first science job out of college involved large (60L) fermentations of E. coli. While the media probably contributes some to the overall color, when you have spun down the bacteria to kg quantities of paste the same consistency as peanut butter, I imagine the bacteria contribute the most to the color.  And that color is...light brown, looked just like peanut butter.  Smelled like shit, looked like peanut butter.   Unless you've brushed your teeth recently, you have a source of pure bacteria very close at hand - dental plaque. As others have mentioned, there are many different kinds of bacteria, and the amount you have in your mouth is nowhere near close to a cup, but that can give you a good idea of what a macroscopic amount of bacteria looks like. I have an aquarium without much of a current flowing through it (betta doesn't like it). Over time, a biofilm consisting of waste products builds up. It's mostly macromolecules - sugar is a big component - and bacteria. It's a milky white film that acts like a prism and creates some rainbows. [Video on the subject.](http://youtu.be/3EsvBsR6ycE)

I have to assume that most bacteria species would look like this as well. There might be some with pigment that color the solution (or is a colloid?) however, perhaps some photosynthetic bacteria? ...It would look disgusting. Phones aren't allowed in my lab classes, or I'd post a picture, but it literally looks like slime. Disgusting slime. I'm cringing. I personally think it's gross, but I'm sure other people would be fascinated. For the fascinated, you can actually grow yourself bacteria in a dish. Make sure it has some moist food and wait, eventually your food particles will dissolve into a wonderfully disgusting mess of bacteria and fungus. This really depends on what type of bacterium. For instance, a mushroom mycelia is almost always pure white and shard-like in appearance from it's lateral hyphae movement. so a cup of that would look kinda like baking soda but more formed together into shards Could there be a point where bacteria could be made into an efficient source of protein for human consumption (from other organic material) ?
I know that Spirulina is sold as a supplement (a green powder) but I don't think it's very efficient (yet ?). Oh, it's super charged in nutrients (something like 20% fats, 30% carbs, and 50% protein). The problem is being able to consume enough without seriously assaulting your taste buds. [deleted] If no one has gone in depth, I will later (on a phone), but its a highly variable process depending on the organic material being deposited, the nature of the deposits, the "oil generation kitchen" available with respect to the processes of diagenesis, catagenesis and metagenesis and the rates at which those processes are occurring.

The mesozoic (age of reptiles/dinos) was fairly prolific for deposition due to climactic reasons (largely algae) and why people often think that oil is Dino bones or Dino blood, but the Dino's are coincidental to the oil production.

Today's climate isn't great for deposition, so it certainly wouldn't be looked upon as prolific no matter what the geology does going forward.

[Here's a primer on the Dia/Meta/Catagenetic process if you're curious.] (http://booksite.elsevier.com/9780120885305/casestudies/01-Ch26-P088530web.pdf&amp;ved=0CDUQFjAH&amp;usg=AFQjCNHKzYTvt-lh3UK7oaq9e_u7B1_BmA)

**EDIT:**  I should be clear -- when we talk about prolific periods of oil generation in petroleum geology we're referring to that source rock / the period in which the organic matter that will eventually become oil was deposited (and sometimes the overlying reservoirs).  Things get a while lot murkier when we start asking about the time periods in which that source got cooked in the oil generation kitchen.  Its certainly happening as we speak in a variety of source rocks around the world but it would be incredibly hard to quantify.

One noteworthy one in north america is the Bakken -- it's actually (generally speaking) an undercooked fairly prolific source upper and lower black shale with a silt or sand between that some of our oil has migrated into.  If we left it alone it would likely continue to generate.  It's Devonian, so older than most reservoirs but also a less thermally mature source rock than most, which speaks to the difficulty of figuring out when oil will be generated from a particular source. 

**EDIT2:**  To flesh this out a little further now that I'm in front of a keyboard:

The first thing you need to produce oil is organic matter.  When it's part of a sedimentary rock, we refer to this organic matter as Kerogen.

There are [four types of Kerogen](https://spec2000.net/text106fp/toc11.jpg), in descending order for potential oil productivity. 

* Type I / Sapropelic / Alginite.  Marine &amp; Most productive

* Type II / Exinite / Amorphous Kerogen. Mostly Marine &amp; second most productive 

* Type III / Vitrinic / Humic.  Tough sledding for oil production, only under extreme circumstances.  Great for coal and methane production

* Type IV / Inertinite.  As the name might suggest, useless decomposed organic matter.

So the first step to producing a quality source rock is to get Type I and Type II kerogens buried in the sea floor in an anoxic environment (if there's oxygen available, you'll end up with decomposed Type IV kerogen, which isn't going to help even if we have algae dying and raining down in quantity).

Next step, once we have our buried kerogen, is to cook it.  [This occurs in three phases (two of which we're looking for](http://1.bp.blogspot.com/-SppkVCspMu8/UnzxgoX-SrI/AAAAAAAAAsk/y9DHj9-DqTo/s1600/tn30_f01.jpg):

* Diagenesis:  Microbes are going to have at our kerogens below about 60 degrees C, and will largely produce some get some biogenic gas from our kerogens.

* Catagenesis: From about 60 degrees to 150C, increasing temperature will result in thermal cracking, transforming our kerogens into the oil we're looking for, in addition to some gas... increasing wet gas fractions as we get to the upper end of that range.

* Metagensis: If we turn the temperature up too hot (&gt; ~ 150C), we're going to keep cracking our kerogen and coal into dry gas / methane and carbon residue.

That's the ELI5 on the process, if you're interested in the chemistry, the link in my original post above goes through it in greater detail.

So to accurately know the rate at which the earth is producing petroleum, you would need to know what the volume and type of kerogen rich source rocks worldwide that are currently going through these various phases as well as the volume of kerogen rich source rocks currently being deposited and take a stab at their geologic future.
, as well the volume of kerogen rich source rocks that will one day end up in catagenesis.

In terms of *actually producing* that oil, we would need to add on a lengthy discussion reservoirs, porosity and permeability.

tl;dr I wouldn't be comfortable even taking a stab at your question OP, but I hope that the above helps to explain why it would be so difficult to make that calculation... &gt;due to climactic reasons (largely algae) 

If it got warmer, then more algae would grow, generating more fossil fuels then? We need them deposited in an anoxic marine environment, preferably with a decent reservoir deposited overtop, and then we need them buried in the kitchen for the just right amount of time.  So, maybe but not necessarily.  Really can't hurt though! Why does everyone keep saying "kitchen?"  Is this a scientific term?  What does it mean?   That's the term used for the geologic situation where we have the right things happening for hydrocarbon generation... a kerogen rich source rock buried at sufficient depth to generate the temperatures required for catagenesis.

The kerogen is getting 'cooked' in a geologic 'kitchen'.

And yes it is [used in scientific literature](http://archives.datapages.com/data/bulletns/2011/05may/BLTN10079/BLTN10079.htm?doi=10.1306%2F09271010079)

I'm not trying to be funny :) "The kitchen" refers to a set of conditions that must be present to transform dead life into oil to be used by living life.  All of this is very important, so I can drive my hummer to the mcdonalds 2 blocks from my house. It's also important to the history of the industrialized world and worldwide economic stability Should we be burying human bodies in a different way to enable more future oil production from them?  I mean, to help out future generations?  It'd be more helpful if we made future generations less reliant on fossil fuels, and enabled them to produce energy more easily than having to dig up a bunch of their ancestors. To be completely realistic for a moment,

Humanity is almost certainly still going to be hugely reliant on fossil fuels a thousand, even ten thousand years from now. But not for energy production. Using perfectly good hydrocarbons as *combustion* fuel will likely be looked upon by future generations as a tragic waste. Hydrocarbons are going to be essential for any kind of synthesis of organic products and compounds, industries that will continue massively growing in the future - especially as food synthesis gets off the ground as an industry. I doubt that humanity is ever, barring hyper-future scenarios, going to outgrow the need for fertilizers and plastics.

EDIT: I doubt that extraterrestial hydrocarbons count as fossil fuel reservoirs lol. But I'm sure our descendants are going to eventually put Titan's (and many other) immense methane reservoirs to some very interesting uses. Honestly, the price point for plant based liquid fuels to become feasible isn't THAT high. The fossil free future will have some vast differences, but I imagine it will look a lot like the present for the end user. Let's not get carried away. At this point, technology is advancing so fast that there is really no way to say what things will look like even a hundred years from now,  much less a thousand or ten thousand. No one in 1915 would have had any hope of making similar predictions about 2015, and technology is growing exponentially faster now than it was then.  There isn't enough organic matter in animals to contribute significantly, and the whole process takes millions of years anyway. I don't think we'll ever have the same amount of underground hydrocarbons, because IIRC most of the material that became our current beds mostly came from the carboniferous era where trees had just developed into what we know them as today, and decomposers had not yet evolved to break them down, leading to great beds of fallen trees which over time cooked into our fossil fuels.

If any actual geologists have any corrections, I'd love to hear them. I'm mostly pulling from 2 basic college courses from a couple years ago. I'm a geologist and have never heard it called the kitchen. I've only ever heard it called the "oil window"

Maybe we could just call it the oil kitchen window. It's a bay window that looks out on the beach and has a few potted plants on sill. I'd like to think they're cacti, but who knows, really. An oil window is merely the depths at which a source rock is subjected to the temperatures requisite to cook oil *in* the source kitchen. There is also a gas and sometimes a wet gas/dry gas window. Really windows are just like temperature ranges in the kitchen.

Edit to better clarify that the point was that a window is a subset of a kitchen. How well does the Dead Sea fit those requirements? The dead sea is not a great example. The waters there are very saline, and may have brine near the bottom. Because of these saline waters and its climate, there's not much organic material deposited within it. 

In fact, if you swim in the water for more than a few minutes, your skin will burn because of the salinity!

This area would be a great place for evaporites and dolomite to deposit. This would provide a pretty great seal for a petroleum system, but would be a poor source and reservoir due to the factors I've explained above. What about the Black Sea? I heard it is anoxic at depth. Is there potential for oil production there?

Also, there have been some articles in the past few years about scientists growing algae that can readily produce petroleum-like substance now, not in thousands of years. Why is there no push to grow more of it? Because the economics still favor extraction of petroleum.  As /u/straighttalkexpress mentioned above, there was a period of geologic time where the planet had a huge biomass that is now fossils.  That period, the Mesozoic, was about 190 million years.  We've also got coal from the Carboniferous, which was about 140 million.  It's hard to produce enough with algae in vats to keep up with demand, especially compared against availability of supply that's still left. Right, I get that, but if we have a renewable petroleum source, isn't it a little hypocritical to dismiss it with the push we have today for renewable energy sources to at least supplant *some* of our oil production? Its not if the net energy balance is negative, i.e. if you end up buring 10 barrels of oil to make one.  You have to realize: we get the best production and preservation of organic material for the last half billion years or so, cooked and refined in natural conditions and then concentrated into traps where we only have to pump it out.  It's an oversimplification, but it's hard to compete with a natural process that has already done most of the work for free and the product is just laying around in the ground.  Doing algal production at an industrial scale that would truly make a difference will be expensive in both a financial and energy return sense.

It's like the difference between finding an abandoned wine cellar full of wine versus having to grow the grapes and make the wine yourself from scratch.  Even knowing the party will have to end eventually, it's hard to accept the implications until the cellar is getting pretty empty. Yes, there are [research projects to turn algae into biodiesel](http://www.smithsonianmag.com/innovation/scientists-turn-algae-into-crude-oil-in-less-than-an-hour-180948282/?no-ist). Quite a bit of DOE funding is being funneled to university teams studying the issue. There are also projects to generate products and [syngas from dairy waste](http://www.makingenergy.com/Dairy%20Waste%20Handbook.pdf), forest waste, and farm waste. All of these technologies are interesting, but not really in the break-even stage economically. There are also similar projects for [producing plastics from plant materials](http://www.smithsonianmag.com/science-nature/corn-plastic-to-the-rescue-126404720/) rather than petrochemicals.

While biodiesel will continue to be produced and researched, other technologies seem more likely to provide energy for both the grid and transportation. Battery innovation will likely make solar the most viable large-scale source of energy in the not too distant future. After all, the energy from oil, gas, and coal are also from the sun, just processed and stored by millions of years of deposition and decomposition. I fit most requirements quite nicely, thank you. Those conditions sound incredibly specific and somewhat rare. 

But I assume that they were more common during the time periods in which most of the oil we know about was made? I would agree on both fronts... a lot has to go right, but they went right in the age of the dinos.

A greenhouse with associated transgressive/rising sea levels and oceanic anoxic events will go a long way to getting us there.  There's an interplay with the geology, as that same transgressive/rising sea level will also tend to result in a deposition of the clay rich sediment that will eventually give us our shale source rock.

It all kind of ties together, but isn't a particularly common occurrence.  [There's a theory that ties volcanism into the mix](http://www.geoexpro.com/articles/2009/05/mid-cretaceous-source-rock-enigma) for our cretaceous/mesozoic source rocks. &gt; Those conditions sound incredibly specific and somewhat rare.

There are zones within oceans and lakes which could be potentially anoxic. Anoxia serves as a means of preservation of organic material. These conditions are not necessarily specific nor are they rare. 

&gt;But I assume that they were more common during the time periods in which most of the oil we know about was made?

In a sense, yes. There are several factors contributing to hydrocarbon production, maturation and preservation. Right now in history, we are amidst another mass extinction. We are in icehouse conditions, which means we have polar ice caps. At times in the past when the Earth didn't have polar ice caps, oceanic currents were sluggish (or even stagnant), and anoxic conditions (for preservation) and rapid burial (on land and also on carbonate platforms in the sea) of sediments is generally higher. Both of these combined means you could reach Strangelove Ocean conditions (where layers of the ocean amalgamate (at least in terms of organic content) into one. This can provide anoxia on a wide scale, and allow for large amounts of organic material to be buried and preserved.
 That said, the slowing down of ocean cycling due to global warming will help with that. That's a good point, and thinking it through, a runaway greenhouse and associated rising sea levels would tick off a lot of the required boxes from a geologic depositional standpoint...   [deleted] [deleted] Higher temperature != more algae. 

There's a lot of conflicting evidence on how marine primary productivity will be affected, but the general thought is that with current climate change projections moving forward, there will be no net change or slight net loss of algae at lower latitudes (i.e., tropics/lower sub-tropics) and no net change or slight net gain of algae at higher latitudes. Bear in mind that most of these forecasts are strictly based on temperature and  atmospheric CO2 projections. It's difficult to accurately project changes in biological communities (e.g., trophic interactions and grazing pressure), hydrography (e.g., currents, mixing), acidification, and physiological responses. It's difficult to gather enough spatial data that nicely shows latitudinal gene expression and proteomics since most, if not all, microbial and phytoplankton communities are quite diverse. Another aspect is actual nutrient concentrations which are fundamental to primary productivity, such as the concentrations of bioavailable iron in the ocean, which is a critical micronutrient for many phytoplankton communities (e.g., high-nutrient-low-chlorophyll regions). 

Source: 
Behrenfeld M. (2014). Climate-mediated dance of the plankton. Natural Climate Change, 4, 880-887. 
http://www.nature.com/nclimate/journal/v4/n10/full/nclimate2349.html

Behrenfeld M. and Boss E. (2014). Resurrecting the ecological underpinnings of ocean plankton blooms. Annual Review of Marine Science, 6, 167-194. 
http://www.annualreviews.org/doi/abs/10.1146/annurev-marine-052913-021325

George J., Lonsdale D., Merlo L., and Gobler C. (2015). The interactive roles of temperature, nutrients, and zooplankton grazing in controlling the winter-spring phytoplankton bloom in a temperate, coastal ecosystem, Long Island Sound. Limnology and Oceanography, 60, 110-126. 

Huertas E., Rouco M., Lopez-Rodas V., and Costas E. (2011). Warming will affect phytoplankton differently: evidence through a mechanistic approach. Proceedings of the Royal Society B, 278, 3534-3543.

Nixon CS., Fulweiler R., Buckley B., Granger S., Nowicki B., and Henry K. (2009). The impact of changing climate on phenology, productivity, and benthicpelagic coupling in Narragansett Bay. Estuarine, Coastal and Shelf Science, 82, 1-18. 

Robinson C., Steinberg D., Anderson T., Aristegui J., Carlson C., Frost J., Ghiglione J., Hernandez-Leon S., Jackson G., Koppelmann R., Queguiner B., Ragueneau O., Rassoulzadegan F., Robison B., Tamburini C., Tanaka T., Wishner K., and Zhang J. (2010). Mesopelagic zone ecology and biogeochemistry - a synthesis. Deep-Sea Research II, 57, 1504-1518.


 &gt; Source: suffered through semesters of graduate biogeochemistry and physical oceanography.

Hi, we don't allow people to cite courses they've taken as a source on /r/AskScience. Thank you!

**Edit: Rock on! Thank you!!** If you don't mind me asking, why are college courses not allowed as a source?  It's unverifiable and leaves no way to find further information on the topic. From our [policy on sources](http://www.reddit.com/r/askscience/wiki/sources):

&gt;Listing yourself leaves people no way to confirm anything that was mentioned in the comment. A source allows people refer to find more information or to verify what is being said. From a philosophical standpoint, stating that you are a source is counter to everything that science is about. It's telling people to take your word for it, and it reinforces the idea that people can claim to have expertise without backing up their assertions.

This applies to listing yourself personally as a source, but also to things like an educational degree or course. Yes, but it would have to be deposited in the kind of anoxic environment, and covered up, etc. scale that occurs on the timescale of many millions of years.

Assuming we don't get into a runaway greenhouse effect and the tectonic plates shift further to bring up new lands and mountain ranges, allowing for new reveals of ore deposits, life forms a hundred million years after us will have a chance again at escaping the gravity well - better than we have squandered ours. Also didn't the microbes that now break down the material not exist hack then so it simply piled up? This is especially true for the Carboniferous period, during which many coal-rich layers were deposited. It was during this time that trees evolved tough, lignin rich bark. However, the bacteria that now exist to break down the lignin did not exist yet, so when the trees died they did not fully decompose, eventually fossilising and creating coal. It was more importantly the higher basidiomycete fungi which had not yet evolved. These organisms are highly efficient decomposers of dead wood in bulk. I thought a big part had to do with trees and no organism able to digest them. 

So they got buried and turned into oil.  No, trees don't make good oil kerogen.  You may be thinking of coal...

[Trees would be a type III and IV](https://spec2000.net/text106fp/toc11.jpg) and they would be pretty low on a hydrocarbon [Van Krevelan diagram](http://wiki.aapg.org/images/thumb/f/ff/VanKrevelanDiagram.png/300px-VanKrevelanDiagram.png).

[Type III works for coal though.](http://aapgbull.geoscienceworld.org/content/95/8/1321/F3.large.jpg) that results in peatlands/the formation of coal, unless you're referring to the [oil that can be extracted from bituminous shales/coals.] (http://en.wikipedia.org/wiki/Coal_oil) But generally speaking, the continuous deposition of organic materials into an anoxic/acidified environment results in a buildup of organics (anoxia prevents decomposers from breaking down organic material, and acidification immobilizes dissolved organic carbon in a wetland), which contributes to the formation of peatlands.

http://en.wikipedia.org/wiki/Anthracite

http://en.wikipedia.org/wiki/Peat

Source - Marine Biology/Ecology major What about the rise of fungi which now decompose organic matter at a rate similar to it being deposited? So since this process is known, is it just super expensive to synthesize fossil fuels or is there some physical limitation stopping us from mass producing it? Yes we can do it: https://en.wikipedia.org/wiki/Synthetic_fuel

TL;DR It is super expensive so we don't do it. As we eventually deplete our fossil fuels, we will eventually have to do this for certain things that are impossible to do any other way than through petrochemicals. (Like rockets for example.) Are rockets 'impossible' without petroleum? I thought it was possible to use hydrogen  There have been some experimental synthesis of crude type oil, but I can't offhand remember any of them being viable. A more viable option I'm a bit more familiar with is thermal depolymerization, which uses pressure and heat to generate clean energy from waste, and leaves behind raw metals and such for reuse. Obviously you'd want to gain energy, and/or to be cheaper then current oil sources.

There's several known methods of producing oil, or at least wanted oil products, and some are in use right now. For example, in the EU some percent of gasoline is made from plant matter, using subsidies and enforced minimum mixtures. During World War II, Germany was crude oil starved and had several factories producing oil products from lignite (which they still have in abundance), by using the [Bergius](http://en.wikipedia.org/wiki/Bergius_process) and the [Fischer-Tropsch](http://en.wikipedia.org/wiki/FischerTropsch_process) process.
 I'm not sure if you are an ecologist, but I have a simpler tag question:  how much biomass leaves the earth's ecosystems per year? Do you mean through deforestation, gases released from decomposition, soil erosion, crop production, deposition as sediment, any specific process? A lot of biomass "leaves" ecosystems through various processes, seems like it'd be difficult to quantify, especially since we don't really have an accurate way of measuring it In general I would mean how much material ceases to be part of any organism per some time period.  If that's still too vague, then perhaps just how much carbon exits the carbon cycle. The vast majority of the biomass is stored in plants, bacterias, and fungi. All of these grow and die all the time (especially bacteria and fungi), so a very large part of the biomass is renewed every year, but very little of it leaves the carbon cycle.

[This graph on wikipedia](http://en.wikipedia.org/wiki/File:Carbon_cycle.jpg) has the relevant figures, I'm not sure how accurate it is but the source is solid. According to it, 3 GtC/y (gigaton carbon per year) gets stored in the soil and 2 GtC/y in the oceans.

Meanwhile humans emit about 9 GtC/y from fossil fuels, deforestation, cement production, thus the net +4 GtC/y increase in the atmosphere.

However, afaik not all of the carbon in oceans actually leaves the cycle. Some of it is deposited in sediments, but a lot of it is simply dissolved and may be released at a later date if the conditions change. The warmer the oceans are the less carbon can be dissolved, and the more carbon there is in the atmosphere the more the oceans will take, there is a (delayed) equilibrium between the two. So the graph doesn't tell the whole story, but I don't know of more accurate figures. Geology/Earth Science was the only natural science class I didn't take in high school, so this is all novel to me. I've got to say, it's incredible how much information is out there about literally everything. Thanks for taking the time to go so in depth. I learned more than I even thought was known about the creation of fossil fuels. I love how Science is such a broad, deep ocean of knowledge. I've spent my whole life studying and learning and researching, and yet I've only been exposed to a tiny, microscopic fraction of the knowledge that we, as a people, possess. Another huge factor is that white-rot fungi had not yet evolved in the Carboniferous period. This meant the accumulation of dead wood and other lignin-rich tissues was much higher than today, as now if left a log will quickly be fed on by fungi.

Here's a source: http://www.scientificamerican.com/article/mushroom-evolution-breaks-down-lignin-slows-coal-formation/

And another: http://pubs.acs.org/doi/abs/10.1021/bk-2014-1158.ch005 What kind of 5 year old were you? ;) Do you think it might be feasible to select an area with the right geologic future and seed it with algae lagoons and bacterial cultures? If you could game the process into going as fast as possible, could you produce usable crude in less than, eh, fifty years? Shell tried a form of this in the Colorado oil shales (which is not at all the same thing as shale oil reservoirs such as the Bakken!!!!). Oil shales are uncooked kerogen. Cooking is the critical issue usually, not organic carbon. Commercial hydrocarbons are cooked into highly reduced forms that provide massive amounts of energy. That's why a fossil fuel economy beats burning potatoes, say.

Now, if you have lots of undermature kerogen, all you have to do is cook it. Shell figured you could install electric heaters underground. Sounds simple, but there's a lot of water down there, too, and you have to prevent water from entering the kerogen stack that you're trying to cook (or it will quench the reaction). So part of the strategy was to build an ice dam around the electrode array. And keep circulating refrigerant to keep it cold.

Shell called the Mahogany project a technical success before shutting it down due to horrific economics, plus in full production you'd need lots of nuclear power plants to generate the electricity to create the heat and cold that you'd need, which simply begs the question of why not build nuclear power plants in the first place and skip the kerogen-cooking intermediate?

So it's not about seeding with carbon. There's plenty of carbon down there. It's about getting the right thermal maturity. And then waiting for a few million years. You would be much better off doing this is laboratory.  Since the pressures and temperatures needed to form hydrocarbons will not be possible in a short amount of time.

Just letting a large algal bloom deposit in a lake would not really change the timing, it would most likely just increase the yield of hydrocarbons.  There is some evidence of increased speed due to volcanic heat.  But still in the multiple thousands of years range. There seems to be very specific conditions in which oil is actually produced. How is there so much oil if it any point in the process it can fail, or not be produced at all? Does it seem like there's a lot?

The Earth is a big place, and we're talking about many millions of years for the processes to have taken place. When you put it that way, it makes sense. But out of context it's a lot of oil There are many periods in which commercial amounts of hydrocarbon have been produced, in many regions around the world. The Utica shale, a modern natural gas resource recently discovered in Ohio, is of Ordovician age, about 450 million years ago. The Devonian-aged Marcellus is younger, at about 400 mya. The Cretaceous-aged Eagle Ford is even younger, 70 mya I think. So over half a billion years, there's a few (less than a dozen, maybe?) of world-class source rock systems deposited in the Lower 48. That doesn't seem like a lot to me. What are the conditions that lead to hydrogen sulfide production? Why are some reservoirs sweet (absent of H2S) and others sour? Great response. That actually looks like a more succinct version of the source/geochemistry unit of the petroleum geology course I took junior year. :D

Just a remark/question on the impact of kerogen (and maceral, I suppose) content here:

I thought there was some ongoing inquiry as to whether type III kerogen and inertinite -- traditionally interpreted as indicators of dry gas and low hydrocarbon generation potential, respectively -- may actually have been undervalued as source material. Specifically, I recall [Smyth (1983)](http://archives.datapages.com/data/bulletns/1982-83/data/pg/0067/0009/1400/1422.htm) arguing that type-III kerogen and high-inertinite maceral distributions were the source material for wet hydrocarbons in the Permian-aged reservoirs in Australia's Cooper Basin.

I think the argument was that high levels of inertinite and vitrinic/humic kerogen were common in the near-shore and lacustrine facies that are associated with hydrocarbon generation both there and elsewhere -- and that the oil and wet gas in the Roseneath/Epsilon/Murteree sequence and the lower parts of the Toolachee Formation were unlikely to have shared a pre-Carboniferous source with the wet hydrocarbons in the Merrimelia and Tirrawarra reservoirs. I've seen it noted as well, though I sadly can't recall the reference, that the H/C ratios in the Permian source material were more consistent with dry gas than with anything wet, but that the prospect of migration from  Warburton Basin source rock into the Cooper Basin's Giddealpa Group was unlikely.

To your knowledge, is the Cooper Basin just an anomalous case study in that regard? Have organic geochemists essentially moved past the hypothesis that type-III kerogen is undervalued for wet hydrocarbons, or is it still an active topic? Thanks!

That's interesting, I was unfamiliar with the source mystery in the Cooper Basin.  From a few minutes of research, it doesn't seem that  the geochemists who have examined those Permian coals post-Smyth are arguing for Inertinite as a major player, but that the Type II and III kerogen sourced coal is actually acting as a source for the Permian oil reserves in the Cooper basin, which is also somewhat odd.

Here's a source on that if you're interested:

http://www.researchgate.net/profile/David_McKirdy/publication/260964455_Petroleum_expulsion_from_Permian_coal_seams_in_the_Patchawarra_Formation_Cooper_Basin_South_Australia/links/0a85e532c2b86695e1000000.pdf

tl;dr I haven't the foggiest idea, but thanks for the question. Any thoughts as to the validity of theories concerning abiogenic oil? Question: Does the relative newness of the Bakken deposits account for its relative higher fraction of volatiles compared to other crude sources? If we were to allow it to sit for another few million years (or some other timeframe) or so, would those volatiles theoretically be converted to more stable compounds? Potentially, although I suspect that it's a more a matter of the kerogen types in the Bakken source.  The Bakken source (which is the bakken) contains Type II-S (for sulphide ) kerogens, which are pretty volatile.

That said, some of the other wet gas compounds are also volatile, and would eventually turn into methane with enough cooking. Okay, this is very interesting.

So, why can't we just artificially create the oil molecules since we know the process that creates it? If we were to use a lab to control the variables, wouldn't we be able to produce a better product?  Good thinking, we can!

http://en.wikipedia.org/wiki/Fischer%E2%80%93Tropsch_process

But it's a matter of efficiency, it's still cheaper to pump it out of the ground after nature has done the heavy lifting than it is to do it ourselves.
 Maybe I'm completely wrong, but I was under the impression that a lot of fossil fuels come from the Carboniferous because plants evolved lignin and it took a long time for decomposers to evolve a method to break it down, so it just accumulated. If this is true, and it may well not be true, I would imagine this to be a unique historical event. For coal production, you're definitely right.  See here: http://www.reddit.com/r/askscience/comments/35isjx/at_what_rate_if_any_does_the_earth_produce_fossil/cr5eovn?context=10

You're talking about Type III kerogens with that, which is a different ballgame than the Type I and Type IIs that we're generally looking for to create oil.

Most of our oil source is a black shale, not coal (although there are a few exceptions). Little late here. But would the "dead zone" in the Gulf of Mexico be a place that would fit the bill right now. Essentially an anoxic area from runoff.  Are we leaving the Bakken alone? Does a reserve's ability to generate additional oil ever factor in to a decision to drill or not, or does that take too long to care? [No, we're fracking the bejesus out of the Bakken.](http://upload.wikimedia.org/wikipedia/commons/e/e8/Bakken_Oil_Production_ND.png)

It takes too long to care, surely we'll be either off of oil or extinct by the time it matters. In a lab it can take hours or days. 

But you mean, "naturally", right? The actual process (catogenesis) is quite fast - getting the raw materials into the situation where it can start in the first place is the hard part and that is the bit that takes a long time. This means that natural oil production is not like an industrial process that is done a gallon at a time ... but millions of barrels in one setup. n a typical petroleum system such as the Mississippi River delta, it may take 10 million years to bury the material deep enough for it to reach temperatures of catagenesis. Add in some volcanic activity that makes a high geothermal gradient and that timing may be quite short and no longer in millions of years. 



Reference https://www.physicsforums.com/threads/how-long-does-it-take-the-earth-to-form-one-gallon-of-oil.667166/

this a copy paste from a diffrent website and not self written
 Would it be feasible to make our own oil with algae and just bury it? i know you are joking with me but algea based fuels can be made 
relative easy in a production facility.

The problem is the enormous scale you need to have to take over a world wide system . the tech to keep it working on such a scale is just not there yet with out massive funding from the all governments world wide and even then it will run costly for car drivers.

algea bio diesel goes for 33 dollar A gallon right now. not barrel a gallon  I would say that the biggest obstacle is that of scale. 

[Algenol](http://www.algenol.com/) is currently producing fuel for ~$1.30/gal. 

[DARPA](http://www.darpa.mil/Our_Work/DSO/Programs/Biofuels.aspx) has claimed that they are approaching $1/gal algae biofuel costs. 

Even if these are exaggerations, I'd say algae biofuel on a large commercial scale is only about two decades out. The funding is already there and working on it. Why do you think that it's only about two decades out? Research began in earnest in the mid-80's, but then fell off drastically in the mid-90's. It then picked up again about ten years ago. 

The state of the technology now is such that they're starting to claim that it is competitive with current options, which *to me* means that it's about halfway to being competitive (me being a pessimist and all). Since there have been about 20 years of real R&amp;D in it, I'll call it another 20 years before it's real. &gt; algea bio diesel goes for 33 dollar A gallon right now. not barrel a gallon

That's not all *that* far off from the current price of diesel in some areas.  liter price in the Netherlands 10th may is 1.87 euro PER liter 

a gallon is 3.7 liters so 1.87 euro x 3.7 = 6.91 euro

on the moment 6.91 euros is 7.75 dollars so. 7.75 dollars in comparison to 33 dollars per gallon

Edit : iam rounding on those numbers a bit so it may be a bit more/less on actual price with more zeros behind the comma Yeah but that's after government tax and other extras added on top. That chap is talking wholesale. Where oil is currently $60 a barrel or so.  A barrel is 40 gallons iirc, so at 33 a gallon that's around 1300 per barrel, vs 60. [deleted] I'm not sure that's an imminently answerable question.  It would depend on the rate of ~~animal~~ *organic* matter making it into sedimentary rock, which is very very slow. 

The world's total future and historical unproven reserves of oil is approximately 2.5 trillion barrels. (+/- 1 trillion).  The age of the oil is almost all under 350mya.

This quick (and dirty, inaccurate, etc) math gives us ~7,000 barrels per year.   It's probably not right, but I'd wager it's within 2 orders of magnitude of reality.  

Fermi Approximation is our friend here and says "about 10,000 barrels per year":

http://what-if.xkcd.com/imgs/a/84/paint_age.png

For context, this is approximately the amount of fuel a supertanker uses to cross the Atlantic ocean once.

It won't last forever.



The  Animal matter is a grossly inaccurate term to use for precursors to oil production. &gt;  It would depend on the rate of animal matter making it into sedimentary rock

Plant matter too.

&gt;The world's total future and historical unproven reserves of oil is approximately 2.5 trillion barrels. (+/- 1 trillion). The age of the oil is almost all under 350mya.

Reserves are the amount of technically and economically recoverable fossil fuels, not total existing. And some of the fossil fuels that had originally been trapped should have been lost due to the various processes the sedimentary rock has undergone since. So between 70 and 700,000? To put that in perspective, even if it's the upper limit of 700,000 (less than a million) barrels a year, we use 31,025,000,000 (31 billion) barrels a year.  We're using oil over 4000 times faster than it's being deposited.

In 70 years we will probably have used most of earth's easily available oil and earth isn't making more.  And we will have destroyed the planet in the process. I think there are really two questions here:

1) What is the rate that dead plant material is being deposited that could eventually become oil.

2) What amount of dead plant material that was already deposited a very long time ago chemically crosses whatever threshold we want to define it as to become "oil" per year? [deleted] It's enough to get a scale of the rate on an approximate level.  Somewhere between "runs a big ship for a minute" and "runs a big ship for a week". [deleted] For even more context, there's some tiny island in French Polynesia (I forget the name, I was searching for tiny islands on Google Earth) which uses ~7,000 barrels of oil per day (according to wikipedia)

The island I saw looked like it was home to less people than I have in my town.

EDIT: It was Tahiti, also according to Wikipedia my town has ~10,000 people less than Tahiti. I wonder how much oil we use. Tahiti is a popular tourist destination, so they need a huge supply of jet fuel and ocean liner fuel that your home town may not need. As a previous answer stated, it mostly occurred in the mesozoic.
basically what happened was a period of increased primary production in the ocean, and a lack of oxygen in the ocean. This allowed the organic carbon from the primary producers to sink without being taken up by oxygen, creating what is known as a black shale. Black shales are basically oil or natural gas deposits in colloquial terms.
This process happens all the time, but about 1/3+ of the world's fossil fuels are believed to have been created during the ocean anoxic events of the mesozoic. Geologically most of the coal in the world is from the 50 million period where tress had evolved however fungi hadn't caught up - thus they piled up, allowing the conditions required to be met easily. These days the conditions can still be met, however it is much rarer... Also the process itself does take millions of years, so my views are coal is very much a finite resource. It doesn't to the same extent it used too. Effectively, once trees evolved (chitin I think?) the support material that makes up their cell walls, it was millions of years before decomposers evolved to break them down, so they piled up and became fossil fuel deposits. There was an interesting bit about this in one of the NDT Cosmos episodes.  Lignin, you're thinking of lignin.


Chitin is what insect exoskeletons are made of. So the oil we use is composed mostly of really old tree bark? [deleted] So why is it found in sedimentary rock?

Some of the natural gas is known to be abiotic though.  It's not like there's a planet with entire oceans of hydrocarbons or anything...

 I think the abiogenic theories are interesting. I read Thomas Gold's rambunctious book claiming oil is abiogenic. It was rad! I would not be stunned if he was at least half right. I believe his book opens with an endorsement by none other than Freeman Dyson. (of course physicists seem to have a habit of unconvincingly trying to overthrow the dogmas of other fields.. cough: Roger Penrose: cough)

Buttt, Hydrocarbons are found throughout the solar systems, and my understanding is that new models of planetary formation indicate they could have coalesced as part of the earth during its formation. What's that moon with the oceans of methane again? Titan that's it.

http://en.wikipedia.org/wiki/Thomas_Gold

Let's see, when I was geeked on this I think I found that some Analytical Chemists had posted a isotopic analysis or something that claimed to show that terrestrial hydrocarbons had to be biogenic. Is the main evidence against the abiogenic theory?

Edit: grammerin' There are multiple lines of evidence that the vast majority of hydrocarbons on Earth are biogenic.  There are abiogenic hydrocarbons too, but they are trace amounts by comparison and are commercially insignificant.  Gold's ideas are interesting, but all the specific tests were failures.  Traces of what was probably diesel contamination was all that was ever found. not in our life times.  our usage vastly exceeds any sort of replenishment - hence the need to find new sources like right off your family beach on the east coast.  it took millions of years for the earth to "produce" the fuels we are using now My understanding was that when the early forests arose, there were no bacteria capable of breaking down the dead wood, so it just stacked up. Those millions of years of forests were buried,  became oil, and eventually bacteria evolved that could break down wood.

I suppose the modern equivalents would be large piles of plastic, but we (personally) don't have a few million years to find out. [deleted] oil production from the earth does not depend on deposited organic material. This is a big fat lie I told to you by the oil industry so that you believe that there is a limited amount. Thus the center of the earth is like a Sun, it produces magma, it produces sulfiric acid even produces the water from the oceans. It also produces oil no surprise there. Why would we be getting oil from under the ocean from dead dinosaurs. It's a bad theory. the earth makes it like it makes all the other toxic chemicals spewed out of volcanoes.. And most likely at a decently fast rate.  What? No. A Black equivalent of Chlorophyll does exist - usually within Seaweed.

This is because most plant life would overheat and their enzymes would denature if they were to absorb all spectra of light - therefore green is the commonly used colour as it reflects mid-energy photons and absorbs high energy (blue) light and lower energy (red) light Also plants are generally limited more by CO2 availability then light, at least under full sun anyway. Thats why plants grow just fine in greenhouses with sun shades drawn to block a portion of the light, still getting all that they need. Could you expand a bit on the discussion of CO2 limitation? Is there some kinetic limitation for incorporation of CO2 into Rubisco or diffusion of CO2 from air to chloroplast? Water limitation can certainly be an issue for CO2 acquisition due to plant transpiration demands, but I'm less familiar with direct CO2 limitation.  Generally limited by CO2 availability from the air. Still air will rapidly be depleted of CO2 around plants. This is why increasing CO2 in greenhouses under otherwise unlimited conditions (lots of light/lots of water) causes increased growth and can also increase plant heat tolerance.

Edit: Also why fans and wind are so good for rapidly growing plants and part of the reason why greenhouse ventilation is such a big deal.

Edit the 2nd: The "unlimited conditions" in the greenhouse would also need to include full access to nutrients such as nitrogen, phosphorus, potassium, magnesium, etc. If you think about a plant's carbon foot print, this makes sense. Dirt is made of many chemicals, but it doesn't always have much carbon in it. Yet plants are made out of it. You can tell because when you burn plants, you get carbon dioxide and charcoal. That carbon has to come from somewhere, and the answer is the air.  Exactly so. With atmospheric CO2 in the neighborhood of 300 ppm a closed room full of plants in full sun can bring that down to 100 ppm in an hour. On the other side of that if CO2 is brought in from somewhere else, such as a product of fermentation or some other waste, most plants benefit from CO2 concentrations up to 1,500ppm. So, theoretically, having too many house plants could conceivably kill them? By overconsumption of CO2? I really doubt they would die, but growing really really slowly is a possibility and they wouldn't make any sort of fruits or flower well at all. Of course if you are in the house with them you are going to provide a large amount of CO2 just by being there so... :)

I have a friend that holds her tomato seedlings and whispers to them. By the end of the season they are 10-15' tall, so it must work right? 15 foot tall?  That's a pretty big tomato plant.  Is she reading them the Iliad? Probably did. That was just in pots on the deck. I have also seen photo of an aquaponically grown tomato plant that was 80 feet long when it died. They had it growing up a cable and would low the the cable as the plant grew and kept it pruned to just the main stem. 

Couldn't find the pic, so have [this one instead](http://en.academic.ru/pictures/enwiki/84/Tomatotree.JPG) of a single plant filling a greenhouse. Or having a planet with, say, twice as much CO2 in the air and the same or more solar energy would lead to amazingly abundant plant growth? If memory of my limited Planetary History is intact, Earth used to be like that; a ton of CO2 and nitrogen, and a whole lot less oxygen. Didn't ancient plants pretty much poison the atmosphere with oxygen?  Not really, plants basically "pause" when they don't have enough of something, for example if you stop watering a plant it will wilt, but if you water a plant that has just wilted you can usually watch it come back to life.  Similarly the plant will slow it's internal processes and bring less water/nutrients up from the roots while it's unable to get enough co2. You should read up on the role of transpiration in plants. In general, water loss through stomata opening in leaves (and stems) is caused by heat evaporating the molecules and wind wicking them away. This loss of water creates a pressure differential that brings water from lower in the plant upwards, replacing what was lost. About 95% of a mature tree's water uptake is lost through transpiration for instance, and it can take up hundreds of gallons of water through its roots to replenish what was lost. 

While some plants have adaptions to try to control the loss of water (timed opening and closing of stomata, respiration that occurs during nighttime), I have never heard of a plant that actively decided when and where to bring water. Water loss inevitably leads to tissue death if it is prolonged (the plant reaches its "permanent wilting point", usually several hours of sustained wilt that persists after the heat of day dissipates, where damage becomes permanent and death is more certain). So there's basically a difference between wilting because it's really hot out and there's a wind, and wilting because there isn't enough water available in the root zone or soil. 

I'm just referring to water in this case as I can't speak with certainty about CO2 and O2 cellular "pausing". I can't imagine a plant can pause respiration for too long without harmful repercussions though.  What we learned in school is that a plant also produces CO2 during nighttime itself. The plant needs energy at night, and since it cannot get any ATP through photosynthesis, it will decompose the sugars which it built during the day (the ratio is not 50/50 though, so a plant does grow).

Wouldn't a plant just consume the sugars it made in its mitochondria when there is too little CO2? Yes, theoretically.  It would take a lot of plants in a house and a very tight building envelope and no other source of CO2.  This can actually be observed in the aquatic plant hobby.  To achieve optimal growth of aquatic plants in an aquarium, its often necessary to supplement the CO2 into the water because the plants will deplete the natural supply of CO2 in the tank.   It can also be observed in the hobby of marijuana cultivation, where the best crops are grown with supplemented CO2. It's unlikely given the low-light conditions in most houses...that's going to reduce the CO2 limitation of plants and make them more light-limited.  

Even in high light lowered CO2 levels are unlikely to _kill_ plants, just prevent them from growing.  A plant doesn't really need CO2 to live, per se, it more needs CO2 to make more plant.  Plants turn CO2 into sugar with sun, then burn that sugar with oxygen to make energy and CO2 again.   Typically a house has pretty good air circulation, but in a sealed system you could. A lot of planted aquariums use CO2 injection to help plants grow quickly, or in some cases, to keep an amount of plants alive that would be impossible with just the CO2 produced by the animal livestock. &gt; most plants benefit from CO2 concentrations up to 1,500ppm.

Oh! That's interesting! Most of the results I have seen about that (not my specialty at all) seemed to indicate clear benefits up to 600 ppm but not much after that. 

Would you have a source for the 1500 limit? From that point, what limits growth? do you know? The limiter appears to be stomatal conductance of water vapor; that is, the surface of leaves are covered in pores (that look disturbingly like they're about to yell, "Feed me, Seymore!") called stomas.  They're unselective, so if they're open, the plant is both gaining CO and losing water.  

This results in slight osmotic pressure towards the stomas (so long as the plant is sufficiently watered), and is responsible for nutrient transport within the plant.

If the CO levels are too high, they outrun their enzymes, and the stomas start to close up.  With sufficiently reduced transpiration, nutrient flow can become low enough that leaves partially die.

One way to get around this is by keeping the air both high CO and very dry, while keeping the roots well-supplied - but honestly, CO concentrations about ~~1%~~ 0.1% start getting dangerous to the _gardeners_, and above 1,500 ppm, most plants' enzymes can't actually keep up with the influx of CO, regardless of other conditions.  So it doesn't really help to go higher, and it could pose a health risk to anyone who needs to enter the greenhouse.

Sources: 

http://www.co2science.org/subject/t/summaries/transpiration.php (usually not a good source, but the science collected here on CO and transpirational water loss is sound.  Their conclusion that this should help plants survive climate change induced drought is wrong, though; the marginal change in water loss doesn't help a plant conserve to zero, as it would need to, the reduction in nutrient flow doesn't benefit the plant, and the arid climate changes the situation anyway).

http://en.wikipedia.org/wiki/Stoma Wouldn't a 1% concentration be 10,000 ppm? Actually, I started reading about that when I was interested in the idea of growing stuff in space or in underground locations.

One of the questions I had was, regarding the possibility to grow things on the moon, where there are 14 days of constant day, "Is it possible to make conditions for growing edible food within a 14 days window, starting from seed?" 

Alternatively, I was interested by the idea of total energy efficiency: assuming a 100% efficient solar to electric conversion, how fast can we grow food by designing the perfect artificial conditions (both with artifical light and atmosphere) for it? How energy-efficient can agriculture be in these conditions? A difficulty there is that free-air carbon enrichment is somewhat energy intensive.  Sadly, this means that most CO-concentrated greenhouses use a propane-burning CO generator.

A home option is to brew beer in your greenhouse; a kitchen trash bin can ferment enough mash to keep a reasonable sized greenhouse carbon-enriched for a couple of weeks (after which you need to do something with the beer).

There doesn't seem to be a commercialized version of CO enrichment using the same techniques that go into [rebreather diving](http://en.wikipedia.org/wiki/Rebreather), but that seems to be to be the best way to concentrate atmospheric CO without the use of a refridgeration cycle (which, because of the mass flow needed to pull a couple hundred ppm of CO out of air, tend to be inefficient). &gt; most plants benefit from CO2 concentrations up to 1,500ppm.

So what you're telling me is if I really want my plants to thrive, I should put them near my fermenting liquor?

Huh. I mean, it makes perfect sense I just never thought about it. I do that! My airlocks lead directly to my plants! Remember that pure CO2 that comes out of there is heavier then air, so put it over the plant or next to a fan so it gets mixed in and blown around. &gt; a closed room full of plants in full sun can bring that down to 100 ppm in an hour

This is AMAZING to me. I'd love to read some papers or something on this, what kind of density in the room is required for this rate? That is, what constitutes "full of plants"? just as an aside, the atmospheric concentration of CO2 has reached 400ppm. This reminds me of my favorite college botany pop quiz question. Where do plants acquire their mass from during growth? The water, the ground, or the air? Most immediately assume water or ground, yet photosynthesis requires CO and produces oxygen so the carbons is absorbed and incorporated into the plant equalling mass If by "mass" you mean "dry mass". Otherwise I say they get most of their mass from water (as do we). Depends on the plant, I assume.  Green wood ranges in percentage of water per mass from 24% to 75%, so a tree may get the vast majority of its mass from the surrounding CO. It's also surprising to below that the majority of weight loss from loss of fat is through exhalation of CO2. I am going to try and hijack your comment!

It's because nature is inefficient! Plants produce large amounts of [an enzyme](http://en.wikipedia.org/wiki/RuBisCO) that evolved in a time when there was no oxygen, which is essential to their creation of enthalpy. 

So they have large metabolic structures in place to deal with all of the toxic products this reaction produces in the presence of oxygen! Nature isn't about being the best it's about luck! Similarly when you lose 100lb on the greatest loser show, most all of that was breathed out not peed or pooped Does that mean that if I grow plants, turn them into charcoal, burn them, then re-grow the same amount of plants it's carbon neutral? It probably sinks slightly more carbon than it expends because some of the plant matter won't be usable as charcoal (leaves and roots) and will instead become part of the organic soil horizon  Yes. Plant reduce carbon in the atmosphere exactly equal to the amount they release back when they are burned. That's why burning fossil fuels is essentially re-emitting the carbon from plants over the last million years at an astounding rate Yes if you could get free energy/didn't need any carbon-sourced energy to turn it into charcoal.  Theoretically it would be carbon neutral. A giant magnifying glass. What could go wrong? As long as you don't add other stuff to the cycle that requires more carbon (aka trucking in fertilizer) then yes. absolutely. Its the normal way the world does it without human help after all. Actually, dirt is absolutely loaded with carbon but the chemical bonds of carbon in soil take much more energy to break than they are worth. The air in our atmosphere is mostly nitrogen, another element that plants need, but plants only get nitrogen from soil for the same reason: diatomic nitrogen's bonds are extremely stable and hard to break. It's not just availability of the elements, it's also usability based on energy required to free essential nutrients. This is why hydroponics are viable. Soil actually plays a relatively small role compared to atmosphere when it comes to plant growth. In a closed system with lots of outside inputs? Sure. In a balanced sustainable ecosystem soil and the microbial life it contains are absolutely critical.  This is only one part of the picture. Many would argue that plants are more limited by nitrogen than by CO2. In full sun, plants are more limited by the rate at which rubisco can fix carbon and be rengenerated, and the limiting factor for rubisco creation is nitrogen availability.  Anything that plants need can be the limiting factor for growth, nitrogen certainly can be a limiting factor for sure.  Thats exactly why I included the "under otherwise unlimited conditions" line, should have included nitrogen in that along with light and water.  Don't forget phosphorus, potassium, iron, magnesium, calcium, sulphur, manganese, copper, boron, zinc... Maybe just start with the '...'. In nature phosphorus tends to be the limiting factor, if I'm not mistaken. So when there was more carbon dioxide in the atmosphere were plants darker? This is exacerbated in Aquatic plants as diffusion is many times slower in water than in air. Incidentally quite a few species of Aquatic plants seem to be able to utilize CO2 from the sediment where there is alot more CO2 available the in the water (Winkel et al., 2009). http://m.aob.oxfordjournals.org/content/early/2009/02/14/aob.mcp036.abstract Does that mean that, as we pump out more carbon dioxide, forests will grow more and become better at processing that back into oxygen?

If so, why is the massive carbon dioxide production considered such a huge issue? Because forests processing more carbon dioxide doesn't sequester it away. It will very soon come back into the air.

Rapidly growing trees suck up a bunch of carbon and store it for a few to hundreds of years but mature forests are basically carbon neutral.

Think of it this way, a bush grows on the forest floor and absorbs carbon to build itself. A deer eats the bush, the carbon is now released back. An old tree falls over and rots away, nearly all its carbon is released back into the air. New trees grow in the gap and absorb that same amount of carbon back.

The forest is in balance with itself. At a higher level of CO2 things will grow bigger more rapidly and perhaps a bit of net carbon will be absorbed but over all the cycle will be the same. If it worked the way you are hoping CO2 levels would have risen because the forests would have absorbed the difference. 

We know that the forests don't absorb the change because they haven't absorbed the change. soo the 400ppm or CO2 is actually a good thing for agriculture and food production then. To add to this, the amount of solar power falling on every m2 is about 1 kW, which is quite substantial.  The partial pressure of CO2, however, will limit diffusion into the plant.  You never quite deplete all CO2, but if the concentration falls too low there's no driving force to absorb it. It's basically how inefficient RuBisCO is, as it will almost just as happily use O2 rather than CO2.

This is the reason there are different photosynthesis methods in plants:

* C3  
* C4 - http://en.wikipedia.org/wiki/C4_carbon_fixation
* CAM  

Now, you're correct that these methods are adaptations to environments, in particular water stress from transpiration.  But, the ultimate reason they are necessary is the inefficiency of RuBisCO / low concentration of CO2.  It's a tradeoff - you can maximize your concetration of CO2 with high transpiration, but then lose lots of water.  If there's lot's of CO2, you can still be efficient and have low transpiration. That's right. Now my Plant Phys. is coming back to me. Essentially, the higher the partial pressure of CO2 during rubisco capture, the less likely rubisco will be to use a competing substrate (O2). Thanks. RuBisCO is also very slow kinetically compared to other enzymes, which is why there's such an enormous amount of it.  The enzyme in plants that converts CO2 to sugar that can then be used for energy is called Rubisco (ribulose-bisphosphate carboxylase). This enzyme adds the CO2 to a molecule called ribulose bisphosphate which is then able to be broken down into other molecules that can be used for making ATP (the energy currency of cells). However, rubisco also has oxygenase activity. This means it can add oxygen (O2) to ribulose bisphosphate instead of carbon dioxide. When this molecule is broken down, it only makes one useful molecule for synthesis of ATP. The other molecule must be dealt with and converted to something the plant can use and this ends up being a costly (energy wise) to do. Therefore, higher amounts of CO2 causes rubisco to work as a carboxylase more than an oxygenase. 

Also, rubisco is a very slow working enzyme. Since it works so slowly it is the rate limiting reaction of the calvin cycle (which is the cycle that fixates carbon dioxide into useful sugars).  

&gt;Is there some kinetic limitation for incorporation of CO2 into Rubisco or diffusion of CO2 from air to chloroplast? 

This is it. RuBisCO isn't totally specific for CO2, it can also use O2. The product of the O2 reaction has to be recycled for re-use in the RuBisCO reaction. When there is a higher concentration of CO2, RuBisCO incorporates more CO2 which makes photosynthesis more efficient.  another thing is that rubisco doesn't differentiate between o2 and co2 -- ie it can bind both. So in areas with high O2 concentration rubisco is binding a lot of o2 which is pretty useless for photosynthesis. [deleted] Here in the Philippines people burn leaves (along with their trash) because they believe it's supposed to help plants. I think it's doing more harm than good to both the environment AND the health of people breathing the stuff in. 

Would burning leaves in a greenhouse increase the growth of plants? Is there any other simple way to increase the amount of CO2 in the air around plants you want to grow faster that isn't as harmful as leaf burning? Burning them in the greenhouse would kill everything in it. Plants don't like smoke or fire at all. 

However if you compost the leaves in the greenhouse you get lots of CO2 plus gentile even heat. Thats a good plan and moderately commonly done. I am sure that a google result will pull it up for you. It also wouldn't involve burning down your greenhouse. :)

[Here](http://www.permaculture.co.uk/articles/heating-greenhouse-compost-and-manure) is a good basic guide, haven't read it in detail but seems helpful. Thanks for the reply. I will check out your link.

What about trees though? I read an study that said trees fortify their bark when they are exposed to smoke to help them resist forest fires. I will try to find the link and post it. I guess this would be less along the lines of C02 being beneficial for growth, and more on the tree "sensing" the C02 and some system turns on to increase the thickness of the tree's bark. I'll see if I can find it for you.

The problem in the Philippines of people burning their trash and leaves is widespread and almost every household does it in the provinces. They say that they are helping the trees, but I can't help but think that they are doing something that MAY have minimal positive effect, while its detrimental to the health of anyone who breathes in the smoke as well as the environment. Some trees don't mind a bit of fire, some of them need fire for their seeds to open. Setting fire to garbage and piles of leaves isn't going to have any positive impact on anything though. The thickness of tree bark would be in response to damage from heat and certainly not from a temporary spike in CO2.

Compost the leaves! Make beautiful soil and use it to gently heat the greenhouse in winter then you can plant stuff in it. The planet (and your countries lungs) would be better off I think if people just dumped the leaves in piles and let them become mulch. Sine we have broken 400ppm CO2, does this mean plants will grow better? Only in places where CO2 is the limiting factor, but yes. Unfortunately as that carbon just runs the circle and back into the atmosphere it doesn't really help anything (other then juicer tomatoes and bigger leaves perhaps). Some amount of it will be fixed more readily into wood, no?  Perhaps not a significant factor. Oh certainly, but unless that wood is turned into biochar or otherwise sequestered it will run the circle and end up back in the air just the same. The best way for trees to keep it out of the air would be to let the young trees grow into huge ancient trees, that would soak up a good chunk. We are just very good at cutting down big trees...

Ultimately its all pretty complex, as there is more carbon available, more things will take up carbon, but the amount that would stay sequestered out of the atmosphere would depend on a great many factors and is, frankly, someone beyond my knowledge and specialty. "Better" is subjective here... better as in taller and bigger, yes... but at the expense of less protein content in the plants (corn, for sure) by mass. Yes most of the plants will grow better but they will be less nutrient dense, which is generally not good for their consumers Follow up question: Shouldn't plants outside grow faster then their counterparts inside as they have wind to distribute more air to them? Greenhouses generally have fans and massive ventilation plans for just this reason. Without good airflow, yes plants don't grow as well. It doesn't take a lot of wind on the plants to circulate available CO2, just some, but it is very necessary. Would it be possible to make a Solar cell that uses CO2 to create electricity? Are you saying that if I hooked my car exhaust up to a greenhouse, the plants would flourish? Nope, if it was a small greenhouse and depending on the car you could kill everything in it. It certainly be bad.

Exhaust, especially car, exhaust is dirt. Particulates, smog, other nasty stuff. Its not the best idea. If you hooked up a really clean burning appliance like a 98% natural gas furnace to exhaust into the greenhouse that could work, but have a bypass so regular air gets mixed in with it. Pure CO2 environment will kill plants and people very quickly. 1,500 ppm is only 0.15% CO2 after all. The furnace would exhaust a lot more then that. So, does this mean that with CO2 levels at an all-time high, plants can absorb more energy? Would that mean greenhouses would benefit from being pumped with CO2? Surely a power station could supply clean CO2 if this could grow plants faster? Yep, they would and many are supplemented. Generally there isn't much of a connection between power plants and greenhouses though, issues of scale, timing, etc. 

Greenhouses should only have supplemented CO2 during peak sunlight hours, power plants function on different schedules, size of power plant exhaust vs greenhouse demand, safety and preventing suffocation of works, etc, as well as issues with the CO2 from the plant not being clean enough because soot/smog/particulates are bad for plants. You are completely correct that lots of work could be done with this. 

I work with some people that are feeding the CO2 from a brewery to a greenhouse. It should work out pretty well. Plus side is that extra CO2 turns into more food, reducing carbon footprint on both sides of the deal.

Sadly, many greenhouses get their extra CO2 and heat through combustion of fossil fuels instead of partnering with a power plant or industrial manufacturer for waste heat and CO2. In fact, the protein/enzyme denaturing isn't that much of an issue, because they could easily adapt to have them denature at a higher temperature. A good example of this is TAQ polymerase used in PCR reactions. Natural selection is a powerful driving force, and if some plant managed to acquire the trait for a higher optimal temperature for some enzymes, then that gene would spread like wildfire through the population. If light isn't the limiting factor, however, the advantage is gone and Darwin cries. Wouldn't it make more sense to absorb green then and reflect the other two, producing purple plants?

Wait, I've seen purple plants before, like the plum tree, is that what they're doing??? I've read arguments that they go hand-in-hand.

Purple plants take advantage of the strongest part of the spectrum, but they pass purple light. Understories will find that the green parts of the spectrum have been stripped, but the red and blue parts of the spectrum are now stronger -- organisms in those regions will evolve to take advantage of those (and end up reflecting/passing green light). This may have all gone down very early in evolutionary history (think of red and green algaes at different depths). The green variants ended up colonizing the land niches, where the whole process repeated but in an inverted form, with purple leaves evolving in the understories. probably not because some processes require specific higher energy photons and won't work regardless of the energy gained from low frequency light.

Most plants get more than enough sunlight and the rate of photosynthesis is limited by the availability of carbon dioxide which can only diffuse into the stomata at a certain rate so there would be no benefit to absorbing green light instead of red or Blue Healthy green plants absolutely absorb across the entire visible spectrum, including the "green". It just absorbs relatively less in green thus appearing green to our eyes. 
http://www.seos-project.eu/modules/agriculture/agriculture-c01-s01.html


https://www.exelisvis.com/portals/0/images/Vegetation_Spectrum_Detail.png A Prof told me last semester that even 90% of the green light is absorbed, compared to 99% of blue and red. So green light is used in plants. Just to add on, aside from denaturation by heat the photosystem of plants can also be overloaded with light such that it increases the rate of production of [reactive oxygen species](http://en.wikipedia.org/wiki/Reactive_oxygen_species) (ROS). Now, ROS are not necessarily bad and plant cells do have mechanisms to maintain them but an excess can lead to damage. And that's why photosynthetic organisms have non-photochemical quenching! The photosystem's antenna complex is so efficient at capturing energy from photons that the photosystem shunts its energy to NPQ in high light conditions, to prevent that energy from running amok and producing ROS. Why would the plant want to absorb high and low energy photons and reflect mid-energy photons instead of high and mid or low and mid? plants usually receive a surplus of energy from sunlight with the limiting factor of Photosynthesis due to lack of CO2.
They therefore reflect any light they don't need that would cause them to overheat - green light wavelength is emitted from our sun with the strongest intensity therefore having a single pigment (chlorophyll) reflect this is simple and effective.
Red wavelength light, as it is emitted at lower intensity, is less of a problem with respect to overheating So why haven't plants evolved to be black and have stronger enzymes or something like that so they wouldn't overheat? [deleted] This is not correct. 

A plant that passes on its genes to more plants will outcompete other plants, even though they also pass on their genes.

Of course Im too late now, and everyone has moved on. Why do I even bother. Natural selection still requires chance mutations to happen. Pigments are smaller, simpler compounds than enzymes (which are relatively massive) so the chance of a mutation which causes the production of pigments which reflect unwanted light is much more likely to occur than one that changes the primary structure of an enzyme to produce one which still functions and also withstands higher temperatures. 

That's not to say that these don't occur - there are bacteria that live in boiling spring water in Iceland and their enzymes have to function at a range of temperatures but it is a very particular mutation.

This would be similar to the fact that males testicles hang outside the body to keep sperm a few degrees cooler instead of evolving sperm that can withstand a few extra degrees of heat - it's easier to solve the problem on a larger scale if that makes sense.

 Some of this is thought to be about activation of sperm. The sperm stay in a different stable state while in the slightly cooler testes, but when exposed to a nice warm vagina switch into a racier mode to try and fertilise an ovum. You can't evolve past physics. Enzymes can't become that strong. You are limited by chemical bond and folding energy. The bonds don't typically break but tertiary structure is crucial for proper enzyme function. The interactions that fold proteins are not as strong as covalent bonds. Therefore you end up reaching an upper limit on the energy input before they'll denature. There are extreme thermophiles such as *Synechococcus lividus* that engage in photosynthesis, so I don't think the thermal hypothesis is incontrovertibly supported. Also, it would make more sense for plants to reflect shorter wavelengths of light rather than green, since any excess energy that the photon has beyond what is required for the photochemical reaction is lost as heat.   The individual interactions are not as strong as a covalent bond, but the sum of many smaller interactions can make some tertiary  structures very very strong. Evolution isn't concerned with making the best enzyme out there, it just wants to make something that is good enough or slightly better than your competition.  Ok correct me if I am wrong isn't evolution random success? Just because something can function better doesn't mean it will evolve to right?  This answer is definitely not correct. [Photosynthetic pigments including chlorophyll evolved in water, not in land plants](http://www.pnas.org/content/93/5/1930.full.pdf) Yes, early single celled organisms developed photosynthetic pigments of a range of colours yet there are few black plants above ground

Plants have a priority of maintaining their temperature such that they use 95%-99.5% of their water for transpiration through their stomata to cool down in the same way that you would sweat, having black pigment would require them to use more water to transpire than they have available.
 Do you happen to have a source I can read about this theory? I've never heard thermal damage being the sole/predominant reason for green chlorophyll.  http://en.wikipedia.org/wiki/Transpiration http://passel.unl.edu/pages/informationmodule.php?idinformationmodule=1092853841&amp;topicorder=3

Plants need to conserve water - they must lower their temperature in other ways such as by reflecting spectra of light that aren't required, there is usually no shortage of sunlight but there is often a shortage of water. Those sources contain no information about chorophyll, however. I haven't been able to find any support for the thermal hypothesis, so it seems to be pure speculation. Chlorophyll initially evolved in aquatic organisms.  [deleted] I know I am late to the discussion, but interestingly enough, prehistoric earth's atmosphere was significantly different that [scientist now believe previous plant life was purple, not green.](http://www.livescience.com/1398-early-earth-purple-study-suggests.html) That then presents the question, then why do some plants uses other colours for photosynthesis? Ex: Red Maples. It's my understanding that Acer rubrum is green in the summer? Interesting side note; there are LED lights out there (usually called 'ufo' lights) that only put out the blue/red spectrums of light, so the plants that they shine on are receiving all of the light that is being given off. If you are in a room with only these lights on the plants, the leaves of the plant look black, because there is no green-spectrum light to bounce off of them. It's pretty easy to deduce that the green light is what's being *reflected* after seeing this. for the lazy, here is a picture: [http://upload.wikimedia.org/wikipedia/en/4/48/LED_panel_and_plants.jpg](http://upload.wikimedia.org/wikipedia/en/4/48/LED_panel_and_plants.jpg) Why? Energy efficient indoor growing? Indeed. Actually, LED lights are some of the most efficient grow lights because they use less electricity (due to not using green light), produce less heat (a factor you want to consider if you're growing anything in an enclosed space), and provide only the spectrum you need. 

[Here's a link to provide an example of a real-world application of LEDs to grow plants](http://www.gelighting.com/LightingWeb/apac/news-and-media/press-room/press-releases/2014/Japan%20Case.jsp)

Another cool fact is that most plants have sleeping cycles - basically they need an uninterrupted period of little to no light where they are allowed to "rest". Some plants can go without it, but for a plant to maintain its natural cycle of life, it's better to have this rest. Any light during this time will disturb the plant and stress it out; it won't die, but it will not grow as fruitfully if continuously disturbed like this. However, if you shine a green-spectrum only light on them during sleep time, it will not disturb them much. This practice is often employed by pot growers to check on their plants during sleepy time without disturbing them :D 

Source(s): Used to grow dank trees. Then my medical card expired :&lt; no more dank trees &gt;It's pretty easy to deduce that the green light is what's being *reflected* after seeing this.

It's even easier to deduce this by observing the fact that plants ARE green under regular sunlight.
 There's a Minute Earth video on that exact subject: https://youtu.be/aAQYpra4aUs

Basically, since there is an abundance of yellow and green sunlight, early photosynthetic bacteria at the surface of the sea were magenta, meaning they absorbed green light and let red and blue through. So other organisms deeper in the water developped the ability to absorb that red and blue light, which made them green. But chlorophyll turned out to have other advantages over the magenta molecules, so that's the form of photosynthesis that took over the world. Once upon a time I read somewhere that all plant life on earth could just as well have ended up purple instead of green, sounds like that's feasible then?  the first plant life was reddish-purple, iirc, because that was the light that wasn't used and got reflected off of leaves. Chlorophyll is a fairly new invention, so to speak, but the earth was a very different place back then anyway.

[source](http://www.livescience.com/1398-early-earth-purple-study-suggests.html) Some fungi seem to photosynthesize using melanin (which is almost black) as the photon absorbing substance. [Fungi have also been found using melanin to absorb photons from more ionizing radiation](http://www.plosone.org/article/fetchArticle.action?articleURI=info%3Adoi%2F10.1371%2Fjournal.pone.0000457) such as that in the Chernobyl reactor, where they have been found growing happily. [In fact, melanin-producing fungi have been shown to grow towards radiation sources!](http://www.ncbi.nlm.nih.gov/pubmed/15506020)

[This is a cool figure from this paper in case you can't open it](http://imgur.com/HReBBHQ) This is incredibly cool.  Why have I not heard about this before?  Are there not any implications here about using fungi to bio scrub radiation? Since the fungus only takes in the radiation and does nothing to the radioactive material itself (akin to plants absorbing sunlight vs. reducing the actual output of the sun), I don't think this would be a workable application.  There is an faq for [this question](http://www.reddit.com/r/askscience/wiki/biology/black_leaves). &gt; most plants in full sunlight are getting far more light than they actually need

Interesting!  My followup question would be, if there were an environment where this was not the case, and they really did need to capture every last photon, would you start to see autotrophs evolving to use multiple photosynthetic molecules to cover more of the spectrum? Photosynthetic bacteria already have multiple photosynthetic molecules (they live in water), so yes. Plants do too, they have Anthocyanin. [Anthocyanines](https://en.wikipedia.org/wiki/Anthocyanin) are the reason blackberrys are black, for example. IIRC every photosynthetic molecule has some wavelenght it doesn't absorb, which means a mixture of different photosynthetic molecules isn't necessarly more effective than more of one kind, but i'm not sure aboput that one.

(Bacteria living deeper in the ocean loses the specialization for normal wavelenghts, so it wont happen in bacteria.)  Anthocyanins, however, are not used in photosynthesis.  A better example would perhaps be Carotenoids like Zeaxanthin which are part of the antenna complex for reaction centers.  Basically, they are molecules that can absorb photons and pass excited electrons to other pigments, and so on until they reach the reaction center of photosystem II.

To address the original question, it seems quite likely that additional parts of the spectrum would be used in a strictly photon-limited environment.  However, there are limits; longer wavelengths would have too little energy to do anything useful, so wouldn't be selected for.  Wavelengths that are too short would likely be too energetic and damaging to organic molecules.  Essentially, the greens might get 'filled in' and absorbed, but wavelengths outside infrared or ultraviolet wouldn't be useful. Many plants have [two types of chlorophyll molecule](http://www.ucmp.berkeley.edu/glossary/gloss3/pigments.html) in order to make use of different wavelengths of light. Algae, chromista, bacteria, and plenty of other organisms make use of other chlorophyll molecules (there are six total) as well as carotenoid and phycobilin molecules. In other words, plants are already using Chlorophyll A &amp; B, other critters are using C1, C2, D, F, and a whole slew of other photoreactive chemicals. It's not uncommon for a single organism to contain more than one molecule.

Bear in mind that the whole point of absorbing light in photosynthesis is to produce H and electrons which are used in metabolic processes to create sugars, starches, and etc. This means that the amount of light that any plant (or other photosynthetic organism) can utilize is dependent on CO^2 and water uptake as well. These are likely more limiting factors than light for most organisms. Our Sun also peaks in the green, but to us this just looks like white light since green is in the center of the visible spectrum. I wonder if this could have anything to do with the way green leaves evolved. I think an important aspect of evolutionary biology is missed by most of the answers.

Evidence suggests that the first/most dominant photosynthetic bacteria were purple in appearance, absorbing primarily green light. Green light is actually the wavelength the sun puts out the most, so this makes a green active photosynthetic molecule utilize energy efficiently.

Since green light was more sparse in an area colonized by these particular photosyntheitc bacteria, there became a niche for other photosynthetic bacteria to utilize the available red and blue light.

Keep in mind that bacteria are genetically much more malleable and progress through the generations much faster, compounded with the fact that we're talking over a billion years of time for all this machinery to be refined.

Then a chance event occurred, where a single celled organism phagocytized one of these red/blue absorbing photosynethic bacteria, and rather than digesting it, allowed it to survive as an internal compartment (a protocholorplast) to provide energy to the remainder of the cell. Over time, this bacteria became "enslaved" by the host cell, giving up some of its genetic control to it, developing into the chloroplast we know today.

This is actually exactly how mitochondria came about as well. The cell utilized these bacteria because they were simply more efficient at carrying out a certain biochemical process. Granted, the chances of a phagocytotic event resulting in symbiosis is basically zero, it only needed to happen once over many billion trillion chances. Mitochondria were captured first (the "power plant" of the cell), which is evidenced by the fact that ALL cellular organisms contain basically the same mitochondria. Some of these mitochondria containing organisms developed into animal and fungi, another branch incorporated chloroplasts and became plants.

Since cellular organisms don't reproduce nearly as quickly, and plants have been around a much much shorter time scale, there simply hasn't been enough time for the chloroplasts to redevelop the green light absorbing pigment.

TL;DR: Plants aren't black because of the die roll of evolution and time.

EDIT: Plants have developed some other pigments, but their purpose isn't primarily energy capture but rather energy dissipation. Here is a source that I found to support your answer:

http://www.livescience.com/1398-early-earth-purple-study-suggests.html Plants have a light saturation level that is usually lower than the actual intensity of full sun.  This is due to many factors both within the plant and its environment.  While not using all the light when your getting full sun at noon, you can still run at 100% in partial shade or clouds.  Also, plants use a lot of water and the more photosynthetically active they are, the more water they use.  This could be an evolutionary way to conserve water.  You don't want to be sucking up every last drop at the hottest most intense times of the day.  Another interesting aspect of the question is that our atmosphere used to be much higher in CO2.  Plants were much more efficient with higher CO2 levels and the light saturation point for a given plant rises with the level of CO2.  This is why you hear about some weed growers pumping CO2 into grow rooms.  Finally, a big reason many plants that grow well in full sun are not dark in color is simply heat related.  A lot of water is used to simply cool a plant and has no interaction with the photosynthetic process.  If all plants were black they would need to find other ways to keep cool or use a lot more water.  

Note: I have a degree in tropical agriculture and soil science but i am by no means an expert.  Please feel free to correct me! Photosynthesis and chlorophyll chemistry don't seem to have the capacity to arbitrarily pick what wavelength to use.  It may not be chemically possible to just change a protein somewhere and use a different wavelength.  


There's also costs in regards to bandgap.  The way photoreactions usually occur, you have a threshold- either you have enough energy to make a reaction occur, or you don't.  Any EXTRA energy past the threshold is wasted.

It's problematic to pick more than one bandgap.  Actually we do, there's chlorophyll A and  chlorophyll B and some minor ancillary pigments.   

But the way this works, you pick a bandgap too high and fewer photons meet the critera, lessening the energy.   You pick it too low and most of the photons meet the criteria, but you get little return per photon.

Like I say, there are multiple absorption lines.  But we can't put in 100.  One physically has to be on top of another and obscures it, making the lower absorber mostly pointless. I don't think the answer is well settled, but [there is a theory](http://www.livescience.com/1398-early-earth-purple-study-suggests.html) that goes like this: The first organisms to harness light used a photosynthesis mechanism that employed a molecule called Retinal.  Retinal most strongly absorbs green light, which is the peak of the light spectrum at the surface of Earth.  Such organisms would have appeared purple, because they do not absorb blue and red light as strongly.  That organism became dominant first.

Then Chlorophyll-based organisms came along that use the blue and red light that the Retinal-based organisms weren't using.  The Chlorophyll organisms could live along side the Retinal organisms.

But eventually the Chlorophyll organisms became dominant and this became the foundation of the multicellular plants that we know today.

Because Chlorophyll strongly absorbs blue and red light at the ends of the visible spectrum, plants look green (which is in the middle of the visible spectrum).

This is why [some efficient indoor farming processes](http://weburbanist.com/2015/04/02/plantlab-urban-farms-40-times-more-productive-than-open-fields/) are using purple light (red and blue LED's) to feed their plants.

Incidentally, there is a BBC series ([How to Grow a Planet](http://www.bbc.co.uk/programmes/b01c6c2b)) that talks about this theory in the first episode.  It just became available on Netflix.

 [deleted] Yeah, the green-absorbing pigment is anthocyanin, and it doesn't actually contribute anything to photosynthesis.  It only functions to protect the plant. Basically they don't need to, organisms are very good at regulating unwanted energy. If they had an unnecessary amount of chlorophyll then the excess energy needs to go somewhere. You may say well why not into growth, and that's because growth requires nutrients as well which they may not have. Why not into respiration, because CO2 is rather limited in our atmosphere, kinda like the nutrients argument. So energy, or in cellular terms, ATP is now in excess within the cells, this is a bad thing and can lead to cell death http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3419021/

ATP is also an important signalling molecule and high, but not lethal, concentration can have negative effects with other pathways. Short answer: it would oveheat.

The sun's light that hits a plant actually peaks in the yellow-greenish region of the spectrum, so the plant is actually reflecting a lot of light that would otherwise heat the plant up.

Remember that plants don't have a real way to regulate their temperature besides expelling water from their stomata on the leaves. Something like 96% of the water taken up plants goes into thermoregulation. I actually looked this up last week!

So ages ago, before chlorophyll and at the dawn of photosynthesis bacteria used a compound called retinal to absorb solar energy. Retinal is more simple than chlorophyll and is purple, meaning it absorbs only the most abundant wavelengths of light generated by the sun: green light. 

What's that you say? Chlorophyll looks green and therefore reflects green light, why wouldn't it absorb the most common wavelengths and just reflect the others?

Well that's a complicated question! Some chalk it up to how common retinal was.

Everybody and their mother had retinal in their system, but that meant that that the blue and red light went unused. So some thrifty single cells developed a new pigment to absorb the scraps, otherwise known as -- you guessed it -- chlorophyll!

Chlorophyll, being more complex yet more efficient than retinal, was prevalent in the predecessors to plants who didn't evolve anything new because it worked so gosh darned well. 

Source: http://m.livescience.com/1398-early-earth-purple-study-suggests.html

TL;DR: chlorophyll uses scraps of an older way of photosynthesis, most plants aren't looking to upgrade Overheating. Black would not only absorb useful wavelengths of light but all the other wavelengths too - increasing the temperature of the cells and requiring the plant to devote a lot of effort to cooling or avoiding the unwanted biochemical effects of heat. I'm very surprised I have not seen this answer here yet. 

The color of chrolophyll is a direct response to the light emitted by our sun.

It is no coincidence that plants have green pigmentation and that our sun's wavelength emission peak in the green visible spectrum of light.

You see, the Sun is so powerful, plants choose to reject most of the energy it emits as a form of protection. 

Pigments like Chlorophyll are very fragile and too much energy could destroy them. 

That is why there are several types of Chlorophyll (A, B and C) among other pigments that are aimed at catching the Blues and the Reds emitted by our Sun.

Efficiency is not as important as avoiding obliteration. Part of it has to do with the fact that plants would overheat if they absorbed too many different wavelengths of light.  The other part has to do with the fact that evolution is full of "good enough" solutions.  Almost nothing that has evolved, has evolved in a fully optimized form (very rare).  Everything improves to the point where it works well enough to serve its purpose, then stops improving since there's no pressure to do so. They do, plants can be grown well on pure green light only. Plants are **fuzzy** systems which rely on broad threshold based decision making and can turn most of the visible spectrum into useful light from plant material excitation mechanics.

Plants use **green** light to switch into growth modes as in nature this would signal overcrowding. 

Plants use **far-red** light to stimulate flowering, seeding and even dormancy due to the seasonal light patterns. 

You can grow plants in pure red and green, but this would be like you living without Vitamins or key minerals without sunlight. Sure, you could survive, but you would be unhealthy and unadaptable.

Plants use light to direct their growth and benefit strongly from the whole visible spectrum. If they were black of-course they would overheat and die, so they are carefully engineered to pick up **a mixed and balanced diet of light** to suit their needs acquired through evolution.     One piece that I haven't seen anyone mention is that the energy requirements of plants are tied to the production of ATP, which is the internal storage mechanism for plants.  Phosphate has a strong binding force and it takes a good bit of energy to free up phosphate atom, but it's a fixed amount of energy.

If it takes 67 units of energy (making up numbers here for the sake of clarity) to free up a phosphate atom and the plant is adsorbing 89 units of energy the excess 22 units are not just useless to the plant, it's potentially harmful as it's heat energy that can denature enzymes within the plant (as mentioned by other users) and cause dehydration.

 Heat has little to do with it, they would have just made smaller leaves or less chromophore. Plant chloroplasts evolved from a bacterial photosynthetic ancestor that used red and blue light. Bacterial photosynthesis evolved in the green "shadow" of early and dominant Archaeal photosystems that consumed much of the very abundant green-ish bands of sunlight at the Earth's surface. Basically, they had to work with the scraps. So you are seeing an evolutionary legacy. Other chromophores, such as carotenoids, help expand the absorption spectra of many plants to more than their visibly dominant chlorophylls.  Why? Because evolution is random and it is not goal-oriented. It just happens.

Adaptation can't create stuff out of thin air, but it instead works with what's already given. If no mutation causing black pigments arose in plants, it's not going to be present. Another example: human photoreceptors point backward, causing a blind spot. Octopus photoreceptors point outward, so there is no blind spot. That is obviously a better design, but humans aren't just gonna reverse the direction of their photoreceptors.

Also, genetic drift. Genetic drift is always the answer because it's a chance event, and it is always at play. Just like red and blue lights stimulate plant growth, green light seems to inhibit growth. So, perhaps it's beneficial to filter out much of the green light present in daylight. [Source](http://jxb.oxfordjournals.org/content/58/12/3099.abstract) Plants actually reflect very little green light [according to plant bilologists.](http://www.nytimes.com/2015/04/21/science/our-world-ever-green.html?_r=0).  However, as you point out there is some variation.  Apparently this variation is mostly due to non-chlorophyll related pigments within plant tissues.

&gt;Dr. Blankenship pointed out that plants were not really averse to green solar radiation: They generate other pigment molecules that, unlike chlorophyll, effectively absorb as much as 90 percent of green light from the sun. But that 10 percent reflection rate, compared with virtually 0 percent giveback for incident blue and red visible light, spells all the difference to our eyes. Were very sensitive in the green region, Dr. Blankenship said, so we see the little bit the plant doesnt absorb. The black plants would absorb too much heat and wither and die. The green allows them to absorb only the color spectrum need for photosynthesis. Some plants variegate their color in very bright light to control the amount of light absorbed. I can't link to the source now (search for "light absorption and photosynthesis" in the hyperphysics wiki) but I've read that the reason is that the first plants evolved in the sea after cyanobacteria. Cyanobacteria already dominated absorption in the green part of the spectrum so plants had to settle with the blue and red parts. There are a number of factors;

Even if 'black is the best', and I am not saying that it is - evolution refines what it starts with, it doesn't just spontaneously evolve the best possible way to do something. Furthermore, one way might give an advantage for any number of other factors even if the 'best possible way' seems apparent to us.

Another factor is why plants use light, specifically, the light is used to splitting water molecules into oxygen and hydrogen (for uses I won't go into here, but ultimately to produce more plant matter and energy). Light from the non-green spectrum is more efficient at doing this than the green parts of the light spectrum that our star produces.

Lastly, green wasn't always the dominant chloroplast on our planet...it was found in an upstart organism that robbed us of seeing something quite spectacular indeed. I won't spoil it, just check out [this documentary](http://www.youtube.com/watch?v=imiy_T0YErc&amp;t=11m0s) by Iain Stewart - an amazing series I heartily recommend watching all the way through. Some chilli plants are purple like in colour. 

Like the Black Pearl:

http://2.bp.blogspot.com/-ZDuBs3l9gwU/T2JcJEqho8I/AAAAAAAAFr0/AfZenvh0LRM/s1600/DSC00408.JPG

http://www.herbgarden.co.za/mountainherb/webherbfotos/big_ChilliBlackPearl4.JPG

http://i140.photobucket.com/albums/r38/picstor77/BlackPearl6-20-09.jpg
 Plants use energy from light to make food. Light is a mix of different colors each of which have different energies and plants have developed ways to absorbs the ones that fulfill their needs.
Some "colors" (i.e wavelengths) have too much energy (like UV) and they would do more harm than good. Actually, the visible spectrum of light as we see it doesn't has a specific wavelength which would characterize black light. An black item doesn't reflect colors, it absorbs the light. And therefore it also would be exposed to a larger ammount of photon energy, the surface temperature would be significantly higher if a leave would be black. You should have take into account that a leaf is still an organic tissue and that the photosynthesis needs to be driven by the chloroplasts, the major component of a leaf, which isn't absorbing light soley. It also requires diffusion of carbon dioxide into the cells. And the release of oxygen as a product of the photosynthesis. As well as the transmission of the nutrients through the plants tissue. Without being completely dry, water has to be transported from the roots into the leaves also. 

Anyway, mostly, the chloroplasts are the motor for the plants (as well as for algaes etc... ) and those are also defining the color of the leaves itself. In healthy state, primarily green. In autumn, when the exposure to sunlight decreases, the color is shifting as you know. Long story short, on the visible spectrum of light, green colors are categorized by the wavelenghts from 500 - 560nm. Red from 600 - 670nm. Without going into further details. Those are the most reactive / efficient wavelenght of photosynthesis known. The color of an individual chloroplast is defined by the specific color pigments found in cyanobacteria and the chloroplasts of algae and plants, called the chlorophyll. Those can be specifcied and categorized, for almost every wavelenght of visible light, from blue to red, there are specific different types of chlorophyll known, while the green spectrum is the most dominant known in nature, and chlorophyll which is reactive to the blue spectrum of light, is mostly only found in bacterias.

Being of green color itself, a green chlorophyll isn't completely specialized to that color and also reacts to red color / the red wavelenghts emitted by the sun. Being of green color doesn't mean that its reactive to green solely. It means reflection of the green spectrum of the visible light. And the absorbtion of blue and red wavelenghts. Which might be a bit confusing in this context. To be a bit more precise, the typical and most common chlorophyll b, which appears green to us, absorbes light of 460 nm (blue)  and 647 nm (red) at it's peak absorbtion rate while being exposed to white light. With a prevalence for blue wavelenghts. Simply said, green leafes have the benefit to react to blue and red. Just the green wavelenghts aren't being absorbed for photosynthesis and reflected to our eyes as we see them. 
 the sun emits the full light spectrum. Visible light is from 350 -  750 nm. The earth's atmosphere absorbs a lot of the spectrum. It also weakens certain wavelengths while others can go through unhindered. Green (around 500nm wavelength) is weakened the least. 
Does that have to do with plants colors?  Yes. It is pretty amazing how chlorophyll manages to have its absorption peak  almost perfectly matched to the spectra of the sun (at the surface of the earth).

Here is a comparison: http://plantphys.info/plant_physiology/images/solarlight.gif

*Should add that it isn't the sole reason for the exact colour of plants but it is better if someone who knows their stuff fills that in. The real answer: because nature doesn't always "create" the ideal solution to every problem, and there are features derived from ancestor organisms that are not necessarily advantageous.

For example, childbirth is an essential yet dangerous activity for human females, why didn't wider hips evolve to eliminate this issue?

If testes are essential for reproduction, why are they so vulnerable? Surely evolving more thermal resistance and keeping them internal would be better than exterior location?

If thermal stress is the issue for terrestrial plants, why aren't all aquatic plants and photosynthetic bacteria black? [deleted] The photons absorbed by the plant provide energy to chemical reactions that provide sustenance for the plant. The absorbed wavelengths correspond to bond energies and activation energies of these reactions. Interestingly, "green" photons are the most common wavelengths emitted by our sun. The highest intensity is arguably closer to [ultraviolet](http://www.fondriest.com/environmental-measurements/wp-content/uploads/2014/03/par_solar-radiation.jpg) or [blue/cyan](http://4.bp.blogspot.com/_fa6AZDCsHnY/S_xmXr6HTaI/AAAAAAAAACw/weKj6XTaf4M/s1600/Solar_Spectrum.png) depending on the measurement you want to believe.  However our eyes are very poor at blue color differentiation and our green color sensitivity is very high (lots of green detail in our environment very little blue detail).   However once the atmosphere comes into play it's essentially equal within the visible spectrum.   So what the sun puts out and what plants receive at sea level are two very different things.  Are red wavelengths a close second? And is that why the sun looks yellow? [Rayleigh scattering](https://en.wikipedia.org/wiki/Rayleigh_scattering#Reason_for_the_blue_color_of_the_sky) is basically why the sky looks blue, the sun looks yellow, and sunsets and sunrises look awesome. Ohhhh. This reminds of a science fair project I did.

I wanted to see if standard plants would grow in black light.

I took a few cardboard boxes, used flourescent shop lights in one, had them on a timer so they'd get about 8 hours of light a day, and I'd water them daily.

Used the blacklight flourescents in the other, same routine.

At FIRST, the plants in the black light seemed to do better, they sprouted about the same time, but they grew MUCH faster than the control box. After about a week or so, the control was growing fine, but the black light experiment were all starting to turn brown...

Eventually, the control group bloomed (I'd chosen some sort of herbs I think.. hell, it's been close to 30 years since I did this... lol) while the black light group completely died without blooming.

It was fun. :) Most of the replies you've gotten so far are perfect material for /r/badlinguistics.

In general, linguists agree that no language is more or less complex than another overall, and *definitely* agree that all natural human languages are effective at communicating. This is in part because there's no agreed upon rubric for what constitutes "complexity," and because there is a very strong pressure for *ineffective* language to be selected against.

&gt;Can very nuanced, subtle communication be lost in translation from one more 'complex' language to a simpler one?

A few thoughts: 

(1) information can be lost in translation, yes. More often than not, it's 'flavor.' That is, social and pragmatic nuances, or how prosodic and phonological factors affect an utterance. Translated poetry, to give an obvious example, will either lose rhythmic feeling and rhyme, or be forced to fit a rhythm and rhyme at the expense of more direct or idiomatic translation. 


(2) You would have to define complexity, before you could answer this. Every time I've seen a question like this, what the OP defines as complexity is just one way of communicating information, and the supposedly more complex language is less complex in other ways. For instance, communicating the syntactic role of a noun phrase can be achieved either through case marking, or through fixed word order. Which of these is more complex? Well, one's got structural requirements at the phrase level, another has morphological requirements at the word level. Or here's another example: think about Mandarin and English. Mandarin has fewer vowels than English. Is it therefore less complex? What about the fact that it has lexical tone that English lacks? 


&gt;Do different languages have varying degrees of 'effectiveness' in communicating? 

No. In general, you'll find that the people who argue they do (1) have not ever seriously studied linguistics, (2) tend not to know how global languages became global languages -- through colonization in the last few centuries, and (3) tend to want to support overly simplistic narratives that are based on ethnoracial or class prejudice.  They're also often really poorly thought-out. For instance, I've seen a lot of arguments in this thread that English is somehow superior for math and science, claiming that speakers of other languages have to switch to English, or borrow words from English to do math or science -- while conveniently forgetting that English borrowed most of those words from Latin and Greek. And that the speakers of other languages they're holding as examples were educated in English in former English colonies, so they were taught math and science terminology in English rather than their home languages.



I would link to peer reviewed papers, but this is so fundamental to the study of linguistics that I'm not even sure where to start, honestly. The claims that a given language is more complex than another, or better suited to abstract thought, or what have you have all gone the way of other racist pseudo-science,= like phrenology...which is to say, long gone from academia, but alive and well on reddit.  \\_()_/


EDIT: I inadvertently put my last paragraph in the middle. Fixed. 



 I remember asking on /r/linguistics or a similar sub years ago why some languages sound "faster" to my ear, and was directed to all sorts of research on language density and language speed. [Here's a little article for example](http://www.adn.com/article/language-study-japanese-spanish-fastest-spoken-tongues) that points out that languages have a spread of densities - basically how much information is expressed per syllable, and it's typically inversely related to the speed at which the language is spoken. Vietnamese is the most dense common language (English is up towards the top), while Japanese and Spanish score fairly low densities. But, in a syllable/second ranking Japanese and Spanish come in towards the top, and for the most part the ability to transmit information runs at a similar speed across all languages. I found the paper that article was talking about. [A cross-language perspective on speech information rate]
(https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;q=linguistic%20society%20of%20america%20density%20lyon&amp;ei=GhdKVdfBMYi6ggSWsYDQCQ&amp;url=http://www.ddl.ish-lyon.cnrs.fr/fulltext/pellegrino/Pellegrino_to%2520appear_Language.pdf&amp;ved=0CBwQFjAA&amp;usg=AFQjCNGzB_Oo7Nzq_bvudX7n3iowD2OeDw&amp;sig2=yKUuZGN2nG2k7AgsPYBR_w)
*Edited into hyperlink Does this not mean that unless those Japanese and Spanish speakers read their languages faster, English transmits information faster in text form? Or are they moving through words faster because the language is less dense? Still seems like not all of these languages were created equal as the product of density and speed wasn't strictly equal either. The factors that would determine that in text are very different from speech. You'd have to consider things like the "efficiency" of spelling or writing systems. For example, in Chinese each syllable is written as one character, and words are therefore one or two characters. So you can say a lot more in, say, a Chinese tweet than an English one. How do you define "faster in text"? Japanese uses chinese characters, which make possible to read a word or phrase much faster than in english (i.e: The amount of symbols one has to see in order know what is written is larger in English) Japanese uses modified chinese characes (kanji) but also use two other sets of symbols (hiragana and katakana) and all three are often used in a single sentence. The writing system is just... cluttered. But considering it is used and understood by a whole country, the problem is probably me. Yeah, hiragana is also quite used, for verbal conjugation, particles, word/expressions, etc. Kata for the imported words. But I really think the point still stands that japanese has more "information per symbol". The different writing systems are actually very helpful when reading. They delineate different words, replacing (to an extent) the role of spaces. They also help differentiate between homonyms, which are incredibly abundant in Japanese. The determining factor in reading rate (assuming basic proficiency) generally isn't the number of symbols you need to interpret, but the complexity of what those symbols describe. We can visually process characters very quickly, and so the efficiency of character use is not a major factor in reading rate across languages. As everyone else is saying, because the writing systems for different languages aren't directly comparable, that doesn't necessarily hold. However, presumably if the text was written phonetically in IPA (or a similar system), the Japanese and Spanish transliterations would be longer and would need to be read faster in order for the reader to pick up information at the same speed.  Are people whose first language was Japanese or Spanish faster readers in other languages their fluent with than the other languages' average native speaker (reader)? Since most people engage in 'Sub Vocalisation' when they read, the rate of information exchange from reading should approximately equal the rate of information exchange from speaking. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Wait... Some languages lack hypotheticals? Which languages specifically? 
 They might lack semantic hypotheticals but they would end up having other ways of expressing that a situation is hypothetical, or even "just being supposed", even if such an expression is only colloquial. Ah OK, so we can assume that every language has the ability to think through counterfactual situations and the like.  Even if it doesn't, native speakers would come up with a way to do it if they ever had to. :) /u/wareya and /u/kosmotron have answered well. Sapir-worf is one of those things that most non-linguists cite but hasn't been as relevant in the field as others think, kind of like how historians refer to the dark ages not because it was backwards or difficult but because we didn't know much about them, and that has since been renamed.  [deleted] [deleted] [deleted] [deleted] &gt;Now that you mention it, I can't think of a correct one word translation of 'mujhe'.

"Mujhe" is the first person singular in the dative case. I'm not sure how cases are done in Hindi, but in Marathi, we would refer to the equivalent (*"mala"*) as "chaturthi"; the dative case.

An equivalent in a European language would be "mir" in German. [deleted] Your Sanskrit example works exactly like Spanish "me gusta" or German "mir is kalt" with a dative subject marking the experiencer. An experiencer is an argument of a verb that doesn't actually *do* or *undergo* anything, but only *senses* or *feels*, for instance the subjects of "I see", "I know", "I love", etc. Some languages like Engliwlsh mark those like any subject, other like Dravidian languages (and I think Sanskrit too, but I know it less) have a special way go mark them with the same form as the recipient of a verb ("You give *me*", "you tell me",...) and are more consistent about it than Spanish or German.

It looks weird if you try to give them a naive word-for-word translation, "to me it pleases", "to me is the cold", "to me is the knowledge"... but then that's not an argument for the language being weird, it's an argument showing that word-for-word translation is fundamentally flawed.

 &gt; I found it really interesting that Hindi uses "The knowledge doesn't belong to me" (Muche nahi maloom) for "I don't know"

Wait, what? That's not what Mujhe Nahi Maloom means. A word for word literal translation of that is "Not known to me." Another equally common way to say "I don't  know" in hindi is "Mai nahi jaanta/jaanti" which is literally "I don't know" (last word different depending on male vs female speaker). Maloom vs Jaanta/Jaanti - both mean "know" but maloom is from urdu and jaanta/jaanti is from hindustani/sanskrit.

Where are you getting this from?   Another aspect is that you are imparting the flavor as the literal translation into English. English has no effect on what it means in Hindi even if the literal structural translation sound's odd. You can't assign English nuance to a non-English language.

Not a linguist but this was one of the hardest things to wrap my head around as a monolingual that fully learned another language.  Wrong translation. Mujhe nahin maaloom translates to "This is not known to me" literally.

The correct Hindi for what you are saying would be "Yeh mera gyan nahi hai", which would be a very awkward sentence that at least I have never seen being used. The closest you get to that is "Yeh mere gyan me nahi hai", which translates to "This is not within my knowledge.".

Trying to make things sound more profound than they are, much? &gt; And that the speakers of other languages they're holding as examples were educated in English in former English colonies, so they were taught math and science terminology in English rather than their home languages.

As a physicist and a non-native English speaker: This is due to the use of English textbooks, and that most international journals are written in English. There is nothing in English itself which makes it more suited to maths/physics etc., even if this language has acquired a lot of speciality words which are missing in my native language, making it harder to discuss some topics in my field without switching to English.

If I go back in time to before WW2, the journals are mostly written in German. The shift from German to English had nothing to do with the languages themselves. &gt;If I go back in time to before WW2, the journals are mostly written in German.

This is a fairly common misconception. You'll get closer to the truth if you say that most people published in one of a few "big" languages and most articles were translated into all of them. Mostly English, French, German and, to a somewhat lesser extent, Russian and Latin. Therefore, most of the scientists of the time were able to publish in their native tongue, but would at least understand the others or be able to get ahold of a translation. Thank you! So good to see a voice of reason who actually knows what they're talking about. I just saw this thread and my blood pressure has been going up with each response I read. Since this seems to be your field, how do you feel about something like the Kolmogorov complexity being a defintion of the effectiveness of  language? I don't think it's adequate. It's not something we use in linguistics, at least as far as I've ever encountered. It works just fine for simple strings like 4c1j5b2p0cv4w1x8rx2y39umgw5q85s7 (copied from wikipedia) but in actual language there's so much more going on, and nothing is ever as clear as the data in that string. Context is huge. Listener expectation is huge. 

There's been a lot written about how language is incredibly ambiguous in order to increase efficiency, because the ambiguity is always cleared up by context. That's how important external factors are. There's a whole subfield of linguistics, discourse analysis, which looks at exactly this sort of thing. It's the subfield of linguistics that tells you why people starting their Reddit posts with "So," is significant and why it's a useful part of communication. 

I think applying the idea of Kolmogorov complexity is oversimplifying the much messier reality of how natural language is actually presenting. What do you think of the idea that some languages are more prone to misunderstandings, and this makes them more suitable for jokes? I've heard for example that it's easier to make jokes in English than in German because we have a lot of homophones, the tell-tale vowel endings don't have to come before the end, and the verb-noun pairing also means you don't have to wait for the whole sentence before (mis)understanding. I'd say that Germans surely make jokes but maybe just not as puns. We do puns like nobodies business in Mandarin, but I wouldn't say Mandarin is over-all more prone to making jokes as a whole. 

If a language is in a state where it truly is more prone to misunderstandings, then some other factor will develop in the language to prevent that. It's why there are tones in Mandarin and Vietnamese; some useful information encoding was lost and tones came in to replace that information, so instead of "pa" and "ba" you have "p" and "p" after the P and B sounds merged. Kolmogorov complexity of what? Of a text? Of the set of words of the language?

If you choose the Kolomogorov complexity of texts translated among languages, there's no reason to believe the more complex text is semantically more effective; it could be a matter of arbitrary choices done in the syntax of the language, which just add to it's incompressible size; it could be adding some not necessarily relevant context, and so on. Also for low complexity, this language might be missing additional semantic context imprinted by more complex languages, so it's not necessarily the most effective either.

I'm not sure what you had in mind. Just wondering if you were to look at a simple interaction-level of language, would there be any language that stand out for quickly giving orders/transmitting facts? Leaving social language and general conversations out, is there a language with the highest spokentime-to-data ratio? If that makes any sense?
 Giving orders such as in the military would constitute a register, and that register would be 'designed' as it were to make things quick and clear. 

&gt;is there a language with the highest spokentime-to-data ratio?

It makes sense.  This has been studied and the answer, based on the hard numbers, is that they're all about the same. So for example Japanese has a faster syllable-per-second speed than English, but then it also requires more syllables for an equivalent amount of meaning. In the end things more or less even out. Mandarin has a far lower rate of syllable per second, but has much more information coded in a couple syllables than Japanese does in the same number of syllables. Exactly, didn't know how to say it but thanks for answering. Does this suggest that language tends towards a certain speed of meaning/s? Is there a limitation on how fast we can transfer meaning that prevents a race to the bottom caused by the efficiency of communicating a lot quickly? I guess that you get into a conflict:

A highly "compact" language would require to learn all the different meanings of (different-meaning) syllables, whereas when you can construct a meaning by sticking "simple-meaning" syllables together, you can start a communication of a certain complexity earlier - the learning curve of the language is different.

But more important: The simpler the syllable/lowest-order-component of a language, the lower is the probability to get a misunderstanding of a syllable - thus, you can speak faster without an increased risk of getting misunderstood. So basically, you "trade" complexity of basic components against the ability to speak &amp; hear faster between different languages - and there is the point where it more or less levels out. I think.

Edit:

So, tl;dr: yes.

And now I seriously hope that I didn't misunderstood your question, Im not sure about

&gt; race to the bottom caused by the efficiency of communicating a lot quickly? That's what I was asking, thanks. As others noted, there are trade-offs. To exemplify, think about how the military [transmits letters and numbers over radio](http://en.wikipedia.org/wiki/NATO_phonetic_alphabet). If they wanted to transmit that information as quickly as possible, they might just use the standard forms we have in English (i.e. 'A' = 'a', 'B' = 'be', 'C' = 'see', etc.), those forms (for the most part) are single syllables and can be uttered very quickly. The problem is that they're confusable! So to deal with that, we can make the forms longer (i.e. 'A' = 'alfa', 'B' = 'bravo', 'C' = 'charlie'). We've made the system more "inefficient" in so far as it takes longer to say the same thing, but we're much less likely to make an error.

You actually can find similar things for other data transfer issues. For transferring data on the internet, [TCP/IP](http://en.wikipedia.org/wiki/Transmission_Control_Protocol#Reliable_transmission) is a common protocol and it has what's called a "handshake". It sends data, the receiver sends a "handshake" to let the sender know the information arrived, and transmission continues. Obviously, this is slower than just pouring out the data and hoping that the receiver gets it (because you have to wait for the handshake), but it ensures the information gets there. Compare that to [UDP](http://en.wikipedia.org/wiki/User_Datagram_Protocol) which has no handshake, therefore faster but less reliable. Although you're correct to discredit the classical Whorfian claim that languages limit the kinds of thoughts you can have, I think you may be throwing the baby out with the bathwater when you (along with many other linguists) claim that all languages are equally effective for communicating any idea. I think this idea stems from (1) the notion of universal grammar, and (2) a backlash to the racist intellectualism of the 19th and 20th centuries. **Modern research in psycholinguistics is beginning to show that languages *are* in fact different with regard to how easily they can be learned and how easily they can convey certain concepts.**

The classic example is Piraha, a language which does not have numbers. One classic study [\(Frank et al. 2008\)](http://www.sciencedirect.com/science/article/pii/S0010027708001042) argues that the Piraha can in fact compare large cardinalities, but are unable to remember or communicate precisely about them. I don't think anyone could argue that Piraha would be just as suitable a language for mathematics as Italian.

In a similar vein [Bleses et al. \(2008\)](http://www.ncbi.nlm.nih.gov/pubmed/18588717) show that not all languages are equally easy to learn, due mostly to their phonotactic structures; languages with lots of vowels strung together, like Danish, are harder for children to learn.

When we view language not as an innate and ideal evolved system (as Chomsky does), but instead as an evolving system itself, we actually *expect* to find differences in languages (see [Christiansen and Chater 2008](http://www.psych.cornell.edu/sec/pubPeople/mhc27/cc-BBS-2008.pdf) for an excellent introduction to this idea). Just as different organisms are better suited to different environments, different languages are better suited to different cultures. In Japan, honor and respect are very important values, and thus we find [a complex linguistic system](http://en.wikipedia.org/wiki/Japanese_honorifics) used to convey different degrees of respect. It would seem silly to say that this language is just as well suited to show deference as English.

As evolving systems, languages are constantly being tweaked to be easier to learn and communicate with. Dialects that meet these desiderata will persist, while those that don't will be mis-learned and mis-used, mutating into a more effective form. The only reason that, in general, languages are so similar in their communicative power is that the communicative needs of human societies are surprisingly similar, especially when you look to aspects of language deeper than vocabulary. However, despite this superficial similarity, differences do exist, and to ignore them is to ignore a fascinating and important aspect of language. &gt; claim that all languages are equally effective for communicating any idea.

No one has claimed this though. We all recognize that there are cultural effects on language, particularly vocabulary, and have discussed this at length in our comments. I think that you've misunderstood us rather severely; essentially, we're discussing "effectiveness" in terms of the needs of the language's users, but you're discussing "effectiveness" in terms of how well a language encodes particular concepts, like numbers or deference. These are two very different things.

If the question was "are there any languages that are more or less effective for discussing math or theoretical physics," then our answers would probably be different. (We might disagree about deference - there are many methods to express deference, and we do it in English quite a bit, and I don't think that we can assume Japanese is "better"; it's just different.)

However, we would still point out that discussing "languages" are abstractions, and in this case the abstraction can get in the way -- if it's difficult to discuss theoretical physics in !Kung it's because there are no theoretical physicists who speak !Kung with knowledge of the relevant concepts who can borrow or create the relevant vocabulary. The properties of the languages here are determined by their speakers, which I think is exactly what you're saying when you talk about cultural influence.

&gt;In a similar vein Bleses et al. (2008)[2] show that not all languages are equally easy to learn, due mostly to their phonotactic structures; languages with lots of vowels strung together, like Danish, are harder for children to learn.

It's very important not to overstate the implications of this study though. This is one study, one language, and one particular feature. The reason it's interesting is *because* this kind of finding is so rare.  [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Thank you for this great answer. Two points I would like to bring up, though not due to disagreement:

1) Languages are always expressed within a cultural context, hence the effectiveness within a given culture are bound to the language (or the version of the language) itself. Example: Someone speaking 19th century London English would be less effective in getting their point across in 2015 North Carolina than someone from that context, not because of "dictionary lexicality" or "syntax" or anything like that but because of context and familiarity with colloquial expressions of the receiver. 

2) Referring back to your point about definitions of "effectiveness," sometimes a language can be more ambiguous than another in getting a certain point across, or take more words to explain. I work as a translator, and speak four languages, three of them well, and often find that I can make a specific argument more economically and precisely in one language, but have to accept either ambiguity or more specificity (or longer explanations) in another. But that doesn't make the economical language more "effective," necessarily. The ambiguity can infuse a phrase with richness and persuasiveness, while the longer explanation often grants greater precision. E.g. in Chinese you could say "I have a matter [to attend to]", implying some kind of urgent importance), but in English saying that would either require some more specifics ("I need to leave to do my homework") or be some kind of dramatic movie line. &gt;In general, linguists agree that no language is more or less complex than another overall, and definitely agree that all natural human languages are effective at communicating. This is in part because there's no agreed upon rubric for what constitutes "complexity,"...

Without knowing or asserting *anything* about linguistics itself, I'm having trouble with the idea that there's consensus over something which doesn't have an "agreed upon rubric" for its own definition. They can agree that the two things are unrelated, so it doesn't matter if we can't measure one of them. 

I can't put a measure on how cool a watch looks, but I can tell you that how cool it looks doesn't determine the watch's accuracy.  That's not a fitting example. A better parallel would be: I don't have a definition for a watch's coolness, but I can assert with certainty that all watches are equally cool. The quote I highlighted contained talk about effectiveness, but that's just because it was in the middle of the two parts I was talking about:

&gt;In general, **linguists agree that no language is more or less complex** than another overall, and definitely agree that all natural human languages are effective at communicating. This is in part because there's **no agreed upon rubric for what constitutes "complexity,"**...

I've bolded the relevant sections. The other response to your post fixes your metaphor.

Someone else has posted a quote from the Linguistic Society of America in which they say all languages are equally complex. I'd imagine they'd have to have at least internal agreement on complexity to come to findings about it. I think they mean complexity overall. There are so many facets to a language that it is essentially impossible to rate a language at 6/10 on the "complexity scale", for example. But linguists generally acknowledge that while a Language B might have this particular quirk that is complex in comparison to Language A, Language A might be more complex in a different way than B. Thus, you can't really judge one more complex than the other overall. would it be inaccurate to say that some languages are more effective at communicating various specific things than others? I've been studying chinese, and from what I've learned in my classes there are some things that you say in english that you'd simply not say in chinese and vice versa, or at least you would say something that is kind of different instead; would some languages be better for describing different situations, like relational/scientific etc? &gt; would it be inaccurate to say that some languages are more effective at communicating various specific things than others?

Certain languages are better at explaining certain specific things: for instance, languages that have evolved in the context of industrial revolutions may be more adept at explaining the parts of an engine, while languages that have evolved in the context of non-industrial farming cultures may be better at explaining the shifting colors of plants due to seasonal changes. 

It doesn't make one language better or more effective overall, as the vocabulary of our imaginary industrial language can be incorporated into our imaginary non-industrial language and vice versa; it just clues us in to what is important to that culture and their survival.  [deleted] [deleted] Linguists have slowly started using algorithmic information theory to describe the complexities of natural language grammars (i.e. Kolmogorov complexity).  See [here] (http://ling50.mit.edu/wp-content/uploads/Goldsmith-slides.pdf).  This also proved to be useful when describing morphological complexity. For instance, Max Bane at UChicago computed upper bounds on the morpho-Kolmogorov complexity of various languages using biblical corpora (upper bounds since k complexity is not computable in general).  Danish seems to be ahead of English. You can read the paper [here](http://www.lingref.com/cpp/wccfl/26/paper1657.pdf).  Of course this says nothing about the communicative efficacy of a given language, but 'complexity' is not foreign to nor dismissed so easily by linguists.  This study is specifically evaluating the length of grammars to ascertain which most easily turn into machine language to input into a Turing Machine. 

They use the calculus term "length", and the term "complexity" interchangeably in an effort to figure out which human language grammar is most applicable to machine language. 

As well, the parameters for determining "length" rely on a variety of other factors, including the use of an outside compiler. 

I do not think this study relates to this current argument.  I only have a cursory understanding of this, so I might be wrong. The end goal it seems is not to find a natural language grammar most applicable to machine language, but to find the most 'simple grammar' based on the data (i.e a corpus).  This is done by means of minimum description length analysis, which essentially says the grammar we want is argmin_g ( length(g) + log(1/(Pr(data | g)). Length, meaning complexity, is the central focus here, because it's hard to quantify.  We can consider the complexity to be the length of the shortest program that outputs a description of the grammar when fed into a universal Turing machine. But again this is Kolmogorov complexity. How useful is this? [deleted] Follow-up: are the languages today more effective than yesterday's? You said yourself that ineffective language is selected against, so the way our languages evolve must be making them more efficient, yes? And what about spacially effectiveness? Can't character based languages like Chinese send more information in less space? &gt; are the languages today more effective than yesterday's? You said yourself that ineffective language is selected against, so the way our languages evolve must be making them more efficient, yes?

They also said that you can't really measure the efficiency of a language, so you can't say that languages are more efficient today than yesterday.

&gt; Can't character based languages like Chinese send more information in less space?

You're confusing languages and writing systems here. Writing systems can be based on characters or whatever, but all spoken languages are based on phonemes. A writing systems is not an inherent part of a language, and there is no reason why you couldn't write Chinese with, say, the Latin alphabet. In fact, that is exactly what you do when you spell the Chinese capital as Beijing. Languages today are likely to be more effective than languages yesterday *for today's contexts and usages* [deleted] [deleted] I've read several times that math tests scores among children in China are much better than their counterparts in North America. I've read in all of these accounts that this was due to the structure of the English language that makes math more difficult.

I've run this by my bilingual gf(she's Chinese) and she also confirmed that the way math questions are phrased makes it easier in Chinese(at least easier to understand).

Can you comment on this? I'm not trying to get into a Mandarin/Cantonese vs English debate, but do the things I read and the confirmation from my gf have any truth? I read an article on this once.  [Here's](http://www.wsj.com/articles/the-best-language-for-math-1410304008) a similar WSJ article that suggests the same. Two points were interesting to me:


In English, even our one syllable numbers are often inefficient for speed. Enunciate "three" (inefficient) compared to "two" (very efficient).  Number recall correlates with how quickly you can state the numbers. Native speakers of languages with shorter numbers may recall longer strings of numbers on average than English speakers.


Some numbering systems may be more intuitive than English. If I want to add 11+12, mentally I break down 11 into 10 and 1, break down 12 into 10 and 2, add those components, and then reassemble as 23. Instead of "eleven" in other languages the word for 11 might translate directly to "ten and one".   For such languages arithmetic may be more intuitive because the mental break down and reassembly parts are organically accomplished in the word choices. More intuitive arithmetic may allow students to grasp it more soundly at a younger age.  For a more dramatic example, consider the boost in mathematics when going from Roman numerals to Arabic numbers.  Adding XVII + IX is less intuitive than adding 17 + 9 because your mind has added steps to break things into parts. Romans didn't use subtractive numbers (like IV or IX) in arithmetic. The actual problem would be:

       XVII
    + VIIII
    = XVVIIIIII = XXVI

Which is super easy to do. Addition basically just becomes playing 2048. Roman arithmetic is really hard to grasp for modern people because it's a weird form of base 5, but it was very intuitive and easy for Romans. &gt;If I want to add 11+12, mentally I break down 11 into 10 and 1, break down 12 into 10 and 2, add those components, and then reassemble as 23. Instead of "eleven" in other languages the word for 11 might translate directly to "ten and one". 

Ignoring 11-19, isn't it already the case for english numbers? **Two** hundred **four**ty **five** plus **three** hundred **fif**ty **four**, the pairs of numbers are obvious. 11-19 can't be ignored because they're commonly used.

We have special names for 11-19, but Spanish only has special names for 11-15, for instance. And, AFAIK, Chinese doesn't have special names for 11+, starting immediately with "ten one" at 11. &gt;I've read in all of these accounts that this was due to the structure of the English language that makes math more difficult.

Where the hell would you even find such a thing? What's repeated over and over again is that Chinese children (especially in the bigger cities: comparisons are usually not made with Chinese children living in smaller cities) spend much, much, much more time in school than say European or American children, and that's by far the most common explanation for why Chinese children perform better. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] I have a question to add to OP's. Is it easier for some people to learn certain languages than others? Like say would it be easier for a person who speaks English to learn Chinese than it would be for them to learn Arabic? I am sure that they could learn a Latin based language easier but what about completely different languages like that? Yes, language learning difficulty is very much dependent on native languages and other languages one knows. The Foreign Service Institute has created a [tier system of languages](http://www.effectivelanguagelearning.com/language-guide/language-difficulty) based on average class hours required for a native English speaker to learn them.

Generally, Romance and Germanic languages are the easiest for English speakers (not surprising, since English is a Germanic language with a quarter of its vocabulary from French and another quarter from Latin), then certain lingua francas (Indonesian and Swahili), then other Indo-European languages, then most other languages, then Arabic and East Asian languages.

Other languages have different 'tier' lists, mostly based on genetic relation (linguistic families) and shared vocabulary. For instance, for Mandarin speakers, other Chinese languages are the easiest, probably followed by Japanese (due to shared vocabulary and characters), then Korean and Vietnamese. In particular, French is considered quite difficult for Chinese speakers, although it is one of the easiest for English speakers.

Note, however, that it also depends on which combination of the four main skills (listening, speaking, reading, writing) one is learning, and varies wildly from person to person, with the most important factor of course being motivation. &gt; Is it easier for some people to learn certain languages than others?

Absolutely! Some languages are closely related to each other, others are only distantly related, and this is more or less a continuous scale. It's far easier to learn languages that are similar to your first language, since there are fewer new concepts.

For example, French is generally considered a comparatively easy language for a native English speaker. Of course there is a certain amount of common vocabulary due to the Latin heritage and so on, but it is also structured relatively similarly, in global terms. There are some new concepts, like extra ways to conjugate verbs and almost everything having gender, but the grammar broadly functions similarly.

Chinese is much harder for an English speaker to learn, and one major reason is the use of [tone](http://en.wikipedia.org/wiki/Tone_%28linguistics%29#Mechanics). In English, tone is used to convey emotion or context, indicating sarcasm, humour, questions, and so on. In French, tone is used in a broadly similar way, but in Chinese, it serves as the sole way to distinguish different words (often with entirely different meanings).

There can also be almost physical difficulties in learning the phonemes required for another language, since no language makes use of all the sounds that a human can produce. Famously, several Southern African languages have [dozens of consonants produced by clicking the tongue in different ways](http://en.wikipedia.org/wiki/Click_consonant) (none of which exist in English), but there are plenty of more ordinary sounds that are not present in all languages. For example, the Arabic letters "" and "" have distinct pronunciations, but both sounds like an "h" to most English speakers.

It's tempting to look at the subjectively difficult bits of other languages and think that English is comparatively simple, but there are equal complications for people trying to learn English as a second language. For example, Russian has no articles, causing native speakers of Russian to struggle with where to place "a" and "the" in English, and Japanese people learning English can have difficulty with "l" and "r" sounds, which are not distinguished in Japanese.

I've probably picked too many examples, but my point is that there there can be aspects 

**TL;DR: It all depends on how different the student's native language is from the language they wish to learn, and all human languages have both similarities and differences.** &gt; Of course there is a certain amount of common vocabulary due to the Latin heritage and so on

Just to nitpick, English does not have a Latin heritage. Is is a Germanic language. It is descended from [Proto-Germanic](http://en.wikipedia.org/wiki/Proto-Germanic_language). Proto-Germanic is also an ancestor of modern German, but it is **not** the same thing as German. English and French (and the vast majority of European languages) have a common ancestor in [Proto Indo-European](http://en.wikipedia.org/wiki/Proto-Indo-European_language). French has also had direct influence on English as a result of the Norman conquest, but it was mostly loanwords, not changing the grammar. &gt; English does not have a Latin heritage

It's not a Romance language, but it does has an exceptional amount of Latin-derived vocabulary for a non-Romance language (much of it dating back to before the Norman conquest, due to pre-migration contact with the Roman Empire, and later to the adoption of Christianity). [deleted] [deleted] [deleted] [deleted] A reminder to all commenters: anecdotes are not allowed and all statements must be based on peer-reviewed research. Please review our [guidelines](http://www.reddit.com/r/AskScience/wiki/quickstart/sources) for more information. &gt;Do different languages have varying degrees of 'effectiveness' in communicating?

If we interpret "effectiveness in communicating" to mean "amount of information transferred per time unit", then [no](http://www.ddl.ish-lyon.cnrs.fr/fulltext/pellegrino/Pellegrino_to%20appear_Language.pdf). In short, [the languages that have less informative syllables make up for it by talking faster](http://i.imgur.com/wHjuO.jpg) (or in [table from](http://i.imgur.com/y6fxy.jpg)).

Thanks for [Lurker378](http://www.reddit.com/r/askscience/comments/15o7bu/what_spoken_language_carries_the_most_information/c7o91s9) fopr posting it two years ago. this is an interesting graph, but i dont really understand it. does english have a higher information density and higher syllabic rate than german? this would mean english does then has a higher amount of information transferred per time unit right? Yes, but then again consider the margin of error (+/- .08 and .09, respectively) and they are basically equal. The largest outlier is Japanese, and I suspect this is due to honorifics, which "occupy" syllables but don't carry much semantic information. I bet that a Japanese person speaking informally is probably closer to .88 in information rate. Another commenter addressed your main question well, but I wanted to add to it. It's worth realizing that when we measure the information density of a language, we're necessarily measuring how that language is used *by its speakers*. That means that the culture of the speakers is going to play a role. In Japanese, for instance, the *culture* demands politeness in the form of honorifics, but the *language* does not require them in and of itself. If Japanese culture changed so that the politeness wasn't required, the language would drop the general use of honorifics too. So although you may find languages that have low information transfer rates, that doesn't necessarily mean the language is inefficient. It may just be that the culture which uses that language requires the language to be somewhat inefficient.

There are also trade-offs between conciseness and redundancy. In German, the use of marking grammatical gender is redundant. If I mark gender on articles (e.g. der, die, das), then marking it as well on adjectives is redundant. Hell, even the use of grammatical gender in the first place is somewhat redundant, once I've said the noun, the grammatical gender information doesn't add much to the meaning of the sentence. But, the redundancy makes it easier to recover from errors, so that if I mis-hear something, I can still figure out what was said relatively easily.

Just food for thought when we're talking about information transferred per unit time. "Effective" is hard to quantify, but there is research that suggests that the "information rate" (bits of data transmitted orally per unit time) is constant across languages. This is non-obvious because some languages use few sounds (like Japanese) but make up for it by simply using more syllables per second. 

https://www.reddit.com/r/askscience/comments/15o7bu/what_spoken_language_carries_the_most_information/

First answer and it's reply cite all the sources.
 Yes, all languages are equally effective.

This is a standard thing in linguistics which you will find in any introductory textbook and is basically taken as a given by anyone working in the field after decades of looking at languages across the globe. It's taken as a given because that's what the evidence supports. While I'd love to provide you with all that evidence, I'm afraid it's not really feasible to summarise a century of research on linguistics in a single Reddit comment. At the very least it would require a semester of a university course to cover this in any appreciable detail. However feel free to run it by /r/linguistics to confirm this point, as many people there would be happy to spend the time going over specific examples of how this plays out as I'm saying it does.

All languages are equally effective at communicating complex ideas, managing social interactions, dealing with complex tasks, and describing anything that would need to be described.

There are no "primitive languages". There are no languages which are globally simpler than other languages. If such differences do exist, they're insignificant and immeasurable.

I'm a little bummed out to see all the speculation going on here, especially considering how much stuff is being posted that's just wrong.

(edited for clarity) The effectiveness^1 of a language seems to me to be more of a question of the characteristics of the people who use the language than the language itself, so it's not a lingual property per se, but depends on the context the communicating parties share. Let's say you live in a land that has never heard of machinery. Try expressing what a nuclear reactor is and you will quickly run into trouble, not being able to explain some things and having to resort to showing things, mathematics, sketches, etc. until your audience develops an understanding of the concepts behind it, and perhaps invents or adopts words for them. Before they do that, their language can be said to be ineffective to communicate the idea of a nuclear reactor.

Similarly, when we scientists first introduce an idea, it often takes many, many words, equations, and images, to describe it. One of the first things we often do is to introduce a name for it. If the idea is important enough, one of the names may stick. Now, if you try to translate the idea to another language, you need to either make up a new word, or introduce the foreign word into your language. This is very noticeable in physics, where we nowadays often use a great many English words when talking about things. Before you do that, the language lacks the capability of (concisely) expressing the idea. One could say that the language gained effectiveness. The more abstract a concept is, the more likely it would seem that a language doesn't have the means to express it. 

As such, I think it is ill-conceived to even talk about languages being more effective than others, because it depends more on the average level of education of their speakers than the languages themselves. It is entirely trivial to create a highly effective language by simply introducing new words for every concept you encounter, but it's also highly useless if the people you're trying to communicate with don't also know the concepts and learn the words for them.

^1 The effect of a language is to generate a representation of an idea in your head. As such, a language could be said to be effective if you can successfully communicate said idea. &gt; it's not a lingual property per se, but depends on the context the communicating parties share.

This is pretty insightful and I'd agree. As an example, Japanese as a language is not inherently more polite than English. Rather the Japanese culture just has particular norms that require the use of more polite language, and a bunch of Japanese guys forced to use English would still follow the cultural norms.

&gt;Try expressing what a nuclear reactor is and you will quickly run into trouble 

As a linguist the problem is that while most people do not have daily exposure to nuclear reactors, they do to language, so they are much more inclined to believe that they are an expert on language. A guy with a couple years of undergraduate German will be much more likely to try to put a linguist in their place than a

&gt;I think it is ill-conceived to even talk about languages being more effective than others, because it depends more on the average level of education of their speakers than the languages themselves.

Absolutely correct.

Excellent comment all around. Thank you. &gt; It's taken as a given because that's what the evidence supports. While I'd love to provide you with all that evidence, I'm afraid it's not really feasible to summarise a century of research on linguistics in a single Reddit comment.

Can you (or someone) at least give examples of the *kinds* of evidence? For example, when explaining the evidence for evolution, I might very broadly name the fossil record, homologous anatomy in related organisms, homologous DNA sequence in related organisms, and cases where evolution has been observed and measured while it happens - this is even more than a century of work but it can be broadly categorized. What are the comparable observations or experiments that led to this conclusion in linguistics? E.g. are there some pivotal experiments testing comprehension and knowledge retention with the same text or speech in different languages? Or has anyone done a comprehensive survey of how many characters or syllables it takes to express a given thought in different languages? All languages are equal because of all languages which have been studied the speakers of said languages have no difficulty expressing complex thoughts, emotions, ideas, lessons to their young, or really any topic to which they may otherwise be introduced. What I mean by that is that to speak in terms of things like astronomy you'd first need to be taught what that conversation is, as the Physics flaired user has already stated here. My English is fine and most would agree that English is a robust language, but I cannot speak on the topic of astronomy because I've never learned the relevant terms or ideas. Teach me and I could. Teach a speaker of Xhosa and they could as well, as presumably their children are taught since reading the stars would have some potential value in that setting.

No language has ever been shown to be deficient in any of these regards. Of the 7000 or so languages, among those that have been well documented or even mildly documented, none have shown an inability to handle social affairs. None have shown an inability to express any idea which may be had by the speakers. Not one has shown any signs of "primitiveness" or overall simplicity as compared to other languages. 

That's the evidence which has been collected by thousands of people researching for the past century. That is what is meant when we say "all languages are equally complex".

Languages neither simplify overall nor become more complex overall by any significant degree, and any language which were made artificially complex would simplify back down to the general level of complexity within a generation of having native speakers. Likewise a language that was constructed to be simple and regular would again within a generation develop the same general level of complexity of any other language. This has been attested. Native speakers of Esperanto do not speak it the way it was originally developed and by having native speakers it has gained features that the inventor would certainly not approve of. Liturgical Sanskrit as a spoken language (which does exist) has likewise simplified losing a lot of the externally supported complexity. How do you reconcile this claim with languages like [Guugu Yimithirr](http://en.wikipedia.org/wiki/Guugu_Yimithirr_language), which [have no words for left or right](http://www.nytimes.com/2010/08/29/magazine/29language-t.html?_r=0)?  Is that not an example of a language which is less effective at communicating anything which involves relative directions?

BTW, can you tell me what phrase to look for, when referencing this in a linguistics book?  I don't remember being told anything like that in my introductory linguistics course, but I have my textbook here so I can look it up if I know what it's called. &gt; How do you reconcile this claim with languages like Guugu Yimithirr, which have no words for left or right?

GY speakers mainly use geographic, as opposed to egocentric directions; so yes, they can accurately and effectively convey direction. 

The Wikipedia article also mentions that this notion is being debated and provides a rather quick but interesting read on the subject, [found here](http://pages.ucsd.edu/~jhaviland/Publications/ETHOSw.Diags.pdf), which notes that the GY language does in fact include relative calculations of direction. 

EDIT: Word Choice [deleted] [deleted] [deleted] /u/Ar_Nimruzir addressed this well. The word you might want to search for is "spacial relations". There are a number of linguists working specifically on how different languages treat this differently. They're still all effective; they just use different reference points. 

Just as an added point: I personally find using cardinal directions as in GY is *more* effective than telling someone "turn left at McDonalds" because for all i know they got lost, doubled back and are now turning what used to be right when I gave the directions in the first place. Where I grew up it was pretty common to say "turn North on Franklin Street" and not "turn left on Franklin Street". Thanks /u/keylian! I appreciate the shout out!

And /u/yepthatguy2, if you are truly interested in how the perception of spatial relations influence language you should look into the Navajo peoples and how their conception of self and person-hood are tied to geography and direction. It's some wild stuff; their tales of creation lose almost all culturally imbued meaning when told outside of a specific geographic context.  I'm curious what you think of John Joseph and Frederick Newmeyer's article, "[All Languages are Equally Complex: The Rise and Fall of a Consensus.](http://www.research.ed.ac.uk/portal/files/4790851/Joseph_ALAEC_pure.pdf)" This doesn't seem like much of an answer.  You state all languages are equally effective because it is taken as a given in the field.  I'm not so sure I agree, but you're not leaving much open to discussion.  

Forty years ago, psychiatrists knew beyond a shadow of a doubt that schizophrenia is caused by bad mothers.  Now we're not so sure anymore.  

Your answer looks to me like, "All languages are equally effective because it's a given.  And, all exceptions are meaningless."  It seems more like dogma than an answer.  

If all linguists agree that all languages are equally effective, then I think it would follow that even a basic linguist could prove that statement is, in fact, true. &gt; Forty years ago, psychiatrists knew beyond a shadow of a doubt that schizophrenia is caused by bad mothers. Now we're not so sure anymore.

I don't think you're in the right place for the "why should we trust experts? experts have been wrong before" argument. &gt;because it is taken as a given in the field

No I'm saying it's taken as a given in the field because that's the position supported by the evidence.

&gt;Your answer looks to me like, "All languages are equally effective because it's a given. And, all exceptions are meaningless." It seems more like dogma than an answer.

Since you're suggest that such an exception exists I'd be more than interested in hearing what that would be.

I've edited my comment above for clarity since it seems it was misunderstood. I have an off-topic question that I really hope doesn't make me sound like a dick: What constitutes evidence in Linguistics? I've always been somewhat interested in the field, and I never really considered that question. Depending on the sub-field of Linguistics, you can have objective numerical data like in Phonetics, such as measuring the duration, formants, muscle movement, or you can have less numerical evidence, like many examples of a specific sound change happening in a language. For language effectiveness, you would want to have the test languages try to convey the same amount of information, then analyze the time, syllable count, syllable speed, etc.  In addition to what /u/starfuzion said there's a lot of statistics as well. Statistical significance of trends, distributions and pretty much anything quantifiable is a really big deal, and you'll see linguistics papers published that look like more math than linguistics if you didn't know what the subject of the paper was. &gt; Are all languages equally as effective?

It depends on the context and goals we use to define their effectiveness. For example, a language with no vocabulary for modern technology, no numbers, and no words relating to commerce would have a really rough time describing a day in the life of a Tokyo businessman in the kind of detail a Tokyo businessman would consider helpful. Let's say Piraha is just not sufficient for that goal or context.

In much the same way, however, Japanese would be more or less at a loss in describing succinctly the events of yesterday's fishing venture, on account of it not having the kind of dedicated vocabulary for what was caught, how it was caught, how the speaker learned it was caught, etc. It certainly could describe them, but to a Piraha it would be somewhat of a downgrade from the ease of communicating such things in their own language.

But a more important point to be made is all languages *can describe*, to varying degrees of detail or in different culturally relevant terms, any real event that takes place, and most imaginary ones that don't take place as well. The relationship to an utterance and what that utterance represents, its semantics, is never one-to-one. There will always be a vast wealth of information that could be relevant, that if provided would communicate a 100% understanding of the sentence's significance, that is unabashedly *omitted in its entirety*. If some language encodes more information succinctly and clearly than another one, it's usually on the margin of one bajillionth of the information that could be communicated (theoretically by a super-language).

Trying to compare how much is communicated in any given language is simply meaningless given that all languages communicate so comparatively little.

&gt; Do different language have varying degrees of effectiveness in communicating?

Yes, but only in specific contexts and with specific goals. In general, all languages fit the overall goal of being able to communicate anything within a very high chance of being understood.

&gt; Can very nuanced, subtle communication be lost in translation from one more complex language to a simpler one?

Well, the terms spectrum complex~simple doesn't really apply to languages, but things can be lost in translation from one language to the next - but nonetheless the very core meaning of the utterance is usually intact. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Driller here.

There are three main issues. One is heat, and the other is pressure, and the final one is hole stability.

Heat from geothermal sources, or just generated from the drill string, causes damage to the drill string components. Some companies have giant radiators that are installed on the surface to cool drilling fluid down before being pumped back down hole, but in the end the cumulative heat reduces the amount of time that is able to be spent downhole and drilling to less than 200 hours per trip.

Pressure is another problem. As you get deeper, the pressure exerted on the formation from drilling fluid gets higher and higher. At the same time, the horsepower required to pump the drilling fluid back up to the surface becomes much greater. You would need enormously powerful pumps capable of generating as much as 10,000 psi.

Finally you have hole stability. This is the ability of the hole to not collapse in on itself, potentially trapping the drill string and getting it stuck. To mitigate this problem casing is run through various sections of the hole. The problem is that every time you run casing, you have to then drill with a smaller drill bit and BHA/drill string. Eventually you can't run anything smaller and are at the limit of what can be reasonably drilled.

The potential to drill deeper than 40,000 feet is there, but absent funding for such a project I find it hard to believe that anyone would undertake such an endeavor. It can be done deeper than 40,000 ft, but not by much.

EDIT: RIP my inbox. Also, [apparently BP is developing very high pressure equipment (20k PSI) to enable very deep offshore wells](http://www.bp.com/en/global/corporate/about-bp/bp-and-technology/more-recovery/deepwater-frontiers.html) Thanks to /u/fanofdeja for that bit of info.

EDIT 2: Gilded?! Thank you kind stranger. What about digging a big hole, like an open cut mine? Yes, after reading some of the replies this is what I want the scientists to calculate for me. And may draw a diagram as well.

Basically make an upside down cone in the earth. How large of an opening would we need to get a hole that's say...500,000ft deep in the earth. 500,000 feet? That's about 94 and a half miles. The crust on average is 30 miles thick, and can go up to the mid 40s in areas, or more. 

At 94 miles you're blasting through the crust and well into the mantle. And you are NOT putting a hole in that. Theoretically, what is stopping us from drilling into the mantle? I found this quote from a [question on stackexchange](http://earthscience.stackexchange.com/questions/246/can-we-really-travel-through-earths-core):

&gt;According to Lide (2006) the pressure in the inner core is 330 to 360 GPa, at which iron becomes a solid even at the high temperatures in the core. If you could drill as far as the core you would have to build a device that's able to withstand that pressure, because if you can't, the material surrounding your well would immediately become liquid and fill the hole, if not shoot up your well towards the surface.

&gt;There are no physical walls between the layers of the Earth, only transition zones where temperature and pressure combinations lead to different behaviour of the materials. An example is the Mohorovii discontinuity, or Moho, which is the boundary between crust and mantle, below which temperatures are high enough and at the same time the pressure is low enough so that rock becomes either liquid or at least a "flowing" solid. Similarly, at the boundary between the inner and outer core the pressure is so high that even at those temperatures the iron becomes a solid. What about drilling just far enough to be able to power a steam turbine and generate power ? I know they have geothermal power in *certain places* already, but why burn coal or nuclear fission when you could just dig down far enough and have an ever-lasting heat supply ? Theoretically, every locale should be able to have geothermal power right underneath them.
 It's a question of efficiency. Yes, there's heat down there, but the problem is being able to move enough of that heat to the surface to generate a useful amount of power.

It's mostly a question of heat transfer - you would want to pump relatively cold water into the hole, have it pick up as much heat as possible from the Earth, then move it back to the surface while losing as little heat as possible on the way back up. You then have to move enough of your working fluid through the system at a high enough temperature difference to generate a useful amount of power - like megawatts at least. You also have to make sure that the Earth is capable of moving heat from the mantle layers to wherever the bottom of your hole is fast enough to keep up with your power generation.

The problem is that most of these things are hard to do at depth. How do you pump your fluid back up 40k feet or whatever it is without it losing most of its heat to the formations on the way up? Once you start moving enough fluid through your system to really make power, you may also start to have problems getting all of that fluid fully heated up in the amount of time it spends at the bottom of the hole.

In theory, it could be done anywhere. But with present technology, it's only practical in a few places where the core heat comes relatively close to the surface so that we don't have to deal with those issues as much. What about putting the turbine down the hole and sending the electricity up rather than the heat? The trouble is, you can't extract energy from something hot alone - it violates the laws of Thermodynamics. To extract energy, you need to build a [Heat Engine](http://www.wikiwand.com/en/Heat_engine) that moves heat energy from something hot to something cool. That's what it would do at the surface - work between the hot fluid and the cool local environment.

You could put a turbine at the bottom of the hole, but then you'd need to move low-temperature working fluid from the surface to the turbine for it to have something to work against. Considering that, plus the difficulty of building a turbine and generator that can work under those conditions, maintaining it at the bottom of the hole, and getting the electricity to the surface, it's a no-go. You need a hot side and a cold side to run a thermodynamic cycle. If you move your generator too depth, you're still pumping working fluid up/down the borehole (Now you're moving cold water down then warm water up rather than moving warm up then cold down - pretty much the same problem), plus now you have all the headaches of keeping your equipment working in a terrible environment. 1. The hole isn't big enough to fit a turbine down

2. Maintenance

3. It is easier to get a "cold side" for the heat engine at the surface. This probably belongs in /r/crazyideas.

Why can't we pump water down the shaft to a heat engine instead of pumping water up and down? In other words; drill the shaft, install a a big ol' pot attached to a turbine and keep the pot full of water from the surface. There could even be a condenser to capture the cooled water and recycle it back into the boiler. At the moment, in some of the places where geothermal power is used (Iceland, for example), it's very easy to get geothermal energy. 

Iceland is a (geologically) very young volcanic island, and geothermal pools and geysers are plentiful around the country. Because of the geology of the area (read: lots of volcanoes), geothermal electricity is totally feasible and economical. Geothermal electricity tends to be less feasible and more expensive if you aren't sitting on a relatively shallow source of magma.  Geothermal energy currently only works in areas where the rock is permeable, so you can pump down cool water and get back hot water. Most places, you don't have that, which is why geothermal power is only used in some places.

There are attempts to fracture rock (like fracking, but really, not like fracking) with high-pressure water in order to *make* it permeable; this would allow the sort of thing you're thinking of. The relevant phrases are "hot dry rock geothermal" and "enhanced geothermal systems". The Department of Energy is [setting up a testing site](http://energy.gov/forge) to see how feasible the idea ends up being. The US Department of Energy is involved in some research into this topic, using oil drilling techniques (including fracking). http://www.energy.gov/eere/forge/forge-home Can we just constantly shoot rail guns at it though? Let's drop a long, thin, hollow quill from orbit and just tap the Earth like a maple tree. Mantle syrup? You should look into the military project on basically that but for busting bunkers, or really anything. Idk if they ever actually did anything toward it, but it was at least proposed to drop guided (but not propelled) tungsten rods from a satalite that would obliterate anything once it hit the ground.   "Rods from God"  was the unofficial name of the project. Orbit a number of huge tungsten poles and keep them in orbit directly above the target, say Moscow, because it was Moscow. Then if war starts you just have to nudge them downwards and you have a mach 6 tungsten dart weighing a few metric tons capable of flattening a city block. It turns out that ICBMs are in the end cheaper and more destructive so the plan wqs never put into reality So basically we would hit magma/lava/whatever and have to stop? I don't think the pressure thing is an issue as its an open pit. Perhaps wall integrity might be. Pretty sure you would still have to deal with pressure from the atmosphere at any significant depth into the earth. true... I wonder what it would be at 500,000'? I don't think it would be so much that it becomes the main reason it wouldn't work, but who knows. Hopefully someone can chime in.  This is a pretty simple problem. Hydro static pressure is a function of air density, height, and gravity (P=rho*g*h)

Therefore, Pressure at 500,000 ft (152,400 meters) beneath the surface would be, (1.225 kg/m3)*(9.81 m/sec2)*(152,400 m) = 1,831,429 pascals + 1 atm (which is 101,325 pascals). Basically, the pressure from air at 500,000 feet beneath the surface of the Earth would be **19** (edit) atmospheres, assuming that density isn't a function of pressure, which it totally is. The limitation of pressure being referred to is the pressure from within the Earth.  To get an idea of how huge this pressure is, think about the existence of hydrothermal vents in the deepest ocean trenches.  The ocean floor here has kilometers of water pushing down on it, which is much heavier than air, and yet magma is being forced upwards through the ocean floor.  That is the pressure which would increasingly be exerted on the pit walls.  The only pressure holding the walls it in place would be air pressure which is nothing compared to the pressure a similar depth of water provides.  Thus the walls would constantly collapse as you tried to dig further. Where would the displaced rock go? How large is this pit? Will it be more of a shaft?  IANAG but the pressure will be an issue.  IANAG? I almost never assume geologically? He's not a geologist. Either that or he is but he's going undercover as a layperson for reasons known only to a select few geologists. Moho is the name of a planet in KSC. I now know where it comes from. Thanks :) I have always assumed temperature was the only thing that determines what state a substance is in.  I've never considered, or even hear of pressure affecting materials like that. You need to learn yourself some thermodynamics! At very high pressure/temperatures you can start having very strange 'states' of matter. I imagine that the pressure on the mantle from the rest of the crust would force the mantle up and into your pit.  I would think that, depending on the pressure, once you hit mantle it would backfill until the pressure equalizes.   Yes, but "hitting the mantle" would be a gradual thing, it's not a defined separation.

It would gradually start to get hotter and hotter, down to the point where you would be removing almost-lava, and then only lava. Just to clarify - the mantle is not magma/lava, it is solid rock (peridotite). Although, one way to melt the mantle is to decrease pressure, so by digging this enormous pit we would be generating partial melts of the mantle.  This might be a silly idea of a question but would it be doable to drill up to 40km, then for the last layers of the crust and beginning of the mantle detonate a bomb (any bomb)? What kind of fallout is that asking for? None. We've blown up nukes underground for decades, because it contains the fallout  [deleted] The pressure from the cone would be gone, but not the pressure from everywhere else. It would create a huge convective mess, and push hot material out of the cone's tip while the pressures are trying to get equalized (1 atm at the cone's tip, many atms in the surroundings below the tip).

If we assume a ton of stuff in the cone's walls, it would be like a passive volcano until a lot of time passes and the crust re-forms around the cone's shape. Then it would seem likely that creating such an abnormality in the boundary of the Crust/Mantle would invite some type of volcanic instrusion... Theres ALOT of power behind mantle currents. Enough to move continents and make mountains.
 Once you get through the crust/lithosphere things get a lot more fluidic.  The outermost layer of the mantle, the asthenosphere, is viscous enough for the crust to "float" on and is what gives rise to plate tectonics.  Depending on exactly where you are drilling it seems like you may be able to start drilling into the mantle but your borehole would quickly contort, or fill in, or unleash a Balrog. 

Keep in mind my scientific specialty is astrophysics so this is a very rudimentary answer.  Would love to hear what a geophysicist would have to say on the matter. I appreciate the balrog reference and never want to drill a hole again.  "float" is definitely  misleading term. Aesthenosphere isn't liquid; it's a solid that moves very, very slowly, in much the way many people (incorrectly) think glass does. How do you drill a hole through magma?  It's called a volcano? Oh man but that would be so *awesome*! A big, molten pit. Man, I'd spend my weekends going to thrift stores and junkyards just to find crap to chuck into it. 

Okay, who's going to do this?! The old quarry is getting boring. You can only throw so many old VCRs into it before they put up signs. As long as you tell me it's okay to wheel in shopping carts I am game, they're wise to me here. Well largest open pit mine in the USA ( Bingham Canyon) has overall 35 degree wall angles in its shallowest stable walls. So let's say that angle was stable for 500,000 feet high wall so you need a hole with 714,000 feet  radius.

Assuming of course that the material you are excavating is solid rock that you could conventionally mine using drill and blast. That's a hole 270 miles in diameter. That's probably about half a county in Arizona somewhere. To Kickstarter!  Well Arizona is 310x400 miles total, so either Arizona has one county or you are fuzzy about how big miles are. That's  nearly the entire state.  Is that all? Alright, Antarctica. We need solutions not problems here man.  Except [this is what it looks like under its glaciers](https://en.wikipedia.org/wiki/File:AntarcticaRockSurface.jpg), not accounting for the rise in sea level you'd have if it melted, nor the rise in the land from the [post-glacial rebound](https://en.wikipedia.org/wiki/Post-glacial_rebound) over the ensuing millenia.

Science: Ruining everything since 1543. Unrelated to this thread, but it's a bit odd that many of lakes on that Antarctica map are in nice regular rows, isn't it? Hey I'm in that mine right now! We're getting rained on :/ snow near the top.  The Achilles heel of this plan is likely to be dewatering. There are large systems of ground water basically everywhere. Deterring is one of the more expensive items when it comes to open pit mining. One reasonably sized open pit mine can have as many as 80 dewatering wells each well pumping thousands of gallons per minute. Pumps that provide that much capacity cost close to a million dollars a a year each in just electricity and maintenance. So unless you can figure out how to mine underwater were screwed. Do this near California? There's a lot less groundwater to deal with, then the Californians will be happy to get anything pumped up. At 500,000 feet you will likely encounter ground water that we don't  even understand yet as that depth is much deeper than we have ever gone. For all I know there might be many more under ground "river" systems below the aquifers we currently use. Although, the likelihood of this decreases at depth due to heat. Also, at some point your focus would turn to demagmaing as you would start hitting magma pockets towards the bottom of the crust.

 Not to mention once you break past the crust the hole is just going to ooze back together because the rock is no longer a solid and there is going to be near explosive depressurization away from the sidewall that has 40 MILES OF ROCK ON IT. 500,000 feet is nearly 95 miles. The crust is no thicker than about 30 miles at the thicket points.

At this point you're not talking about drilling, you're talking about a massive hole in the side of the planet.  I came close to this one time on the beach during spring break when I was 8. The water from the waves kept filling my hole thus thwarting my attempts at a record.  Assuming a side angle of about 30^o to the horizontal (the angle of a flight of stairs) the diameter of the opening would span about 522 km (324 miles).

Fun fact, a cone-shaped pit of this size would have a volume of 10,800,000 km^3 , or 2,600,000 cubic miles. This is nearly 1% of the volume of all Earth's oceans combined. Better start digging. Can you imagine where we would put the water, soil, and rock that was dug up? What if we dug another hole next to it, and used it to hold the overburden? Brilliant..  And the material from that hole could be put in the first hole.  Yes... we'd use it to build a giant dike around our coastal cities before they get flooded.  Well, except for Florida because climate change doesn't happen there. A follow up question.

We drill to get minerals and such up. What stuff is so deep down, than is rarer closer to the surface?

 Not minerals. Fluids and gases. We're talking oil and natural gas. At that depth you have no potential to mine it has to come to you therefore it has to flow therefore Fluids and gases.  And in terms of drilling deeper and deeper for oil and natural gas the answer is twofold - 

1) We've already produced from shallow and easy-to-reach reservoirs.

2) Oil and natural gas come from organic-rich source rocks that are buried to a certain depth (which means they are warmed up) in order to breakdown the organic molecules into shorter chain hydrocarbons. Too cold and you don't generate hydrocarbons, too hot and you break them all down.

As such, source rocks are (or were) necessarily at some depth. As hydrocarbons migrate out of those source rocks, they can be trapped in reservoirs nearby (still at depth), or migrate up-dip to shallower reservoirs.
 How are these deep reservoirs discovered? [deleted] I'm currently studying to be a Geophysicist, and have some experience with attempting to analyse the seismic logs to detect potential reservoirs. 
The seismic surveys are often marine, a boat tows streamers of hydrophones 5-10 km long. giant geology sections at companies like exxonmobil and conocophillips spend the vast majority of their time analyzing the rock and doing studies.  a field development plan usually means starting with a series of surface tests, where they detonate explosives or use various forms of sound waves to attempt to map the subsurface.  If successful they will drill a series of exploration wells to actually look. Once those are drilled, they run a series of tools to measure different qualities of the rock to try to determine the size/shape/lithography of the reservoir.  If all that is successful and the project is still economically viable they drill a followon series of development wells for production of the hydrocarbons.

All of this takes years and is extremely expensive.  Last project I worked on was deepwater exploration wells, it took us over a year to drill two wells at a dayrate just shy of $600,000 per day. [deleted] Depends on the resource and formations. Shale gas is quite shallow (500-1500) meters. If you are drilling for oil onshore you will typically be between 3000-5000 meters. Offshore oil and gas is 6000-7000 meters, but a lot of that is covered in the water and you may only be drilling in rock for a few thousand meters. It is quite variable as many have mentioned depending on source rocks and seismic. This are just some typical ranges you will see. They use seismic charges and interpret the echo returns.

Auto-Tune for example, was designed to filter noise out of the returned data from these seismic tests.

http://en.wikipedia.org/wiki/Auto-Tune  Remember [this scene](https://www.youtube.com/watch?v=z2UQv2JUZoU)?

Approximately the same thing. You could drill deep into a mineral deposit and use solution chemistry to in-situ leach metals out. However you would need to know what was sown there and geological techniques for not invasive (drilling expensive holes to get lucky and find gold) are good enough to be economic. The future of mining will be ultra deep or in-situ solution extraction. Worlds largest gold deposit is dissolved in the ocean.  [deleted] The [deepest mines] (http://www.mining-technology.com/features/feature-top-ten-deepest-mines-world-south-africa/) are Gold in South Africa and currently sit around the 4km deep mark.

The geothermal gradient increases at roughly 0.5-1 degree C for ever 100m, so these South African mines send down refrigerated air so workers can even be this deep. Even then it is still hot as heck. [deleted] I'm not /u/Leather_boots, but he doesn't seem to be eager to add something anyway, so let me provide a bit of context:

At those depths, the rocks around you are hot. Touching them is not comfortable, and it's possible that you'll get burnt(not anything too drastic, just what you would feel when touching a really hot radiator.

In the mines that are not as deep, you usually only have to worry about providing enough air so your workers don't die. The "comfortable" work environment is considered to be up to 32 degrees(celsius). Anything above that and your hours get cut down to 6 from 8. 

Anyway, the air is supplied by giant fans. [No, really, they're the size of a building](http://www.stalkowent.pl/pic/WPK-2.gif). The performance is dependant on the model, and for "normal" mines is somewhere from 45 cubic meters to 450 cubic meters of air. Per second. The mass of those fans is up to 50 tonnes, without engine.

Now on top of that you have to add giant cooling stations, because if you were to just pump the air in, it would absorb all the heat from surrounding rocks and become unbearably hot.


The air from the giant fans and the main cooling station will not get to each and every corner of the mine, and it will not stay cool forever, so there are several smaller cooling substations and different smaller fans that help with that. What if those fans break? Can they evacuate the workers fast enough? There's always a backup, in case something goes wrong, or when one needs to go down on maintenance. 

If all the main fans were to break however, there should be enough time for the workers to get back to the shaft. 
There still would be the air that was pumped in, there just wouldn't be any fresh air, and immediate evacuation would be necessary.

Additionaly, all workers are required to carry "escape apparatus"(Self-contained closed-circuit oxygen breathing apparatus) which allows you to breathe for up to an hour in any conditions, so that's some extra time for escaping. I'm actually a Southern Hemisphere geologist, that has worked for 13 years in the FSU. Sorry for the delayed reply.

I have not worked down in the Deep South African mines on the Witswatersrand reef, but I have in a number of other mines around the world.

The non refrigerated temperatures reach over 55C (edit - in the very deep mines) and due to the cost of sending down cool air the mine typically works in sections. Once a section is mined out the mine will block it off to avoid having to ventilate it and to stop workers going into unsafe areas, as well as to reduce the cost and improve air circulation- air circulation is one of the most important aspects of mining. This is normally done by building a wall (often with a door).

Think of air circulation being a loop. Air goes down (forced down, or pulled down depending upon the type of mine) the main vent intake and is then sent into sub workings via smaller bags and fans underground and then the air needs a way out back to the surface to expel the bad air containing gases like CO2, CO and other fumes from blasting, or equipment and heat.

In cold countries with more shallow mines, the air in winter is actually heated as it goes underground, so the air coming in the mine is in the range of &gt;0-10 C. Mines create and use a lot of water, coming from rock fractures, as well as piped down to use in the mining process to prevent dust. Dust causes [silicosis] (http://en.m.wikipedia.org/wiki/Silicosis) over time and not good for the workers lungs. Just to add some visual representation of the ventilation, here's a simple drawing showing what /u/Leather_Boots is talking about:

In [drawing a)](http://i.imgur.com/gzKW7um.jpg) you can see the air going in down the shaft(1), following the tunnels, entering the active longwalls(3, 4). It also enters the Explosive Materials Chamber(2), as it needs ventilation.

You can see those "T T" signs in couple of places- They are called "dams", the walls with doors he was talking about. In some places they just separate the air stream and force it to go through all places you want it to go(like the two dams in upper side of the drawing), or additionally present alternative way to go through the mine(The bottom one)

As you can see, the air leaves in the second shaft(8), with the fan mounted on it(IIRC it's better to pump the air out rather than in, something about efficiency)

The drawing b) is the same mine, just a bit more schematic. Even if a mine isn't that deep, the air gets hot as: compressing a gas (pushing it underground) makes it hotter; and mining machinery heats up the air.

Also it's generally wet underground, which raises the humidity and limits the ability of sweat to cool you down. I think when you say "drill for minerals", you mean that mining companies will drill holes to find gold in the subsurface, and you're right. However, these tend to be holes that are drilled that tell geologists where the gold is and where they should build/extend their mine.

In terms of rare material being at depth - that's sort of the case for some elements, but I think this explanation might help: It's important to think of valuable orebodies (say some quartz veins with gold in them) as three dimensional objects. Say you find a vein with gold in it that looks something like [this](http://www.racerocks.com/racerock/abiotic/geology/quartzvein2.jpg).

You can see that it's a relatively linear feature on the surface, but you could excavate back into that hillside (or down, in our example above) to follow the vein and find that it's actually somewhat of a tabular or planar feature that exists in three dimensions.

When companies drill for this gold (or whatever metal), they are more or less taking rock samples from depth and seeing if/where these veins intersect their hole and how they can most strategically continue mining an area. Also important is that around mineralized zones, there is often host rock that is elevated with the metal of interest, but we need to assess how much metal is in those rocks to determine if it's economically feasible to mine that area out.

Note that this is a gross oversimplification of the metals mining process and not all valuable ores occur in veins like this - some are in disseminated through the host rock, some are hosted in layers in cooled magma chambers, some are found in ancient coral reefs, even! It depends on the style of mineralization. [deleted] Very cool explanation. 

I'm curious, what kind of valuable ore is found in ancient coral reefs? [Black smoker deposits] (http://en.m.wikipedia.org/wiki/Volcanogenic_massive_sulfide_ore_deposit), so Lead, Copper, Zinc, Gold, Silver and lots of other metals

I used to work in a mine in North Western Australia in a Lead, Zinc mine on the Lennard Shelf and the deposits of the area were old Devonian and older reef complexes.

We would mine through massive fossilised Rugose corals to get to the ore body.

Edit - damn iPad spelling Most of the lead (and also zinc) produced in the United States comes from an area called the [Southeast Missouri Lead District](http://en.wikipedia.org/wiki/Southeast_Missouri_Lead_District)

The majority of the lead there is mineralized in limestones that formed in shallow, subtropical marine seas which include areas of carbonate reef material deposited by algal creatures called stromatolites. 

(Edit from my previous post - I should have said stromatolites, not corals).

Nonetheless, these reef areas of rock have different porosity and permeability than the surrounding limestone, meaning that metal-rich fluids that deposited the lead could flow through the reefs more easily. Which, in turn, means that we often find more of the metal of interest in the reef material, compared to the surrounding limestone. It's so cool!
 As you go deeper then then you get the high grade metamorphic minerals caused by the heat and pressure at that depth which makes minerals found at the surface to change atomic structure. (Amphibole, Garnet, Ecologite etc.)

Minerals thought only to be from the mantle that are rare at the surface are Olivine, Fosterite etc, it's incredibly hard to know but the rocks would be a lower % of Silicon and Aluminium and higher in Iron and Nickel.

However none of these are drilled for at industrial level (Or even research level as research doesn't have the money) Eclogite is a metamorphic rock facies/type, not a mineral. But you're right, the scientific benefit to cost ratio is too high to drill wells beyond 12km just to hope that you can scrape a few samples of UHP/UHT minerals from a wellbore. I remember reading as a kid a SciFi story, where they used a kind of a "mole" which melted the surrounding rock, turning it into in-situ casing.

Could it be done?

Also, what about using "moles", large self-sufficient platforms travelling down the vertical tunnel they make by the above mentioned method, instead of the traditional drilling systems? Is there any sense in idea like that? This is done, using laser drilling.  However, due to the aforementioned pressure issues, it's only good for shallow depths.  Also, the melted-rock casing is not a very good casing.
 What is the best kind of casing? Industry standard casing is steel pipe which is then cemented in place.  Different grades of steel are used depending on strength and corrosion needs.  I don't know of any other widely used alternatives.  I've never heard, for example, of an aluminum or plastic casing.

When drilling is being done, there is often immense fluid pressure from underground saltwater which permeates porous rock.  Therefore, boreholes are usually filled with drilling fluid (aka mud) while being drilled, to balance out the hydrostatic pressure from the saltwater.  However, if the drilling mud is too dense, it can fracture the formation and cause the hole to collapse.

Once a segment of drilling is done, metal casing is lowered and cemented in place.  You could say that the casing protects the hole from the formation, and also protects the formation from the hole.

When laser boring is done, mud can't be used, it would soak up all the energy.  That means laser boring can't usually be done very deeply.  Also, the melted rock created by a laser bore is unlikely to be as consistent as a good cement job.  Laser boring IS practical, it just requires a very specific set of conditions.

By the way, casing serves another important purpose: it protects groundwater.  Freshwater aquifers near the surface could be contaminated by substances found more deeply underground, such as saltwater, oil, gas, or hydrogen sulfide.     Therefore, when drilling an oil well, first, the groundwater is drilled through.  Then, a casing is put into place to isolate the layer.  Then, the casing integrity is tested.  Finally, deeper drilling is permitted.  Doing a bad job of putting this casing and cement into place is a MUCH more likely cause of groundwater contamination than fracking ever is. Interesting. Thank you! Was this story, by any chance, Artemis Fowl? You can read up on BP's project 20k. They are trying to develop 20,000 psi rated equipment to tap some ultra high pressure fields in the Gulf of Mexico. Will be interesting to see the applications of the tech once it's developed.  That's fascinating - I've never even heard of equipment rated that high for drilling.

Do you have a link to more information? http://www.bp.com/en/global/corporate/about-bp/bp-and-technology/more-recovery/deepwater-frontiers.html

Last time I spoke with my contact at BP they said the project is on track to be completed in a few years. They need it to tap the Kaskida field.  Thanks, that's amazing. Having spent many, many hours as a well-site geologist with drillers, allow me to confirm that everything he said is accurate (as far as I know, and... in general the driller knows more about this than the geologist, haha). Unstable rock? Yes. Telescoping casing? Yes. Then of course you have the issue with the required power to rotate a 40,000 foot drill rod and occasionally replacing a drill bit that's thousands of feet underground (I feel bad for that rig hand...) and the geothermal gradient - the crust warms by about 1 degree F with every 75 feet you drill.

Ultimately though, it really does just come down to funding. Drilling is crazy expensive and unfortunately there is no point in drilling a hole that deep. We drill deep holes for mineral exploration, because they pay off. We drill deeper holes for oil because they also pay off. Drilling a deep hole for the hell of it wouldn't pay off. It's the same reason we've yet to put a person on Mars. There's no financial gain to be had and curiosity isn't enough to sink literally billions of dollars into endeavors like this.  Totally forgot about that: the torque would be INSANE at that depth. I don't know what kind of pipe would be required, but I imagine it'd have to be something crazily expensive to endure torque that would likely be at or over 20k ft-lbs  What if one managed to drill straight from the surface to the mantle? I assume breaching it would result in a huge blast of magma... Is there anything one would be worried about when it comes to digging that far? Like earthquake tendency/plate disruption, or perhaps accidentally making essentially a volcano? 

Or are those all silly scenarios? 

Guess more of questions for a geologist..  In fact, despite popular conception, [the mantle is not made of magma. ](http://www.earthobservatory.sg/faq-on-earth-sciences/earth%E2%80%99s-mantle-made-liquid-magma)  It is mostly solid rock (kept that way by high pressures) that behaves like a plastic.   If you drill at a "hotspot", though, you [can get magma in the hole, although this is very rare.](http://news.ucdavis.edu/search/news_detail.lasso?id=9174)
 If you were drilling (or digging) down to the mantle, would you not be relieving enough of the pressure for it to become liquid or, if not, expand, shift and destroy the hole? You're talking about a blowout, and yes that's a real problem that exists when drilling a well (2010 BP disaster, for example. Not sure how that would work with magma though.  You have to remember that your drill hole is trying to squeeze shut all of the time and especially more so as you get deeper into the higher pressure gradients.

Add in the more plastic ductile nature of the rocks at that depth and you are very quickly looking at a stuck drill string, the metal in the drill bit failing and the cutting diamonds, rotary bit, or teeth starting to fail. This would result in pulling the rods more frequently to change the cutting bit and everytime that happens you risk the hole closing up.

To borrow a technological term from one of our mining engineers, you get "squeezure". Mud engineer. I've worked ultra- high temp/pressure. We had a BOP capable of closing in on 24,500 psi, and 30k psi pumps on board. Mud coolers all over the rig. Special fluids to handle the heat.

I wish I could share more about the well, but I was asked to censor bunches of info while I was out there, so I'm certain I can't share much here.  Wow, that's crazy...

Can you say if this was offshore or land based? Do you think it'd be easier to train you as to be an astronaut or for an astronaut to be trained to drill? I believe NASA already laughed that question off when it came to the movie Armageddon. It would most likely be much easier to train an astronaut to be a driller than vice versa. 
 Now NASA knows who they need. &gt; Pressure is another problem. As you get deeper, the pressure exerted on the formation from drilling fluid gets higher and higher. At the same time, the horsepower required to pump the drilling fluid back up to the surface becomes much greater. You would need enormously powerful pumps capable of generating as much as 10,000 psi.

Is there any reason you couldn't pump the fluid to the surface in stages? Pump it 1000ft up into a reservoir, then another thousand, etc? Geologist for an oil company here.

If you let pressure go lower than the surrounding pore pressure of the rock then you'll take whats known as a kick which is fluid coming into your borehole under pressure from the surrounding rock. If a kick is bad it leads to a blowout and this causes things like the BP Deepwater Horizon to blow up.

You can have issues with overpressure too (Especially if you hit a salt, Halite, Gypsum, Anhydrite, Sylvite, Polyhalite, Carnalite, Kieserite, Lanbenite layer, Carbonates also have there own problems on the type of thing you can pump into a hole) so you can't just pump under increasing pressures. You aren't trying to pump fluid up, it is under pressure and it wants to come up. You are pumping fluid down, to cool and lubricate the drill. Your also pumping fluid up to bring cuttings out the hole and stabilize the entire drill string.  Then you would need to integrate a reservoir and pump in to the drill. I'm not sure there would be enough room for that Where you going to find the room to put them? Not like it's a giant hole where you can stick a pump and power source down there. Right, many production casing is less than a foot in diameter (especially onshore, not as sure for offshore), with the drill string taking up some of the space, the  resulting annulus is fairly small. Fun facts:
40,000 feet is about 7.57 miles

Average distance to core: 3,964 miles

Starting in the ocean may give you a headstart, but that brings up other issues. &gt;Average distance to core: 7,929 miles.

You are confused. The Earth's equatorial radius is [only 6378.1 km](http://en.wikipedia.org/wiki/Earth) or 3963 miles. That's how far you'd have to dig to reach the center of the Earth, never mind the core.

To reach the core you'd have to dig a lot less than even that. To reach the outer core, [you'd need to dig 1790 miles](http://en.wikipedia.org/wiki/Structure_of_the_Earth). To reach the inner core, you'd need to dig 3160 miles. A headstart? Not by much. Maybe 2.5 miles at most. You still have 7,920 miles to go you didn't even put a *dent* in it. And chances are, water pressure has already half ruined you.


Some headstart. since heat is a big issue would it be easier to drill in extremely cold climates, or does the ground get too hard when its froze over? A cold surface temperature has no effect on temperatures deep underground No matter where you are, once your are 30 or so feet underground it's all about the same temperature.

This actually allows a type of geothermal heating for homes in cold climates, in which a deep hole is dug, allowing air to be warmed to a reasonable temperature (not very hot but warmer than the outside air) and then pumped into a person's home. Sorry, this isn't true at all.

The northern parts of Russia and Canada get permafrost running into hundreds of metres into the ground. I have been in mines in Russia where they are mining through permafrost.

Areas without permafrost run geothermal gradients of between 0.5-1 degree Celsius increase for around every 100m increase in depth as a rule of thumb.

The upper several hundred metres of rock will often be cooler than outside surface temperatures in summer, but in winter these rocks can then be considered like a radiator releasing heat back to cooler outside surface temps. Couldn't you use the heat and convert it into another kind of energy to get the stuff up? Heat is not power. If you want to use heat to make usable energy you need both a hot thing and a cold thing. It's the difference between the two that allows generation of electricity etc.

Unfortunately, if everything around you is the same temperature, whether hot or cold, there is no heat flow and thus you cannot generate power. Great answer. I don't do drilling but work-over. Deepest I've pulled was 19,800. Interesting stuff.  if hypotetically people attempted to drill as far down as possible, would the hole go straight down towards the center of the planet? or is there a better path? If we really considered it important to get really deep, and decided to just dig a really wide, really deep hole, as far down as we could, until we absolutely couldn't do that anymore, then start drilling from there, what would that change in the equation? Your answer is spot on. The Russians have a borehole that is somewhere in the neighborhood of 12km deep in Siberia. I don't think it is still operational though. That's deep enough for my purposes. Thanks, Azreel. I'm leaving the thread now. So are you working right now? I'm an Alberta oil driller and its down to a stand still up here. You offshore or land based? BHA  is bottom hole assembly = bit, drill collar and other specialty items that aren't drill stem How far is that in real units? When you say drilling fluid, does that mean that large drills run on some sort of working fluid? Or do they squirt out fluid at the bottom at high speed to drill? I'm assuming the first one since if you squirted it out you wouldn't have to pump it back up. Right? Is the fluid used hydraulically or is it burned like some sort of engine?  The drill string is hollow so think of it like a tube. The drill bit kind of grinds away rather than drill like you would think. This means it needs good lubrication, needs to be cooled, and more importantly it needs a way to move the shit that's been ground away out of the hole. The fluid is pumped from the surface down the drill string and out the bit. It then suspends the cuttings and goes back up to the surface on the outside of the drill string. 

Easy way to think of it is imagine you have milkshake and you blow through the straw. The air goes to the bottom but then comes right back up to the surface on the outside of the straw. Only in this case you are using giant pumps and you are removing solids from downhole. 

Edit: Drilling mud systems are extremely efficient so there is nearly no loss of mud in the process unless you have an overbalanced well in which case the mud pressure is higher than formation pressure so instead of it all returning to the surface, some of it will enter the reservoir.  Great answer. Thanks so much.  Really. There's a lot of really awesome informative answers here. I'm really enjoying learning about drilling. Kinda weird. What if you drilled a vertical *tunnel*, ie a hole with support along the walls, instead of just a hole? Would that be feasible, or just too expensive due to the cost of the support material able to cope with the heat? That's what most mining drillholes already are, once you get past a certain depth. What about a specially made drill which you case the hole walls, have a fluid transferring string and have a liquid nitrogen compartment to cool the fluid? Not only would you still have to pump the liquid N2, which would raise it's temperature.  It would be so cold that it would freeze the drilling fluid, and most likely the drilling head which would cause it to be very brittle.  Not something you'd want in a drilling bit.  Furthermore, the soil surrounding the drill string would need to contain water for freezing to do anything.  If the material was dry sand, then freezing it will do effectively nothing for stability.

Amongst a myriad of other reasons why that is not feasible. what's preventing someone from drilling a really deep hole, and using the heat at the bottom of it to boil water to generate electricity? Even at those temperatures, it's not hot enough to heat water for electricity.  Geothermal power plants usually use sub-surface magma flows. Its been tried, Australia in particular had some projects going, but they've had issues with well blow outs.  Habanero 3 was the most notable.

The main thing is that for power generation,  you want the steam going through the turbine to be dry-aka not condensing- all the way through.  This means the point where your are done getting work out of the steam is above 212F.   So if you are pulling the steam up at 300F and ~atmospheric pressure there isn't much energy to get out of it.  

For comparison a boiler at a fossil plant may generate steam at 900F and 5000+ PSI.  Question, a friend told me that once you reach a certain depth the heat causes the rock to stop behaving like rock and more like a plastic. Is this true? Not plastic like what your phone is made of. Your friend may have been confused by the fact that the adjective 'plastic' (malleable or deformable) is used to describe rock at that depth.  About about using lasers instead of iron drill bits? The deepest drill hole for those curious is in Russia called [The Kola Deep] (http://en.m.wikipedia.org/wiki/Kola_Superdeep_Borehole). 12,262 vertical metres.

Modern down hole drill technology has improved somewhat since then, so theoretically it might be able possible to go a further few 1-2,000m, but the cost would be horrendous and it is doubtful that any company would attempt it without a very good economic reason.

Pressure, temperatures, the weight of the drill string as others have mentioned all start having serious effects.

In terms of mining, most mineral (non oil and gas) drill holes don't go much deeper that 1,500m for the simple reason that it is cheaper to mine a decline, or put down a shaft and drill out the potential ore body of interest with a greater number of shallower holes.

For example, a 1,000m diamond hole might cost in the region of $250-300,000 and take 4-8 weeks to finish depending upon the Rock, drill rig and several other variables. A 300m deep hole might run $35-45k and have a greater chance of success and take a week to two weeks.

To drill out the potential ore body, you might need dozens to over a hundred holes depending upon the type of mineral and size of deposit. &gt; it is doubtful that any company would attempt it without a very good economic reason.

This is pretty much why there are no experiments with super deep holes. I *think* the Russians were sort of hoping to find abiotic hydrocarbons. They didn't and as far as I know there really isn't any reason to think they would other than quite tenuous hypotheses.
 Yeah, I have heard a bunch of reason why they drilled it.

Along with the hydrocarbon theory, I have also heard to show off the Soviet technological prowess in being able to drill so deep- Cold War stuff, plus it is an area with very thick ultra mafic sequences and the Soviets wanted to study them in greater detail theorising it was a mantle upwelling and there are several other theories that are probably more here say, so not relevant in this discussion.

As an aside, that area of Murmansk has a huge number of Nickel, Apatite and Platinum deposits. I spent several days a number of years ago flying around a bunch of stuff in a Mi8 helo. Actually a mile down is the minimum most oil wells these days go.  In the baken most wells are one mile down one mile over.  Cost about one million to drill.  But resently they drill 2 miles down 2 over.  I was on one well sight that the bottom perfection was 24000 feet about 4.5 miles What does 2 over mean? Horizontal drilling? Yep, horizontal drilling. The true vertical depth can be two miles down, and the total hole length(measured depth) will be around 4 miles. This means that the total lateral distance from the original hole will be just under 2 miles.  This is in the baken where they drill for shale oil.  Not sure about the rest of the world Yeah, there haven't exactly been any revolutionary breakthroughs in the technology in the past 20 years. Compared to the older Soviet stuff there has been. Pretty much all down hole tooling in the former Soviet Union has been replaced with Western stuff, both in Mining and oil and gas. The Soviets had metallurgical issues with some of their steel in certain industries.

In the Kola wiki article I linked elsewhere in this thread they mention a few more recent oil and gas holes that have managed the length, just not the depth.

I know that diamond drilling has changed quite a bit over the past 20 odd years I've been in the industry. The oil and gas side I don't know a huge amount about. This question was answered in a recent Discovery Magazine article found here: http://discovermagazine.com/2014/julyaug/13-journeys-to-the-center-of-the-earth 

The relevant excerpt:

"Everything we know about the mantle, which begins about 15 miles below the surface, and about Earths core, 1,800 miles beneath us, has been gleaned remotely."

Others have mentioned the Kola dig, which is also discussed in the article.

"Temperatures at the bottom of the Kola hole exceeded 300 degrees Fahrenheit; the rocks were so plastic that the hole started to close whenever the drill was withdrawn . . . If Earth were the size of an apple, the Kola hole wouldnt even break through the skin."


 More than this depth and mines would collapse. The temperature would be hotter than the point where drill bits are useful. You could also drill from a deeper point. The Moho Borehole was a US project to drill into the mantle from a point on the seabed where the crust is thin.

But there are some alternatives. There have been proposals to create self-sinking probes containing radioactive isotopes. A few hundred pounds of radioactive cesium would melt its way through the crust and into the mantle hundreds of kilometers down. They could be used either for exploration or disposal of nuclear waste. The sound given off by the rocks as they cracked and melted could be used to figure out the location of the probe and the composition of the earth.

An even more outrageous plan was to crack the Earth's crust with a hydrogen bomb, then pour ten million tons of molten steel into it with an embedded high-temperature probe. The steel is denser than the mantle, so it will sink all the way to the core. The probe can communicate with the surface by vibrating. [deleted] First I've heard of it, but thanks. [This is the 2003 proposal for the molten metal probe.](http://news.nationalgeographic.com/news/2003/05/0514_030514_earthcore.html) What are the advantages of reaching the mantle (and beyond) besides knowledge? Also a good way to dispose of highly radioactive materials.

As it is, though, we know a lot more about outer space than the interior of our own planet. So many of the reasons for space exploration apply, including getting a better understanding of how our solar system evolved and what might have helped give rise to life. We could use these kinds of probes on other planets, too. little off topic

&gt;Also a good way to dispose of highly radioactive materials.


Can't we just dump the radioactive materials in space? Like lets say build a big spaceship then launch the thing towards the sun and let it burn? This would be good, until there's a mishap and the rocket explodes in our atmosphere.  No, not only is it impractically expensive, the first rocket to explode with nuclear waste will contaminate the Earth more than the entirety of well-contained nuclear waste vessels we currently use will release in a million years.

Scattering horrible pollution into our very air instead of storing it in very well contained sites with a low risk that it ever contaminates anything is only something people are okay with if we're talking about burning coal. I think the problem isn't as much safety as it is cost.  [This article](http://www.universetoday.com/25431/why-cant-we-launch-garbage-into-space/) uses the space shuttle's $10,000 per kg cost to launch into space, meaning just one reactor's waste per year would cost $250 million.  Each year.  Unmanned rockets would probably be cheaper, but with the dangerous payload and requisite safety precautions... maybe even more expensive. How much are we currently spending on storing nuclear waste? I'd say there's no such thing as nuclear waste, just nuclear energy we haven't extracted yet.

If we do want to waste that energy by disposing of it, there is really no reason not to just bury the waste somewhere stable and water-impermeable. The high level waste will decay in a few centuries. There are lots of geological features where we can guarantee very stable conditions for much longer than that. If we're worried about civilization collapsing and cavemen eating the waste one day, we can bury it in deep holes drilled in seabed subduction zones, but that's a bit ridiculous. How confident are you in space-launch tech that it would never, ever explode in the atmosphere during or after launch?

It *might* be cautiously feasible once we have a space elevator. [deleted] http://dune.wikia.com/wiki/Stone_burner

http://dunepedia.wikifoundry.com/page/Stone+Burner

"J radiation" is very unlikely, eye tissue is not easily targeted, as they are just regular animal cells, the rods and cones are actually brain tissue, as they grow out of the developing brain.

http://www.britannica.com/media/full/506498/136387
https://nanohub.org/site/resources/2013/10/19552/slides/010.01.jpg


And detonating a big big megaton bomb in the core would probably do nothing. That stuff is already very energy dense, with a high density and thus high momentum. The inner core is crushed solid by gravity, radioactive and hot and floats in fluid rock rich in metals that power the geodynamo - at least that's the theory. A detonation would move things a bit, but the resulting shock wave would disperse its energy very fast. (Though the wave would travel far, because dense materials are good pressure wave conductors.)

http://onlinelibrary.wiley.com/doi/10.1029/JZ070i004p00885/abstract sadly I wasn't able to find a proper full text version to look at the forumas about wave propagation underground. That probe plan was real eh? It was in Artemis fowl, I thought that Eoin colfer had made it up lol.

 That seems like an insane waste of good steel. What could ever warrant that kind of investment of resources?  Regarding the heat, how deep do one have to drill to establish some kind of power plant - sending down water, to a depth where it boils - get steam back up, run it through a turbine to generate electricity just like any other nuclear / coal / general power plant.. Get clean "limitless" energy.. Would it be possible with the technology of today? If so, is the process of doing so too expensive for it to be worth it? 
I'm guessing the answer depends on where on earth you are, Iceland have hot springs and already takes advantage of that energy wise.
But could the method provide clean energy in most other places in the world too with "just a bit of drilling"? It's not just about creating a bit of steam. There is steam and then there is steam. The kind of steam that runs the turbines in a conventional surface power plant is at an insane level of temperature and pressure. Who said that we have to work with water steam?  There's systems that can be made with more volatile liquids/gases, most notably ammonia. That's called Geo thermal energy. [It's already a thing](
http://www.ucsusa.org/clean_energy/our-energy-choices/renewable-energy/how-geothermal-energy-works.html#.VU4kB3rD_qB) Look up enhanced geothermal systems. They're based on the idea that everywhere is suitable for geothermal energy. Just how deep.  This depends on the place. But you don't need it to boil to get energy, any differential is potentially usable, it is a matter of getting enough of a differential to be worthwhile economically. If you're going to drill into the Earth to get at a heat source, you better be getting more than hot water back from it... This is already a [thing](http://en.wikipedia.org/wiki/Geothermal_electricity), but I don't know much about them About 10 years ago, my geology teacher said humans have yet to get below the earth's crust to the mantle. But there was a drilling project in France (at the thinnest crust area known) that was attempting just that, by constantly drilling. Don't know what ever became of this. Underground Diamond Driller here.

We use 10 foot rods threaded together to drill over 3000m into the earth for core retrieval. Our drills at that depth and through all that rock requires rod grease to keep the rods from burning. It also pumps water down the hollow center of the rods that are down the hole to cool the rods and prevent breaking them. 
 There are many issues with drilling that deep, such as collapsing holes near loose rock or crucial drill problems from withstanding all the weight from the rods. 
There is over 50,000lb of force per foot coming from the rods that deep.

There are always new drills and forms of drilling being tested, but to get any closer than that is nearly melting drill bits. 

Edit: Forgot to mention the fact that we usually start drilling these holes 5000m underground in mines.
 Well, we drilled past 40,000 feet a long time ago.  They probably could have got much further.  The problem is that they stopped around 39,000ft and waited a year to continue.  When they did the drill didn't get far before it over heated.  But the drill experienced unexpected temps, likely due to the friction created by the buildup around the drill that occurred over the course of a year.

http://en.m.wikipedia.org/wiki/Kola_Superdeep_Borehole People are talking about big drills, massive wells, deep winding mines... what I want to know is if we could make a small little robotic device that could withstand heat and pressure, and basically worm its way down to the core. How would you power it? That little device would have to send back to surface the miles of rocks it drills through With what? Mini-drill on the front? Who would replace it after it wears down? How? Could be made of Tungsten (Unless i'm wrong and all drill bits are made of Tungsten) because then it wouldn't deteriorate pretty much at all as long as it doesn't fall a considerable amount.  Tungsten-carbide (Mohs 9) would be harder than just tungsten (Mohs 8) but there are steel alloys stronger and maybe even some type of depleted uranium alloy (M1 A1 use depleted U armor for its density).

 Some sort of man-made sapphire/diamond or carbon type material such as ADNR.

[Wikipedia Mohs scale link](https://en.wikipedia.org/wiki/Mohs_scale_of_mineral_hardness) shows some alloys of rhenium and titanium at Mohs 9.5 and 10. It varies greatly by location. If you find a highly geologically inactive area you could dig through most of the mantle with a cone shaped hole to prevent collapse maybe even down to 1000 km. But even if you could get a 45 degree slope without collapse the width of the hole at the top would be 1,400 km (around the distance from Paris to Rome). 

But 45 degrees is the maximum angle of repose for any lose material. Most materials like soil will begin to collapse around 30 to 35 degrees. 

**Edit:** 
but this is completely hypothetical because at that point you are going to have displaced a mass of earth that would destabilize the planet's orbit. Who knows what kind of tectonic events would be triggered. What if instead of drilling a hole, we use multiple, very long hollow cylinders and just hammer those suckers in one after the other. They would be able to connect to each other. Have many tiny tubes, formed from the same material as the cylinder, run along the insides of these cylinders, that connect together. Once incredibly deep, pump water so the water would flow down these small tubes up towards the surface. With enough time, get a crazy strong shop vac and suck out the insides of the tube. It would create a super deep reinforced hole. This wouldn't work, as the force exerted by tubes added to force needed to push the tube into the rock would cause the tubes to deform very quickly.  
  
 Even if you don't count in the fact that the temperature, which rises with depth, would make it even easier to deform said tubes. You're talking about going to a place with so much heat and pressure that rocks aren't really solid, they kinda start melting more the deeper you go until they're liquid. [deleted] Piggy-backing on anothers post: the Kola hole sounds like a good place to try this, where the rock is deep enough to be softened. No, a diamond is not forever. Given enough time, a diamond will turn completely into graphite because it is a spontaneous process. The Gibbs free energy of the change from diamond into graphite is -3 kJ/mol @ 298 K. Accounting for a cosmic background temperature of about 3 K, G = -1.9 kJ/mol.

Recall that G=H-TS.

EDIT: The physical importance of this statement is that even in an ideal world -- where nothing hits the mass and no external forces are present --  the diamond will eventually turn into a pencil.

EDIT 2: typo on sign for delta G; spontaneous processes have a negative delta G, and non-spontaneous processes are positive.

EDIT 3: I'm very forgetful today :p. I just remembered that space is very very cold (~3 K). While the thermodynamics are clear, the kinetics are less so. If the diamond is in deep space, it will constantly lose heat as blackbody radiation. Given that the rate of reaction decreases with temperature (as exp[-E/kT]), and temperature decreases with time, the diamond really could remain a diamond forever.


EDIT: To do a simple calculation, we can assume that in the "void of space" there is no radiation incident upon the diamond. [It will lose heat proportional to its temperature to the 4th power](http://en.wikipedia.org/wiki/Black_body#Radiative_cooling). If it has a heat capacity of C, an initial temperature of T , a surface area of A, and an emissivity of , then its current temperaure is related to time as:

time = C*(T - T)/(AT)

We can rearrange this for temperature as a function of time, but the expression is [ugly](http://www.wolframalpha.com/input/?i=solve+C*T+%3D+U+-+t*K*T^4+for+T). Alternatively, we can just look at the long-ish time limit (~after a year or so for a jewelry-sized diamond) where the current temperature is much much smaller than the initial temperature. In this regime, time and temperature are effectively related by:

t = C*(T)/(AT)

which can be rearranged to

T = (C*T/(A*t))

plugging this in to the Arrhenius rate equation, where D is the amount of diamond at time t, using R as the pre-exponential, and normalizing E by boltzman's constant:

dD/dt = -Rexp{-E/[(C*T/(A*t))]}

Unfortunately, I don't think there's a way to do the indefinite integral, but the definite integral from 0 to  is known to be:

D() = -24*RCT/(AE)

Indicating that there is only a finite amount of diamond that will convert to graphite even after infinite time. What happens to the graphite? Does it just float in space forever?  Does graphite decay? It might have a very long half life and eventually the element will decay to something lighter. No. The primary isotopes (12C and 13C) of carbon present in nature are fully stable, and will never spontaneously decay. If we want to get picky, Carbon-14 is radioactively unstable, but it only makes up ~1 part per trillion of carbon in nature.

In fact, the standard isotopes of all elements lighter than Technetium (n=43) are considered entirely stable. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] but won't it after enough time start to decay on subatomic level? granted extremely long time but entropy doesn't stop True, it would decay if the proton decays. But I'm pretty sure it's still up for debate when and whether proton decay will take place (if it does decay, it won't be for a loooong time).  What about interactions with vacuum energy/virtual particles?

And what about the carbon atoms tunneling away from the molecule, or the particles that make up the atoms tunneling away from them? If I'm not mistaken, carbon atoms will outlast our planet. Please, someone let me know if I'm wrong about this. but theoretically if enough time passes then it would...we don't know if it actually does because not enough time has passed for us to see it decay, this is one of those purely theoretical experiments, there is simply no way of practically setting up an experiment to see if a diamond decays into something else At some point the universe may end before that happens at which point time has no meaning.   I think if you are going to start considering proton decay (from memory  if it happens, the half life is over 10^^30 years) you then have to consider what "forever" actually means. At what point does the universe still exist or at what point does anything "in" the universe still exist? Things get pretty esoteric at the end of time. Quantum tunneling means that it, and everything else, will (very) slowly become iron. 

http://beyondearthlyskies.blogspot.com/2013/04/iron-stars-at-eternitys-end.html
 Do you have a reference other than a blog post citing an almost 40 year old paper?  Carbon has a stable nucleus but won't a lump of graphite sublimate in space?  Imagine one carbon atom at the edge of the lump of graphite.  It can either stay attached to the adjacent carbons (energetically favored) or be anywhere in any position in all of space (infinitely statistically favored).  Even at very low temperatures, shouldn't sublimation slowly occur? Atoms at the edge will occasionally have enough energy to separate from the rest of the graphite lattice. Am I missing something here?         
I'm aware that I'm neglecting gravity and that the same logic applies to all solids in space.  Similarly, radiation should provide enough energy for particles to detach even if heat does not. They're entirely stable provided their constituent particles are themselves stable. The standard model says the proton is stable, but some new attempts at unified theories suggest it is not; see [proton decay](http://en.wikipedia.org/wiki/Proton_decay). If proton decay is real, then atomic matter will itself decay (though it will take a long time, i.e. lower limit estimates of proton half-life are now on the order of 10^34 years.  &gt; They're entirely stable provided their constituent particles are themselves stable.

I'm not sure what you mean by this - carbon nuclei are made of both protons and neutons. While there is some doubt about the stability of the proton, the neutron is known to be able to decay. That's very interesting especially when coupled with the accelerating expansion of the universe. If that acceleration continues and the universe did succumb to heat death, AND protons decay, then would it not be possible for other subatomic particles to decay in a similarly astronomic timescale? What I'm getting at is if there is a possibility of all matter decaying back into energy would time-space in this universe continue, or would pure energy simply diffuse into whatever medium our universe spawned from. Obviously I use the word "medium" in the abstract sense since we can't yet know the conditions or even the existence of a multi verse, although I would bet my life that there is one, since things rarely occur only once, at least in this universe : )

Edit. Words, how do they work??? &gt; the existence of a multi verse, although I would bet my life that there is one

Funnily enough there is a way to [make that bet](https://en.wikipedia.org/wiki/Quantum_suicide_and_immortality) (for a certain type of multiverse anyway).

^^Warning: ^^Betting ^^your ^^life ^^on ^^speculative ^^metaphysics ^^may ^^be ^^harmful ^^to ^^your ^^health [deleted] I think there's an underlying assumption that the diamond is composed of one or both of the two stable isotopes of carbon (there are at least 15) and that there are no quantum tunneling effects which would disintegrate the diamond after a time. If it helps, I found a paper [doi:10.1134/S0016702908100017] that suggests that the ^13 C in diamond runs from 3-10% depending on sample origin.

There's also the issue that we don't know if protons are stable or not. If not, then it doesn't matter what the matter is composed of, they'll eventually (6x10^33 y) turn into a radioactive compound and disintegrate that way.

Also, quantum tunneling, but by the time the diamond vanishes from tunneling, nobody in the universe is likely to be around to care. But the CMB has a temperature of ~3K, so even with BBR the diamond will come into equilibrium at a temperature with a finite reaction rate  See my response [here](http://www.reddit.com/r/askscience/comments/36606x/if_you_put_a_diamond_into_the_void_of_space/crb5655) This is true but it ignores the fact that there are other processes that happen on a longer time scale that would prevent a diamond ever lasting forever. For example proton decay is predicted to occur after approximately 10^36 years. Luckily, we don't need to worry too much about this this because there are enough high energy particles in space that neither a pure diamond structure nor a pure graphite structure would survive for very long. The incident power might be quite small, but it only takes a few 10s of eV to displace a carbon atom from its lattice position and there are plenty of protons, helium nuclei, neutrons etc. with energies &gt;&gt;1MeV whizzing around space that can set up very large cascades of displacements of atoms in graphite or diamond. In both cases, the effect is to push the structure towards some amorphous intermediate state that is neither pure graphite nor pure diamond. While not thermodynamically optimal, it will persist as long as the irradiation does. Where cosmic rays are concerned, kinetics will overwhelm everything else. You'll also get a certain amount of other elements produced through nuclear reactions due to collisions with high energy particles which will also disrupt the ordered carbon structure. I am confused by your statement. Kinetics, in the sense your wrote it (assuming you were comparing it to thermodynamics) is the study of motion. Can you explain the relationship here? And what is the reason that the diamond would eventually reach a temperature lower than background temperature of space? My understanding is that it would reach an equilibrium with the temperature in space but it sounds like you are saying that due to some principle in kinetics it would eventually reach absolute zero? Sorry for my confusion but what you are saying is interesting and i have never heard of it. I apologize if I am misunderstanding something. &gt;Kinetics, in the sense your wrote it (assuming you were comparing it to thermodynamics) is the study of motion.

This is a reference to chemical kinetics, because we're talking about a chemical reaction (diamond turning into graphite requires rearranging bonds). This specific example is actually an extremely common topic in introductory level chemistry classes to demonstrate in a numberless hand-wavy way the importance of an activation energy (which depends generally mostly on kinetics and not thermodynamics) in a reaction. Graphite is the thermodynamically preferred form of elemental carbon, but in order to get the reaction to occur at appreciable rates, very high temperatures are required. Given infinite time yes, all diamonds will eventually turn to graphite in the absence of any other intervention. Keep the temperature reasonably low though and a diamond will stay a diamond longer than anybody will be alive to measure its change, so it's *effectively* inert under normal conditions.

Anyways, kinetic effects vs thermodynamic effects have to be considered in every chemical reaction. There are plenty of examples where they compete. Many reactions can occur in different ways to give different products: the thermodynamic product is the most stable product, and the kinetic product is the one that is easiest to form (the one with the most stable transition state). These products are often not the same, and it's a big reason why we have to choose specific reaction conditions (like solvent, temperature, and concentration) to get desired products.

&gt;And what is the reason that the diamond would eventually reach a temperature lower than background temperature of space? My understanding is that it would reach an equilibrium with the temperature in space but it sounds like you are saying that due to some principle in kinetics it would eventually reach absolute zero?

You're correct here. Space is not empty, and a macroscopic object will still be bombarded by particles somewhat often. It's not enough to make a difference for warn objects, but by the time you get down into the single digits Kelvin it's enough to make a difference compared to blackbody radiation. Also the poster above you is ignoring that there is nowhere in space that is absent radiation, which is *exactly why the rest of space has a higher temperature than he predicts* the diamond would quickly reach. The diamond may have a different absorption spectrum but it is not immune to this radiation, and will be heated by it. In the end you're absolutely right though - the diamond will probably not get significantly colder than the interstellar medium in which it sits.

Sorry for any typos - written from my phone. &gt; Keep the temperature reasonably low though and a diamond will stay a diamond longer than anybody will be alive to measure its change, so it's effectively inert under normal conditions.

"A diamond is effectively inert under normal conditions" just doesn't have the same ring to it... &gt; Can you explain the relationship here?

Using thermodynamics to predict what will happen is really only helpful when the rate is nonzero. As per my math, if the rate goes to zero before the reaction completes, then the diamond will remain diamond forever, regardless of the thermodynamics.

&gt; And what is the reason that the diamond would eventually reach a temperature lower than background temperature of space?

It's a hypothetical. OP suggested a "void of space" which I took to mean a region devoid of anything. Alternatively, if the transformation takes longer than the heat death of the universe, then it will reach absolute zero, and the transformation will not complete, as per my post above. So please allow me to ask a question that I hope isn't too stupid, because I haven't studied this stuff for 25 years. 

The top response made a case that the whole diamond will eventually turn to carbon because the Gibbs free energy is favorable for that.  

First, what would be the conversion rate, if we assume equilibrium at 3K?  Or put another way, how long would it take for a 1 carat (1/5 gram) diamond take to convert 95% of its mass to carbon?

Second, we assumed an average temperature of 3K, but at such low temps, do we have to take electron energy states into account?

Finally, it would be disappointing to hear that James Bond was wrong. &gt; First, what would be the conversion rate, if we assume equilibrium at 3K? Or put another way, how long would it take for a 1 carat (1/5 gram) diamond take to convert 95% of its mass to carbon? 

That is a good question, but I don't know. I could make some assumptions: The bond dissociation energy in diamond is 347 kj/mol, so if we might assume that is the activation energy in the Arrhenius rate equation, we just need a pre-exponential factor.

[This PDF](http://www.htracyhall.org/papers/19610151.pdf)  says the conversion rate of graphite into diamond becomes appreciable around 1200 C (~1500 K). If we assume the "appreciable" means 1 mol per hour, and that the reverse reaction proceeds at around the same rate, then the pre-exponential can be solved for:

1mol/3600s = Rexp(-347000/(8.3141500))

R = 5.610 mol/s

So, plugging that in for T = 3K gives a number so small, my calculator won't even say it. It's on the order of 10^-6033 mol/s . In order for 0.2 grams (0.017 mols ~ 10^-2 mols) of carbon to completely undergo conversion to graphite at 3 K, it would take 10^6031 seconds, which is 10^6024 years. Longer than the [heat death of the universe (10^100 years)](http://en.wikipedia.org/wiki/Heat_death_of_the_universe#Time_frame_for_heat_death). 

In case you doubt that number, I re-ran my estimations with 10x lower activation energy (assumes some low-energy transition state between diamond and graphite) and 10x higher rate at 1200 C (maybe "appreciable" meant 1 mol per 6 minutes). That still gives a rate at 3 K of 10^-524 mols/s .

&gt; Second, we assumed an average temperature of 3K, but at such low temps, do we have to take electron energy states into account?

I don't know. That could certainly throw a wrench into my calculations. I wish this was more visible.  The Gibbs energy is irrelevant when you can make a statement like


&gt; Longer than the heat death of the universe (10100 years). Thank you very much for your detailed response and the work you put into it!  It looks like the answer might be "the amount of time for a universe like ours to form and thermodynamically die, 10^60 times.

I was thinking about a situation and wondered if it applies here.  In model rocketry, the motors have a certain chemical energy, but they also have a specific thrust vs time curve. If your rocket weighs more than the peak thrust, it won't move an inch. I'm wondering if there would be an analogous minimum activation energy here, and if 3K would be enough for that.

 &gt; Second, we assumed an average temperature of 3K, but at such low temps, do we have to take electron energy states into account?


Electronic transitions are generally more energy-intensive than vibrational and rotational transitions.  Even at room temperature, electronic states are often neglected in stat mech calculations.  So they would be pretty much useless at 3 K.


Edit:  But it's a good question! Actually doesn't the universe still have a nonzero temperature after heat death? I thought heat death just refers to a total equilibrium (no temperature gradient, no heat). Wouldn't the incomplete conversion of any amount of diamond to graphite preclude the heat death of the universe? Since the conversion of diamond to graphite is entropically favorable, the universe couldn't be said to be at "maximum entropy", yes? You are confusing two different types of "kinetics". In chemistry, kinetics refers to the study of the rates of chemical reactions... and not to the the physics aspect (which is like you said, the study of motion) In thermal equilibrium the coldest anything will get in space is the temperature of the cosmic microwave background which is like 2.7kelvin.   2.7 K is the "temperature" of empty space based on the power *spectrum*. That is to say, the distribution of photon frequencies in CMB matches an object emitting at 2.7 K. But, for an object cooling via blackbody radiation, the *spectrum* of CMB hitting it is unimportant. What matters is how much *power* is hitting it from the CMB (ie, the integral over all frequencies). I've been digging and can't find anything on it. The effective temperature of the CMB (based on power) may be much lower than 2.7 K.

I show [here](http://www.reddit.com/r/askscience/comments/36606x/if_you_put_a_diamond_into_the_void_of_space/crbezxm) that the rate of conversion from diamond to graphite is so slow, that the universe will undergo heat death way before it is complete. As the universe experiences heat death, the power incident on a diamond will go to zero, so the diamond will cool to absolute zero. Is there a time frame for this? Actually, it is *negative* 3 kJ/mol (assuming that number is correct). A spontaneous process will have a negative G. Thanks! Fixed. now how do we reverse the process and turn pencil into diamond? We do that when we make [artificial diamonds](https://en.wikipedia.org/wiki/Synthetic_diamond). It requires very high pressures and temperatures. [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] [deleted] Well, geology does it simply by applying extremely high pressure to the graphite. Actually, natural diamonds aren't formed by the compression of graphite. Instead they're formed by precipitation of carbon-bearing fluids in the Earth's mantle through redox reactions. As full as the Wikipedia page on diamonds is, it still doesn't really cover this at all, but basically what happens is either methane becomes oxidized or CO2 is reduced to precipitate pure carbon. Many geologists used to believe that graphite-diamond conversion was a naturally occurring process, but more recently they have realized this doesn't actually occur. The pressures needed for this to happen are so great that you would need to overstep the static formation boundary by about 100km depth (relative to where we know diamonds naturally occur).

Source: just finished my undergrad in geology with a big focus on mantle petrography.

Edit: typos Thank you very much for the informative answer, but please don't cite your degree as a source on /r/AskScience.  Ah, fair enough. For anyone deeply interested, here is the citation info for some scientific papers I was directed to in my classes - they would serve as a far better source than myself for the specifics about redox reactions in diamond formation:

Eggler, D. H., &amp; Baker, D. R. (1982). Reduced volatiles in the system COH: implications to mantle melting, fluid formation, and diamond genesis. High pressure research in geophysics, 12, 237-250.

Taylor, W. R., &amp; Green, D. H. (1988). Measurement of reduced peridotite-COH solidus and implications for redox melting of the mantle. Nature 332, 349 - 352 Awesome! Thank you so much! Thanks for using what looks like APA - it's my favorite. Here's a question, I promise I mean it completely in earnest: I'm a political scientist and we usually cite things in APA, Chicago or MLA formats. I had never even thought about how people cite things in the natural sciences before right now. Do you guys use the same formats? Many of the major journals have slightly different citation style guidelines but they are all fairly similar to standard as there are only so many ways to give the same information. [Here](http://www.geosociety.org/pubs/documents/GSA_RefGuide_Examples_000.pdf) is a example list from the most popular (Geologic Society of America) although they frustratingly do not publish a complete citation handbook. So, if a diamond and a similarly sized piece of uranium-238 (half-life of billions of years) were put in space, would the diamond turn into graphite faster or slower than the U238 turns into lead?  Anyone can look up Gibbs free energy on Google, but giving half-life numbers would probably be more helpful. This ignores the energy hill between the two states. Even at room temperature the reaction rate may be zero.  Unless it can tunnel.   Tunneling can always occur, unless the transition to the lower energy state is somehow forbidden by a conservation law.

I don't think that's the case here, so there will be tunneling. Isn't there some activation energy required to start the process? This activation energy being the reason why diamonds are metastable at the conditions of the earths surface? I'm glad this answer is so simply put for the layman!

This one time I shook a pencil back and forth and made it look like rubber! It was neat! 